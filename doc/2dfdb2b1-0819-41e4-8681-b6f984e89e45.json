{
    "summary": "This Python script converts text to speech using argparse, argues SSML input, and connects to Microsoft Cognitive Services TTS endpoint. It also handles time fixes, timestamps, and async WebSocket communication with potential API key authentication, runs on an asyncio event loop, and writes audio responses to a file.",
    "details": [
        {
            "comment": "This code is a Python file that utilizes the `argparse` library to parse command-line arguments. The purpose of this script seems to be text-to-speech conversion, where it accepts an SSML (Speech Synthesis Markup Language) input file and outputs an MP3 audio file. It also includes functions for fixing time formats to match American conventions and generating formatted timestamps.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/bilibili_video_recommendation_server/sample_video/tts.py\":0-34",
            "content": "# \u6765\u6e90 https://github.com/OS984/DiscordBotBackend/blob/3b06b8be39e4dbc07722b0afefeee4c18c136102/NeuralTTS.py\n# A completely innocent attempt to borrow proprietary Microsoft technology for a much better TTS experience\nimport requests\nimport websockets\nimport asyncio\nfrom datetime import datetime\nimport time\nimport re\nimport uuid\nimport argparse\n'''\u547d\u4ee4\u884c\u53c2\u6570\u89e3\u6790'''\ndef parseArgs():\n    parser = argparse.ArgumentParser(description='text2speech')\n    parser.add_argument('--input', dest='input', help='SSML(\u8bed\u97f3\u5408\u6210\u6807\u8bb0\u8bed\u8a00)\u7684\u8def\u5f84', type=str, required=True)\n    parser.add_argument('--output', dest='output', help='\u4fdd\u5b58mp3\u6587\u4ef6\u7684\u8def\u5f84', type=str, required=False)\n    args = parser.parse_args()\n    return args\n# Fix the time to match Americanisms\ndef hr_cr(hr):\n    corrected = (hr - 1) % 24\n    return str(corrected)\n# Add zeros in the right places i.e 22:1:5 -> 22:01:05\ndef fr(input_string):\n    corr = ''\n    i = 2 - len(input_string)\n    while (i > 0):\n        corr += '0'\n        i -= 1\n    return corr + input_string\n# Generate X-Timestamp all correctly formatted"
        },
        {
            "comment": "This code defines two functions: `getXTime` and `transferMsTTSData`. The `getXTime` function returns the current date and time in a specific format. The `transferMsTTSData` function is an asynchronous function responsible for communicating with a WebSocket endpoint, potentially using an API key to authenticate the request. It generates a unique ID (req_id) and prints it before potentially making the WebSocket connection.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/bilibili_video_recommendation_server/sample_video/tts.py\":35-51",
            "content": "def getXTime():\n    now = datetime.now()\n    return fr(str(now.year)) + '-' + fr(str(now.month)) + '-' + fr(str(now.day)) + 'T' + fr(hr_cr(int(now.hour))) + ':' + fr(str(now.minute)) + ':' + fr(str(now.second)) + '.' + str(now.microsecond)[:3] + 'Z'\n# Async function for actually communicating with the websocket\nasync def transferMsTTSData(SSML_text, outputPath):\n    # endpoint1 = \"https://azure.microsoft.com/en-gb/services/cognitive-services/text-to-speech/\"\n    # r = requests.get(endpoint1)\n    # main_web_content = r.text\n    # # They hid the Auth key assignment for the websocket in the main body of the webpage....\n    # token_expr = re.compile('token: \\\"(.*?)\\\"', re.DOTALL)\n    # Auth_Token = re.findall(token_expr, main_web_content)[0]\n    # req_id = str('%032x' % random.getrandbits(128)).upper()\n    # req_id is generated by uuid.\n    req_id = uuid.uuid4().hex.upper()\n    print(req_id)\n    # wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId=577D1E595EEB45979BA26C056A519073"
        },
        {
            "comment": "This code connects to the Microsoft Cognitive Services TTS (Text-to-Speech) websocket endpoint, sends two payloads for speech synthesis, and sets various headers such as Authorization, X-ConnectionId, Content-Type, etc. The current authentication may expire soon, so a new temporary endpoint is used instead of the original one.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/bilibili_video_recommendation_server/sample_video/tts.py\":52-62",
            "content": "    # endpoint2 = \"wss://eastus.tts.speech.microsoft.com/cognitiveservices/websocket/v1?Authorization=\" + \\\n    #     Auth_Token + \"&X-ConnectionId=\" + req_id\n    # \u76ee\u524d\u8be5\u63a5\u53e3\u6ca1\u6709\u8ba4\u8bc1\u53ef\u80fd\u5f88\u5feb\u5931\u6548\n    endpoint2 = f\"wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId={req_id}\"\n    async with websockets.connect(endpoint2) as websocket:\n        payload_1 = '{\"context\":{\"system\":{\"name\":\"SpeechSDK\",\"version\":\"1.12.1-rc.1\",\"build\":\"JavaScript\",\"lang\":\"JavaScript\",\"os\":{\"platform\":\"Browser/Linux x86_64\",\"name\":\"Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0\",\"version\":\"5.0 (X11)\"}}}}'\n        message_1 = 'Path : speech.config\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/json\\r\\n\\r\\n' + payload_1\n        await websocket.send(message_1)\n        payload_2 = '{\"synthesis\":{\"audio\":{\"metadataOptions\":{\"sentenceBoundaryEnabled\":false,\"wordBoundaryEnabled\":false},\"outputFormat\":\"audio-16khz-32kbitrate-mono-mp3\"}}}'"
        },
        {
            "comment": "Sends text to TTS service for synthesis and awaits response. Stores the SSML XML for audio customization. Sends SSML XML payload for final audio output generation. Continuously receives response from websocket until 'turn.end' path detected, storing data in audio_stream variable.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/bilibili_video_recommendation_server/sample_video/tts.py\":63-77",
            "content": "        message_2 = 'Path : synthesis.context\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/json\\r\\n\\r\\n' + payload_2\n        await websocket.send(message_2)\n        # payload_3 = '<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" version=\"1.0\" xml:lang=\"en-US\"><voice name=\"' + voice + '\"><mstts:express-as style=\"General\"><prosody rate=\"'+spd+'%\" pitch=\"'+ptc+'%\">'+ msg_content +'</prosody></mstts:express-as></voice></speak>'\n        payload_3 = SSML_text\n        message_3 = 'Path: ssml\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/ssml+xml\\r\\n\\r\\n' + payload_3\n        await websocket.send(message_3)\n        # Checks for close connection message\n        end_resp_pat = re.compile('Path:turn.end')\n        audio_stream = b''\n        while(True):\n            response = await websocket.recv()"
        },
        {
            "comment": "This code snippet is a part of a TTS (Text-to-Speech) server implementation. It receives an audio response from the server, checks if it's text or binary data, and writes the audio to a file. The `mainSeq` function initiates the transfer process by calling `transferMsTTSData` function with SSML text and output path. The `get_SSML` function reads SSML text from input file. The code is run as a main program after parsing command-line arguments using `parseArgs()`.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/bilibili_video_recommendation_server/sample_video/tts.py\":78-106",
            "content": "            print('receiving...')\n            # Make sure the message isn't telling us to stop\n            if (re.search(end_resp_pat, str(response)) == None):\n                # Check if our response is text data or the audio bytes\n                if type(response) == type(bytes()):\n                    # Extract binary data\n                    try:\n                        needle = b'Path:audio\\r\\n'\n                        start_ind = response.find(needle) + len(needle)\n                        audio_stream += response[start_ind:]\n                    except:\n                        pass\n            else:\n                break\n        with open(f'{outputPath}.mp3', 'wb') as audio_out:\n            audio_out.write(audio_stream)\nasync def mainSeq(SSML_text, outputPath):\n    await transferMsTTSData(SSML_text, outputPath)\ndef get_SSML(path):\n    with open(path,'r',encoding='utf-8') as f:\n        return f.read()\nif __name__ == \"__main__\":\n    args = parseArgs()\n    SSML_text = get_SSML(args.input)\n    output_path = args.output if args.output else 'output_'+ str(int(time.time()*1000))"
        },
        {
            "comment": "This code calls the `mainSeq` function with SSML text and output path, using asyncio event loop to run until completion. It prints \"completed\" upon execution. The two command examples show how to input an SSML file and optionally specify an output filename.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/bilibili_video_recommendation_server/sample_video/tts.py\":107-110",
            "content": "    asyncio.get_event_loop().run_until_complete(mainSeq(SSML_text, output_path))\n    print('completed')\n    # python tts.py --input SSML.xml\n    # python tts.py --input SSML.xml --output \u4fdd\u5b58\u6587\u4ef6\u540d"
        }
    ]
}