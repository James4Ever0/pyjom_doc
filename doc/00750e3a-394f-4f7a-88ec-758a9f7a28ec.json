{
    "summary": "The code defines the shapes of video and audio data, generates random one-hot encoded target sentences, and creates random data for both videos. It then prints the shapes of the generated video and audio data.",
    "details": [
        {
            "comment": "The code defines the shapes of video and audio data, generates random one-hot encoded target sentences, and creates random data for both videos. It then prints the shapes of the generated video and audio data.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/video_script_generation_reconstruction/raw_data_understanding.py\":0-30",
            "content": "# 2d understanding or 3d?\n# what about the freaking audio?\nimport numpy as np\nimport torch\nvideo_shape = (30,100,100) # thirty frames extracted.\naudio_shape = (1,40000)\nvideo2_shape = (60,200,200) # thirty frames extracted.\naudio2_shape = (1,80000)\ntarget_sentence_shape = (10,40000) # full charset. you may choose not to speak. when should you freaking speak?\ntarget_sentence2_shape = (15,40000) # full charset. you may choose not to speak. when should you freaking speak?\n# one hot encoding.\nimport random\ntarget_sentence = np.array([random.randint(0,39999) for _ in range(10)])\ntarget_sentence2 = np.array([random.randint(0,39999) for _ in range(15)])\n# i really don't care how. freaking do it!\nvideo_data = np.random.random(video_shape)\naudio_data = np.random.random(audio_shape)\nvideo2_data = np.random.random(video2_shape)\naudio2_data = np.random.random(audio2_shape)\n# print(data)\n# I really not caring the freaking data range.\nprint(video_data.shape)\nprint(audio_data.shape)"
        }
    ]
}