{
    "summary": "This code initializes shapes, generates cut targets, and ensures correct tensor dimensions. It applies convolution, pooling, activation functions, performs two RNN operations, prints output/hidden state shapes, defines a final linear layer, transposes data, and suggests MaxPool1d for character extraction.",
    "details": [
        {
            "comment": "Code initializes various shapes for video and audio data, randomly generates cut targets, and ensures tensor dimensions are correct for GPU usage.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/video_script_generation_reconstruction/raw_data_cut.py\":0-32",
            "content": "# 2d understanding or 3d?\n# what about the freaking audio?\nimport numpy as np\nimport torch\nvideo_shape = (30,100,100) # thirty frames extracted.\naudio_shape = (1,40000) # so batch size is included.\nvideo2_shape = (60,200,200) # thirty frames extracted.\naudio2_shape = (1,80000)\ntarget_cut_shape = (30,2) # choose either beginning or to cut?\ntarget_cut2_shape = (60,2) # choose either beginning or to cut?\nimport random\ntarget_cut = np.array([random.randint(0,1) for _ in range(30)])\ntarget_cut2 = np.array([random.randint(0,1) for _ in range(60)])\nvideo_data = np.array(np.random.random(video_shape))\naudio_data = np.array(np.random.random(audio_shape))\nvideo2_data = np.array(np.random.random(video2_shape))\naudio2_data = np.array(np.random.random(audio2_shape))\n# print(data)\n# I really not caring the freaking data range.\nprint(video_data.shape)\nprint(audio_data.shape)\nprint(target_cut2.shape)\ndevice = torch.device(\"cuda\")\nvideo_data = torch.Tensor([video_data]) # to make sure the first dimension is batchsize\ntarget_cut = torch.Tensor([target_cut])"
        },
        {
            "comment": "This code applies convolution, pooling, and activation functions to the input data. It reshapes the output for RNN processing with a specific structure, and performs two RNN operations.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/video_script_generation_reconstruction/raw_data_cut.py\":33-66",
            "content": "audio_data = torch.Tensor(audio_data)\nlayer_1 = torch.nn.Conv2d(30,3,10) # original shape: (30,100,100)\noutput_1 = layer_1(video_data)\nprint(output_1.shape) #(1,3,91,91)\nlayer_2 = torch.nn.Conv2d(3,1,10)\noutput_2 = layer_2(output_1)\nprint(output_2.shape) #([1, 2, 82, 82])\nlayer_3 = torch.nn.MaxPool1d(4)\noutput_3 = layer_3(audio_data)\nprint(output_3.shape) # torch.Size([1, 10000]) # what is this fuck?\nlayer_4 = torch.nn.MaxPool2d(2)\noutput_4 = layer_4(output_2)\nprint(output_4.shape) # 1,2,41,41 freaking bad.\nlayer_5 = torch.nn.Sigmoid()\noutput_5 = layer_5(output_4)\nprint(output_5.shape) # 1,2,41,41\noutput_5 = output_5.reshape(1,41,41)\n# get this reshaped.\noutput_5 = output_5.reshape(1,1,41*41)\nrnn_layer_1 = torch.nn.RNN(41*41,41*41,3) # must have three dimensions.\nrnn_output_1, rnn_hidd_1 = rnn_layer_1(output_5)\nprint(rnn_output_1.shape,rnn_hidd_1.shape) #tuple torch.Size([1, 41, 20]) torch.Size([3, 41, 20])\nrnn_output_2, rnn_hidd_2 = rnn_layer_1(output_5,rnn_hidd_1)\nprint(\"RNN 2:\",rnn_output_2.shape,rnn_hidd_2.shape)"
        },
        {
            "comment": "This code applies an RNN layer, prints the shapes of output and hidden states, defines a final linear layer with 41x41 input size and 2 output sizes, passes RNN output through it, transposes the data, and suggests using MaxPool1d for possible character extraction.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/video_script_generation_reconstruction/raw_data_cut.py\":68-80",
            "content": "rnn_output_3, rnn_hidd_3 = rnn_layer_1(rnn_output_1,rnn_hidd_1)\nprint(\"RNN 3:\",rnn_output_3.shape,rnn_hidd_3.shape)\n# final_data = \nfinal_layer = torch.nn.Linear(41*41,2) # the final swap.\nfinal_data = final_layer(rnn_output_1)\nprint(final_data.shape)\n# find the max one.\nfinal_data = final_data.transpose(2,1)\nprint(final_data.shape)\n# output_final_layer = torch.nn.MaxPool1d(41) \n# final_data2 = output_final_layer(final_data)\n# print(final_data2.shape) # 40000,1 this is a single character. is it?"
        }
    ]
}