{
    "summary": "The code performs text processing, device movement detection, and entity identification using Levenshtein's algorithm. It calculates string similarities, generates test results, compares content and location changes to find or create entity structures, initializes variables, detects and tracks entities, updates text detection results, merges entries based on similarity and temporal proximity, and returns a formatted result dictionary.",
    "details": [
        {
            "comment": "The code includes a function \"resplitedEnglish\" that splits the given string into individual words, potentially skipping special characters. It uses wordninja for splitting and attempts to merge adjacent words if they have been mistakenly separated by special characters. Another function, \"ocrEntityDetector\", receives data as input and returns alteredData, but the code lacks implementation details. Lastly, there's a helper function \"getMinLenStr\" that takes two inputs 'a' and 'b', likely for comparison purposes.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":0-28",
            "content": "from .mediaDetector import *\nimport Levenshtein\nimport string\nimport zhon.hanzi\nimport wordninja\ndef resplitedEnglish(string2,skipSpecial=True):\n    if skipSpecial:\n        header = string2[0]\n        if header in string.punctuation or header in zhon.hanzi.punctuation:\n            return string2 # this could be buggy.\n    result = wordninja.split(string2)\n    if len(result)>1:\n        mlist = zip(result[:-1], result[1:])\n        for a,b in mlist:\n            combined = \"{} {}\".format(a,b)\n            error = a+b\n            string2 = string2.replace(error,combined)\n    return string2 # really? this is not good. maybe you should provide some version of continuality, for channel id watermarks.\n    # @MA SECO. -> @MASECO\n# maybe you can read it here?\n# you need double language check. both chinese and english. or really?\ndef ocrEntityDetector(mdata):\n    alteredData = [] # we should do a demo. \n    return alteredData # now we are on the same page, paddleocr is using cuda 11.2 which is compatible to 11.3\ndef getMinLenStr(a,b):"
        },
        {
            "comment": "This code defines several functions for text processing, including getting the length of Chinese characters, English punctuation marks, and English words. It also calculates string similarity and distance using Levenshtein's algorithm. The \"getBlockType\" function determines if the device is stationary or moving based on its location and content.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":29-69",
            "content": "    la,lb = len(a),len(b)\n    if la < lb:return a\n    return b\ndef getBlockType(dlocation,dcontent):\n    if not dlocation:\n        if not dcontent: return \"stationary\"\n        else: return \"typing\"\n    else:\n        if not dcontent: return \"typing_moving\"\n        else: return \"moving\"\ndef getStringDistance(a,b):\n    return Levenshtein.distance(a,b)\ndef getStringSimilarity(a,b):\n    return Levenshtein.ratio(a,b)\ndef getChineseLen(string2):\n    counter  = 0\n    upperLimit, lowerLimit = 0x4e00, 0x9fff\n    for elem in string2:\n        ordNum = ord(elem)\n        if ordNum <= upperLimit and ordNum>=lowerLimit:\n            counter+=1\n    return counter\ndef getPunctualLen(string2):\n    counter = 0\n    chinesePunctuals = zhon.hanzi.punctuation\n    englishPunctuals = string.punctuation\n    standardString = chinesePunctuals+englishPunctuals\n    for elem in string2:\n        if elem in standardString:\n            counter+=2\n    return counter\ndef getEnglishLen(string2):\n    counter = 0\n    standardString = \"abcdefghijklmnopqrstuvwxyz\""
        },
        {
            "comment": "The code defines a series of functions for detecting changes in textual data, such as entity detection and calculating point differences. It also involves calculating Chinese, English, and punctuation lengths and uses them to determine if the text is changing or moving based on certain thresholds.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":70-103",
            "content": "    standardString += standardString.upper()\n    standardString += \"0123456789\"\n    # it won't split. you may need double check the thing.\n    # standardString += \" \"\n    for elem in string2:\n        if elem in standardString:\n            counter+=1\n    return counter\ndef getMinMaxText(a,b):\n    mlist = [a,b]\n    clens = [getChineseLen(x) for x in mlist]\n    elens = [getEnglishLen(x) for x in mlist]\n    slens = [getPunctualLen(x) for x in mlist]\n    mlens = [x[0]+x[1]+x[2] for x in zip(clens,elens,slens)]\n    if len(a) > len(b):\n        if mlens[0] > mlens[1]:\n            return a\n        return b\n    else:\n        if mlens[0] < mlens[1]:\n            return b\n        return a\ndef pointDifference(a,b):\n    return [a[0] - b[0], a[1] - b[1]]\ndef makeOCREntity(ocrData,minMaxThresh = 24 ,# max difference is ten pixel. or it is considered as moving.\nstrDisThreshold = 2 ,# or considered as changing?\ncertThreshold = 0.6,\nchangingMinMaxThresh = 45,\nchangingstrDisThreshold = 3,\ntimeThreshold = 0.3 ,# i intentially set it.\nblockTimeThreshold = 0.3, # at least last this long?"
        },
        {
            "comment": "This code initializes variables and iterates through OCR data, specifically focusing on recognized text from each result. It checks if any previously identified elements have identical locations to the current element, updating a flag accordingly. The purpose seems to be detecting entities based on overlapping locations in different frames or times.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":104-127",
            "content": "strSimThreshold = 0.8):\n    testElemIds = {} # just show processed items.\n    for line in ocrData:\n        mtime,mframe,mresult = line[\"time\"],line[\"frame\"],line[\"paddleocr\"]\n        # print(\"______________________\")\n        # print(\"time:\",mtime)\n        # newlyAddedIds = [] # will directly added if not in.\n        # initiate things here.\n        for mid in testElemIds.keys(): # must trt\n            testElemIds[mid][\"hasIdentical\"] =False  #initialization.\n        for presult in mresult:\n            location, mtext = presult\n            p1, p2, p3, p4 = location\n            text, certainty = mtext\n            print(\"RECOGNIZED TEXT:\",text)\n            mtimestamp = {\"frame\":mframe,\"time\":mtime}\n            # print(\"location:\",location)\n            # print(\"text:\",text)\n            # print(\"certainty:\",certainty)\n            foundIdentical = False\n            for mid in testElemIds.keys():\n                myid = testElemIds[mid]\n                myLastLocation = myid[\"locations\"][-1]\n                px1,px2,px3,px4 = myLastLocation"
        },
        {
            "comment": "This code calculates the maximum movement and string similarity between consecutive entities, considering time deltas and thresholds. If the movement is within a threshold and the string distance or similarity meets specific criteria, it indicates an identical entity. However, the current logic for identifying identical entities may be incorrect.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":128-141",
            "content": "                myMinMax = max([max(pointDifference(a,b)) for a,b in zip(location,myLastLocation)])\n                myMinMaxs = [max([max(pointDifference(a,b)) for a,b in zip(location,myLL)]) for myLL in myid[\"locations\"]] # changing it. the max movement.\n                mLastTime = myid[\"timestamps\"][-1][\"time\"]\n                timeDelta = mLastTime - mtime\n                myLastContent = myid[\"contents\"][-1]\n                strDistance = getStringDistance(myLastContent,text)\n                strDistances = [getStringDistance(myLastContent,text) for myLC in myid[\"contents\"]]\n                strSim = getStringSimilarity(myLastContent,text)\n                strSims = [getStringSimilarity(myLC,text) for myLC in myid[\"contents\"]]\n                foundIdentical = False\n                movementMap = {\"location\":False,\"content\":False,\"continual\":False}\n                if timeDelta < timeThreshold:\n                    if myMinMax <= minMaxThresh and ((strDistance <= strDisThreshold) or (strSim >= strSimThreshold )) : # wrong logic."
        },
        {
            "comment": "This code block is checking for identical entities or potential movements in a video. It uses thresholds to determine if the entity is the same, and if it's a movement, it checks if it's the same content or location. The code also prints test results and specific lines for debugging purposes.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":142-160",
            "content": "                        foundIdentical = True\n                        print(\"test result:\",myMinMax <= minMaxThresh ,(strDistance <= strDisThreshold) , (strSim >= strSimThreshold ))\n                        print(myMinMax,strDistance,strSim)\n                        print(minMaxThresh,strDisThreshold,strSimThreshold)\n                        print(\"line a\")\n                        pass\n                        # stricter limit, to know if really is movement?\n                    elif myMinMax <= changingMinMaxThresh:\n                        foundIdentical = True\n                        movementMap[\"location\"] = True\n                        if max(strDistances) <= strDisThreshold or max(strSims) >= strSimThreshold:\n                            # make sure it is globally the same.\n                            print(\"line b\")\n                            pass\n                        elif min(strDistances) <= changingstrDisThreshold:\n                            print(\"line c\")\n                            movementMap[\"content\"] = True"
        },
        {
            "comment": "This code checks if the text has a matching content or location change using string similarity and minimum-maximum thresholds. If a match is found, it prints \"FOUND IDENTICAL\" with the original text and reason for identification from the movementMap dictionary.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":161-182",
            "content": "                        else: # consider something else\n                            print(\"line d\")\n                            foundIdentical = False\n                    elif strDistance <= changingstrDisThreshold or strSim >= strSimThreshold:\n                        foundIdentical = True\n                        print(\"line e\")\n                        movementMap[\"content\"] = True\n                        if max(myMinMaxs) <= minMaxThresh:\n                            print(\"line f\")\n                            pass\n                        elif min(myMinMaxs) <= changingMinMaxThresh:\n                            print(\"line g\")\n                            movementMap[\"location\"] = True\n                        else:\n                            print(\"line h\")\n                            foundIdentical = False\n                else:\n                    foundIdentical = False\n                if foundIdentical:\n                    print(\"FOUND IDENTICAL\",text,myLastContent)\n                    print(\"REASON\",movementMap)"
        },
        {
            "comment": "This code is searching for identical entities based on location, text content, and timestamps. If a duplicate is found or time difference is small, it continues to the next entity. If no duplicates are found and certainty level is high, it creates a new entity structure with unique ID, locations, contents, movements, and timestamps.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":183-199",
            "content": "                    print(\"ID\",mid)\n                    print()\n                    # care about continuality here.\n                    if timeDelta < timeThreshold:\n                        movementMap[\"continual\"] = True\n                    if myid[\"hasIdentical\"] or timeDelta == 0: # eliminate duplicates.\n                        continue # do not check this.\n                    # print(\"found Identical:\",mid)\n                    testElemIds[mid][\"hasIdentical\"]=True\n                    testElemIds[mid][\"locations\"].append(location)\n                    testElemIds[mid][\"contents\"].append(text)\n                    testElemIds[mid][\"timestamps\"].append(mtimestamp)\n                    testElemIds[mid][\"movements\"].append(movementMap)\n                    break\n            if not foundIdentical:\n                if certainty > certThreshold:\n                    minitStruct = {str(uuid.uuid4()):{\"locations\":[copy.deepcopy(location)],\"contents\":[copy.deepcopy(text)],\"movements\":[],\"hasIdentical\":False,\"timestamps\":[mtimestamp]}}"
        },
        {
            "comment": "This code is initializing variables for block detection and compression. It creates an empty dictionary, loops through the timestamps and contents of elements, and assigns the first timestamp and content as the starting point of a stationary block. It also copies the location from the first content to the \"location\" field in the initBlock.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":200-220",
            "content": "                    testElemIds.update(minitStruct) # do you really expect it? i mean it could have cracks.\n    # print(json.dumps(testElemIds,indent=4))\n    keys= list(testElemIds.keys())\n    print(\"keyNum:\",len(keys))\n    mfinal = {}\n    for key in keys:\n        mblocks = []\n        kElem = testElemIds[key]\n        # we try to compress this thing.\n        initBlock = {\"type\":\"stationary\",\"text\":None,\"location\":None,\"timespan\":{\"start\":None,\"end\":None}} # we will have shortest text.\n        for index, mtimestamp in enumerate(kElem[\"timestamps\"]):\n            thisText = kElem[\"contents\"][index]\n            thisLocation = kElem[\"locations\"][index]\n            if index == 0:\n                initBlock[\"timespan\"][\"start\"] = mtimestamp\n                initBlock[\"timespan\"][\"end\"] = mtimestamp\n                initBlock[\"text\"] = thisText\n                initBlock[\"location\"] = copy.deepcopy(thisLocation)\n            else:\n                movementMap = kElem[\"movements\"][index-1]\n                dlocation, dcontent, dtime = movementMap[\"location\"], movementMap[\"content\"], movementMap[\"continual\"]"
        },
        {
            "comment": "This code snippet initializes a new block for text detection whenever there is a change in type or no time stamp. The block's details are updated based on the current type, location, and texts. It also stores the previous and new types, with the option to select the best text if the type is \"stationary\" or \"moving\".",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":221-236",
            "content": "                lastType = initBlock[\"type\"]\n                thisType = getBlockType(dlocation,dcontent)\n                if (not dtime) or (thisType != lastType):\n                    # will abandon all no matter what. cause it is not continual.\n                    mblocks.append(copy.deepcopy(initBlock))\n                    initBlock = {\"type\":thisType,\"timespan\":{\"start\":mtimestamp,\"end\":mtimestamp}} # get the content.\n                    if thisType in [\"stationary\", \"moving\"]:\n                        # lastText = initBlock[\"text\"]\n                        # mselectedText = getMinMaxText(lastText,thisText)\n                        initBlock.update({\"text\":thisText}) # not right. we select the best one.\n                    if thisType in [\"stationary\", \"typing\"]:\n                        initBlock.update({\"location\":copy.deepcopy(thisLocation)})\n                    if thisType in [\"typing_moving\",\"typing\"]:\n                        initBlock.update({\"texts\":[thisText]})\n                    if thisType in [\"moving\", \"typing_moving\"]:"
        },
        {
            "comment": "This code appears to be part of a function that detects and tracks entities such as text or movement. It updates the initialization block based on the detected entity type, appends locations or texts, creates a copy of the block for later use, and filters out blocks with duration shorter than the given threshold.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":237-253",
            "content": "                        initBlock.update({\"locations\":[copy.deepcopy(thisLocation)]})\n                else:\n                    initBlock[\"timespan\"][\"end\"] = mtimestamp\n                    if thisType in [\"moving\",\"typing_moving\"]:\n                        initBlock[\"locations\"].append(copy.deepcopy(thisLocation))\n                    if thisType in [\"typing_moving\",\"typing\"]:\n                        initBlock[\"texts\"].append(thisText)\n                    if thisType in [\"moving\",\"stationary\"]: # we don't change stationary/typing's location. or do we?\n                        mLastText = initBlock[\"text\"]\n                        initBlock[\"text\"] = getMinMaxText(mLastText,thisText)\n                        # initBlock[\"text\"] = getMinLenStr(mLastText,thisText)\n        mblocks.append(copy.deepcopy(initBlock))\n        mblocks2 = []\n        for block in mblocks:\n            start,end = block[\"timespan\"][\"start\"], block[\"timespan\"][\"end\"]\n            timedelta = end[\"time\"] - start[\"time\"]\n            if timedelta > blockTimeThreshold:"
        },
        {
            "comment": "This function takes a dictionary of results and applies static OCR combining by processing each element in the dictionary. It uses WordNinja for English splitting, and stores last word result, id, location, and timestamp.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":254-282",
            "content": "                mblocks2.append(block)\n        mfinal.update({key:mblocks2})\n    return mfinal\n    # print(json.dumps(mfinal,indent=4))\n    # print(\"___________\")\ndef staticOCRCombinator(myresult,simThreshold= 0.8):\n    # we use wordninja to do the english spliting.\n    # you can also get this working for non-static.\n    myNewResult = {}\n    lastWordResult = None\n    lastId = None\n    lastLocation = None\n    lastTimeStamp = {\"start\":{},\"end\":{}}\n    for key in myresult.keys():\n        melems = myresult[key]\n        for melem in melems:\n            mtype = melem[\"type\"]\n            if mtype in [\"stationary\", \"moving\"]:\n                mtext = melem[\"text\"] # maybe there are some moving things out there?\n            else:\n                mtext = melem[\"texts\"][0]\n            mtext = resplitedEnglish(mtext)\n            if lastWordResult is None:\n                lastWordResult = mtext\n                lastId = key\n                lastTimeStamp[\"start\"] = melem[\"timespan\"][\"start\"]\n                lastTimeStamp[\"end\"] = melem[\"timespan\"][\"end\"]"
        },
        {
            "comment": "This code is merging and updating text detection results based on similarity and temporal proximity. It keeps track of the last detected word, its location, and timestamp, updating or creating new result entries accordingly.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":283-300",
            "content": "                if mtype in [\"stationary\", \"typing\"]:\n                    lastLocation = melem[\"location\"]\n                else:\n                    lastLocation = melem[\"locations\"][0]\n            else:\n                if getStringSimilarity(lastWordResult,mtext) > simThreshold:\n                    # merge the thing.\n                    lastTimeStamp[\"start\"] = list(sorted([melem[\"timespan\"][\"start\"],lastTimeStamp[\"start\"]],key=lambda x:x[\"time\"]))[0]\n                    lastTimeStamp[\"end\"] = list(sorted([melem[\"timespan\"][\"end\"],lastTimeStamp[\"end\"]],key=lambda x:-x[\"time\"]))[0]\n                else:\n                    myNewResult.update({lastId:{\"content\":lastWordResult,\"timespan\":lastTimeStamp,\"location\":lastLocation}})\n                    lastWordResult = mtext\n                    lastId = key\n                    if mtype in [\"stationary\", \"typing\"]:\n                        lastLocation = melem[\"location\"]\n                    else:\n                        lastLocation = melem[\"locations\"][0]\n                    lastTimeStamp[\"start\"] = melem[\"timespan\"][\"start\"]"
        },
        {
            "comment": "Checking if the element matches the expected format, if not print relevant details and proceed with updating the result dictionary. Finally, print \"process complete\" and return the result dictionary.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/pyjom/medialang/functions/detectors/entityDetector.py\":301-308",
            "content": "                    lastTimeStamp[\"end\"] = melem[\"timespan\"][\"end\"]\n            # else:\n            #     print(\"found different type:\",mtype)\n            #     print(\"text:\",mtext)\n            #     print(\"element:\",melem)\n    myNewResult.update({lastId:{\"content\":lastWordResult,\"timespan\":lastTimeStamp,\"location\":lastLocation}})\n    print(\"process complete\")\n    return myNewResult"
        }
    ]
}