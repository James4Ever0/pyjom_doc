{
    "summary": "The code imports libraries, reads an image, applies blur detection and edge detection, displays edges with lines based on Hough line detection using OpenCV, waits for a key press to close the window.",
    "details": [
        {
            "comment": "The code imports necessary libraries, reads an image from disk, applies blur detection using bilateral filtering to remove blur and detect motion blur, converts the image to grayscale, detects edges using Canny edge detection, displays the edges, applies HoughLines to find lines in the image, and then waits for a key press to close the window.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/unittest_houghline_dog_blur_detection.py\":0-27",
            "content": "from lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nimport cv2\nimport numpy as np\n# command used for reading an image from the disk, cv2.imread function is used\nimagePath = \"/root/Desktop/works/pyjom/samples/image/dog_blue_sky_split_line.png\"\n# cannot find image without dark/black boundaries.\n# use blur detection, both for blur area removal and motion blur detection for key frame sampling/filtering\n# tool for finding non-blur based black borders:\n# ffmpeg -loop 1 -i /root/Desktop/works/pyjom/samples/image/dog_blue_sky_split_line.png -t 15 -vf cropdetect -f null -\n# maybe you can change the seconds to something shorter.\nimg1 = cv2.imread(imagePath)\n# gray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n# edges1 = cv2.Canny(gray1,50,150,apertureSize=3)\n# blurred = cv2.GaussianBlur(img1, (5, 5), 0)\nblurred = cv2.bilateralFilter(img1, 15, 75, 75)\nedges1 = cv2.Canny(blurred, 20, 210, apertureSize=3)\ncv2.imshow(\"EDGE\", edges1)\ncv2.waitKey(0)\nlines1 = cv2.HoughLines(edges1, 1, np.pi / 180, 200)  # wtf?"
        },
        {
            "comment": "This code generates lines on an image based on Hough line detection. It iterates over the lines, calculates the coordinates of endpoints, and draws lines using OpenCV. The GUI window displays the image with the drawn lines, holds it open for any key press (cv2.waitKey), then destroys all windows upon closing.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/unittest_houghline_dog_blur_detection.py\":28-42",
            "content": "for rho, theta in lines1[0]:\n    a = np.cos(theta)\n    b = np.sin(theta)\n    x = a * rho\n    y = b * rho\n    x_1 = int(x + 1000 * (-b))\n    y_1 = int(y + 1000 * (a))\n    x_2 = int(x - 1000 * (-b))\n    y_2 = int(y - 1000 * (a))\n    cv2.line(img1, (x_1, y_1), (x_2, y_2), (0, 0, 255), 2)\n# Creation of a GUI window in order to display the image on the screen\ncv2.imshow(\"line detection\", img1)\n# cv2.waitKey method used for holding the window on screen\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        }
    ]
}