{
    "summary": "This script uses FFmpeg and TensorFlow to process video files, applying Super Resolution and Edge Preserving Blur filters for improved quality. It utilizes Anaconda libraries for CUDA toolkit and CuDNN in a non-real-time processing manner.",
    "details": [
        {
            "comment": "The script contains FFmpeg commands to resize, denoise and apply different filters on a GIF file. It uses the TensorFlow model \"espcn.pb\" for super-resolution and the \"yaepblur\" filter. The environment variable LD_LIBRARY_PATH is used to specify paths for CUDA toolkit and CUDNN libraries. The final output is saved as \".mp4\" files with different names.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/vapoursynth_linux_test/pure_ffmpeg_interpolate_resolution_denoise.sh\":0-12",
            "content": "# ffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -vf \"minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d\" -r 60 ffmpeg_samoyed.mp4\n# SRCNN=espcn.pb\n# 5fps or something\n# env LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr_models/dnn_models/espcn.pb\"  ffmpeg_samoyed_espcn.mp4\n# 9fps or something\n# ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"yaepblur\"  ffmpeg_samoyed_srcnn.mp4\n# strange shit.\n# env LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur,hqdn3d\"  ffmpeg_samoyed_srcnn.mp4\n# env LD_LIBRARY_PATH=/root/anaco"
        },
        {
            "comment": "This code uses FFmpeg to process video files, applying filters like Super Resolution (SR) using deep learning models and Edge Preserving Blur. It utilizes TensorFlow as the dnn_backend for SR filter and Anaconda libraries for CUDA toolkit and CuDNN. The processing is not real-time but improves picture quality.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/vapoursynth_linux_test/pure_ffmpeg_interpolate_resolution_denoise.sh\":12-26",
            "content": "nda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur\"  ffmpeg_samoyed_dctdnoiz.mp4\nenv LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur\"  supertest.mp4\n# dctdnoiz is not for real time processing. it is slow.\n# but somehow it makes the picture great. is it?\n#  TSC hqdn3d            V->V       Apply a High Quality 3D Denoiser.\n# check out all filters by `ffmpeg -filters`\n# yaepblur\n# yet another edge preserving blur filter\n# ffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -filter \"minterpolate=mi_mode=2\" -r 60 ffmpeg_samoyed.mp4\n# use deep learning models:\n# https://video.stackexchange.com/questions/29337/how-do-the-super-resolution-filters-in-ffmpeg-work"
        }
    ]
}