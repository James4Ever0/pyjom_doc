{
    "summary": "This code imports and processes images using the YOLO model, filters frames based on criteria, selects candidates for main frame detection, draws a rectangle around the detected frame, and displays an image with the PIP frame.",
    "details": [
        {
            "comment": "This code imports the YOLO model from ultralytics, loads a specific model file, and defines image paths. It also retrieves all image files in the current directory, filters frames based on aspect ratio and area threshold, and processes each image using the loaded YOLO model. This might involve downgrading the ultralytics version due to frequent updates and creating a dataset to prevent detection of pure color/gradient borders as TODO tasks.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/anime_highlight_cuts/theme_collector/yolov8_test.py\":0-42",
            "content": "from ultralytics import YOLO\n## yolov8 tracking needs special ultralytics version. it is been updated too damn often. you need to downgrade.\n## https://github.com/mikel-brostrom/yolov8_tracking\n## this might add unwanted overheads. warning!\n# no one will miss `genesis.pt`, right?\nmodel = YOLO(\"general_ver1.pt\")\n## TODO: create dataset to prevent detection of pure color/gradient borders\n# model = YOLO(\"ver3.pt\")\n# find trained weights on huggingface:\n# https://huggingface.co/James4Ever0/yolov8_pip_ultralytics\n# imagePaths = [\n#     \"000000003099.png\",\n#     \"simple_pip.png\",\n#     \"no_border_0.jpg\",\n#     \"has_border_0.jpg\",\n#     \"has_border_1.jpg\",\n#     \"has_border_2.jpg\",\n# ]\nimport os\nimagePaths = [\n    fpath\n    for fpath in os.listdir(\".\")\n    if fpath.split(\".\")[-1].lower() in (\"jpg\", \"jpeg\", \"png\")\n]\nimport cv2\nframeRatioFilters = [(16 / 9, 0.2, \"landscape\")]\nframeAreaThreshold = 0.15\nfor imagePath in imagePaths:\n    image = cv2.imread(imagePath)\n    output = model(image)\n    height, width, _ = image.shape\n    center = (width / 2, height / 2)"
        },
        {
            "comment": "This code filters out detected frames based on area, frame aspect ratio, and possibly malformed frames. It appends valid frames to the 'candidates' list, which may be sorted by area and centrality later in the script.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/anime_highlight_cuts/theme_collector/yolov8_test.py\":43-68",
            "content": "    # print(\"CENTER:\",center)\n    candidates = []\n    for xyxy in output[0].boxes.xyxy.numpy().astype(int).tolist():\n        x0, y0, x1, y1 = xyxy\n        currentFrameWidth = x1 - x0\n        currentFrameHeight = y1 - y0\n        currentFrameArea = currentFrameWidth * currentFrameHeight\n        # area filter? a must.\n        if currentFrameArea / (height * width) < frameAreaThreshold:\n            continue\n        else:\n            # filter out malformed frames? just for anime?\n            currentFrameRatio = currentFrameWidth / currentFrameHeight\n            if all(\n                [\n                    (\n                        currentFrameRatio < frameRatioStandard - frameRatioMargin\n                        or currentFrameRatio > frameRatioStandard + frameRatioMargin\n                    )\n                    for frameRatioStandard, frameRatioMargin, _ in frameRatioFilters\n                ]\n            ):\n                continue\n            candidates.append((x0, y0, x1, y1))\n    # sort it by area, then by centrality?"
        },
        {
            "comment": "The code sorts the candidates by area and centrality, selects two candidates, and if a main frame is found, it draws a rectangle around it. If no main frame is found, it displays a message. Finally, it shows the image with the PIP frame.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/anime_highlight_cuts/theme_collector/yolov8_test.py\":70-88",
            "content": "    candidates.sort(\n        key=lambda points: -(points[2] - points[0]) * (points[3] - points[1])\n    )\n    # print(\"SORT_AREA:\", [(points[2] - points[0]) * (points[3] - points[1]) for points in candidates])\n    candidates = candidates[:2]\n    candidates.sort(\n        key=lambda points: (((points[2] + points[0]) / 2) - center[0]) ** 2\n        + (((points[3] + points[1]) / 2) - center[1]) ** 2\n    )\n    # print(\"SORT_CENTRALITY:\", [(((points[2] + points[0]) / 2) - center[0]) ** 2\n    # + (((points[3] + points[1]) / 2) - center[1]) ** 2 for points in candidates])\n    if len(candidates) > 0:\n        print(\"main frame found.\")\n        x0, y0, x1, y1 = candidates[0]\n        cv2.rectangle(image, (x0, y0), (x1, y1), (0, 0, 255), thickness=10)\n    else:\n        print(\"no main frame found.\")\n    cv2.imshow(\"PIP\", image)\n    cv2.waitKey(0)"
        }
    ]
}