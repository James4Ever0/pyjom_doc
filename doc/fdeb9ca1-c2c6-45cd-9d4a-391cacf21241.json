{
    "summary": "The code imports the spaCy English language model, tokenizes text, sets stopwords, applies Porter stemming, initializes a sentence splitter, and stores lemmatized words in a variable. The document is preprocessed by removing certain parts of speech and stop words, then stemmed using the PorterStemmer, resulting in Stem_words.",
    "details": [
        {
            "comment": "This code imports necessary libraries and loads the English language model from spaCy, tokenizes text, sets stopwords, applies Porter stemming, initializes a sentence splitter, and defines a variable to hold lemmatized words.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/topic_modeling/poc_english_preprocessing.py\":0-26",
            "content": "# https://huggingface.co/spacy/en_core_web_sm\n# https://medium.com/analytics-vidhya/nlp-essentials-removing-stopwords-and-performing-text-normalization-using-nltk-and-spacy-in-python-2c4024d2e343\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\n# from lazero.utils import inspectObject\nfrom lazero.utils import sprint # print with spliter\n# metalazero belongs to lazero package.\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\ndoc = nlp(\n    \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were.\"\"\"\n)\n# the sentence spliter includes unwanted \"\\n\" char\nset(stopwords.words(\"english\"))\nstop_words = set([elem.lower() for elem in stopwords.words(\"english\")])\nlemma_word1 = []\n# this shit has the lang tag. it might be useful for language detection. really?"
        },
        {
            "comment": "This code preprocesses a document by removing certain parts of speech and stop words, then applies stemming using the PorterStemmer to reduce words to their root form. The resulting list of stemmed words is stored in Stem_words.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/topic_modeling/poc_english_preprocessing.py\":27-41",
            "content": "for token in doc:\n    if token.pos_ in ['PRON','CCONJ','ADP','PART','PUNCT','AUX']:\n        continue\n    if token.text.lower() in stop_words:\n        continue\n    lemma_word1.append(token.text)\nsprint(lemma_word1)  # there is no such -PRON- thing.\n# 1st step.\nStem_words = []\nps = PorterStemmer()\nfor w in lemma_word1:\n    rootWord = ps.stem(w)\n    Stem_words.append(rootWord)\nsprint(Stem_words) # 3rd step"
        }
    ]
}