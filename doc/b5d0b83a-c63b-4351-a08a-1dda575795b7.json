{
    "summary": "The `spatial_pyramid_pool` function performs spatial pyramid pooling on convolutional output using max pooling, and the code includes a main section for testing. The code also performs 1D convolutions followed by LSTM layers to process sequential data.",
    "details": [
        {
            "comment": "This function, `spatial_pyramid_pool`, takes in a tensor vector from the previous convolution layer, the number of samples in the batch, the size of the matrix features in the previous layer, and the expected output size for max pooling. It returns a tensor vector with shape [1 x n], which represents the concentration of multi-level pooling. The function calculates the height and width padding required for each level of the max pooling based on the input sizes and desired output sizes.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/video_script_generation_reconstruction/spp_module.py\":0-21",
            "content": "import math\nfrom torch import nn\nimport torch\ndef spatial_pyramid_pool(previous_conv, num_sample, previous_conv_size, out_pool_size):\n    '''\n    previous_conv: a tensor vector of previous convolution layer\n    num_sample: an int number of image in the batch\n    previous_conv_size: an int vector [height, width] of the matrix features size of previous convolution layer\n    out_pool_size: a int vector of expected output size of max pooling layer\n    returns: a tensor vector with shape [1 x n] is the concentration of multi-level pooling\n    '''    \n    # print(previous_conv.size())\n    for i in range(len(out_pool_size)):\n        # print(previous_conv_size)\n        h_wid = int(math.ceil(previous_conv_size[0] / out_pool_size[i]))\n        w_wid = int(math.ceil(previous_conv_size[1] / out_pool_size[i]))\n        h_pad = (h_wid*out_pool_size[i] - previous_conv_size[0] + 1)/2 # float man.\n        h_pad = math.ceil(h_pad)\n        w_pad = (w_wid*out_pool_size[i] - previous_conv_size[1] + 1)/2\n        w_pad = math.ceil(w_pad)"
        },
        {
            "comment": "This code defines a function that performs spatial pyramid pooling on convolutional output. It uses max pooling with fixed window sizes and combines the results into a single tensor. The code also includes a main section for testing purposes, where it applies convolutions to random input data and then calls the spatial_pyramid_pool function.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/video_script_generation_reconstruction/spp_module.py\":22-48",
            "content": "        maxpool = nn.MaxPool2d((h_wid, w_wid), stride=(h_wid, w_wid), padding=(h_pad, w_pad)) # this has no trainable parameter.\n        x = maxpool(previous_conv)\n        # print(x.size())\n        torch.Size([20, 16, 20, 20])\n        # this is it.\n        if(i == 0):\n            spp = x.view(num_sample,-1)\n            # print(\"spp size:\", spp.size())\n        else:\n            # print(\"size:\",spp.size())\n            spp = torch.cat((spp,x.view(num_sample,-1)), 1)\n    return spp\nif __name__ == \"__main__\":\n    # to test the freaking video.\n    for i in [200,1000]:\n        w0 = h0 = i\n        x = torch.rand(20,3,w0,h0) # 20 frames, 20 width, 20 height8\n        # three channels? where is the optical flow layer?\n        c2layer_1 = nn.Conv2d(3,4,4)\n        c2_output_1 = c2layer_1(x)\n        print(c2_output_1.shape)\n        c2layer_2 = nn.Conv2d(4,16,20)\n        c2_output_2 = c2layer_2(c2_output_1)\n        print(c2_output_2.shape)\n        output_num = [20]\n        spp = spatial_pyramid_pool(c2_output_2,20,[int(c2_output_2.size(2)),int(c2_output_2.size(3))],output_num) # great now you have the batch size."
        },
        {
            "comment": "The code performs 1D convolutions followed by LSTM layers to process a sequence of data. It reshapes the input and applies two Conv1d operations, reducing the dimensionality of the data. Then, it applies three LSTM layers with decreasing hidden dimensions for further processing. The output shapes are printed at each step.",
            "location": "\"/media/root/Toshiba XG3/works/pyjom_doc/src/tests/video_script_generation_reconstruction/spp_module.py\":49-66",
            "content": "        print(x.shape,spp.shape) # 1,5120\n        spp_lstm = spp[None,:]\n        print(spp_lstm.shape) # 1,1,5120\n        cnn_1 = nn.Conv1d(20,20,16,stride=2)\n        cout_1 = cnn_1(spp_lstm)\n        print(cout_1.shape)\n        cnn_2 = nn.Conv1d(20,20,16,stride=2)\n        cout_2 = cnn_2(cout_1)\n        print(cout_2.shape)\n        lstm_1 = nn.LSTM(1589,400)\n        out_1,hid_1 = lstm_1(cout_2)\n        print(out_1.shape)\n        lstm_2 = nn.LSTM(400,20)\n        out_2,hid_2 = lstm_2(out_1)\n        print(out_2.shape)\n        lstm_3 = nn.LSTM(20,2)\n        out_3,hid_3 = lstm_3(out_2)\n        print(out_3.shape)"
        }
    ]
}