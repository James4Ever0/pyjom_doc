{
    "4600": {
        "file_id": 596,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/download_when_complete.py",
        "type": "filepath"
    },
    "4601": {
        "file_id": 596,
        "content": "The code is using the subprocess module to periodically check the status of a Kaggle kernel. If the status is \"running\" or \"complete\", it executes a final command and sets a lock file. It continues checking until the status is one of the valid ones or an unknown status occurs, in which case it breaks the loop.",
        "type": "summary"
    },
    "4602": {
        "file_id": 596,
        "content": "import parse\nimport subprocess\nimport time\nimport os\n# import pathlib\ndownload_lock = \".kaggle_downloaded\"\nif os.path.exists(download_lock):\n    print(\"already fetched content.\")\nwait_duration = 60\nformatx = '{a} has status \"{b}\"'\nvalid_status = [\"running\",\"complete\"]\nfinal_command = \"kaggle kernels output jessysisca/test-of-yt-dlp2\"\ncmd = \"kaggle kernels status jessysisca/test-of-yt-dlp2\"\nwhile True:\n    output = subprocess.check_output(cmd.split(\" \"))\n    output = output.decode('utf-8')\n    output = output.replace('\\n',\"\").strip()\n    result = parse.parse(formatx,output)\n    rb = result['b']\n    print(\"STATUS:\",rb)\n    if rb in valid_status:\n        if rb == \"complete\":\n            print(\"DOWNLOADING OUTPUT\")\n            os.system(final_command)\n            os.system(\"touch {}\".format(download_lock))\n            break\n        else:\n            time.sleep(wait_duration)\n    else:\n        print(\"UNKNOWN STATUS. ERROR.\")\n        break",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/download_when_complete.py:1-40"
    },
    "4603": {
        "file_id": 596,
        "content": "The code is using the subprocess module to periodically check the status of a Kaggle kernel. If the status is \"running\" or \"complete\", it executes a final command and sets a lock file. It continues checking until the status is one of the valid ones or an unknown status occurs, in which case it breaks the loop.",
        "type": "comment"
    },
    "4604": {
        "file_id": 597,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/create_output.sh",
        "type": "filepath"
    },
    "4605": {
        "file_id": 597,
        "content": "This code utilizes FFmpeg to merge webm video with subtitle files, trimming and styling as needed. It provides links for similar tasks, and seeks PlayResX, PlayResY, and ssa subtitle coordinates.",
        "type": "summary"
    },
    "4606": {
        "file_id": 597,
        "content": "ffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Scientists Discovered a Bubble Around Our Solar System! [At7ORzmAaT4].webm\"  -vf \"subtitles=zh_translated.srt:force_style='MarginV=60',subtitles=en_.srt:force_style='Fontsize=10,PrimaryColour=&H00FFFF00,Alignment=6,MarginV=228'\" scientists_bubbles.mp4\n# ffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Scientists Discovered a Bubble Around Our Solar System! [At7ORzmAaT4].webm\" -ss 00:00:07 -to 00:01:00  -vf \"subtitles=zh_translated.srt:force_style='MarginV=60',subtitles=en_.srt:force_style='Fontsize=10,PrimaryColour=&H00FFFF00,Alignment=6,MarginV=228'\" scientists_bubbles.mp4\n# https://www.zhihu.com/question/20779091\n# https://www.jianshu.com/p/cfdbfdc6d3a7\n# https://fileformats.fandom.com/wiki/SubStation_Alpha#Style_overrides\n# PlayResX: 384\n# PlayResY: 288\n# 384×288是标准的4：3画面分辨率之一。ssa字幕里的坐标（字幕的位置）即根据这2个数值的范围来定义。\n# ffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Scientists Discovered a Bubble Around Our Solar System! [At7ORzmAaT4].webm\" -ss",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/create_output.sh:1-9"
    },
    "4607": {
        "file_id": 597,
        "content": "The code uses FFmpeg to combine a webm video with two subtitle files, creating an mp4 output. It also trims the video for a specific duration and applies style overrides for subtitles. The provided links are for reference material on similar tasks. The final part of the code seeks information about PlayResX and PlayResY, along with ssa subtitle coordinates.",
        "type": "comment"
    },
    "4608": {
        "file_id": 597,
        "content": " 00:00:07 -to 00:01:00  -vf \"subtitles=zh_translated.srt:force_style='MarginV=0',subtitles=en_.srt\" scientists_bubbles.mp4",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/create_output.sh:9-9"
    },
    "4609": {
        "file_id": 597,
        "content": "Applying subtitles to a video.",
        "type": "comment"
    },
    "4610": {
        "file_id": 598,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/commons.py",
        "type": "filepath"
    },
    "4611": {
        "file_id": 598,
        "content": "This code defines `jsonWalk` and `jsonLocate` functions that recursively traverse JSON objects, handling dictionaries, lists, tuples, and raising exceptions for non-JSON types. It also updates json's dictionary with new \"walk\" and \"locate\" functions.",
        "type": "summary"
    },
    "4612": {
        "file_id": 598,
        "content": "import json\ndef jsonWalk(jsonObj,location=[]):\n    # this is not tuple. better convert it first?\n    # mlocation = copy.deepcopy(location)\n    if type(jsonObj) == dict:\n        for key in jsonObj:\n            content = jsonObj[key]\n            if type(content) not in [dict,list,tuple]: \n                yield location+[key], content\n            else:\n                # you really ok with this?\n                for mkey, mcontent in jsonWalk(content,location+[key]):\n                    yield mkey, mcontent\n    elif type(jsonObj) in [list,tuple]:\n        for key,content in enumerate(jsonObj):\n        # content = jsonObj[key]\n            if type(content) not in [dict,list,tuple]:\n                yield location+[key], content\n            else:\n                for mkey, mcontent in jsonWalk(content,location+[key]):\n                    yield mkey, mcontent\n    else:\n        raise Exception(\"Not a JSON compatible object: {}\".format(type(jsonObj)))\ndef jsonLocate(jsonObj,location=[]):\n    # print(\"object:\",jsonObj)\n    # print(\"location:\",location)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/commons.py:1-29"
    },
    "4613": {
        "file_id": 598,
        "content": "This code defines two functions, `jsonWalk` and `jsonLocate`, which recursively traverse a JSON object and yield the location and value of each item. It handles dictionaries, lists, and tuples while raising an exception for non-JSON compatible types.",
        "type": "comment"
    },
    "4614": {
        "file_id": 598,
        "content": "    if location!=[]:\n        return jsonLocate(jsonObj[location[0]],location[1:])\n    return jsonObj\njson.__dict__.update({\"walk\":jsonWalk,\"locate\":jsonLocate})\ndef list_startswith(a,b):\n    value = 0\n    if len(a) < len(b): return False\n    for i,v in enumerate(b):\n        v0 = a[i]\n        if v == v0:\n            value +=1\n    return value == len(b)\ndef list_endswith(a,b):\n    value = 0\n    if len(a) < len(b): return False\n    c = a[-len(b):]\n    for i,v in enumerate(b):\n        v0 = c[i]\n        if v == v0:\n            value +=1\n    return value == len(b)\n# list.__dict__.update({\"startswith\": list_startswith,\"endswith\": list_endswith})",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/commons.py:30-57"
    },
    "4615": {
        "file_id": 598,
        "content": "The code contains functions for checking if a list starts or ends with another list, but they are not added to the list class. It also updates json's dictionary with \"walk\" and \"locate\" functions.",
        "type": "comment"
    },
    "4616": {
        "file_id": 599,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py",
        "type": "filepath"
    },
    "4617": {
        "file_id": 599,
        "content": "This code uses BeautifulSoup and JavaScript libraries to extract HTML data, processes it into a JSON object with view count and video length updates.",
        "type": "summary"
    },
    "4618": {
        "file_id": 599,
        "content": "target = \"curl_dump_youtube.html\"\nfrom bs4 import BeautifulSoup\n# this is m.youtube.com/watch?v={videoId}\n# import esprima\nimport js2py\nsoup = open(target,\"r\",encoding=\"utf-8\").read()\nsoup = BeautifulSoup(soup,features=\"lxml\")\nscripts = soup.find_all(\"script\")\njsfunc = lambda x: \"function f9x() { \"+x+ \"  \\n return ytInitialData;}\"\njsfunc2 = lambda x: \"function f9x() { \"+x+ \"  \\n return ytInitialPlayerResponse;}\"\n# breakpoint()\nfrom commons import *\ndata = None\ndata2 = None\nfor script in scripts:\n    content = script.string\n    if content is not None:\n        if \"var ytInitialPlayerResponse = {\" in content:\n            print(\"HAS DATA\") # only one.\n            # script_obj = esprima.parse(content)\n            script_obj = jsfunc2(content)\n            # print(script_obj)\n            obj = js2py.eval_js(script_obj)\n            # print(obj)\n            data2 = obj() # need a json walker, from pyjom.\n            # breakpoint()\n    # print(content)\nfor script in scripts:\n    content = script.string\n    if content is not None:",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:1-40"
    },
    "4619": {
        "file_id": 599,
        "content": "This code retrieves HTML from a specific target file, parses it using BeautifulSoup, and searches for scripts containing \"ytInitialData\" or \"ytInitialPlayerResponse\". It then uses JavaScript conversion libraries to extract the data from these scripts as Python objects. The data is stored in variables 'data' and 'data2', respectively.",
        "type": "comment"
    },
    "4620": {
        "file_id": 599,
        "content": "        if \"var ytInitialData = {\" in content:\n            print(\"HAS DATA\") # only one.\n            # script_obj = esprima.parse(content)\n            script_obj = jsfunc(content)\n            # print(script_obj)\n            obj = js2py.eval_js(script_obj)\n            # print(obj)\n            data = obj() # need a json walker, from pyjom.\n            # breakpoint()\n    # print(content)\n    # print(\"================================\")\n#     # breakpoint()\ndata_dict =  data.to_dict()\ndata2_dict =  data2.to_dict()\n# print(type(data))\n# breakpoint()\ntarget1 = [\"viewCountText\",\"lengthText\",\"publishedTimeText\"]\ntargets = [\"videoId\", \"simpleText\"]\ninits = ['contents', 'twoColumnWatchNextResults', 'secondaryResults', 'secondaryResults', 'results']\n# inits2 = ['contents', 'twoColumnWatchNextResults', 'secondaryResults', 'secondaryResults', 'results']\nends2 = {\"title\":['compactVideoRenderer', 'title', 'simpleText'],\"viewCountText\": ['compactVideoRenderer', 'viewCountText', 'simpleText'],\"publishTime\":['compactVideoRe",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:41-67"
    },
    "4621": {
        "file_id": 599,
        "content": "This code checks if the content contains \"var ytInitialData = {\" and then parses it using jsfunc, converts to Python object with js2py, extracts data, converts it to dictionaries, and defines some target variables.",
        "type": "comment"
    },
    "4622": {
        "file_id": 599,
        "content": "nderer', 'publishedTimeText', 'simpleText'],\"lengthText\":['compactVideoRenderer', 'lengthText', 'simpleText'],\"videoId\":['compactVideoRenderer', 'videoId']}\nvideoDetails = data2_dict[\"videoDetails\"]\nvideoDetails = {k:videoDetails[k] for k in [\"viewCount\",\"author\",\"keywords\",\"channelId\",\"shortDescription\",\"lengthSeconds\",\"videoId\",\"title\"]}\n# \"https://i.ytimg.com/vi_webp/{videoId}/maxresdefault.webp # default cover.\nvideoDicts = {}\nfor key, content in json.walk(data_dict):\n    # print(key)\n    final_key = key[-1]\n    if final_key in targets:\n        if list_startswith(key,inits):\n            for k in ends2.keys():\n                v = ends2[k]\n                if list_endswith(key,v):\n                    valueType = k\n                    value = content\n                    valueIndex = key[len(inits)]\n                    if valueIndex not in videoDicts.keys():\n                        videoDicts[valueIndex] = {}\n                    # print(valueIndex,valueType,value)\n                    videoDicts[valueIndex].update({valueType:value})",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:67-88"
    },
    "4623": {
        "file_id": 599,
        "content": "This code appears to extract specific data from a JSON object, specifically looking for keys that match certain endings and initials. The extracted data is then stored in a dictionary called \"videoDicts\" with the index as the key and the type and value of the data as the values. The purpose seems to be extracting specific information from the given JSON data, potentially for further use or processing.",
        "type": "comment"
    },
    "4624": {
        "file_id": 599,
        "content": "                    break\n        # print(key)  # i want to know the views of these.\n    # breakpoint()\ndef getViewCount(vc): return vc.replace(\",\",\"\").split(\" \")[0]\ndef getLengthSeconds(lt):\n    lt0 = lt.split(\":\")\n    assert len(lt0) <=5 # no more than week please?\n    dicIndex = {0:1,1:60,2:60*60,3:60*60*24,4:60*60*24*7}\n    seconds = 0\n    for i,v in enumerate(reversed(lt0)):\n        vn = int(v)\n        vs = vn*dicIndex[i]\n        seconds += vs\n    return str(seconds)\nfor k in videoDicts.keys():\n    v = videoDicts[k]\n    viewCount = getViewCount(v[\"viewCountText\"])\n    v.update({\"viewCount\":viewCount})\n    lengthSeconds = getLengthSeconds(v[\"lengthText\"])\n    v.update({\"lengthSeconds\":lengthSeconds})\n    print(v)\n    # for k0 in ends2.keys():\n    #     assert k0 in v.keys()\nprint(videoDetails)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:89-116"
    },
    "4625": {
        "file_id": 599,
        "content": "This code iterates over the 'videoDicts' dictionary, extracting and updating the view count and video length (in seconds) for each video. The extracted information is stored as values in the dictionary with keys \"viewCount\" and \"lengthSeconds\". Finally, it prints the updated 'videoDicts' dictionary and the 'videoDetails'.",
        "type": "comment"
    },
    "4626": {
        "file_id": 600,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/init.sh",
        "type": "filepath"
    },
    "4627": {
        "file_id": 600,
        "content": "This script initializes a Kaggle kernel, checks its status, and sets proxy environment variables to download at maximum speed.",
        "type": "summary"
    },
    "4628": {
        "file_id": 600,
        "content": "# kaggle kernels init # we have it do not fuck up again\n# code/jessysisca/some-yt-stuff \n# kaggle kernels push\nkaggle kernels status jessysisca/test-of-yt-dlp2\n# jessysisca/some-yt-stuff has status \"complete\"\n# root@alpharetta ~/android_connect_scrcpy_patch# \n# kaggle kernels status jessysisca/test-of-yt-dlp\n# jessysisca/test-of-yt-dlp has status \"running\"\n# after it is done, we pull back all shit.\n# skip all proxies.\n# export http_proxy=\"\"\n# export https_proxy=\"\"\n# kaggle kernels output jessysisca/test-of-yt-dlp2 # what is the freaking speed?\n# not too slow.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/init.sh:1-14"
    },
    "4629": {
        "file_id": 600,
        "content": "This script initializes a Kaggle kernel, checks its status, and sets proxy environment variables to download at maximum speed.",
        "type": "comment"
    },
    "4630": {
        "file_id": 601,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/web_translator.py",
        "type": "filepath"
    },
    "4631": {
        "file_id": 601,
        "content": "The code defines a translator function that randomly selects from multiple translation services to convert English text to either \"zh\" or \"zh-CHS\". It uses the \"translators\" module and imports random for selecting the translation service and language. The code also allows for different combinations of translation services to be tested by uncommenting specific lines in the mtranslators list. If an error occurs during translation, it prints the exception stack trace using traceback.",
        "type": "summary"
    },
    "4632": {
        "file_id": 601,
        "content": "import translators as ts\n# translator = \n# mtranslators = [ts.sogou] #this is pure shit.\n# mtranslators = [ts.baidu,ts.sogou]\n# mtranslators = [ts.baidu,ts.sogou,ts.iciba]\nmtranslators = [ts.youdao,ts.baidu,ts.alibaba] # no yandex, tencent, sogou.\n# mtranslators = [ts.baidu,ts.iciba]\nimport random\ndef translator(text):\n    randomLang = [\"zh\",\"zh-CHS\"]\n    from_language = \"en\"\n    # lang = random.choice(randomLang)\n    while True:\n        t = random.choice(mtranslators)\n        # print(type(translator))\n        for rl in randomLang:\n            try:\n                result = t(text,from_language=from_language,to_language=rl)\n                # if len(result) < 3:\n                #     print(t)\n                #     breakpoint()\n                return result\n            except:\n                import traceback\n                traceback.print_exc()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/web_translator.py:1-27"
    },
    "4633": {
        "file_id": 601,
        "content": "The code defines a translator function that randomly selects from multiple translation services to convert English text to either \"zh\" or \"zh-CHS\". It uses the \"translators\" module and imports random for selecting the translation service and language. The code also allows for different combinations of translation services to be tested by uncommenting specific lines in the mtranslators list. If an error occurs during translation, it prints the exception stack trace using traceback.",
        "type": "comment"
    },
    "4634": {
        "file_id": 602,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/translate_srt.py",
        "type": "filepath"
    },
    "4635": {
        "file_id": 602,
        "content": "Code reads an SRT file, translates each line of the content using a web translator, wraps the translated lines to meet a certain character limit, and then saves the results in a new SRT file. The process involves parsing the input SRT file using the \"srt\" library, translating text with \"web_translator\", and modifying the line wrapping for better readability.",
        "type": "summary"
    },
    "4636": {
        "file_id": 602,
        "content": "src = \"en_.srt\"\nfinal_srt = \"zh_translated.srt\"\nimport srt\nwrap_limit = 20\nsource_srt = open(src, \"r\",encoding=\"utf-8\").read()\nssrt = srt.parse(source_srt)\nfrom web_translator import translator\nimport math\ndef wrapLine(line):\n    lines = [line[x*wrap_limit:(x+1)*wrap_limit] for x in range(math.ceil(len(line)/wrap_limit))]\n    return \"\\n\".join(lines)\ndef fixline(line):\n    notEndings = [\"。\",\"，\"]\n    for x in notEndings:\n        if line.endswith(x): return line[:-1]\n    return line\nnew_ssrt = []\nfor line in ssrt:\n    # print(line)\n    start = line.start\n    end = line.end # timedelta.\n    content = line.content\n    index = line.index\n    unwrapped_content = content.replace(\"\\n\",\" \")\n    result = translator(unwrapped_content)\n    result = fixline(result)\n    print(result)\n    line.content = result\n    new_ssrt.append(line)\n    # wrapped = wrapLine(result)\n    # print(wrapped)\n    # print(start, end, content, index)\nfinal_content = srt.compose(new_ssrt)\nwith open(final_srt,\"w+\",encoding=\"utf-8\") as f:\n    f.write(final_content)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/translate_srt.py:1-45"
    },
    "4637": {
        "file_id": 602,
        "content": "Code reads an SRT file, translates each line of the content using a web translator, wraps the translated lines to meet a certain character limit, and then saves the results in a new SRT file. The process involves parsing the input SRT file using the \"srt\" library, translating text with \"web_translator\", and modifying the line wrapping for better readability.",
        "type": "comment"
    },
    "4638": {
        "file_id": 603,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test2.py",
        "type": "filepath"
    },
    "4639": {
        "file_id": 603,
        "content": "The code imports the os module and defines two commands - one to install yt-dlp using pip3, another to download subtitles from a YouTube video with yt-dlp. It then iterates over each command in the list and runs them using os.system(). This will result in yt-dlp being installed and the subtitles being downloaded for the specified YouTube video.",
        "type": "summary"
    },
    "4640": {
        "file_id": 603,
        "content": "import os\ncommands = [\"pip3 install yt-dlp\",'yt-dlp --write-subs --convert-subtitles srt \"https://m.youtube.com/watch?v=At7ORzmAaT4\"'] # get recommendation this time.\n# we will still get many videoId from curl.\nfor c in commands:\n    os.system(c)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test2.py:1-8"
    },
    "4641": {
        "file_id": 603,
        "content": "The code imports the os module and defines two commands - one to install yt-dlp using pip3, another to download subtitles from a YouTube video with yt-dlp. It then iterates over each command in the list and runs them using os.system(). This will result in yt-dlp being installed and the subtitles being downloaded for the specified YouTube video.",
        "type": "comment"
    },
    "4642": {
        "file_id": 604,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test.py",
        "type": "filepath"
    },
    "4643": {
        "file_id": 604,
        "content": "Code installs yt-dlp and downloads subtitles from a YouTube video, then converts them to SRT format. Optionally, it also enables sponsorblock-mark for highlighting ad breaks in the output.",
        "type": "summary"
    },
    "4644": {
        "file_id": 604,
        "content": "import os\ncommands = [\"pip3 install yt-dlp\",'yt-dlp --write-subs --convert-subtitles srt  \"https://m.youtube.com/watch?v=At7ORzmAaT4\"']\n# commands = [\"pip3 install yt-dlp\",'yt-dlp --write-subs --convert-subtitles srt --sponsorblock-mark poi_highlight \"https://m.youtube.com/watch?v=At7ORzmAaT4\"']\n# this will mark the highlights.\nfor c in commands:\n    os.system(c)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test.py:1-8"
    },
    "4645": {
        "file_id": 604,
        "content": "Code installs yt-dlp and downloads subtitles from a YouTube video, then converts them to SRT format. Optionally, it also enables sponsorblock-mark for highlighting ad breaks in the output.",
        "type": "comment"
    },
    "4646": {
        "file_id": 605,
        "content": "/tests/bilibili_practices/bilibili_video_translate/web_translator.py",
        "type": "filepath"
    },
    "4647": {
        "file_id": 605,
        "content": "This code imports a translators module and defines a function for translating Chinese to English. It randomly selects a translator, fixes line endings if needed, and returns the result. The code also prints exception tracebacks in case of errors.",
        "type": "summary"
    },
    "4648": {
        "file_id": 605,
        "content": "import translators as ts\n# translator = \n# mtranslators = [ts.sogou] #this is pure shit.\n# mtranslators = [ts.baidu,ts.sogou]\n# mtranslators = [ts.baidu,ts.sogou,ts.iciba]\nmtranslators = [ts.youdao,ts.baidu,ts.alibaba] # no yandex, tencent, sogou.\n# mtranslators = [ts.baidu,ts.iciba]\nimport random\ndef fixline(line):\n    notEndings = [\"。\",\"，\"]\n    for x in notEndings:\n        if line.endswith(x): return line[:-1]\n    return line\ndef zh_to_en_translator(text,needFixLine=True):\n    randomLang = [\"zh\",\"zh-CHS\"]\n    from_language = \"en\"\n    # lang = random.choice(randomLang)\n    while True:\n        t = random.choice(mtranslators)\n        # print(type(translator))\n        for rl in randomLang:\n            try:\n                result = t(text,from_language=from_language,to_language=rl)\n                # if len(result) < 3:\n                #     print(t)\n                #     breakpoint()\n                if needFixLine:\n                    result = fixline(result)\n                return result\n            except:\n                import traceback",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/web_translator.py:1-34"
    },
    "4649": {
        "file_id": 605,
        "content": "This code imports a translators module and defines a function for translating Chinese (zh) to English (en). It randomly selects a translator from a list of options and attempts to translate the text. If needed, it fixes the line endings before returning the result.",
        "type": "comment"
    },
    "4650": {
        "file_id": 605,
        "content": "                traceback.print_exc()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/web_translator.py:35-35"
    },
    "4651": {
        "file_id": 605,
        "content": "This line of code is used for printing the exception traceback in case of an error or unhandled exception.",
        "type": "comment"
    },
    "4652": {
        "file_id": 606,
        "content": "/tests/bilibili_practices/bilibili_video_translate/translate_srt.py",
        "type": "filepath"
    },
    "4653": {
        "file_id": 606,
        "content": "Code reads an SRT file, translates each line of the content using a web translator, wraps the translated lines to meet a certain character limit, and then saves the results in a new SRT file. The process involves parsing the input SRT file using the \"srt\" library, translating text with \"web_translator\", and modifying the line wrapping for better readability.",
        "type": "summary"
    },
    "4654": {
        "file_id": 606,
        "content": "src = \"en_.srt\"\nfinal_srt = \"zh_translated.srt\"\nimport srt\nwrap_limit = 20\nsource_srt = open(src, \"r\",encoding=\"utf-8\").read()\nssrt = srt.parse(source_srt)\nfrom web_translator import translator\nimport math\ndef wrapLine(line):\n    lines = [line[x*wrap_limit:(x+1)*wrap_limit] for x in range(math.ceil(len(line)/wrap_limit))]\n    return \"\\n\".join(lines)\ndef fixline(line):\n    notEndings = [\"。\",\"，\"]\n    for x in notEndings:\n        if line.endswith(x): return line[:-1]\n    return line\nnew_ssrt = []\nfor line in ssrt:\n    # print(line)\n    start = line.start\n    end = line.end # timedelta.\n    content = line.content\n    index = line.index\n    unwrapped_content = content.replace(\"\\n\",\" \")\n    result = translator(unwrapped_content)\n    result = fixline(result)\n    print(result)\n    line.content = result\n    new_ssrt.append(line)\n    # wrapped = wrapLine(result)\n    # print(wrapped)\n    # print(start, end, content, index)\nfinal_content = srt.compose(new_ssrt)\nwith open(final_srt,\"w+\",encoding=\"utf-8\") as f:\n    f.write(final_content)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/translate_srt.py:1-45"
    },
    "4655": {
        "file_id": 606,
        "content": "Code reads an SRT file, translates each line of the content using a web translator, wraps the translated lines to meet a certain character limit, and then saves the results in a new SRT file. The process involves parsing the input SRT file using the \"srt\" library, translating text with \"web_translator\", and modifying the line wrapping for better readability.",
        "type": "comment"
    },
    "4656": {
        "file_id": 607,
        "content": "/tests/bilibili_practices/bilibili_video_translate/test_curve_converter.py",
        "type": "filepath"
    },
    "4657": {
        "file_id": 607,
        "content": "The code defines a function `curve_converter` that applies bitwise operations and conditional logic on an input value using a provided curve function, transforming it into an output array after iterating through pairs of points from the curve and maintaining data types.",
        "type": "summary"
    },
    "4658": {
        "file_id": 607,
        "content": "import numpy as np\ndef curve_converter(value,curve_function):\n    # do bitwise operation.\n    marray = None\n    curve2 = zip(curve_function[:-1],curve_function[1:])\n    dtype = value.dtype\n    for (orig, target0), (forig,ftarget) in curve2:\n        locs1 = value>orig # forget about zero.\n        locs1 = locs1.astype(dtype)\n        locs2 = value<=forig\n        locs2 = locs2.astype(dtype)\n        # new_value = locs1 and locs2\n        new_value = locs1 * locs2\n        mask_backup = new_value.copy()\n        # print(\"LOCMAP:\",new_value)\n        # new_value = new_value.astype(dtype)\n        new_value = value * new_value\n        # print(\"MASKED VALUES:\", new_value)\n        new_value = new_value.astype(np.float32)\n        new_value2 = (new_value-orig)/(forig-orig)\n        new_diff = new_value2*(ftarget-target0)\n        new_value = target0+new_diff\n        new_value = new_value*mask_backup\n        new_value = new_value.astype(dtype)\n        if marray is None:\n            marray = new_value.copy()\n        else:\n            # assert np.all(marray< value) # NOT RIGHT. WHERE?",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/test_curve_converter.py:1-33"
    },
    "4659": {
        "file_id": 607,
        "content": "This code defines a function `curve_converter` that performs bitwise operations on an input `value` using a provided curve function. The function iterates through pairs of points from the curve and applies conditional logic based on the value's relationship to these points, resulting in a transformed output array. The function also checks for duplicate values and ensures the proper data types are maintained throughout the process.",
        "type": "comment"
    },
    "4660": {
        "file_id": 607,
        "content": "            marray += new_value\n        # print(\"INTERMEDIATES:\",marray)\n    return marray\nif __name__ == '__main__':\n    data = np.array([1,40,100,245])\n    curve_function = [[0,0],[40,30],[100,50],[150,100],[255,130]]\n    out = curve_converter(data,curve_function)\n    print(data)\n    print(out)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/test_curve_converter.py:34-44"
    },
    "4661": {
        "file_id": 607,
        "content": "The code defines a function called curve_converter that takes two inputs - data and curve_function. It then adds the new values to marray, which seems to be an array of intermediate values. The code returns the marray after performing the calculations. In the main block, it tests the function by creating arrays for data and curve_function and prints out both the original data and the output of the curve_converter function.",
        "type": "comment"
    },
    "4662": {
        "file_id": 608,
        "content": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_english_text.py",
        "type": "filepath"
    },
    "4663": {
        "file_id": 608,
        "content": "This code utilizes PaddleOCR to translate and rectify text from images, applies Levenshtein distance filtering, calculates text size and positioning, and saves results.",
        "type": "summary"
    },
    "4664": {
        "file_id": 608,
        "content": "from paddleocr import PaddleOCR\n# cannot translate everything... not frame by frame...\n# can summarize things. can block texts on location.\n# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n# You can set the parameter `lang` as `ch`, `en`, `french`, `german`, `korean`, `japan`\n# to switch the language model in order.\nocr = PaddleOCR(use_angle_cls=True, lang='en') # need to run only once to download and load model into memory\nimg_path = 'target.png' # only detect english. or not?\nimport cv2\nimage = cv2.imread(img_path)\nresult2 = ocr.ocr(image, cls=True)\nprob_thresh = 0.6 # found watermark somewhere. scorpa\nresult = []\nimport wordninja\nfor index, line in enumerate(result2):\n    # print(line)\n    # breakpoint()\n    coords, (text, prob) = line\n    prob = float(prob)\n    if prob > prob_thresh:\n        rectified_text = \" \".join(wordninja.split(text))\n        line[1] = (rectified_text, prob)\n        print(line)\n        result.append(line)\nimport numpy as np\na,b,c = image.shape\nblank_image = np.zeros(shape=[a,b], dtype=np.uint8) # the exact order",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_english_text.py:1-38"
    },
    "4665": {
        "file_id": 608,
        "content": "The code utilizes the PaddleOCR library to translate text from an image. It supports multiple languages and requires model downloading upon initialization. The code reads an image, detects English text using OCR, and applies a rectification process to improve readability. It then filters out results below a probability threshold before saving the final results.",
        "type": "comment"
    },
    "4666": {
        "file_id": 608,
        "content": "for coords, (text,prob) in result:\n    polyArray = np.array(coords).astype(np.int64) # fuck.\n    # print(polyArray)\n    # print(polyArray.shape)\n    # breakpoint()\n    # points = np.array([[160, 130], [350, 130], [250, 300]])\n    # print(points.dtype)\n    # points = np.array([[454.0, 22.0], [464.0, 26.0], [464.0, 85.0]]).astype(np.int64)\n    color= 255\n    cv2.fillPoly(blank_image,[polyArray],color)\n    isClosed = True\n    thickness = 30\n    cv2.polylines(blank_image, [polyArray], isClosed, color, thickness) # much better.\n#     # cv2.fillPoly(blank_image,pts=[points],color=(255, 255,255))\n# cv2.imshow(\"mask\",blank_image)\n# cv2.waitKey(0)\n# use wordninja.\n# before translation we need to lowercase these shits.\ndst = cv2.inpaint(image,blank_image,3,cv2.INPAINT_TELEA)\n# from PIL import Image\nfrom PIL import Image, ImageFont, ImageDraw  \ndef np2pillow(opencv_image):\n    color_coverted = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)\n    pil_image = Image.fromarray(color_coverted)\n    return pil_image\n    # pil_image.show()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_english_text.py:40-67"
    },
    "4667": {
        "file_id": 608,
        "content": "Iterating through coordinates and text-probability pairs, converting coordinates to numpy array for drawing on image. Using cv2.fillPoly() and cv2.polylines() for shape fills and outlines. Inpainting image with cv2.inpaint(), then converting opencv image to pillow image using np2pillow() function.",
        "type": "comment"
    },
    "4668": {
        "file_id": 608,
        "content": "def pillow2np(pil_image):\n    # pil_image=Image.open(\"demo2.jpg\") # open image using PIL\n    # use numpy to convert the pil_image into a numpy array\n    numpy_image=np.array(pil_image)  \n    # convert to a openCV2 image, notice the COLOR_RGB2BGR which means that \n    # the color is converted from RGB to BGR format\n    opencv_image=cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR) \n    return opencv_image\n# draw text now!\nmpil_image = np2pillow(dst)\ndraw = ImageDraw.Draw(mpil_image)\nfont_location = \"/root/Desktop/works/bilibili_tarot/SimHei.ttf\" # not usual english shit.\ndef get_coord_orientation_font_size_and_center(coords):\n    xlist, ylist = [x[0] for x in coords], [x[1] for x in coords]\n    min_x, max_x = min(xlist), max(xlist)\n    min_y, max_y = min(ylist), max(ylist)\n    width,height = max_x-min_x, max_y-min_y\n    center = (int((max_x+min_x)/2),int((max_y+min_y)/2))\n    # what about rotation? forget about it...\n    if (width / height) < 0.8:\n        orientation = \"vertical\"\n        font_size = int(width)\n    else:",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_english_text.py:69-93"
    },
    "4669": {
        "file_id": 608,
        "content": "Function `pillow2np` converts a PIL image to a numpy array, then converts it to an OpenCV BGR format. Draws text on the image using PIL's ImageDraw module and specifies font location. Function `get_coord_orientation_font_size_and_center` calculates image dimensions, center, and determines orientation based on aspect ratio for possible vertical text.",
        "type": "comment"
    },
    "4670": {
        "file_id": 608,
        "content": "        orientation = \"horizontal\"\n        font_size = int(height)\n    return orientation, font_size, center,(width,height)\nreadjust_size=True\ncomparedWaterMarkString = \"scorpa\".lower() # the freaking name \ncomparedWaterMarkStringLength = len(comparedWaterMarkString)\nimport Levenshtein\nfor coords, (text,prob) in result:\n    # remove watermarks? how to filter?\n    editDistanceThreshold = 4\n    probThreshold = 0.8\n    textCompareCandidate = text.replace(\" \",\"\").lower()\n    distance = Levenshtein.distance(textCompareCandidate,comparedWaterMarkString)\n    string_length = len(text)\n    string_length_difference = abs(string_length-comparedWaterMarkStringLength)\n    length_difference_threshold = 3\n    if (distance < editDistanceThreshold and string_length_difference < length_difference_threshold) or prob < probThreshold:\n        continue # skip all shits.\n    # specified font size \n    orientation, font_size, center ,(width,height) = get_coord_orientation_font_size_and_center(coords)\n    if orientation == \"horizontal\":",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_english_text.py:94-116"
    },
    "4671": {
        "file_id": 608,
        "content": "This code is filtering and processing text from the results. It checks the distance between the text and a given string (comparedWaterMarkString) using Levenshtein distance algorithm. If the difference in length is less than a threshold, or the probability of the text being correct is below a certain threshold, the code skips that particular text. The orientation, font size, center, and dimensions are obtained from the coordinates and returned.",
        "type": "comment"
    },
    "4672": {
        "file_id": 608,
        "content": "        font = ImageFont.truetype(font_location, font_size)\n        # text = original_text\n        # drawing text size \n        stroke_width = int(0.1*font_size)\n        (string_width,string_height) = draw.textsize(text,font=font,stroke_width=stroke_width)\n        # print(string_width)\n        # breakpoint()\n        if readjust_size:\n            change_ratio = width/string_width\n            new_fontsize = font_size*change_ratio\n            font = ImageFont.truetype(font_location, new_fontsize)\n            start_x = int(center[0]-width/2)\n            start_y = int(center[1]-height/2)\n        else:\n            start_x = int(center[0]-string_width/2)\n            start_y = int(center[1]-font_size/2)\n        draw.text((start_x, start_y), text, font = font, fill=(255,255,255),stroke_fill=(0,0,0),stroke_width = stroke_width,align =\"left\") # what is the freaking align?\n# mpil_image.show() \nmpil_image.save(\"redraw_english.png\")\n# cv2.imshow('dst',dst2)\n# cv2.waitKey(0)\n# cv2.destroyAllWindows()\n# expand the area somehow.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_english_text.py:117-141"
    },
    "4673": {
        "file_id": 608,
        "content": "This code calculates the size of text using a given font, adjusts it based on image size, and draws the text centered or aligned to the left. It then saves the resulting image.",
        "type": "comment"
    },
    "4674": {
        "file_id": 608,
        "content": "# draw result\n# simhei_path = \"/root/Desktop/works/bilibili_tarot/SimHei.ttf\"\n# from PIL import Image\n# image = Image.open(img_path).convert('RGB')\n# boxes = [line[0] for line in result]\n# txts = [line[1][0] for line in result]\n# scores = [line[1][1] for line in result]\n# im_show = draw_ocr(image, boxes, txts, scores, font_path=simhei_path)\n# im_show = Image.fromarray(im_show)\n# im_show.save('result.jpg')\n# we will be testing one image only. not the whole goddamn video.\n# may have cuda error when using my cv2 cuda libs.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_english_text.py:142-154"
    },
    "4675": {
        "file_id": 608,
        "content": "This code snippet is responsible for drawing OCR results on an image, saving the result as 'result.jpg'. It uses a specific font path and processes one image only to avoid potential CUDA errors with cv2 CUDA libraries.",
        "type": "comment"
    },
    "4676": {
        "file_id": 609,
        "content": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_chinese_text.py",
        "type": "filepath"
    },
    "4677": {
        "file_id": 609,
        "content": "This code utilizes PaddleOCR for OCR, applies text rectification with probability threshold and WordNinja, performs color inpainting, filters coordinates, removes watermarks, adjusts font size/position, and outputs 'result.jpg'. Issues may arise with CUDA-based OpenCV libraries.",
        "type": "summary"
    },
    "4678": {
        "file_id": 609,
        "content": "from paddleocr import PaddleOCR\n# cannot translate everything... not frame by frame...\n# can summarize things. can block texts on location.\n# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n# You can set the parameter `lang` as `ch`, `en`, `french`, `german`, `korean`, `japan`\n# to switch the language model in order.\nocr = PaddleOCR(use_angle_cls=True, lang='en') # need to run only once to download and load model into memory\nimg_path = 'target.png' # only detect english. or not?\nimport cv2\nimage = cv2.imread(img_path)\nresult2 = ocr.ocr(image, cls=True)\nprob_thresh = 0.6 # found watermark somewhere. scorpa\nresult = []\nimport wordninja\nfor index, line in enumerate(result2):\n    # print(line)\n    # breakpoint()\n    coords, (text, prob) = line\n    prob = float(prob)\n    if prob > prob_thresh:\n        rectified_text = \" \".join(wordninja.split(text))\n        line[1] = (rectified_text, prob)\n        print(line)\n        result.append(line)\nimport numpy as np\na,b,c = image.shape\nblank_image = np.zeros(shape=[a,b], dtype=np.uint8) # the exact order",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_chinese_text.py:1-38"
    },
    "4679": {
        "file_id": 609,
        "content": "This code uses PaddleOCR to perform optical character recognition (OCR) on an image file. It detects English text in the image and applies a probability threshold for accuracy. The code rectifies the detected text by splitting it into words using WordNinja, then stores the result in a list. The script also creates a blank image using NumPy.",
        "type": "comment"
    },
    "4680": {
        "file_id": 609,
        "content": "for coords, (text,prob) in result:\n    polyArray = np.array(coords).astype(np.int64) # fuck.\n    # print(polyArray)\n    # print(polyArray.shape)\n    # breakpoint()\n    # points = np.array([[160, 130], [350, 130], [250, 300]])\n    # print(points.dtype)\n    # points = np.array([[454.0, 22.0], [464.0, 26.0], [464.0, 85.0]]).astype(np.int64)\n    color= 255\n    cv2.fillPoly(blank_image,[polyArray],color)\n    isClosed = True\n    thickness = 30\n    cv2.polylines(blank_image, [polyArray], isClosed, color, thickness) # much better.\n#     # cv2.fillPoly(blank_image,pts=[points],color=(255, 255,255))\n# cv2.imshow(\"mask\",blank_image)\n# cv2.waitKey(0)\n# use wordninja.\n# before translation we need to lowercase these shits.\ndst = cv2.inpaint(image,blank_image,3,cv2.INPAINT_TELEA)\n# from PIL import Image\nfrom PIL import Image, ImageFont, ImageDraw  \ndef np2pillow(opencv_image):\n    color_coverted = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)\n    pil_image = Image.fromarray(color_coverted)\n    return pil_image\n    # pil_image.show()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_chinese_text.py:40-67"
    },
    "4681": {
        "file_id": 609,
        "content": "Iterates through result coordinates and text probabilities, converts coordinates to numpy array, fills polygon on the image, draws polyline, performs color inpainting on the image, and converts the final image from OpenCV to PIL format.",
        "type": "comment"
    },
    "4682": {
        "file_id": 609,
        "content": "def pillow2np(pil_image):\n    # pil_image=Image.open(\"demo2.jpg\") # open image using PIL\n    # use numpy to convert the pil_image into a numpy array\n    numpy_image=np.array(pil_image)  \n    # convert to a openCV2 image, notice the COLOR_RGB2BGR which means that \n    # the color is converted from RGB to BGR format\n    opencv_image=cv2.cvtColor(numpy_image, cv2.COLOR_RGB2BGR) \n    return opencv_image\n# draw text now!\nmpil_image = np2pillow(dst)\ndraw = ImageDraw.Draw(mpil_image)\nfont_location = \"/root/Desktop/works/bilibili_tarot/SimHei.ttf\" # not usual english shit.\ndef get_coord_orientation_font_size_and_center(coords):\n    xlist, ylist = [x[0] for x in coords], [x[1] for x in coords]\n    min_x, max_x = min(xlist), max(xlist)\n    min_y, max_y = min(ylist), max(ylist)\n    width,height = max_x-min_x, max_y-min_y\n    center = (int((max_x+min_x)/2),int((max_y+min_y)/2))\n    # what about rotation? forget about it...\n    if (width / height) < 0.8:\n        orientation = \"vertical\"\n        font_size = int(width)\n    else:",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_chinese_text.py:69-93"
    },
    "4683": {
        "file_id": 609,
        "content": "Function `pillow2np` converts a PIL image to a numpy array and then to an OpenCV image, changing the color format from RGB to BGR.\nIn the `get_coord_orientation_font_size_and_center` function, it calculates width, height, center coordinates of the bounding box based on given coordinates, and determines the font size and orientation (vertical or horizontal) based on aspect ratio of the image.",
        "type": "comment"
    },
    "4684": {
        "file_id": 609,
        "content": "        orientation = \"horizontal\"\n        font_size = int(height)\n    return orientation, font_size, center,(width,height)\nreadjust_size=False # just center.\ncomparedWaterMarkString = \"scorpa\".lower() # the freaking name \ncomparedWaterMarkStringLength = len(comparedWaterMarkString)\nimport Levenshtein\nfrom web_translator import zh_to_en_translator as translator\nfor coords, (text,prob) in result:\n    # remove watermarks? how to filter?\n    editDistanceThreshold = 4\n    probThreshold = 0.8\n    textCompareCandidate = text.replace(\" \",\"\").lower() # original text, no translation.\n    distance = Levenshtein.distance(textCompareCandidate,comparedWaterMarkString)\n    string_length = len(text)\n    string_length_difference = abs(string_length-comparedWaterMarkStringLength)\n    length_difference_threshold = 3\n    if (distance < editDistanceThreshold and string_length_difference < length_difference_threshold) or prob < probThreshold:\n        continue # skip all shits.\n    # specified font size \n    text = translator(text) # now translate.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_chinese_text.py:94-117"
    },
    "4685": {
        "file_id": 609,
        "content": "Code snippet is filtering and translating text from a given list of coordinates and text-probability pairs. It removes watermarks by comparing the original text to \"scorpa\" (lowercase) and skips texts with high edit distance, length difference or low probability. The font size is set, and the translated text is returned.",
        "type": "comment"
    },
    "4686": {
        "file_id": 609,
        "content": "    orientation, font_size, center ,(width,height) = get_coord_orientation_font_size_and_center(coords)\n    if orientation == \"horizontal\":\n        font = ImageFont.truetype(font_location, font_size)\n        # text = original_text\n        # drawing text size \n        stroke_width = int(0.1*font_size)\n        (string_width,string_height) = draw.textsize(text,font=font,stroke_width=stroke_width)\n        # print(string_width)\n        # breakpoint()\n        if readjust_size:\n            change_ratio = width/string_width\n            new_fontsize = font_size*change_ratio\n            font = ImageFont.truetype(font_location, new_fontsize)\n            start_x = int(center[0]-width/2)\n            start_y = int(center[1]-height/2)\n        else:\n            start_x = int(center[0]-string_width/2)\n            start_y = int(center[1]-font_size/2)\n        draw.text((start_x, start_y), text, font = font, fill=(255,255,255),stroke_fill=(0,0,0),stroke_width = stroke_width,align =\"left\") # what is the freaking align?\n# mpil_image.show() ",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_chinese_text.py:118-138"
    },
    "4687": {
        "file_id": 609,
        "content": "The code calculates the text's dimensions and adjusts the font size and position based on the provided coordinates. If 'readjust_size' is True, it resizes the font to fit within the given width. It then draws the text with specified alignment using the ImageDraw module.",
        "type": "comment"
    },
    "4688": {
        "file_id": 609,
        "content": "mpil_image.save(\"redraw_eng_to_chinese.png\")\n# cv2.imshow('dst',dst2)\n# cv2.waitKey(0)\n# cv2.destroyAllWindows()\n# expand the area somehow.\n# draw result\n# simhei_path = \"/root/Desktop/works/bilibili_tarot/SimHei.ttf\"\n# from PIL import Image\n# image = Image.open(img_path).convert('RGB')\n# boxes = [line[0] for line in result]\n# txts = [line[1][0] for line in result]\n# scores = [line[1][1] for line in result]\n# im_show = draw_ocr(image, boxes, txts, scores, font_path=simhei_path)\n# im_show = Image.fromarray(im_show)\n# im_show.save('result.jpg')\n# we will be testing one image only. not the whole goddamn video.\n# may have cuda error when using my cv2 cuda libs.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_redraw_chinese_text.py:139-157"
    },
    "4689": {
        "file_id": 609,
        "content": "This code saves an image, displays it using OpenCV, expands the area of the image and draws the result using a specific font, and finally saves the final output as 'result.jpg'. It is specifically testing one image from a video, and may encounter issues when using CUDA-based OpenCV libraries due to potential errors.",
        "type": "comment"
    },
    "4690": {
        "file_id": 610,
        "content": "/tests/bilibili_practices/bilibili_video_translate/main_mask_english_text.py",
        "type": "filepath"
    },
    "4691": {
        "file_id": 610,
        "content": "This code uses PaddleOCR to detect English text in images, applies a specific font for OCR, and visualizes the results. Testing is limited to one image, and CUDA errors may occur with certain CV2 libraries.",
        "type": "summary"
    },
    "4692": {
        "file_id": 610,
        "content": "from paddleocr import PaddleOCR,draw_ocr\n# cannot translate everything... not frame by frame...\n# can summarize things. can block texts on location.\n# Paddleocr supports Chinese, English, French, German, Korean and Japanese.\n# You can set the parameter `lang` as `ch`, `en`, `french`, `german`, `korean`, `japan`\n# to switch the language model in order.\nocr = PaddleOCR(use_angle_cls=True, lang='en') # need to run only once to download and load model into memory\nimg_path = 'target.png' # only detect english. or not?\nimport cv2\nimage = cv2.imread(img_path)\nresult2 = ocr.ocr(image, cls=True)\nprob_thresh = 0.8\nresult = []\nimport wordninja\nfor index, line in enumerate(result2):\n    # print(line)\n    # breakpoint()\n    coords, (text, prob) = line\n    prob = float(prob)\n    if prob > prob_thresh:\n        rectified_text = \" \".join(wordninja.split(text))\n        line[1] = (rectified_text, prob)\n        print(line)\n        result.append(line)\nimport numpy as np\na,b,c = image.shape\nblank_image = np.zeros(shape=[a,b], dtype=np.uint8) # the exact order",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_mask_english_text.py:1-38"
    },
    "4693": {
        "file_id": 610,
        "content": "The code uses PaddleOCR to detect English text in an image. It loads the model once and then reads the image file 'target.png'. The OCR function is used to recognize the text in the image, and a probability threshold is set. The detected lines with probabilities above the threshold are processed further using wordninja to rectify the text. These lines are stored in the result list. Finally, a blank image is created for an unknown purpose.",
        "type": "comment"
    },
    "4694": {
        "file_id": 610,
        "content": "for coords, (text,prob) in result:\n    polyArray = np.array(coords).astype(np.int64) # fuck.\n    # print(polyArray)\n    # print(polyArray.shape)\n    # breakpoint()\n    # points = np.array([[160, 130], [350, 130], [250, 300]])\n    # print(points.dtype)\n    # points = np.array([[454.0, 22.0], [464.0, 26.0], [464.0, 85.0]]).astype(np.int64)\n    color= 255\n    cv2.fillPoly(blank_image,[polyArray],color)\n    isClosed = True\n    thickness = 30\n    cv2.polylines(blank_image, [polyArray], isClosed, color, thickness) # much better.\n#     # cv2.fillPoly(blank_image,pts=[points],color=(255, 255,255))\n# cv2.imshow(\"mask\",blank_image)\n# cv2.waitKey(0)\n# use wordninja.\n# before translation we need to lowercase these shits.\ndst = cv2.inpaint(image,blank_image,3,cv2.INPAINT_TELEA)\ncv2.imshow('dst',dst)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n# expand the area somehow.\n# draw result\n# simhei_path = \"/root/Desktop/works/bilibili_tarot/SimHei.ttf\"\n# from PIL import Image\n# image = Image.open(img_path).convert('RGB')\n# boxes = [line[0] for line in result]",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_mask_english_text.py:40-68"
    },
    "4695": {
        "file_id": 610,
        "content": "Iterating through result coordinates, creating a numpy array for each set of coordinates, filling the poly with color and drawing polylines on blank image. Displaying and destroying windows after inpainting, expanding area, and converting to RGB using PIL Image.",
        "type": "comment"
    },
    "4696": {
        "file_id": 610,
        "content": "# txts = [line[1][0] for line in result]\n# scores = [line[1][1] for line in result]\n# im_show = draw_ocr(image, boxes, txts, scores, font_path=simhei_path)\n# im_show = Image.fromarray(im_show)\n# im_show.save('result.jpg')\n# we will be testing one image only. not the whole goddamn video.\n# may have cuda error when using my cv2 cuda libs.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/main_mask_english_text.py:69-76"
    },
    "4697": {
        "file_id": 610,
        "content": "This code segment retrieves text and scores from the result, applies OCR to an image using a specific font, and saves the resulting image as 'result.jpg'. It mentions that testing is focused on one image only, and CUDA errors may occur when using certain CV2 libraries.",
        "type": "comment"
    },
    "4698": {
        "file_id": 611,
        "content": "/tests/bilibili_practices/bilibili_video_translate/m2m100_1b_translator.py",
        "type": "filepath"
    },
    "4699": {
        "file_id": 611,
        "content": "This code imports the `m2m100_zte_translator` function from the `functional_dl_translator_1b_deepspeed` module, and defines two helper functions: `fixline` to remove specific Chinese ending characters, and `zh_to_en_translator` which uses `m2m100_zte_translator` to translate Chinese text to English and applies the line-fixing function if needed.",
        "type": "summary"
    }
}