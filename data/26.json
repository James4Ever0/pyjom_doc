{
    "2600": {
        "file_id": 283,
        "content": "var figures = document.getElementsByTagName(\"figure\");\nvar mlinks = []\nfor (var fig of figures) {\n    var link = fig.getElementsByTagName(\"img\")[0].getAttribute(\"data-src\").split(\"@\")[0].replace(\"//\", \"https://\");\n    mlinks.push(link)\n}\nconsole.log(JSON.stringify(mlinks));",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/get_figures.js:1-7"
    },
    "2601": {
        "file_id": 283,
        "content": "This code retrieves all \"figure\" tags from the HTML document, extracts the URLs of the first image in each figure using their \"data-src\" attribute, removes the \"@\" symbol, and replaces \"//\" with \"https://\". Finally, it logs the extracted URLs as a JSON string to the console.",
        "type": "comment"
    },
    "2602": {
        "file_id": 284,
        "content": "/tests/bilibili_practices/bilibili_tarot/generate_typography_with_voice.py",
        "type": "filepath"
    },
    "2603": {
        "file_id": 284,
        "content": "This code sets up a drawing environment and generates typography frames by rendering text onto an image, handling wrapping and tracking position on screen. It also initializes new lists, saves screenshots, and handles different scenarios before exiting.",
        "type": "summary"
    },
    "2604": {
        "file_id": 284,
        "content": "from p5 import *\nimport os\nfrom test_common import demo_text\nos.system(\"rm screenshot*\")\ntarget_dir = \"demo_typography\"\nos.system(\"rm -rf {}\".format(target_dir))\nos.system(\"mkdir {}\".format(target_dir))\ntsize = 100\ncounterx = 0\nxcoord = 20\nycoord = 75\nscrwidth = 1920\nscrheight = 1080\nlineNum = 0\n# what fucking ever.\ns = demo_text\ns0 = [\"\"]\ndef setup():\n    size(scrwidth,scrheight)\n    text_font(create_font('./SimHei.ttf', size=tsize))\ndef draw():\n    global counterx,xcoord,ycoord,s,s0,scrheight,scrwidth,lineNum,target_dir\n    if len(s0) ==1:\n        if len(s0[0]) == 0:\n            background(0)\n    if counterx > len(s)-1:\n        exit()\n    s1 = s[counterx]\n    stemp0 = s0[-1]+s1\n    tw = text_width(stemp0)\n    th = tsize*(lineNum+1) + tsize*0.2*lineNum\n    # th = tsize*(stemp0.count(\"\\n\")+1)\n    # if (ycoord+th> scrheight):\n    #     s0 = s1\n    # else:\n    if (tw + xcoord+ tsize*0.5> scrwidth):\n        stemp0 = s1\n        s0.append(stemp0)\n        lineNum +=1\n        th = tsize*(lineNum+1) + tsize*0.2*lineNum\n        if (ycoord+th> scrheight):",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_typography_with_voice.py:1-47"
    },
    "2605": {
        "file_id": 284,
        "content": "This code sets up a drawing environment with a specified size and font, and then generates typography frames by rendering text onto an image. It handles wrapping text to multiple lines if the width is exceeded and keeps track of the number of lines and position on the screen. The code also clears any existing files named \"screenshot*\" and creates a new directory for storing the resulting images.",
        "type": "comment"
    },
    "2606": {
        "file_id": 284,
        "content": "            # stemp0 = s1\n            s0 = [stemp0]\n            background(0)\n            lineNum = 0\n    else:\n        s0[-1]= stemp0\n        # no_loop()\n        # clear\n    # s0 = stemp0\n        # end all evil.\n    counterx+=1\n    # load_font(\"SimHei.ttf\")\n    print(\"text w/h:\",tw,th)\n    # for l, text9 in enumerate(s0):\n    text9 = s0[-1][-1]\n    l = len(s0)-1\n    text(text9, (xcoord+text_width(s0[-1][:-1]), ycoord+ l*(tsize*1.2)))  # add str() to key\n    save_frame(\"{}/screenshot.png\".format(target_dir))\nrun()\nprint(\"EXITED.\")",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_typography_with_voice.py:48-69"
    },
    "2607": {
        "file_id": 284,
        "content": "The code handles different scenarios by either initializing a new list 's0' or updating the last element in 's0'. It uses variables like 'l', 'xcoord', 'ycoord', 'target_dir', 'counterx', and 'text9' to handle text placement, saving screenshots, and maintaining state. The font \"SimHei.ttf\" is loaded, and the width of each line of text is calculated using the 'text_width' function. Finally, a screenshot is saved and the script exits.",
        "type": "comment"
    },
    "2608": {
        "file_id": 285,
        "content": "/tests/bilibili_practices/bilibili_tarot/generate_typography.py",
        "type": "filepath"
    },
    "2609": {
        "file_id": 285,
        "content": "This code generates typography using Processing library in Python, handling line wrapping and text overflows, with a Chinese SimHei font, adjustable line heights, and separate line storage. It displays the typography on screen and saves screenshots until all elements are processed.",
        "type": "summary"
    },
    "2610": {
        "file_id": 285,
        "content": "from p5 import *\nimport os\nos.system(\"rm screenshot*\")\ntsize = 100\ncounterx = 0\nxcoord = 20\nycoord = 75\nscrwidth = 1920\nscrheight = 1080\nlineNum = 0\n# what fucking ever.\ns = \"[START]\"+\"SOME TEXT\"*500+\"[END]\"\ns0 = [\"\"]\ndef setup():\n    size(scrwidth,scrheight)\n    text_font(create_font('./SimHei.ttf', size=tsize))\ndef draw():\n    global counterx,xcoord,ycoord,s,s0,scrheight,scrwidth,lineNum\n    if len(s0) ==1:\n        if len(s0[0]) == 0:\n            background(0)\n    if counterx > len(s)-1:\n        exit()\n    s1 = s[counterx]\n    stemp0 = s0[-1]+s1\n    tw = text_width(stemp0)\n    th = tsize*(lineNum+1) + tsize*0.2*lineNum\n    # th = tsize*(stemp0.count(\"\\n\")+1)\n    # if (ycoord+th> scrheight):\n    #     s0 = s1\n    # else:\n    if (tw + xcoord+ tsize*0.5> scrwidth):\n        stemp0 = s1\n        s0.append(stemp0)\n        lineNum +=1\n        th = tsize*(lineNum+1) + tsize*0.2*lineNum\n        if (ycoord+th> scrheight):\n            # stemp0 = s1\n            s0 = [stemp0]\n            background(0)\n            lineNum = 0\n    else:\n        s0[-1]= stemp0",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_typography.py:1-48"
    },
    "2611": {
        "file_id": 285,
        "content": "This code generates a typography using Processing (p5.js) library in Python, handling line wrapping and text overflows to fit within the specified screen width and height. It uses a Chinese SimHei font, dynamically adjusts line heights, and stores each line of text separately for easier manipulation.",
        "type": "comment"
    },
    "2612": {
        "file_id": 285,
        "content": "        # no_loop()\n        # clear\n    # s0 = stemp0\n        # end all evil.\n    counterx+=1\n    # load_font(\"SimHei.ttf\")\n    print(\"text w/h:\",tw,th)\n    # for l, text9 in enumerate(s0):\n    text9 = s0[-1][-1]\n    l = len(s0)-1\n    text(text9, (xcoord+text_width(s0[-1][:-1]), ycoord+ l*(tsize*1.2)))  # add str() to key\n    save_frame(\"screenshot.png\")\nrun()\nprint(\"EXITED.\")",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_typography.py:49-64"
    },
    "2613": {
        "file_id": 285,
        "content": "The code snippet seems to be responsible for generating typography using a specific font and displaying it on the screen. It tracks the length of the text being displayed, calculates the position based on that length, and saves a screenshot after each iteration. The loop continues until all elements in 's0' are processed, and then it exits.",
        "type": "comment"
    },
    "2614": {
        "file_id": 286,
        "content": "/tests/bilibili_practices/bilibili_tarot/generate_demo_tarot.py",
        "type": "filepath"
    },
    "2615": {
        "file_id": 286,
        "content": "The code imports libraries, creates a video clip from an image, applies filters, saves it, and then resizes/pads the file using ffmpeg.",
        "type": "summary"
    },
    "2616": {
        "file_id": 286,
        "content": "import os\nfrom vidpy import Clip, Composition  #many shitty things...\ntarot_target = \"/root/Desktop/works/bilibili_tarot/tarot_pictures/0_THE_FOOL.jpg\"\nos.system(\"rm tarot_demo.mp4\")\nfps =60\nmyprofile = {'width': 1320, 'height': 2644}\n# just create profile from it. are you sure?\nclip = Clip(tarot_target, output_fps=fps,start=0, end=16, profile_override=myprofile,override=False)\n# clip.edgeglow()\n# clip.crop\n# 1320x2645 # unbelievable.\n# clip.fx(\"\",{})\n# clip.resize(w=1920, h=1080, distort=True)\n# distort=False\nc_w = clip.width\nc_h = clip.height\n# comp = Composition([clip])\nclip.dither(amount=0.2) # the greater the better.\nclip.fadein(0.5)      # fade the clip in over 1 second\n# clip.fadeout(3.5)   # fade the clip over 0.5 seconds\n# clip.glow(3.5)         # add a glow effect\nclip.spin(4, axis=\"z\")\n# clip.crop(right=c_w,bottom=c_h)\nclip.save(\"tarot_demo.mp4\", fps=60,duration = 3,width=c_w,height=c_h) # good.\n# print(c_w,c_h)\n# 720 576\nr1 = c_w/c_h\ntarget_w, target_h = 1920, 1080\nr2 = target_w/ target_h\nif r1 < r2:\n  ",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_demo_tarot.py:1-32"
    },
    "2617": {
        "file_id": 286,
        "content": "The code imports necessary libraries, defines a tarot image file path and removes an existing mp4 file. It then creates a video clip object from the image using specific parameters, applies various filters and transformations to the clip, saves the modified clip as \"tarot_demo.mp4\" with specified duration, width, and height.",
        "type": "comment"
    },
    "2618": {
        "file_id": 286,
        "content": "  os.system('ffmpeg -y -i tarot_demo.mp4  -vf \"scale=-1:{},pad={}:ih:(ow-iw)/2\"  tarot_demo2.mp4'.format(target_h,target_w))\nelse:\n    os.system('ffmpeg -y -i tarot_demo.mp4  -vf \"scale={}:-1,pad=iw:{}:0:(oh-ih)/2\"  tarot_demo2.mp4'.format(target_w,target_h))",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_demo_tarot.py:32-34"
    },
    "2619": {
        "file_id": 286,
        "content": "This code uses ffmpeg to resize and pad tarot_demo.mp4 video file into tarot_demo2.mp4, adjusting dimensions based on target_h and target_w variables.",
        "type": "comment"
    },
    "2620": {
        "file_id": 287,
        "content": "/tests/bilibili_practices/bilibili_tarot/flipcards.py",
        "type": "filepath"
    },
    "2621": {
        "file_id": 287,
        "content": "This code generates flipcards for Major and Minor Arcana in Tarot. It first clears directories, creates them, and then iterates over dictionaries to generate flipcard videos with specified background music, storing them accordingly.",
        "type": "summary"
    },
    "2622": {
        "file_id": 287,
        "content": "# generate all flipcards.\nfrom tarot_correspondences import *\nfrom functional_generate_demo_tarot import gen_tarot\n# mtarget_0, mtarget_1\ndir_0 = \"major\"\ndir_1 = \"minor\"\nos.system(\"rm -rf {}\".format(dir_0))\nos.system(\"rm -rf {}\".format(dir_1))\nos.mkdir(dir_0)\nos.mkdir(dir_1)\nbgm_path = \"/root/Desktop/works/bilibili_tarot/some_bgm.mp3\"\nfor k in mtarget_0.keys():\n    value = mtarget_0[k]\n    videoPath = \"/\".join([dir_0,\"{}.mp4\".format(k)])\n    picture_path = value\n    gen_tarot(picture_path,bgm_path,videoPath)\nfor k in mtarget_1.keys():\n    value = mtarget_1[k]\n    videoPath = \"/\".join([dir_1,\"{}.mp4\".format(k)])\n    picture_path = value\n    gen_tarot(picture_path,bgm_path,videoPath)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/flipcards.py:1-27"
    },
    "2623": {
        "file_id": 287,
        "content": "This code generates flipcards for Major and Minor Arcana in Tarot. It first clears directories, creates them, and then iterates over dictionaries to generate flipcard videos with specified background music, storing them accordingly.",
        "type": "comment"
    },
    "2624": {
        "file_id": 288,
        "content": "/tests/bilibili_practices/bilibili_tarot/gen_typo_video_seq.py",
        "type": "filepath"
    },
    "2625": {
        "file_id": 288,
        "content": "Generates a video sequence by splitting images into clips with adjusted duration and fps, appends background music clip, composes the clips into a single composition, and saves it as \"typography_demo.mp4\".",
        "type": "summary"
    },
    "2626": {
        "file_id": 288,
        "content": "seq = [0,1,2,3,4,5,6] # 7\nduration = 4\nmduration = duration / len(seq)\nfrom vidpy import Composition, Clip\nclips = []\nwidth,height =1920,1080\nfps=60\norig_fps = 24\nshift = fps/orig_fps\nfor i,s in enumerate(seq):\n    codec = str(s)\n    codec = \"0\"*(4-len(codec)) + codec\n    path = \"/root/Desktop/works/bilibili_tarot/demo_typography/screenshot{}.png\".format(codec)\n    start = i*mduration\n    end = start + mduration\n    print(start,end)\n    clip = Clip(path,output_fps=fps,start=0,end=mduration*shift,offset = start*shift,profile_override = {\"fps\":60,\"width\": width, \"height\": height})\n    clips.append(clip)\n# breakpoint()\nbgm_path = \"/root/Desktop/works/bilibili_tarot/some_bgm.mp3\"\n# maybe some other bgm.\nbgm = Clip(bgm_path,start=0)\nclips.append(bgm)\n# breakpoint()\ncomp = Composition(clips,duration=duration,fps=fps,width=width,height=height)\ncomp.save(\"typography_demo.mp4\",fps=60,duration = duration,width=width,height=height)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/gen_typo_video_seq.py:1-35"
    },
    "2627": {
        "file_id": 288,
        "content": "Generates a video sequence by splitting images into clips with adjusted duration and fps, appends background music clip, composes the clips into a single composition, and saves it as \"typography_demo.mp4\".",
        "type": "comment"
    },
    "2628": {
        "file_id": 289,
        "content": "/tests/bilibili_practices/bilibili_tarot/all_typography_underline_subtitle.py",
        "type": "filepath"
    },
    "2629": {
        "file_id": 289,
        "content": "The code removes files, uses external scripts and programs to generate typography for a bilibili video, and is part of a larger video editing or manipulation process.",
        "type": "summary"
    },
    "2630": {
        "file_id": 289,
        "content": "from tarot_descriptions import *\n# mdict, smdict2\nimport os\ndef gen_typography_part1(content):\n    with open(\"demo_text.log\",\"w+\",encoding=\"utf8\") as f:\n        f.write(content)\n    os.system(\"xvfb-run -s '-screen 0 1920x1080x24' python3 scriptable_generate_typography_with_voice_underline_subtitle.py\")\ndef kill_script():\n    os.system(\"bash kill_xb.sh\")\ntyp_0 = \"typo_0\"\ntyp_1 = \"typo_1\"\n# os.system(\"rm -rf {}\".format(typ_0))\n# os.system(\"rm -rf {}\".format(typ_1))\n# os.mkdir(typ_0)\n# os.mkdir(typ_1)\nfrom functional_voice_with_pictures import gen_typography_part3\n# intro_text = \"\"\"塔罗牌，是一种针对人、事、物进行分析、预测和提供建议的工具，被称为“大自然的奥秘库”。\n# 抽取一张塔罗牌，今天的你会是怎样的呢？\"\"\"\nintro_text = \"\"\"奥拓是只猫～\"\"\"\n# bgm_path = \"/root/Desktop/works/bilibili_tarot/tarot_random_shuffle.mp3\"\ntarget_video = \"cat_intro_video.mp4\"\nos.system(\"rm {}\".format(target_video))\nkill_script()\n# v = mdict[k]\nv = intro_text\ngen_typography_part1(v)\n# target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\ngen_typography_part3(v,target_video)\nkill_script()\nintro_text = \"\"\"喜欢本期视频的话 点个关注再走吧～\"\"\"",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography_underline_subtitle.py:1-43"
    },
    "2631": {
        "file_id": 289,
        "content": "This code generates typography for a bilibili video, involves creating directories and removing files, uses os.system to run external scripts and programs, and has an introductory message followed by an ending message for the video.",
        "type": "comment"
    },
    "2632": {
        "file_id": 289,
        "content": "# bgm_path = \"/root/Desktop/works/bilibili_tarot/tarot_random_shuffle.mp3\"\ntarget_video = \"cat_outro_video.mp4\"\nos.system(\"rm {}\".format(target_video))\nkill_script()\n# v = mdict[k]\nv = intro_text\ngen_typography_part1(v)\n# target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\ngen_typography_part3(v,target_video)\nkill_script()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography_underline_subtitle.py:45-56"
    },
    "2633": {
        "file_id": 289,
        "content": "This code removes the target video file, terminates a script, generates typography for a specific text using functions gen_typography_part1 and gen_typography_part3, and then terminates another script. It seems to be part of a process involving video editing or manipulation.",
        "type": "comment"
    },
    "2634": {
        "file_id": 290,
        "content": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py",
        "type": "filepath"
    },
    "2635": {
        "file_id": 290,
        "content": "This code generates typography for videos using TTS, external tools, and FFMPEG, performing directory operations, merging audio/video, exporting, calculating tempo, and applying it to the audio track.",
        "type": "summary"
    },
    "2636": {
        "file_id": 290,
        "content": "import os\nfrom test_common import *\nimport shutil\ndef split_sentences(sent):\n    spliters = \"\\n，。、？： \"\n    cursent = \"\"\n    results = []\n    for elem in sent:\n        cursent += elem\n        if elem in spliters:\n            results.append(cursent)\n            cursent = \"\"\n    if len(cursent) > 0:\n        results.append(cursent)\n    return results\ndef get_speech(sent,output):\n    assert output.endswith(\".wav\")\n    os.system(\"bash kill_pdspc.sh\")\n    with open(\"temp.txt\", \"w+\",encoding=\"utf-8\") as f:\n        f.write(sent.replace(\"\\n\",\"\")) # important.\n    os.system(\"cat temp.txt | paddlespeech tts --output {}\".format(output))\nfrom pydub import AudioSegment\nfrom functional_gen_typo_video_seq import gen_video\n# import matplotlib # doing this before importing moviepy editor. or we will fail.\n# matplotlib.use(\"TkAgg\")\n# from moviepy.editor import VideoFileClip\n# cannot mix moviepy with vidpy or we get fucked.\nfrom MediaInfo import MediaInfo\ndef merge_audio(asegs):\n    audio_3 = AudioSegment.empty() #shit\n    for seg in asegs:",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py:1-35"
    },
    "2637": {
        "file_id": 290,
        "content": "The code imports necessary libraries and defines functions for handling sentences, obtaining speech output, and merging audio segments. It also sets up a function that generates a video using the functional_gen_typo_video_seq module. The code uses bash scripts and external tools like PaddleSpeech and MediaInfo to manipulate text-to-speech and audio/video files.",
        "type": "comment"
    },
    "2638": {
        "file_id": 290,
        "content": "        try:\n            audio_3 = audio_3.append(seg,crossfade=100) # also shit.\n        except:\n            audio_3 = audio_3.append(seg,crossfade=0) # also shit.\n    return audio_3\n    # audio_3.export(\"audio_3.wav\", format=\"wav\")\ndef gen_typography_part2(intro_text, bgm_path,target_video):\n    # intro_text = \"\"\"塔罗牌，由“TAROT”一词音译而来，被称为“大自然的奥秘库”。抽取一张塔罗牌，今天的你会是怎样的呢？\"\"\"\n    os.system(\"bash kill_pdspc.sh\")\n    sents = split_sentences(intro_text)\n    # breakpoint()\n    voice_dir = \"voice\"\n    video_dir = \"video\"\n    os.system(\"rm -rf {}\".format(voice_dir))\n    os.system(\"rm -rf {}\".format(video_dir))\n    os.mkdir(\"{}\".format(voice_dir))\n    os.mkdir(\"{}\".format(video_dir))\n    index = 0\n    voice_clips = []\n    video_names = []\n    for i,sent in enumerate(sents):\n        print(\"READING:\",sent)\n        aname = \"{}/{}.wav\".format(voice_dir,i)\n        get_speech(sent,aname)\n        lsent = len(sent)\n        # if no audio then just skip.\n        if not os.path.exists(aname):\n            index += lsent\n            continue",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py:36-66"
    },
    "2639": {
        "file_id": 290,
        "content": "This code is attempting to generate typography for a video using voice and pictures. It first clears the existing voice and video directories, then creates new ones. It splits the input text into sentences, and for each sentence, it attempts to get speech audio from that sentence and create a corresponding picture. If no audio is found, it skips that sentence. Finally, it returns the generated audio.",
        "type": "comment"
    },
    "2640": {
        "file_id": 290,
        "content": "        seg = AudioSegment.from_wav(aname)\n        duration = seg.duration_seconds\n        voice_clips.append(seg)\n        # get the duration you fuck.\n        # breakpoint()\n        current_indexs = list(range(index,index+lsent))\n        # you can generate video for it.\n        index += lsent\n        vname = \"{}/{}.mp4\".format(video_dir,i)\n        gen_video(vname,current_indexs,duration) # where from?\n        video_names.append(vname)\n    # and finally?\n    final_video = \"{}/final_video.mp4\".format(video_dir)\n    final_audio = \"{}/final_audio.wav\".format(voice_dir)\n    audio_merged = merge_audio(voice_clips)\n    # bgm_path = \"/root/Desktop/works/bilibili_tarot/some_bgm.mp3\"\n    bgm = AudioSegment.from_mp3(bgm_path)\n    # duration2 = audio_merged.duration_seconds\n    # bgm = bgm[:duration2*1000] # really?\n    # breakpoint()\n    # audio_merged = audio_merged.overlay(audio_merged,bgm,loop=True)  #wtf?\n    audio_merged = audio_merged.overlay(bgm,loop=True)\n    # audio_merged = audio_merged.normalize()\n    # is it needed?",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py:67-91"
    },
    "2641": {
        "file_id": 290,
        "content": "This code generates videos for each segment of audio and appends the video names to a list. It then combines all audio clips into one merged audio file, overlays background music, and saves the final audio and video files. The code also includes debugging tools like breakpoint() to help with troubleshooting.",
        "type": "comment"
    },
    "2642": {
        "file_id": 290,
        "content": "    # shit.\n    audio_merged.export(final_audio, format=\"wav\")\n    final_video2 = \"{}/final_video2.mp4\".format(video_dir)\n    with open(\"mylist.txt\",\"w+\") as f:\n        for n in video_names:\n            f.write(\"file \"+n+\"\\n\")\n    os.system(\"ffmpeg -f concat -safe 0 -i mylist.txt -c copy {}\".format(final_video))\n    # output_length = VideoFileClip(final_video).duration\n    output_length = MediaInfo(filename=final_video).getInfo()[\"videoDuration\"]\n    output_length = float(output_length)\n    input_length = AudioSegment.from_wav(final_audio).duration_seconds\n    tempo = input_length/output_length\n    t_a,t_b = tempo.as_integer_ratio()\n    os.system('ffmpeg -i {} -i {} -c:v copy -c:a aac -filter:a \"atempo={}/{}\" -map 0:v:0 -map 1:a:0 {}'.format(final_video,final_audio,t_a,t_b,final_video2))\n    shutil.move(final_video2,target_video)\ndef gen_typography_part3(intro_text, target_video): #slient\n    # intro_text = \"\"\"塔罗牌，由“TAROT”一词音译而来，被称为“大自然的奥秘库”。抽取一张塔罗牌，今天的你会是怎样的呢？\"\"\"\n    os.system(\"bash kill_pdspc.sh\")\n    sents = split_sentences(intro_text)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py:92-114"
    },
    "2643": {
        "file_id": 290,
        "content": "This code performs video and audio processing, using ffmpeg commands to merge and manipulate the files. It exports an audio file in wav format, creates a mylist.txt file with video names, concatenates videos using ffmpeg, calculates the tempo between audio and video duration, applies the tempo to the final audio track, and finally moves the final video to the target location. This function also includes a shell command to kill pdspc process when finished.",
        "type": "comment"
    },
    "2644": {
        "file_id": 290,
        "content": "    # breakpoint()\n    voice_dir = \"voice\"\n    video_dir = \"video\"\n    os.system(\"rm -rf {}\".format(voice_dir))\n    os.system(\"rm -rf {}\".format(video_dir))\n    os.mkdir(\"{}\".format(voice_dir))\n    os.mkdir(\"{}\".format(video_dir))\n    index = 0\n    voice_clips = []\n    video_names = []\n    for i,sent in enumerate(sents):\n        print(\"READING:\",sent)\n        aname = \"{}/{}.wav\".format(voice_dir,i)\n        get_speech(sent,aname)\n        lsent = len(sent)\n        # if no audio then just skip.\n        if not os.path.exists(aname):\n            index += lsent\n            continue\n        seg = AudioSegment.from_wav(aname)\n        duration = seg.duration_seconds\n        voice_clips.append(seg)\n        # get the duration you fuck.\n        # breakpoint()\n        current_indexs = list(range(index,index+lsent))\n        # you can generate video for it.\n        index += lsent\n        vname = \"{}/{}.mp4\".format(video_dir,i)\n        gen_video(vname,current_indexs,duration) # where from?\n        video_names.append(vname)\n    # and finally?",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py:115-147"
    },
    "2645": {
        "file_id": 290,
        "content": "This code removes existing voice and video directories, creates new ones, reads sentences, saves corresponding audio files for each sentence, checks if audio files are generated correctly, generates videos based on the sentences and their respective positions in the text, and stores the names of generated videos.",
        "type": "comment"
    },
    "2646": {
        "file_id": 290,
        "content": "    final_video = \"{}/final_video.mp4\".format(video_dir)\n    final_audio = \"{}/final_audio.wav\".format(voice_dir)\n    audio_merged = merge_audio(voice_clips)\n    # bgm_path = \"/root/Desktop/works/bilibili_tarot/some_bgm.mp3\"\n    # bgm = AudioSegment.from_mp3(bgm_path)\n    # duration2 = audio_merged.duration_seconds\n    # bgm = bgm[:duration2*1000] # really?\n    # breakpoint()\n    # audio_merged = audio_merged.overlay(audio_merged,bgm,loop=True)  #wtf?\n    # audio_merged = audio_merged.overlay(bgm,loop=True)\n    # audio_merged = audio_merged.normalize()\n    # is it needed?\n    # shit.\n    audio_merged.export(final_audio, format=\"wav\")\n    final_video2 = \"{}/final_video2.mp4\".format(video_dir)\n    with open(\"mylist.txt\",\"w+\") as f:\n        for n in video_names:\n            f.write(\"file \"+n+\"\\n\")\n    os.system(\"ffmpeg -f concat -safe 0 -i mylist.txt -c copy {}\".format(final_video))\n    # output_length = VideoFileClip(final_video).duration\n    output_length = MediaInfo(filename=final_video).getInfo()[\"videoDuration\"]",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py:148-170"
    },
    "2647": {
        "file_id": 290,
        "content": "This code is performing audio and video merging, exporting the final audio file, creating a mylist.txt file for ffmpeg concatenation, and determining the output length of the final video. The code seems to have undergone revisions as there are comments stating \"wtf?\", \"shit.\", and \"is it needed?\" suggesting possible confusion or uncertainty about certain parts of the code.",
        "type": "comment"
    },
    "2648": {
        "file_id": 290,
        "content": "    output_length = float(output_length)\n    input_length = AudioSegment.from_wav(final_audio).duration_seconds\n    tempo = input_length/output_length\n    t_a,t_b = tempo.as_integer_ratio()\n    os.system('ffmpeg -i {} -i {} -c:v copy -c:a aac -filter:a \"atempo={}/{}\" -map 0:v:0 -map 1:a:0 {}'.format(final_video,final_audio,t_a,t_b,final_video2))\n    shutil.move(final_video2,target_video)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_voice_with_pictures.py:171-176"
    },
    "2649": {
        "file_id": 290,
        "content": "This code calculates the tempo of an audio file and then applies it to another audio-video file using FFMPEG. It then moves the resulting file to a specified target location.",
        "type": "comment"
    },
    "2650": {
        "file_id": 291,
        "content": "/tests/bilibili_practices/bilibili_tarot/functional_generate_demo_tarot.py",
        "type": "filepath"
    },
    "2651": {
        "file_id": 291,
        "content": "This code generates a tarot image sequence, applies various filters and effects, resizes videos, pads them if necessary, compresses audio, and merges videos using FFmpeg commands.",
        "type": "summary"
    },
    "2652": {
        "file_id": 291,
        "content": "import os\nfrom vidpy import Clip, Composition  #many shitty things...\n# tarot_target = \"/root/Desktop/works/bilibili_tarot/tarot_pictures/0_THE_FOOL.jpg\"\nimport random\ndef gen_tarot(tarot_target,bgm_path,final_output):\n    os.system(\"rm tarot_demo.mp4\")\n    fps =60\n    # myprofile = {'width': 1320, 'height': 2644} # wtf?\n    # just create profile from it. are you sure?\n    clip = Clip(tarot_target, output_fps=fps,start=0, end=16,override=True)\n    # clip.edgeglow()\n    # clip.crop\n    # 1320x2645 # unbelievable.\n    # clip.fx(\"\",{})\n    # clip.resize(w=1920, h=1080, distort=True)\n    # distort=False\n    c_w = clip.width\n    c_h = clip.height\n    # comp = Composition([clip])\n    clip.dither(amount=0.07) # the greater the better.\n    clip.fadein(0.5)      # fade the clip in over 1 second\n    # clip.fadeout(3.5)   # fade the clip over 0.5 seconds\n    # clip.glow(3.5)         # add a glow effect\n    clip.spin(4, axis=\"z\")\n    clip.vignette()\n    clip.dust()\n    clip.hue(shift = 1-random.random()*0.5)\n    clip.pixelize(width = 0.005,height=0.01)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_generate_demo_tarot.py:1-30"
    },
    "2653": {
        "file_id": 291,
        "content": "Code snippet imports necessary libraries, defines a function for generating a tarot image sequence, and applies various filters and effects to the input image. The function generates a random hue shift, pixelizes the image, adds a vignette effect, spins the image on the z-axis, and fades the clip in and out. The code uses overridden parameters for output resolution and aspect ratio, potentially causing inconsistencies or errors.",
        "type": "comment"
    },
    "2654": {
        "file_id": 291,
        "content": "    # clip.invert()\n    # clip.luminance\n    # clip.charcoal()\n    # clip.crop(right=c_w,bottom=c_h)\n    clip.save(\"tarot_demo.mp4\", fps=60,duration = 3,width=c_w,height=c_h) # good.\n    # print(c_w,c_h)\n    # 720 576\n    r1 = c_w/c_h\n    target_w, target_h = 1920, 1080\n    r2 = target_w/ target_h\n    if r1 < r2:\n        os.system('ffmpeg -y -i tarot_demo.mp4  -vf \"scale=-1:{},pad={}:ih:(ow-iw)/2\"  tarot_demo2.mp4'.format(target_h,target_w))\n    else:\n        os.system('ffmpeg -y -i tarot_demo.mp4  -vf \"scale={}:-1,pad=iw:{}:0:(oh-ih)/2\"  tarot_demo2.mp4'.format(target_w,target_h))\n    os.system(\"ffmpeg -y -i {} -i {} -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest {}\".format(\"tarot_demo2.mp4\",bgm_path,final_output))\n    os.system(\"rm -rf tarot_demo2.mp4\")\n    os.system(\"rm -rf tarot_demo.mp4\")",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_generate_demo_tarot.py:31-49"
    },
    "2655": {
        "file_id": 291,
        "content": "The code resizes and pads a video, applies audio compression, then deletes intermediate files. It uses FFmpeg commands to scale the video, pad it if necessary, compress audio, and merge videos.",
        "type": "comment"
    },
    "2656": {
        "file_id": 292,
        "content": "/tests/bilibili_practices/bilibili_tarot/all_typography.py",
        "type": "filepath"
    },
    "2657": {
        "file_id": 292,
        "content": "This code generates typography for a video and stores it in a specific format, using functions `gen_typography_part1`, `gen_typography_part2`, and `kill_script()`. It imports modules for creating files, executing scripts, and generating intermediate videos.",
        "type": "summary"
    },
    "2658": {
        "file_id": 292,
        "content": "from tarot_descriptions import *\n# mdict, smdict2\nimport os\ndef gen_typography_part1(content):\n    with open(\"demo_text.log\",\"w+\",encoding=\"utf8\") as f:\n        f.write(content)\n    os.system(\"xvfb-run -s '-screen 0 1920x1080x24' python3 scriptable_generate_typography_with_voice.py\")\ndef kill_script():\n    os.system(\"bash kill_xb.sh\")\ntyp_0 = \"typo_0\"\ntyp_1 = \"typo_1\"\n# os.system(\"rm -rf {}\".format(typ_0))\n# os.system(\"rm -rf {}\".format(typ_1))\n# os.mkdir(typ_0)\n# os.mkdir(typ_1)\nfrom functional_voice_with_pictures import gen_typography_part2\ninter_text = \"\"\"再抽取一张牌吧~\"\"\"\nbgm_path = \"/root/Desktop/works/bilibili_tarot/tarot_random_shuffle.mp3\"\ntarget_video = \"intermediate_video.mp4\"\nos.system(\"rm {}\".format(target_video))\nkill_script()\n# v = mdict[k]\nv = inter_text\ngen_typography_part1(v)\n# target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\ngen_typography_part2(v,bgm_path,target_video)\nkill_script()\nintro_text = \"\"\"塔罗牌，是一种针对人、事、物进行分析、预测和提供建议的工具，被称为“大自然的奥秘库”。\n抽取一张塔罗牌，今天的你会是怎样的呢？\"\"\"\n# intro_text =\n# bgm_path = \"/root/Desktop/works/bilibili_tarot/tarot_random_shuffle.mp3\"",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography.py:1-46"
    },
    "2659": {
        "file_id": 292,
        "content": "The code imports modules and defines functions for generating typography with voice and video. It creates files, executes scripts, and generates intermediate videos for a tarot reading process. It also generates a final video after killing the script.",
        "type": "comment"
    },
    "2660": {
        "file_id": 292,
        "content": "# target_video = \"intro_video.mp4\"\n# os.system(\"rm {}\".format(target_video))\n# kill_script()\n# # v = mdict[k]\n# v = intro_text\n# gen_typography_part1(v)\n# # target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\n# gen_typography_part2(v,bgm_path,target_video)\n# kill_script()\nbgms = [\"you_got_me_acc.wav\", \"tarot_desc_acc.wav\"]\n# outro_text = \"\"\"今天的你运气不错哦～\n# 喜欢的话请分享点赞，一键三联哦～\"\"\"\n# bgm_path = bgms[0]\n# target_video = \"outro_video.mp4\"\n# os.system(\"rm {}\".format(target_video))\n# kill_script()\n# # v = mdict[k]\n# v = outro_text\n# gen_typography_part1(v)\n# # target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\n# gen_typography_part2(v,bgm_path,target_video)\n# kill_script()\nimport random\n# for k in mdict.keys():\n#     if k !=16:\n#         continue\n#     kill_script()\n#     v = mdict[k]\n#     gen_typography_part1(v)\n#     target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\n#     gen_typography_part2(v,random.choice(bgms),target_video)\n#     kill_script()\n# for k in smdict.keys():\n#     v = smdict[k]\n#     # kill_script()\n#     # v = mdict[k]",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography.py:48-93"
    },
    "2661": {
        "file_id": 292,
        "content": "The code removes the target video, generates typography for intro and outro text using different background music, and randomly selects a background music from the given list for each card in mdict and smdict.",
        "type": "comment"
    },
    "2662": {
        "file_id": 292,
        "content": "#     gen_typography_part1(v)\n#     target_video = \"/\".join([typ_1,\"{}.mp4\".format(k)])\n#     gen_typography_part2(v,random.choice(bgms),target_video)\n#     kill_script()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography.py:94-97"
    },
    "2663": {
        "file_id": 292,
        "content": "This code section generates typography for a video and stores it in a specific format. It first calls a function `gen_typography_part1` passing some parameter v, then combines the typography name with the video number as the file name. The next step is to call another function `gen_typography_part2`, which takes two parameters: v and a randomly chosen bgm (background music) from some list of choices. It also passes the target video file as an argument. Lastly, it calls the `kill_script()` function to terminate the script execution.",
        "type": "comment"
    },
    "2664": {
        "file_id": 293,
        "content": "/tests/bilibili_practices/bilibili_tarot/functional_gen_typo_video_seq.py",
        "type": "filepath"
    },
    "2665": {
        "file_id": 293,
        "content": "This function generates a video sequence with input \"seq\" and duration, applies filters to each clip, uses vidpy library for handling video composition, and saves the final composition as a video file.",
        "type": "summary"
    },
    "2666": {
        "file_id": 293,
        "content": "# seq = [0,1,2,3,4,5,6] # 7\n# duration = 4\nfrom vidpy import Composition, Clip\ndef gen_video(vname, seq, duration):\n    mduration = duration / len(seq)\n    clips = []\n    width,height =1920,1080\n    fps=60\n    orig_fps = 24\n    shift = fps/orig_fps\n    for i,s in enumerate(seq):\n        codec = str(s)\n        codec = \"0\"*(4-len(codec)) + codec\n        path = \"/root/Desktop/works/bilibili_tarot/demo_typography/screenshot{}.png\".format(codec)\n        start = i*mduration\n        end = start + mduration\n        print(start,end)\n        clip = Clip(path,output_fps=fps,start=0,end=mduration*shift,offset = start*shift,profile_override = {\"fps\":60,\"width\": width, \"height\": height})\n        clip.vignette()\n        clip.dust()\n        # clip.charcoal()\n        clip.dither(amount=0.10)\n        # clip.\n        # clip.pixelize()\n        clip.pixelize(width = 0.002,height=0.002)\n        clips.append(clip)\n    # breakpoint()\n    # # maybe some other bgm.\n    # bgm = Clip(bgm_path,start=0)\n    # clips.append(bgm)\n    # breakpoint()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_gen_typo_video_seq.py:1-39"
    },
    "2667": {
        "file_id": 293,
        "content": "This function generates a video sequence based on input \"seq\" and duration, with each clip corresponding to a number in the sequence. It reads image files from \"/root/Desktop/works/bilibili_tarot/demo_typography/\" and applies various filters (vignette, dust, dithering, pixelize) to each clip before adding it to the list of clips. The function uses vidpy library for handling video composition and Clip class for each image frame.",
        "type": "comment"
    },
    "2668": {
        "file_id": 293,
        "content": "    comp = Composition(clips,duration=duration,fps=fps,width=width,height=height)\n    comp.save(vname,fps=60,duration = duration,width=width,height=height)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/functional_gen_typo_video_seq.py:40-42"
    },
    "2669": {
        "file_id": 293,
        "content": "The code above creates a Composition object with the specified clips, duration, fps, width, and height. Then, it saves this composition as a video file under the given 'vname' while maintaining the same settings.",
        "type": "comment"
    },
    "2670": {
        "file_id": 294,
        "content": "/tests/bezier_paddlehub_dogcat_detector_serving/server.py",
        "type": "filepath"
    },
    "2671": {
        "file_id": 294,
        "content": "This code changes the directory, appends current path to sys.path, and imports specific configurations and classes for a Bezier PaddleHub ResNet50 Image DogCatDetectorServer in pyjom project.",
        "type": "summary"
    },
    "2672": {
        "file_id": 294,
        "content": "import sys\nimport os\ndef changeDirForImport():\n    os.chdir(\"/root/Desktop/works/pyjom\")\n    sys.path.append(\".\")\nif __name__ == '__main__':\n    changeDirForImport()\n    from pyjom.config.shared import pyjom_config\n    pyjom_config['BEZIER_PADDLE_RESNET50_IMAGE_DOG_CAT_DETECTOR_SERVER_INSTANCE']=True\n    from pyjom.imagetoolbox import bezierPaddleHubResnet50ImageDogCatDetectorServer\n    bezierPaddleHubResnet50ImageDogCatDetectorServer()",
        "type": "code",
        "location": "/tests/bezier_paddlehub_dogcat_detector_serving/server.py:1-13"
    },
    "2673": {
        "file_id": 294,
        "content": "This code changes the directory, appends current path to sys.path, and imports specific configurations and classes for a Bezier PaddleHub ResNet50 Image DogCatDetectorServer in pyjom project.",
        "type": "comment"
    },
    "2674": {
        "file_id": 295,
        "content": "/tests/bezier_paddlehub_dogcat_detector_serving/client.py",
        "type": "filepath"
    },
    "2675": {
        "file_id": 295,
        "content": "The code reads an image file from a specific location, changes the working directory for importing necessary libraries, initializes a client and server object for detecting dog/cat images using PaddleHub's ResNet50 model, reads the test image using OpenCV, performs detection on the image with the client object, and finally prints the result.",
        "type": "summary"
    },
    "2676": {
        "file_id": 295,
        "content": "test_image = \"/root/Desktop/works/pyjom/samples/image/dog_with_text.jpg\"\nfrom server import changeDirForImport\nchangeDirForImport()\nfrom pyjom.imagetoolbox import bezierPaddleHubResnet50ImageDogCatDetectorClient,bezierPaddleHubResnet50ImageDogCatDetectorServerChecker\nimport cv2\ntest_image = cv2.imread(test_image)\nbezierPaddleHubResnet50ImageDogCatDetectorServerChecker()\nresult = bezierPaddleHubResnet50ImageDogCatDetectorClient(test_image)\nprint(\"RESULT?\",result)",
        "type": "code",
        "location": "/tests/bezier_paddlehub_dogcat_detector_serving/client.py:1-10"
    },
    "2677": {
        "file_id": 295,
        "content": "The code reads an image file from a specific location, changes the working directory for importing necessary libraries, initializes a client and server object for detecting dog/cat images using PaddleHub's ResNet50 model, reads the test image using OpenCV, performs detection on the image with the client object, and finally prints the result.",
        "type": "comment"
    },
    "2678": {
        "file_id": 296,
        "content": "/tests/basic_pitch_multi_midi_conversion/test.sh",
        "type": "filepath"
    },
    "2679": {
        "file_id": 296,
        "content": "Creates a new folder called \"output_path\", then uses the 'basic-pitch' command to convert MIDI files from \"/media/root/help/pyjom/tests/bilibili_practices/bilibili_tarot/some_bgm.mp3\" into audio format, saving them in the newly created folder.",
        "type": "summary"
    },
    "2680": {
        "file_id": 296,
        "content": "mkdir output_path\nbasic-pitch --sonify-midi output_path /media/root/help/pyjom/tests/bilibili_practices/bilibili_tarot/some_bgm.mp3",
        "type": "code",
        "location": "/tests/basic_pitch_multi_midi_conversion/test.sh:1-2"
    },
    "2681": {
        "file_id": 296,
        "content": "Creates a new folder called \"output_path\", then uses the 'basic-pitch' command to convert MIDI files from \"/media/root/help/pyjom/tests/bilibili_practices/bilibili_tarot/some_bgm.mp3\" into audio format, saving them in the newly created folder.",
        "type": "comment"
    },
    "2682": {
        "file_id": 297,
        "content": "/tests/dapp_ethereum_python_crypto/test.py",
        "type": "filepath"
    },
    "2683": {
        "file_id": 297,
        "content": "The code uses Web3 to connect to a local Ethereum node, imports necessary libraries, checks connection status and account balance, unlocks accounts, sends transactions, and verifies received funds.",
        "type": "summary"
    },
    "2684": {
        "file_id": 297,
        "content": "from web3 import Web3\n# testnet, bitcoind, regtest\n# https://bitcoin.stackexchange.com/questions/42026/is-it-possible-to-use-bitcoind-as-a-private-blockchain\n# mine only when pending transaction happens:\n# https://ethereum.stackexchange.com/questions/3151/how-to-make-miner-to-mine-only-when-there-are-pending-transactions\n# maybe you want money even if without transaction, or low in cash.\n# https://hackernoon.com/hands-on-creating-your-own-local-private-geth-node-beginner-friendly-3d45902cc612\nlink = \"/root/.ethereum/geth.ipc\"\nweb3 = Web3(Web3.IPCProvider(link))\nprint(web3.isConnected())\n# account_genesis = \"0xde478bde26d711414fae26133e759d8a82a202ab\"  # aka: eth.coinbase\n# account_genesis = \"0x6fe20a7157fdb705278fffda4ea0ebf4694f31ea\"\naccount_genesis = \"0xd6e79c8d5b7d41cc1a3b98373c98618ea267852f\"\naccount_genesis = Web3.toChecksumAddress(account_genesis)\npassword_genesis = \"abcdefg\"\n# let's see!\n# target_account = \"0x033799af9b29e1d7dbf3c8dd64647df345f67bf1\"\ntarget_account = \"0x463f061d2add7987e2a7d14920e18194107ea991\"",
        "type": "code",
        "location": "/tests/dapp_ethereum_python_crypto/test.py:1-26"
    },
    "2685": {
        "file_id": 297,
        "content": "The code imports Web3, sets the IPC link to connect to a local Ethereum node, checks the connection status, assigns an account address and password, and specifies a target account.",
        "type": "comment"
    },
    "2686": {
        "file_id": 297,
        "content": "target_account = Web3.toChecksumAddress(target_account)\n# you was connected ethereum to mainnet! not good.\n# anyway, we need money!\nb = web3.eth.get_balance(web3.eth.coinbase)\nprint(b)\n# proof of authority, puppeth\n## need password!\nweb3.geth.personal.unlock_account(web3.eth.coinbase, password_genesis)\nweb3.eth.send_transaction(\n    {\n        \"to\": target_account,\n        \"from\": web3.eth.coinbase,\n        \"value\": 1,\n    }\n)\nweb3.geth.personal.lock_account(web3.eth.coinbase)\n# you can choose to use 'with' statement.\nb = web3.eth.get_balance(target_account)\nprint(b)\n# still no money! fuck.",
        "type": "code",
        "location": "/tests/dapp_ethereum_python_crypto/test.py:27-52"
    },
    "2687": {
        "file_id": 297,
        "content": "Code connects to Ethereum mainnet, checks balance of the coinbase account, unlocks account using a password, sends transaction to target_account, and verifies if funds have been received.",
        "type": "comment"
    },
    "2688": {
        "file_id": 298,
        "content": "/tests/dapp_ethereum_python_crypto/README.md",
        "type": "filepath"
    },
    "2689": {
        "file_id": 298,
        "content": "The code is expressing the difficulty in validating a 'hacker' program within AGI and the need to create dummy crypto elements for testing purposes.",
        "type": "summary"
    },
    "2690": {
        "file_id": 298,
        "content": "not sure how to validate my 'hacker' program in AGI. just create some dummy crypto things.",
        "type": "code",
        "location": "/tests/dapp_ethereum_python_crypto/README.md:1-1"
    },
    "2691": {
        "file_id": 298,
        "content": "The code is expressing the difficulty in validating a 'hacker' program within AGI and the need to create dummy crypto elements for testing purposes.",
        "type": "comment"
    },
    "2692": {
        "file_id": 299,
        "content": "/tests/cpm_chinese_chitchat_model_gpt2/test.sh",
        "type": "filepath"
    },
    "2693": {
        "file_id": 299,
        "content": "This code changes the directory to GPT2-chitchat, checks RAM consumption and urges to buy new RAM for CPU model testing. It runs 'interact.py' with no CUDA and using a specific model path.",
        "type": "summary"
    },
    "2694": {
        "file_id": 299,
        "content": "# no fucking gpu. just test how much RAM it consumes.\ncd GPT2-chitchat # 1.8GB mem consumption. freaking hell.\n# BUY NEW RAM AND RUN MODELS ON CPU!\npython3 interact.py --no_cuda --model_path ../model",
        "type": "code",
        "location": "/tests/cpm_chinese_chitchat_model_gpt2/test.sh:1-4"
    },
    "2695": {
        "file_id": 299,
        "content": "This code changes the directory to GPT2-chitchat, checks RAM consumption and urges to buy new RAM for CPU model testing. It runs 'interact.py' with no CUDA and using a specific model path.",
        "type": "comment"
    },
    "2696": {
        "file_id": 300,
        "content": "/tests/cpm_chinese_chitchat_model_gpt2/init.sh",
        "type": "filepath"
    },
    "2697": {
        "file_id": 300,
        "content": "Code is cloning the GPT2-chitchat repository with a single commit from GitHub.",
        "type": "summary"
    },
    "2698": {
        "file_id": 300,
        "content": "git clone --depth 1 https://github.com/yangjianxin1/GPT2-chitchat",
        "type": "code",
        "location": "/tests/cpm_chinese_chitchat_model_gpt2/init.sh:1-1"
    },
    "2699": {
        "file_id": 300,
        "content": "Code is cloning the GPT2-chitchat repository with a single commit from GitHub.",
        "type": "comment"
    }
}