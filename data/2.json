{
    "200": {
        "file_id": 26,
        "content": "import pixie\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nimport cv2\ndef getImageW2H(image_path):\n    image = cv2.imread(image_path)\n    height, width = image.shape[:2]\n    w2h = width / height\n    return w2h\nTMP_DIR_PATH = \"/dev/shm/qq_ad\"\nimport shutil\nimport os\nif os.path.exists(TMP_DIR_PATH):\n    shutil.rmtree(TMP_DIR_PATH)\nos.mkdir(TMP_DIR_PATH)\nimport random\ndef generateFakeVideoStats():\n    play_count = \"{:.1f}万\".format(\n        random.randint(100, 1000) * 0.1\n    )  # anyway both int and str are compatible\n    comment_count = random.randint(100, 1000)\n    danmaku_count = random.randint(500, 3000)\n    return play_count, comment_count, danmaku_count\nRESOURCE_PATH = \"/root/Desktop/works/pyjom/tests/bilibili_video_recommendation_server\"\nQRCODE_PATH = \"MyQRCode1.png\"\nFONT_PATH = \"wqy-microhei0.ttf\"\nFONT_BOLD_PATH = \"wqy-microhei1.ttf\"\nCOVER_PATH = \"sample_cover.jpg\"\nPLAY_BUTTON_PATH = \"play_white_b.png\"\nBILIBILI_LOGO_PATH = \"bili_white_b_cropped.png\"\nAD_LOCK = \"ad_lock.lock\"\nimport filelock",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:1-46"
    },
    "201": {
        "file_id": 26,
        "content": "The code initializes necessary libraries and functions, creates a temporary directory for storing images and files, generates random video stats, defines file paths, and locks the ad using FileLock.",
        "type": "comment"
    },
    "202": {
        "file_id": 26,
        "content": "def getAdLock(lockPath: str = os.path.join(TMP_DIR_PATH, AD_LOCK)):\n    return filelock.FileLock(lockPath)\n# use this decorator outside. not here. not any function written in here.\ndef withAdLock(func):\n    def innerFunc(*args, **kwargs):\n        with getAdLock():\n            return func(*args, **kwargs)\n    return innerFunc\nRESOURCES_RELATIVE_PATH = [\n    FONT_PATH,\n    FONT_BOLD_PATH,\n    COVER_PATH,\n    PLAY_BUTTON_PATH,\n    BILIBILI_LOGO_PATH,\n]\nOUTPUT_STANDALONE = \"ad_2_standalone_cover.png\"\nOUTPUT_PATH = \"ad_2.png\"\nOUTPUT_MASKED_PATH = \"ad_2_mask.png\"\nimport progressbar\ndef prepareMaterials(tmpDirPath: str = TMP_DIR_PATH, resourcePath: str = RESOURCE_PATH):\n    print(\"Preparing materials...\")\n    for path in progressbar.progressbar(RESOURCES_RELATIVE_PATH):\n        shutil.copy(os.path.join(resourcePath, path), os.path.join(tmpDirPath, path))\nprepareMaterials()\ndef generateBilibiliShortLinkMethod2(videoLink: str):\n    apiUrl = (\n        \"https://service-ijd4slqi-1253419200.gz.apigw.tencentcs.com/release/short_url\"",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:49-89"
    },
    "203": {
        "file_id": 26,
        "content": "This code defines a function `getAdLock` for acquiring a file lock, a decorator `withAdLock` to use the lock around a function execution, and prepares materials by copying resources to a temporary directory. The code also includes a function `generateBilibiliShortLinkMethod2` that calls an API endpoint to generate a short link on Bilibili using a given video link.",
        "type": "comment"
    },
    "204": {
        "file_id": 26,
        "content": "    )\n    # longUrl = \"https://www.bilibili.com/video/BV1Wv41157Wz\"\n    longUrl = videoLink\n    import urllib.parse as urlparse\n    # params = {\"url\": longUrl}\n    params = {\n        \"url\": urlparse.quote(longUrl).replace(\"/\", \"%2F\"),\n        \"href\": \"https://xiaojuzi.fun/bili-short-url/\",\n    }\n    # print(params)\n    # exit()\n    headers = {\n        \"accept\": \"*/*\",\n        \"accept-language\": \"en-US,en;q=0.9\",\n        \"if-none-match\": 'W/\"35-oPDNsqBGaZKqGe83GW6wem+lkww\"',\n        \"sec-ch-ua\": '\"Google Chrome\";v=\"105\", \"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"105\"',\n        \"sec-ch-ua-mobile\": \"?0\",\n        \"sec-ch-ua-platform\": '\"macOS\"',\n        \"sec-fetch-dest\": \"empty\",\n        \"sec-fetch-mode\": \"cors\",\n        \"sec-fetch-site\": \"cross-site\",\n        \"Referer\": \"https://xiaojuzi.fun/\",\n        \"Referrer-Policy\": \"strict-origin-when-cross-origin\",\n        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\",  # this is important.\n    }",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:90-116"
    },
    "205": {
        "file_id": 26,
        "content": "This code snippet is preparing a request to shorten a video link. It defines the long URL, uses URL parsing to format the parameters, and sets headers for the HTTP request. The goal is to obtain a shortened version of the provided video link using the \"https://xiaojuzi.fun/bili-short-url/\" API.",
        "type": "comment"
    },
    "206": {
        "file_id": 26,
        "content": "    import requests\n    request_url = apiUrl + \"?url={url}&href={href}\".format(**params)\n    # request_url = 'https://service-ijd4slqi-1253419200.gz.apigw.tencentcs.com/release/short_url?url=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2FBV1Wv41157Wz&href=https://xiaojuzi.fun/bili-short-url/'\n    # print(request_url)\n    r = requests.get(request_url, headers=headers)\n    if r.status_code == 200:\n        # print(r.json())\n        r_json = r.json()\n        success = r_json.get(\"success\", False)\n        if success:\n            short_url = r_json.get(\"short_url\", None)\n            print(short_url)\n            return short_url\n    # starts with 'https://b23.tv'\ndef generateBilibiliShortLinkMethod1(\n    videoLink: str,\n):  # get bilibili user email address by asking them from chat. if they give the email address, send setu as gift. for other users, you may improvise. send video link, recommendations\n    url = \"https://api.bilibili.com/x/share/click\"\n    # burl = \"https://www.bilibili.com/read/cv19232041\" # my article with e-begging",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:118-139"
    },
    "207": {
        "file_id": 26,
        "content": "Code imports requests library, constructs a request URL with provided parameters, sends a GET request to the Bilibili API, and checks if the status code is 200. If so, it retrieves the short link from the response JSON and returns or prints it.",
        "type": "comment"
    },
    "208": {
        "file_id": 26,
        "content": "    burl = videoLink\n    data = {\n        \"build\": 6700300,\n        \"buvid\": 0,\n        \"oid\": burl,\n        \"platform\": \"android\",\n        \"share_channel\": \"COPY\",\n        \"share_id\": \"public.webview.0.0.pv\",\n        \"share_mode\": 3,\n    }\n    import requests\n    headers = {\n        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"\n    }\n    r = requests.post(\n        url, data=data, headers=headers\n    )  # maybe you two share the same user agent!\n    # we have the link!\n    if r.status_code == 200:\n        # print(r.content)\n        r_json = r.json()\n        code = r_json[\"code\"]\n        if code == 0:\n            link = r_json[\"data\"][\"content\"]\n            print(link)\n            return link\n    # fail, obviously.\ndef generateBilibiliShortLink(videoLink: str):\n    link = None\n    try:\n        link = generateBilibiliShortLinkMethod1(videoLink)\n        assert link is not None\n    except:\n        import traceback\n        traceback.print_exc()",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:140-178"
    },
    "209": {
        "file_id": 26,
        "content": "This code is trying to generate a Bilibili short link for a given videoLink. It first defines the necessary data, sets headers using a user-agent, and then sends a POST request to get the short link. If successful (status_code 200), it extracts the link from the returned JSON, prints it, and returns it. In case of failure or exceptions, it prints the traceback.",
        "type": "comment"
    },
    "210": {
        "file_id": 26,
        "content": "        link = generateBilibiliShortLinkMethod2(videoLink)\n        assert link is not None\n    return link\ndef makeQRCode(content: str, savePath: str):\n    # Importing library\n    import qrcode\n    # Encoding data using make() function\n    def makeAndSaveQrcode(data, save_path, debug=False):\n        img = qrcode.make(data)\n        if debug:\n            print(\"image type:\", type(img))\n        img.save(save_path)\n    data = content\n    save_path = savePath\n    makeAndSaveQrcode(data, save_path)\ndef generateQRCodeFromBVID(\n    bvid: str, qrCodeSavePath: str = os.path.join(TMP_DIR_PATH, QRCODE_PATH)\n):\n    videoLink = \"https://www.bilibili.com/video/{}\".format(bvid)\n    shortLink = generateBilibiliShortLink(videoLink)\n    makeQRCode(shortLink, qrCodeSavePath)\n    return shortLink\ndef generateBilibiliVideoAd(\n    bvid: str,\n    title_text: str,\n    image_link: str,\n    cover_path: str = os.path.join(TMP_DIR_PATH, COVER_PATH),\n):\n    import requests\n    r = requests.get(image_link)\n    with open(cover_path, \"wb\") as f:\n        c = r.content",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:179-219"
    },
    "211": {
        "file_id": 26,
        "content": "The code is used to generate a bilibili video ad. It imports the qrcode library, generates a QR code from the BVID, retrieves the short link of the video, and then saves it along with an image in the TMP_DIR_PATH directory. The image is downloaded using requests module and saved as a cover for the ad.",
        "type": "comment"
    },
    "212": {
        "file_id": 26,
        "content": "        f.write(c)\n    link = generateQRCodeFromBVID(bvid)\n    return (generateVideoAdUniversal(\n        videoStats=generateFakeVideoStats(),\n        title_text=title_text,\n        cover_path=cover_path,\n    ), link)\n# you must have some lock outside while using this.\ndef generateVideoAdUniversal(\n    videoStats=None,  # will it work?\n    night_mode: bool = True,\n    title_text: str = \"\",\n    framework_only: bool = False,\n    ad_width: int = 1000,\n    ad_height: int = 1000,\n    font_path: str = os.path.join(TMP_DIR_PATH, FONT_PATH),\n    font_bold_path: str = os.path.join(TMP_DIR_PATH, FONT_BOLD_PATH),\n    cover_path: str = os.path.join(TMP_DIR_PATH, COVER_PATH),\n    qrcode_path: str = os.path.join(TMP_DIR_PATH, QRCODE_PATH),\n    play_button_path: str = os.path.join(TMP_DIR_PATH, PLAY_BUTTON_PATH),\n    output_path: str = os.path.join(TMP_DIR_PATH, OUTPUT_PATH),\n    output_standalone: str = os.path.join(TMP_DIR_PATH, OUTPUT_STANDALONE),\n    output_masked_path: str = os.path.join(TMP_DIR_PATH, OUTPUT_MASKED_PATH),",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:220-244"
    },
    "213": {
        "file_id": 26,
        "content": "This function generates a video ad using the provided parameters. It writes the code to a file, generates a QR code, and returns a tuple containing the generated video ad and the QR code link. The function uses temporary directory paths for various resources.",
        "type": "comment"
    },
    "214": {
        "file_id": 26,
        "content": "    bilibili_logo_path: str = os.path.join(TMP_DIR_PATH, BILIBILI_LOGO_PATH),\n):\n    # fake these numbers.\n    # one extra space.\n    assert videoStats is not None\n    play_count, comment_count, danmaku_count = videoStats\n    assert title_text != \"\"\n    stats_text = \" {}播放 {}评论 {}弹幕\".format(play_count, comment_count, danmaku_count)\n    qrcode_scan_text = \"\\n\" + \"\\n\".join(list(\"扫码观看\"))\n    white = pixie.Color(1, 1, 1, 1)\n    black = pixie.Color(0, 0, 0, 1)\n    image = pixie.Image(ad_width, ad_height)\n    # we are creating this, not replacing qr code.\n    if not framework_only:\n        if night_mode:\n            image.fill(black)\n            # irreversible!\n        else:\n            image.fill(white)\n    else:\n        image2 = image.copy()  # as mask.\n    # place the cover.\n    cover_w2h = getImageW2H(cover_path)\n    cover_width = int(ad_width * 0.9)\n    cover_height = int(cover_width / cover_w2h)\n    cover_round_corner_radius = int(ad_width * 0.05)\n    cover = pixie.read_image(cover_path)\n    cover = cover.resize(cover_width, cover_height)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:245-274"
    },
    "215": {
        "file_id": 26,
        "content": "This code is setting up an image with various elements such as play count, comment count, danmaku count, and a QR code. It creates a white or black background depending on the night mode option, copies the image to create a mask, reads a cover image, and resizes it. The code uses Pixie for image manipulation, os for file paths, and other libraries for formatting and image reading.",
        "type": "comment"
    },
    "216": {
        "file_id": 26,
        "content": "    # cover gradient.\n    gradient_paint = pixie.Paint(pixie.LINEAR_GRADIENT_PAINT)\n    gradient_paint.gradient_handle_positions.append(\n        pixie.Vector2(100, int(cover_height) * 0.8)\n    )\n    gradient_paint.gradient_handle_positions.append(pixie.Vector2(100, cover_height))\n    gradient_paint.gradient_stops.append(pixie.ColorStop(pixie.Color(0, 0, 0, 0), 0))\n    gradient_paint.gradient_stops.append(pixie.ColorStop(pixie.Color(0, 0, 0, 0.3), 1))\n    cover_mask_path = pixie.Path()\n    cover_mask_path.rounded_rect(\n        0, 0, cover_width, cover_height, *([cover_round_corner_radius] * 4)\n    )\n    stroke_param = 100\n    stroke_width = int(ad_width / stroke_param)\n    stroke_width_half = int(ad_width / stroke_param / 2)\n    cover_mask_path2 = pixie.Path()\n    cover_round_corner_radius2 = int(cover_round_corner_radius * 0.85)\n    cover_mask_path2.rounded_rect(\n        stroke_width_half,\n        stroke_width_half,\n        cover_width - stroke_width,\n        cover_height - stroke_width,\n        *([cover_round_corner_radius2] * 4)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:275-302"
    },
    "217": {
        "file_id": 26,
        "content": "Creating a gradient paint for the cover and defining its positions and color stops. Defining paths and rectangles with rounded corners for cover mask creation, adjusting stroke parameters based on ad width.",
        "type": "comment"
    },
    "218": {
        "file_id": 26,
        "content": "    )\n    # path = cover_mask_path\n    # cover.fill_path(cover_mask_path, gradient_paint)\n    cover_mask = pixie.Mask(cover_width, cover_height)\n    cover_mask.fill_path(cover_mask_path)\n    cover.mask_draw(cover_mask)\n    cover_transform_width = cover_transform_height = int((ad_width - cover_width) / 2)\n    cover_transform = pixie.translate(cover_transform_width, cover_transform_height)\n    if framework_only:\n        # image2.fill(black)\n        image2_paint = pixie.Paint(pixie.SOLID_PAINT)\n        image2_paint.color = white\n        image2.fill_path(cover_mask_path, image2_paint, cover_transform)\n    cover_stroke_paint = pixie.Paint(pixie.SOLID_PAINT)\n    cover_stroke_paint.color = pixie.parse_color(\"#FC427B\")\n    image.stroke_path(\n        cover_mask_path,\n        cover_stroke_paint,\n        cover_transform,\n        stroke_width=stroke_width,\n    )\n    if not framework_only:\n        image.draw(cover, cover_transform)  # you can choose to discard the cover\n    image.fill_path(cover_mask_path2, gradient_paint, cover_transform)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:303-334"
    },
    "219": {
        "file_id": 26,
        "content": "This code creates a mask, applies it to an image, and fills the resulting path with a gradient paint. It also has an optional step for white-filling another image, and discards the cover if not required.",
        "type": "comment"
    },
    "220": {
        "file_id": 26,
        "content": "    # now place the bilibili logo.\n    bilibili_logo = pixie.read_image(bilibili_logo_path)\n    bilibili_logo_w2h = getImageW2H(bilibili_logo_path)\n    bilibili_logo_width = int(ad_width * 0.2)\n    bilibili_logo_height = int(bilibili_logo_width / bilibili_logo_w2h)\n    bilibili_logo = bilibili_logo.resize(bilibili_logo_width, bilibili_logo_height)\n    bilibili_logo_transform = pixie.translate(\n        cover_transform_width + int(bilibili_logo_height / 8),\n        int(cover_transform_width + (bilibili_logo_height / 4)),\n    )\n    # bilibili_logo_transform = pixie.translate(\n    #     cover_transform_width, 0\n    # )\n    image.draw(bilibili_logo, bilibili_logo_transform)\n    # now place the play button.\n    play_button = pixie.read_image(play_button_path)\n    play_button_w2h = getImageW2H(play_button_path)\n    play_button_width = play_button_height = int(ad_width * 0.2)\n    play_button = play_button.resize(play_button_width, play_button_height)\n    play_button_transform = pixie.translate(\n        int(cover_transform_width + (cover_width - play_button_width) / 2),",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:336-361"
    },
    "221": {
        "file_id": 26,
        "content": "This code resizes bilibili logo and play button images according to ad width, and positions them on the image using Pixie library.",
        "type": "comment"
    },
    "222": {
        "file_id": 26,
        "content": "        int(cover_transform_width + (cover_height - play_button_height) / 2),\n    )\n    image.draw(play_button, play_button_transform)\n    # place some stats.\n    font = pixie.read_font(font_path)\n    font.size = int(ad_width * 0.04)\n    font.paint.color = pixie.Color(1, 1, 1, 1)\n    stats_transform = pixie.translate(\n        int(cover_transform_width * 1.3),\n        cover_transform_width + cover_height - int(font.size * 2),\n    )\n    image.fill_text(font, stats_text, transform=stats_transform)\n    # place the qrcode.\n    qrcode = pixie.read_image(qrcode_path)\n    qrcode_width = qrcode_height = int(0.3 * ad_width)\n    qrcode = qrcode.resize(qrcode_width, qrcode_height)\n    font = pixie.read_font(font_path)\n    font.size = int(ad_width * 0.04)\n    if night_mode:\n        font.paint.color = pixie.Color(1, 1, 1, 1)\n    else:\n        font.paint.color = pixie.Color(0, 0, 0, 1)\n    qrcode_scan_text_transform_x = int(ad_width - qrcode_width * 1.1 - font.size * 1)\n    qrcode_scan_text_transform = pixie.translate(\n        qrcode_scan_text_transform_x + qrcode_width,",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:362-390"
    },
    "223": {
        "file_id": 26,
        "content": "This code is placing a play button, statistics text, and QR code on an image. It adjusts the position of each element based on the image size and ad width. The font size and color are set according to night mode.",
        "type": "comment"
    },
    "224": {
        "file_id": 26,
        "content": "        int(ad_height - qrcode_height * 1.1),\n    )\n    image.fill_text(font, qrcode_scan_text, transform=qrcode_scan_text_transform)\n    qrcode_transform = pixie.translate(\n        int(ad_width - qrcode_width * 1.1 - font.size * 1.2),\n        int(ad_height - qrcode_height * 1.1),\n    )\n    qrcode_rounded_corner = int(0.05 * ad_width)\n    qrcode_stroke_path = pixie.Path()\n    qrcode_stroke_path.rounded_rect(\n        0, 0, qrcode_width, qrcode_height, *([qrcode_rounded_corner] * 4)\n    )\n    image.stroke_path(\n        qrcode_stroke_path,\n        cover_stroke_paint,\n        qrcode_transform,\n        stroke_width=stroke_width,\n    )\n    qrcode_mask = pixie.Mask(qrcode_width, qrcode_width)\n    qrcode_mask.fill_path(qrcode_stroke_path)\n    qrcode.mask_draw(qrcode_mask)\n    image.draw(qrcode, qrcode_transform)\n    # now for the title\n    font = pixie.read_font(font_bold_path)\n    font.size = int(ad_width * 0.06)\n    if night_mode:\n        font.paint.color = pixie.parse_color(\"#B0B0B0\")\n    else:\n        font.paint.color = pixie.parse_color(\"#4F4F4F\")",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:391-425"
    },
    "225": {
        "file_id": 26,
        "content": "This code generates a QR code for an ad and applies a mask to it, adjusting its size, position, corner radius, stroke width, and color based on ad dimensions. The font and color of the text are also set according to night mode or daylight conditions.",
        "type": "comment"
    },
    "226": {
        "file_id": 26,
        "content": "    # use some gray text.\n    # font.paint.color = pixie.parse_color(\"#4F42B5\")\n    # font.paint.color = pixie.parse_color(\"#FC427B\")\n    # font.paint.color = pixie.Color(0,0,0,1)\n    title_text_transform = pixie.translate(\n        int(font.size * 0.8), int(ad_height - qrcode_height * 1.1)\n    )\n    title_text_bounds = pixie.Vector2(\n        int(qrcode_scan_text_transform_x - font.size * 1.1), int(qrcode_height)\n    )\n    image.fill_text(\n        font, title_text, bounds=title_text_bounds, transform=title_text_transform\n    )\n    delta = int(cover_width * 0.02)\n    sub_image_params = (\n        cover_transform_width - delta,\n        cover_transform_height - delta,\n        cover_width + 2 * delta,\n        cover_height + 2 * delta,\n    )\n    standalone_cover_image = image.sub_image(*sub_image_params)\n    standalone_cover_image.write_file(output_standalone)\n    image.write_file(output_path)  # make sure you write to desired temp path.\n    if framework_only:\n        image2.sub_image(*sub_image_params).write_file(output_masked_path)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:426-450"
    },
    "227": {
        "file_id": 26,
        "content": "This code generates an image with a QR code and text on top of it. It then creates two versions - one with the entire image, and another without any framework elements. The transformed QR code and text are placed on the image, and then saved in specified output files.",
        "type": "comment"
    },
    "228": {
        "file_id": 26,
        "content": "    return (\n        output_path,\n        output_standalone,\n        output_masked_path,\n    )  # well, pick up if you want.\nIMAGE_WITH_QRCODE_PATH = \"image_with_qrcode.png\"\nOUTPUT_WITH_QRCODE_PATH = \"output_with_qrcode.png\"\ndef removeQRCodes(\n    image_with_qrcode_path: str = os.path.join(TMP_DIR_PATH, IMAGE_WITH_QRCODE_PATH)\n):\n    # use best method to remove qrcode.\n    # import cv2\n    # import imutils\n    from PIL import Image\n    from pyzbar.pyzbar import decode, ZBarSymbol\n    # @function 'detect_qr' detect and decode qrcode from frame using pyzbar lib\n    # @param 'inputFrame' type <class 'numpy.ndarray'>\n    # @return if detected type 'bool'\n    import numpy as np\n    def detect_qr(inputFrame):\n        img = Image.fromarray(inputFrame)  # fuck?\n        decodedImg = decode(img, symbols=[ZBarSymbol.QRCODE])\n        # it reads the content. but where is the code?\n        print(\"total %d qrcode detected\" % len(decodedImg))\n        # breakpoint()\n        # length: 2\n        if len(decodedImg) > 0:\n            polygons = []",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:451-485"
    },
    "229": {
        "file_id": 26,
        "content": "This code defines a function to remove QR codes from an image. It uses the Pyzbar library for QR code detection and removal. The function takes the path of the image with QR codes as input and returns the output path without QR codes, the standalone output path, and the masked output path. The code also includes a helper function called \"detect_qr\" which detects and decodes the QR codes from an input frame.",
        "type": "comment"
    },
    "230": {
        "file_id": 26,
        "content": "            for code in decodedImg:\n                decodedBytes = code.data\n                # stringData = decodedBytes.decode(\"utf-8\")\n                # print(\"QRCode content:\")\n                # print(stringData)\n                polygon = code.polygon\n                # print('POLYGON CONTENT:')\n                # print(polygon)\n                mpolygon = []\n                for point in polygon:\n                    mpolygon.append([point.x, point.y])\n                #     print('POINT:',point.x,point.y)\n                polygons.append(np.array(mpolygon, dtype=np.int32))\n            return polygons\n        else:\n            return []\n    def getInputFrameFromImagePath(imagePath: str):\n        inputFrame = cv2.imread(imagePath)\n        return inputFrame\n    inputFrame = getInputFrameFromImagePath(image_with_qrcode_path)\n    QRCodeCoordinates = detect_qr(inputFrame)\n    img = cv2.imread(image_with_qrcode_path)\n    if QRCodeCoordinates != []:\n        mask_image = np.zeros((*img.shape[:2], 1), dtype=img.dtype)\n        for poly in QRCodeCoordinates:",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:486-513"
    },
    "231": {
        "file_id": 26,
        "content": "The code iterates over decoded QR codes and extracts their data, polygon coordinates, and converts them to a numpy array. The function returns the polygons if any QR code is detected; otherwise, it returns an empty list. There is also a separate function to read input frames from image paths and detect QRCodeCoordinates using the detect_qr function.",
        "type": "comment"
    },
    "232": {
        "file_id": 26,
        "content": "            cv2.fillPoly(mask_image, [poly], 255)\n        inpainted_im = cv2.inpaint(img, mask_image, 3, cv2.INPAINT_TELEA)\n    else:\n        inpainted_im = img\n    return QRCodeCoordinates, inpainted_im\nfrom typing import Union\ndef removeAndInsertQRCode(\n    image_with_qrcode_path: str = os.path.join(TMP_DIR_PATH, IMAGE_WITH_QRCODE_PATH),\n    qrcode_path: str = os.path.join(TMP_DIR_PATH, QRCODE_PATH),\n    output_with_qrcode_path: Union[None, str] = os.path.join(\n        TMP_DIR_PATH, OUTPUT_WITH_QRCODE_PATH\n    ),\n):  # remove all detected QRCodes. add qrcode nevertheless.\n    # TODO: use more advanced models to detect QRCodes.\n    # TODO: increase the size of the original image if too small.\n    QRImage = cv2.imread(qrcode_path)\n    import math\n    def get_rotation_angle_and_center(p1, p2, p3, p4):\n        # Find the center of the rectangle\n        center_x = int((p1[0] + p3[0]) / 2 + (p2[0] + p4[0]) / 2) / 2\n        center_y = int((p1[1] + p3[1]) / 2 + (p2[1] + p4[1]) / 2) / 2\n        center = (center_x, center_y)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:514-540"
    },
    "233": {
        "file_id": 26,
        "content": "The code reads an image with a QR code and removes all detected QR codes while adding the specified QR code to the output image. It also calculates the rotation angle and center of a rectangle formed by four points. The function takes paths for the input image, QR code image, and the desired output image path. It uses OpenCV for image processing operations like reading images, inpainting, and applying transformations.",
        "type": "comment"
    },
    "234": {
        "file_id": 26,
        "content": "        width = math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n        height = math.sqrt((p2[0] - p3[0]) ** 2 + (p2[1] - p3[1]) ** 2)\n        # Calculate the slope of one of the edges\n        slope = (p2[1] - p1[1]) / (p2[0] - p1[0])\n        # Calculate the angle of the edge from the x-axis\n        angle = (math.pi / 2) - math.atan(\n            slope\n        )  # correct the angle. according to opencv.\n        while True:\n            if angle > math.pi / 2:\n                angle -= math.pi / 2\n            elif angle < 0:\n                angle += math.pi / 2\n            else:\n                break\n        return angle, center, width, height\n    QRCodeCoordinates, img = removeQRCodes(image_with_qrcode_path)\n    hasQRCode = len(QRCodeCoordinates) > 0\n    from shapely.geometry import Polygon\n    import numpy as np\n    if hasQRCode:  # put the biggest one there.\n        QRCodeCoordinates.sort(key=lambda x: -Polygon(x.tolist()).area)\n        biggest_polygon = QRCodeCoordinates[0]\n        cv2.fillPoly(img, [biggest_polygon], (0, 0, 0))",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:541-568"
    },
    "235": {
        "file_id": 26,
        "content": "Calculates angle, width, and height of a polygon formed by points p1, p2, and p3. Sorts QRCodeCoordinates based on their area and draws the largest one using cv2.",
        "type": "comment"
    },
    "236": {
        "file_id": 26,
        "content": "        angle, center, width, height = get_rotation_angle_and_center(\n            *biggest_polygon.tolist()\n        )  # will fail?\n        QRWidth, QRHeight = int(width), int(height)\n        startingPoint = [int(center[0] - QRWidth / 2), int(center[1] - QRHeight / 2)]\n    else:\n        # randomly select one place to insert the shit.\n        height, width = img.shape[:2]\n        QRSize = min(height, width) / 5\n        QRHeight, QRWidth = QRImage.shape[:2]\n        if QRWidth > QRHeight:\n            QRHeight = int((QRHeight / QRWidth) * QRSize)\n            QRWidth = int(QRSize)\n        else:\n            QRWidth = int((QRWidth / QRHeight) * QRSize)\n            QRHeight = int(QRSize)\n        startingPoint = [\n            random.randint(0, math.floor(width - QRWidth)),\n            random.randint(0, math.floor(height - QRHeight)),\n        ]\n        angle, center = 0, [\n            startingPoint[0] + int(QRWidth / 2),\n            startingPoint[1] + int(QRHeight / 2),\n        ]\n        biggest_polygon = np.array(\n            [",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:569-594"
    },
    "237": {
        "file_id": 26,
        "content": "This code is responsible for determining the position and size of a QR code image to be inserted into an image. It first checks if there's a polygon present, and if so, it calculates the angle, center, width, and height based on the given polygon. If not, it randomly selects a place to insert the QR code by adjusting its size to fit within 5% of the image size and then determines the starting point and other parameters. The code is written in Python with libraries like numpy and random for numerical operations and generating random numbers.",
        "type": "comment"
    },
    "238": {
        "file_id": 26,
        "content": "                startingPoint,\n                [startingPoint[0], startingPoint[1] + QRHeight],\n                [startingPoint[0] + QRWidth, startingPoint[1] + QRHeight],\n                [startingPoint[0] + QRWidth, startingPoint[1]],\n            ]\n        )\n        cv2.fillPoly(img, [biggest_polygon], (0, 0, 0))\n    QRImage = cv2.resize(QRImage, (QRWidth, QRHeight), interpolation=cv2.INTER_LINEAR)\n    # then we expand the image.\n    expanded_QR = np.zeros(img.shape, dtype=img.dtype)\n    height, width = QRImage.shape[:2]\n    slice_x_start, slice_x_end = startingPoint[1], height + startingPoint[1]\n    slice_y_start, slice_y_end = startingPoint[0], width + startingPoint[0]\n    # print(\"SLICES?\", slice_x_start, slice_x_end , slice_y_start, slice_y_end )\n    # print(\"IMAGE SHAPE?\",QRImage.shape)\n    expanded_QR[slice_x_start:slice_x_end, slice_y_start:slice_y_end] = QRImage\n    # then rotate.\n    if angle == 0:\n        rotated_im = expanded_QR\n    else:\n        angle_deg = 180 * (angle / np.pi)  # rotation error.",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:595-617"
    },
    "239": {
        "file_id": 26,
        "content": "This code detects QR codes, creates a bounding box around them, fills the polygon with black color, resizes and expands the image, and then rotates it by 180 degrees if angle is not zero. The purpose is to prepare a QR code image for further operations in an image processing pipeline.",
        "type": "comment"
    },
    "240": {
        "file_id": 26,
        "content": "        rotation_matrix = cv2.getRotationMatrix2D(center, angle_deg, 1)\n        rotated_im = cv2.warpAffine(\n            expanded_QR, rotation_matrix, (img.shape[1], img.shape[0])\n        )\n    # combine. what?\n    output_img = rotated_im + img\n    # regularize\n    output_img.put(np.where(output_img > 255), 255)\n    output_img.put(np.where(output_img < 0), 0)\n    # save the image.\n    if output_with_qrcode_path is not None:\n        cv2.imwrite(output_with_qrcode_path, output_img)\n    return output_img  # for viewing.",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/ad_template_2_functional.py:618-633"
    },
    "241": {
        "file_id": 26,
        "content": "This code rotates an image using OpenCV, combines the rotated and original images, applies a regularization to pixel values, saves the resulting image if necessary, and returns it for viewing.",
        "type": "comment"
    },
    "242": {
        "file_id": 27,
        "content": "/tasks/qq/qq_red_packet_collect/paddletts/test.sh",
        "type": "filepath"
    },
    "243": {
        "file_id": 27,
        "content": "The code uses the PaddleSpeech TTS (Text-to-Speech) model to convert text \"你好\" into speech and saves it as hello.wav using CPU device. The model is located at ~/.paddlespeech in a drive named Toshiba3000, with possible English-Chinese splitting tests. Pyjom is related to these tests and possibly offers other server interactions.",
        "type": "summary"
    },
    "244": {
        "file_id": 27,
        "content": "paddlespeech tts --input \"你好\" --output hello.wav --voc hifigan_csmsc --device cpu\n# model location ~/.paddlespeech -> /media/root/Toshiba3000/paddlespeech_models\n# check out pyjom about english-chinese spliting tests. we have model server other than cli interactions.",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/paddletts/test.sh:1-4"
    },
    "245": {
        "file_id": 27,
        "content": "The code uses the PaddleSpeech TTS (Text-to-Speech) model to convert text \"你好\" into speech and saves it as hello.wav using CPU device. The model is located at ~/.paddlespeech in a drive named Toshiba3000, with possible English-Chinese splitting tests. Pyjom is related to these tests and possibly offers other server interactions.",
        "type": "comment"
    },
    "246": {
        "file_id": 28,
        "content": "/tasks/qq/qq_red_packet_collect/fill_mask_model/test_macbert.sh",
        "type": "filepath"
    },
    "247": {
        "file_id": 28,
        "content": "The code makes a POST request to the Hugging Face API's inference endpoint for the \"hfl/chinese-macbert-base\" model, sending input text with a masked token and an access token as authorization.",
        "type": "summary"
    },
    "248": {
        "file_id": 28,
        "content": "curl https://api-inference.huggingface.co/models/hfl/chinese-macbert-base \\\n\t-X POST \\\n\t-d '{\"inputs\": \"我感冒了，今天天气[MASK]\"}' \\\n\t-H \"Authorization: Bearer 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\"",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/fill_mask_model/test_macbert.sh:1-4"
    },
    "249": {
        "file_id": 28,
        "content": "The code makes a POST request to the Hugging Face API's inference endpoint for the \"hfl/chinese-macbert-base\" model, sending input text with a masked token and an access token as authorization.",
        "type": "comment"
    },
    "250": {
        "file_id": 29,
        "content": "/tasks/qq/qq_red_packet_collect/fill_mask_model/test.py",
        "type": "filepath"
    },
    "251": {
        "file_id": 29,
        "content": "The code uses 'hfl/chinese-macbert-base' for masked language modeling, removes [] or [MASK] values, tokenizes input, gets logits, iterates over mask token indices, predicts next tokens, decodes to strings, and prints without gradients.",
        "type": "summary"
    },
    "252": {
        "file_id": 29,
        "content": "import os\nimport torch\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"\nfrom transformers import BertTokenizer, BertForMaskedLM\nmodel_name = \"hfl/chinese-macbert-base\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertForMaskedLM.from_pretrained(model_name) # where the heck is the model?\n#location:\n# resolved_archive_file = cached_path(...)\n# already outsourced this shit.\n# /root/.cache/huggingface/transformers/f350d12c99d2a8d00f4299b8e292c2248422676424702a2c45a8a3d65646f738.749c1a543002a65141e104ba5e040263fd8eabc9d2dcfb537bf681345565ef45\n# first ensure there is no [MASK] or [] surrounded values. otherwise, remove these shits.\n# split them using re.split and filter these shits out with re.match\ninputs = tokenizer(\"如果今天天气[MASK][MASK]\", return_tensors=\"pt\")\nwith torch.no_grad():\n    logits = model(**inputs).logits\n# retrieve index of [MASK]\nmask_token_indexs = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0] # (tensor([5, 6]),) without [0]\n# print(mask_token_indexs) #5 and 6.",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/fill_mask_model/test.py:1-27"
    },
    "253": {
        "file_id": 29,
        "content": "The code is using the 'hfl/chinese-macbert-base' model for masked language modeling. It first checks if there are any [MASK] or [] surrounded values and removes them. Then, it tokenizes the input text using the BertTokenizer from transformers library. After that, it passes the input to the BertForMaskedLM model and retrieves the logits corresponding to the mask tokens. The mask token indices are obtained from the input tensors.",
        "type": "comment"
    },
    "254": {
        "file_id": 29,
        "content": "for mask_token_index in mask_token_indexs:\n    predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n    result = tokenizer.decode(predicted_token_id)\n    print(mask_token_index,result)\n# with torch.no_grad():\n#     outputs = model(**inputs)\n# print(dir(outputs))",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/fill_mask_model/test.py:28-35"
    },
    "255": {
        "file_id": 29,
        "content": "Iterates over each mask token index in the list, predicts the next token, decodes the predicted token ID to string using tokenizer, and prints the mask token index and result. This process is done without gradients for computational efficiency.",
        "type": "comment"
    },
    "256": {
        "file_id": 30,
        "content": "/tasks/qq/qq_red_packet_collect/fill_mask_model/init.sh",
        "type": "filepath"
    },
    "257": {
        "file_id": 30,
        "content": "The code installs git LFS, runs a Python script named \"test.py\" with specified environment variables, and clones the \"chinese-macbert-base\" model from Hugging Face Co.",
        "type": "summary"
    },
    "258": {
        "file_id": 30,
        "content": "# git lfs install\nenv http_proxy=\"\" https_proxy=\"\" python3 test.py\n# env http_proxy=\"\" https_proxy=\"\" git clone https://huggingface.co/hfl/chinese-macbert-base",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/fill_mask_model/init.sh:1-3"
    },
    "259": {
        "file_id": 30,
        "content": "The code installs git LFS, runs a Python script named \"test.py\" with specified environment variables, and clones the \"chinese-macbert-base\" model from Hugging Face Co.",
        "type": "comment"
    },
    "260": {
        "file_id": 31,
        "content": "/tasks/qq/qq_red_packet_collect/textfilter/launch.sh",
        "type": "filepath"
    },
    "261": {
        "file_id": 31,
        "content": "Launches the FastAPI application using uvicorn, listens on port 8932, and provides an option for auto-reloading with --reload. However, the comment suggests not to use the reload feature.",
        "type": "summary"
    },
    "262": {
        "file_id": 31,
        "content": "python3 -m uvicorn filter_py3_fastapi:app --port 8932 \n# python3 -m uvicorn filter_py3_fastapi:app --reload --port 8932 \n# do not use reload!",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/launch.sh:1-3"
    },
    "263": {
        "file_id": 31,
        "content": "Launches the FastAPI application using uvicorn, listens on port 8932, and provides an option for auto-reloading with --reload. However, the comment suggests not to use the reload feature.",
        "type": "comment"
    },
    "264": {
        "file_id": 32,
        "content": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py",
        "type": "filepath"
    },
    "265": {
        "file_id": 32,
        "content": "The code offers text filtering through classes like NaiveFilter and BSFilter for keyword removal and regex processing, plus a DFAFilter for performance boost. It checks characters, translates Chinese to Pinyin, and returns moderated text via FastAPI endpoint.",
        "type": "summary"
    },
    "266": {
        "file_id": 32,
        "content": "#!/usr/bin/env python\n# -*- coding:utf-8 -*-\nfrom collections import defaultdict\nimport re\n__all__ = ['NaiveFilter', 'BSFilter', 'DFAFilter']\n__author__ = 'observer'\n__date__ = '2012.01.05'\nclass NaiveFilter():\n    '''Filter Messages from keywords\n    very simple filter implementation\n    >>> f = NaiveFilter()\n    >>> f.add(\"sexy\")\n    >>> f.filter(\"hello sexy baby\")\n    hello **** baby\n    '''\n    def __init__(self):\n        self.keywords = set([])\n    def parse(self, path):\n        for keyword in open(path):\n            self.keywords.add(keyword.strip().decode('utf-8').lower())\n    def filter(self, message, repl=\"*\"):\n        message = str(message).lower()\n        for kw in self.keywords:\n            message = message.replace(kw, repl)\n        return message\nclass BSFilter:\n    '''Filter Messages from keywords\n    Use Back Sorted Mapping to reduce replacement times\n    >>> f = BSFilter()\n    >>> f.add(\"sexy\")\n    >>> f.filter(\"hello sexy baby\")\n    hello **** baby\n    '''\n    def __init__(self):\n        self.keywords = []",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py:1-48"
    },
    "267": {
        "file_id": 32,
        "content": "This code is for creating a filter to remove specific keywords from a given message. It provides three classes: NaiveFilter, BSFilter, and DFAFilter. NaiveFilter is the simplest implementation using set data structure, while BSFilter uses Back Sorted Mapping to improve performance by reducing replacement times. The code also includes parsing functionality to add keywords from a file.",
        "type": "comment"
    },
    "268": {
        "file_id": 32,
        "content": "        self.kwsets = set([])\n        self.bsdict = defaultdict(set)\n        self.pat_en = re.compile(r'^[0-9a-zA-Z]+$')  # english phrase or not\n    def add(self, keyword):\n        if not isinstance(keyword, str):\n            keyword = keyword.decode('utf-8')\n        keyword = keyword.lower()\n        if keyword not in self.kwsets:\n            self.keywords.append(keyword)\n            self.kwsets.add(keyword)\n            index = len(self.keywords) - 1\n            for word in keyword.split():\n                if self.pat_en.search(word):\n                    self.bsdict[word].add(index)\n                else:\n                    for char in word:\n                        self.bsdict[char].add(index)\n    def parse(self, path):\n        with open(path, \"r\") as f:\n            for keyword in f:\n                self.add(keyword.strip())\n    def filter(self, message, repl=\"*\"):\n        if not isinstance(message, str):\n            message = message.decode('utf-8')\n        message = message.lower()\n        for word in message.split():",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py:49-77"
    },
    "269": {
        "file_id": 32,
        "content": "This code defines a class with methods for adding keywords, parsing from a file, and filtering text. It uses regular expressions to identify English words and stores them in dictionaries based on their characters or full words. The parse method reads a file of keywords and the filter method processes input messages by replacing non-keyword parts with \"*\".",
        "type": "comment"
    },
    "270": {
        "file_id": 32,
        "content": "            if self.pat_en.search(word):\n                for index in self.bsdict[word]:\n                    message = message.replace(self.keywords[index], repl)\n            else:\n                for char in word:\n                    for index in self.bsdict[char]:\n                        message = message.replace(self.keywords[index], repl)\n        return message\nclass DFAFilter():\n    '''Filter Messages from keywords\n    Use DFA to keep algorithm perform constantly\n    >>> f = DFAFilter()\n    >>> f.add(\"sexy\")\n    >>> f.filter(\"hello sexy baby\")\n    hello **** baby\n    '''\n    def __init__(self):\n        self.keyword_chains = {}\n        self.delimit = '\\x00'\n    def add(self, keyword):\n        if not isinstance(keyword, str):\n            keyword = keyword.decode('utf-8')\n        keyword = keyword.lower()\n        chars = keyword.strip()\n        if not chars:\n            return\n        level = self.keyword_chains\n        for i in range(len(chars)):\n            if chars[i] in level:\n                level = level[chars[i]]",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py:78-113"
    },
    "271": {
        "file_id": 32,
        "content": "This code defines a DFAFilter class to filter messages from keywords. It uses DFA (Deterministic Finite Automaton) to improve algorithm performance. The add method adds a keyword and the filter method replaces keywords with asterisks (*). If the keyword is already in the DFA, it updates the level of the DFA accordingly.",
        "type": "comment"
    },
    "272": {
        "file_id": 32,
        "content": "            else:\n                if not isinstance(level, dict):\n                    break\n                for j in range(i, len(chars)):\n                    level[chars[j]] = {}\n                    last_level, last_char = level, chars[j]\n                    level = level[chars[j]]\n                last_level[last_char] = {self.delimit: 0}\n                break\n        if i == len(chars) - 1:\n            level[self.delimit] = 0\n    def parse(self, path):\n        with open(path) as f:\n            for keyword in f:\n                self.add(keyword.strip())\n    def filter(self, message, repl=\"*\"):  # what is this repl?\n        if not isinstance(message, str):\n            message = message.decode('utf-8')\n        message = message.lower()\n        ret = []\n        start = 0\n        while start < len(message):\n            level = self.keyword_chains\n            step_ins = 0\n            for char in message[start:]:\n                if char in level:\n                    step_ins += 1\n                    if self.delimit not in level[char]:",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py:114-143"
    },
    "273": {
        "file_id": 32,
        "content": "This code is parsing a text file of keywords and their corresponding chains. It then filters a given message by replacing instances of the keyword chains with a placeholder (\"*\"). The \"repl\" argument in filter() function seems to be optional and represents the placeholder character used for replacement. If the input message is not a string, it's decoded from its original format (like bytes) to a string. The code maintains a nested dictionary structure representing keyword chains, and if a delimiter is found missing in a chain, it's set to 0.",
        "type": "comment"
    },
    "274": {
        "file_id": 32,
        "content": "                        level = level[char]\n                    else:\n                        # print(\"STEPINS\", step_ins)\n                        # print(\"CHAR\", char)\n                        # print(level[char])\n                        ret.append(repl * step_ins)\n                        start += step_ins - 1\n                        break\n                else:\n                    ret.append(message[start])\n                    break\n            else:\n                ret.append(message[start])\n            start += 1\n        return ''.join(ret)\ndef test_first_character():\n    gfw = DFAFilter()\n    gfw.add(\"1989年\")\n    assert gfw.filter(\"1989\", \"*\") == \"1989\"\ngfw = DFAFilter()\ngfw.parse(\"keywords\")\nfrom typing import Union\nfrom fastapi import FastAPI\napp = FastAPI()\nfrom snownlp import SnowNLP\nfrom snownlp.normal import pin, re_zh\n# import re\ndef getPinyin(originalText,\n              filteredText,\n              whitelistChars=[\"的\"],\n              whitelistNonChinese=True):  # any repl will do.\n    blocks = [x for x in re_zh.split(originalText) if len(x) > 0]",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py:144-186"
    },
    "275": {
        "file_id": 32,
        "content": "This function takes a message and filters it based on a DFA (Deterministic Finite Automaton) filter. It checks each character in the message, appending replacements if necessary or keeping the original character if not. If a keyword is found, it replaces it with '*'. The function returns the filtered text as a string.\n\nThe code also includes a test case for checking if the first character of the filter result matches the expected output for the given input. Additionally, there are import statements and function definitions for other functionalities like getting pinyin and handling Chinese text.",
        "type": "comment"
    },
    "276": {
        "file_id": 32,
        "content": "    # words = result.words\n    translate_list = []\n    for block in blocks:\n        if re_zh.match(block):\n            block_pinyin = pin.get(block)\n            for index, pinyin in enumerate(block_pinyin):\n                character = block[index]\n                translate_list.append((character, pinyin[0]))\n        else:\n            for index, character in enumerate(block):\n                translate_list.append((character, character))\n    moderatedText = \"\"\n    for index, (originalCharacter, pinyin) in enumerate(translate_list):\n        filteredCharacter = filteredText[index]\n        if filteredCharacter == originalCharacter or originalCharacter in whitelistChars or (\n                whitelistNonChinese and (not re_zh.match(originalCharacter))): # changed the moderator logic.\n            moderatedText += originalCharacter\n        elif pinyin != originalCharacter:\n            moderatedText += pinyin\n        else:\n            moderatedText += filteredCharacter\n    return moderatedText\n@app.get(\"/\")\ndef read_root():",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py:187-213"
    },
    "277": {
        "file_id": 32,
        "content": "This code filters text by translating Chinese characters into their corresponding Pinyin while preserving non-Chinese characters or whitelisted characters. It creates a list of translated characters and applies the filter logic to generate a moderated text output, which is returned as the result. Additionally, there's an API endpoint (\"/\") defined for accessing this functionality through a FastAPI server.",
        "type": "comment"
    },
    "278": {
        "file_id": 32,
        "content": "    return {\"response\": \"DFAFilter based Chinese text filter(censor)\"}\n@app.get(\"/filter\")\ndef read_item(text: Union[str, None] = None, moderate: bool = True):\n    originalText = text\n    filteredText = gfw.filter(text, \"*\")\n    if moderate:\n        moderatedText = getPinyin(originalText, filteredText)\n        return {\"response\": moderatedText}\n    else:\n        return {\"response\": filteredText}",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/textfilter/filter_py3_fastapi.py:214-225"
    },
    "279": {
        "file_id": 32,
        "content": "This code defines a FastAPI route (\"/filter\") that takes in a text input and applies GFW filtering. If the \"moderate\" parameter is True, it generates a moderated text by replacing Chinese characters with their corresponding pinyin. Otherwise, it returns the filtered text.",
        "type": "comment"
    },
    "280": {
        "file_id": 33,
        "content": "/samples/medialang/dog_cat_test_nofast.mdl",
        "type": "filepath"
    },
    "281": {
        "file_id": 33,
        "content": "The code manages multiple videos, sets properties like silence and speed, and cuts specific durations for multimedia projects using a specific directory. It specifies video file paths with properties like muting, speed control, and timed cuts for sequenced or simultaneous playback within an application.",
        "type": "summary"
    },
    "282": {
        "file_id": 33,
        "content": "(\".mp4\", backend=\"editly\",\n    bgm=\"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\",\n    fast=false\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_gWkCsQZ4YlU1a]_[300x214].gif\",\n    video=true, slient=true, speed=1.043468,\n    cutFrom=0.0, cutTo=2.4\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_2tNwXMxMpUAsiSbyck]_[480x270].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564027\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_dTYI2Cu25gsTK]_[242x250].gif\",\n    video=true, slient=true, speed=1.006185,\n    cutFrom=0.0, cutTo=6.5\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_5Y8xYjHG9AcjWlz23h]_[480x480].gif\",\n    video=true, slient=true, speed=0.997826,\n    cutFrom=0.0, cutTo=4.6\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_iOGRWFLgGBRTxz7i22]_[270x480].gif\",\n    video=true, slient=true, speed=1.050456,\n    cutFrom=0.0, cutTo=10.2\n)\n(\"/r",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:1-31"
    },
    "283": {
        "file_id": 33,
        "content": "This code defines multiple video sources and their properties, including the video file path, duration, and speed. The videos are set to be silent (slient=true) and played at specified speeds with specific time intervals cut from the original video (cutFrom and cutTo). It is used in a media project likely for creating a montage or sequence of videos with background music.",
        "type": "comment"
    },
    "284": {
        "file_id": 33,
        "content": "oot/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_MB7AnGuoZ0ruqsFM1G]_[480x400].gif\",\n    video=true, slient=true, speed=0.934218,\n    cutFrom=0.0, cutTo=3.017544\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_UuebWyG4pts3rboawU]_[480x480].gif\",\n    video=true, slient=true, speed=0.976488,\n    cutFrom=0.0, cutTo=5.4\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_kOEYOwSaKbFra]_[350x197].gif\",\n    video=true, slient=true, speed=1.006486,\n    cutFrom=0.0, cutTo=9.3\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_QGSEGsTr04bPW]_[450x254].gif\",\n    video=true, slient=true, speed=0.833326,\n    cutFrom=0.0, cutTo=2.3\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_23kXtcba8igBvs8DQ1]_[400x225].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=11.076082\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_ANWIS2HYfROI8]_[250x250].gif\",\n    video=true, slient=true, speed=1.04277,",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:31-57"
    },
    "285": {
        "file_id": 33,
        "content": "The code defines a series of video files with their respective paths, each associated with the \"video\" and \"silent\" parameters, and has a specific speed and cut duration.",
        "type": "comment"
    },
    "286": {
        "file_id": 33,
        "content": "    cutFrom=0.0, cutTo=5.297297\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_3oEduYITQ7uOYLPZjq]_[480x270].gif\",\n    video=true, slient=true, speed=0.981427,\n    cutFrom=0.0, cutTo=4.985673\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_26BRGvcRTuqWhoLzW]_[320x320].gif\",\n    video=true, slient=true, speed=0.937354,\n    cutFrom=0.0, cutTo=5.192982\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_S3KIhtDGjLKWbnwtrQ]_[480x270].gif\",\n    video=true, slient=true, speed=0.990204,\n    cutFrom=0.0, cutTo=7.08\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_JPayEyQPRCUTe]_[245x177].gif\",\n    video=true, slient=true, speed=0.93862,\n    cutFrom=0.0, cutTo=2.6\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_TGKnLbfAzkk3DDNt8K]_[320x480].gif\",\n    video=true, slient=true, speed=1.096676,\n    cutFrom=0.0, cutTo=5.066667\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_3boPPdHk2ueo8]_[480x270].gif\",",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:58-86"
    },
    "287": {
        "file_id": 33,
        "content": "This code represents a list of video files and their associated properties. Each item in the list contains the file path, whether it's a video (video=true), if it's silent (silent=true), its speed, and specific cutFrom/cutTo timestamps for each clip.",
        "type": "comment"
    },
    "288": {
        "file_id": 33,
        "content": "    video=true, slient=true, speed=1.079128,\n    cutFrom=0.0, cutTo=3.0\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_UvvK8rOSHPxgjo9ryD]_[728x728].gif\",\n    video=true, slient=true, speed=0.999996,\n    cutFrom=0.0, cutTo=6.0\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_3o6fJ9cQXux6wfA2BO]_[480x264].gif\",\n    video=true, slient=true, speed=0.987647,\n    cutFrom=0.0, cutTo=3.2\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_OOTtmh8oXrFK5ccNU7]_[460x460].gif\",\n    video=true, slient=true, speed=1.018824,\n    cutFrom=0.0, cutTo=4.004\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_Dcf2hNSaAiLV6]_[400x300].gif\",\n    video=true, slient=true, speed=0.987007,\n    cutFrom=0.0, cutTo=6.84\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_yXBqba0Zx8S4]_[480x324].gif\",\n    video=true, slient=true, speed=0.976134,\n    cutFrom=0.0, cutTo=4.5\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_bhSi84uFsp66s]_[354x306].gif\",",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:87-116"
    },
    "289": {
        "file_id": 33,
        "content": "The code is a list of video files and their corresponding parameters for use in the media language model. The videos are located on the desktop under the \"pyjom/samples/medialang/source/video\" directory, with each file having properties such as being silent, specific speeds, and cut durations.",
        "type": "comment"
    },
    "290": {
        "file_id": 33,
        "content": "    video=true, slient=true, speed=1.026876,\n    cutFrom=0.0, cutTo=4.733945\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_NmGbJwLl7Y4lG]_[480x270].gif\",\n    video=true, slient=true, speed=0.96385,\n    cutFrom=0.0, cutTo=4.0\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_FOL5mK0tXUmXe]_[450x254].gif\",\n    video=true, slient=true, speed=0.830318,\n    cutFrom=0.0, cutTo=2.3\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_77vjJEy9IRqJW]_[303x476].gif\",\n    video=true, slient=true, speed=1.192301,\n    cutFrom=0.0, cutTo=4.96\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_T7nRl5WHw7Yru]_[320x240].gif\",\n    video=true, slient=true, speed=0.883147,\n    cutFrom=0.0, cutTo=3.25\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_37R1oJeXReoJW]_[291x294].gif\",\n    video=true, slient=true, speed=1.010094,\n    cutFrom=0.0, cutTo=7.0\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_3oz8xEFHNzQE3VIRCE]_[480x490].gif\",",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:117-146"
    },
    "291": {
        "file_id": 33,
        "content": "This code represents a series of video clips with their respective file paths, along with information about each clip such as its speed, duration, and whether it is silent or not. The code seems to be part of a larger program that likely involves processing or playing these videos in a specific sequence or context.",
        "type": "comment"
    },
    "292": {
        "file_id": 33,
        "content": "    video=true, slient=true, speed=1.010619,\n    cutFrom=0.0, cutTo=4.2042\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_Bkcls2eA8Fc6A]_[480x480].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=10.692054\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_11kgieHVYW53lC]_[480x360].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564027\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_Ev17f0KeO9qkE]_[300x169].gif\",\n    video=true, slient=true, speed=0.817758,\n    cutFrom=0.0, cutTo=3.017544\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_U7969wTwwtn6KBvEdA]_[384x480].gif\",\n    video=true, slient=true, speed=1.009003,\n    cutFrom=0.0, cutTo=3.733333\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_IPUFTmRYZqG2s]_[480x270].gif\",\n    video=true, slient=true, speed=0.973326,\n    cutFrom=0.0, cutTo=5.84\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_hNRA4W7qJnbpK]_[389x415].gif\",",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:147-176"
    },
    "293": {
        "file_id": 33,
        "content": "The code represents a list of video files with their corresponding properties such as file path, if the video is silent and muted, and the speed at which it should play. The cutFrom and cutTo values define the specific time intervals for each video file within the media language script.",
        "type": "comment"
    },
    "294": {
        "file_id": 33,
        "content": "    video=true, slient=true, speed=1.15384,\n    cutFrom=0.0, cutTo=4.8\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_Ul2rAQJqNXp9S]_[400x225].gif\",\n    video=true, slient=true, speed=0.963845,\n    cutFrom=0.0, cutTo=4.0\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_4MXO2o9MbPBi6M79G6]_[480x270].gif\",\n    video=true, slient=true, speed=0.99367,\n    cutFrom=0.0, cutTo=3.666667\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_HC995u2L4I7mg]_[300x169].gif\",\n    video=true, slient=true, speed=0.817758,\n    cutFrom=0.0, cutTo=3.017544\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_i0lkOcXmpcE92]_[400x225].gif\",\n    video=true, slient=true, speed=1.054048,\n    cutFrom=0.0, cutTo=3.9\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_QxqqwXQuSWufNazWWU]_[448x450].gif\",\n    video=true, slient=true, speed=0.86666,\n    cutFrom=0.0, cutTo=5.2\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_XlNkepH9WJO3C]_[245x160].gif\",",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:177-206"
    },
    "295": {
        "file_id": 33,
        "content": "This code contains a list of video files with their corresponding paths, and each video has properties like \"video=true\", \"slient=true\", speed, cutFrom, and cutTo. The videos are likely being used in a media processing or editing program where the specified parameters determine how the video will be displayed or edited.",
        "type": "comment"
    },
    "296": {
        "file_id": 33,
        "content": "    video=true, slient=true, speed=0.975598,\n    cutFrom=0.0, cutTo=3.6\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_cEPFSJokR4hzi]_[480x270].gif\",\n    video=true, slient=true, speed=1.031923,\n    cutFrom=0.0, cutTo=8.08\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_ghHZVf7kK9379nbcuh]_[442x468].gif\",\n    video=true, slient=true, speed=0.969893,\n    cutFrom=0.0, cutTo=3.578947\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_5t7AJfJQnmsP5Tm1QS]_[480x480].gif\",\n    video=true, slient=true, speed=1.042304,\n    cutFrom=0.0, cutTo=6.733333\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_x42zjj678Sr6M]_[420x241].gif\",\n    video=true, slient=true, speed=1.071709,\n    cutFrom=0.0, cutTo=7.92\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_wBQa0CjlSySUE]_[320x180].gif\",\n    video=true, slient=true, speed=1.005696,\n    cutFrom=0.0, cutTo=8.82\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_fJdpdS5jaDje8]_[361x194].gif\",",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:207-236"
    },
    "297": {
        "file_id": 33,
        "content": "These code snippets define media files and their properties for the \"medialang\" project. Each entry consists of a file path, video=true (indicating it's a video), silent=true, speed value, and cutFrom/cutTo time values. These media files are likely being used in a multimedia presentation or production.",
        "type": "comment"
    },
    "298": {
        "file_id": 33,
        "content": "    video=true, slient=true, speed=0.882244,\n    cutFrom=0.0, cutTo=5.302326\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_IT4fLZjxyDu24]_[720x540].gif\",\n    video=true, slient=true, speed=0.83194,\n    cutFrom=0.0, cutTo=5.0\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_q9ETKoMaBMsNy]_[300x300].gif\",\n    video=true, slient=true, speed=0.956076,\n    cutFrom=0.0, cutTo=6.16\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_lQI2sf2qserJsrixfw]_[270x480].gif\",\n    video=true, slient=true, speed=0.992241,\n    cutFrom=0.0, cutTo=6.4\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_MOgAd5Z2LZRHW]_[338x254].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_GSsTZNQjPvl1m]_[500x377].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564\n)\n(\"/root/Desktop/works/pyjom/samples/medialang/source/video/video_[giphy_pCyN4mn4MbGCY]_[306x215].gif\",",
        "type": "code",
        "location": "/samples/medialang/dog_cat_test_nofast.mdl:237-266"
    },
    "299": {
        "file_id": 33,
        "content": "This code represents a series of video file paths along with their properties, such as being muted, having specific speeds and cut durations. It is likely used for playing multiple videos in sequence or simultaneously within a larger application.",
        "type": "comment"
    }
}