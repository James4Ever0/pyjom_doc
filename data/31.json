{
    "3100": {
        "file_id": 358,
        "content": "/tests/voice_detect_extract_split/paddlespeech/test.sh",
        "type": "filepath"
    },
    "3101": {
        "file_id": 358,
        "content": "The code exports HTTP and HTTPS proxy variables, runs TTS (Text-to-Speech) to convert text into audio (output.wav), and then performs ASR (Automatic Speech Recognition) in Chinese language using the output audio file. The code is intended for testing purposes with PaddleSpeech deep learning framework.",
        "type": "summary"
    },
    "3102": {
        "file_id": 358,
        "content": "export http_proxy=\"\"\nexport https_proxy=\"\"\n# this voice is great. excellent for my shit.\npaddlespeech tts --input \"你好，欢迎使用飞桨深度学习框架！\" --output output.wav # must download models on the fly.\npaddlespeech asr --lang zh --input output.wav\n# 你好欢迎使用非讲深度学习框架\n# how does it feel to have errors?\n# left and right variables are not the same. what is that?",
        "type": "code",
        "location": "/tests/voice_detect_extract_split/paddlespeech/test.sh:1-12"
    },
    "3103": {
        "file_id": 358,
        "content": "The code exports HTTP and HTTPS proxy variables, runs TTS (Text-to-Speech) to convert text into audio (output.wav), and then performs ASR (Automatic Speech Recognition) in Chinese language using the output audio file. The code is intended for testing purposes with PaddleSpeech deep learning framework.",
        "type": "comment"
    },
    "3104": {
        "file_id": 359,
        "content": "/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh",
        "type": "filepath"
    },
    "3105": {
        "file_id": 359,
        "content": "This code utilizes yt-dlp to download Bilibili video sections with authentication, handles subtitles and danmaku, supports multiple portions, updates cookies, allows title-only downloads, and retrieves metadata.",
        "type": "summary"
    },
    "3106": {
        "file_id": 359,
        "content": "# 关于视频合集 分p视频的分析逻辑：\n# https://github.com/Satoing/python_bilibili_downloader/blob/master/bilibili_video.py\n# 解析这个接口可以得到分p或者合集的信息 以及字幕信息 AI生成的字幕\n# https://api.bilibili.com/x/web-interface/view?bvid=BV1Fs411k7e9\n# https://api.bilibili.com/x/web-interface/view?bvid=BV1Cg411E7NF\nURL=\"https://www.bilibili.com/video/BV1Fs411k7e9\" #老戴 马克思佩恩 分p视频\n# 也可以直接网页parse\n# executing this you will get \"subtitle\" in \"danmaku\" as language, in xml format.\n# 对于海量弹幕的某些视频 （超电磁炮 12w asoul的某些二创 3w）不建议进行弹幕分析 可以通过API获取弹幕总数 不下载弹幕 \n# yt-dlp --skip-download --list-subs -I 1 \"https://www.bilibili.com/video/BV1Fs411k7e9\"\n# URL=\"https://www.bilibili.com/video/BV1Cg411E7NF\" #苏打baka 魔改机箱 合集\n# 合集视频 用bilibili_api 或者直接网页parse即可\n# it has multiple videos. what to do?\n# --force-keyframes-at-cuts\n# man i just need the first chapter.\n# yt-dlp --download-sections \"*0:05:00-0:06:30\" --playlist-items \"1\" \"$URL\" # only first video.\n# premium?\n# this feature is awesome! how to extract cookies programmatically from browser?\n# Use --cookies-from-browser o",
        "type": "code",
        "location": "/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh:1-26"
    },
    "3107": {
        "file_id": 359,
        "content": "This code snippet is for downloading specific sections of Bilibili videos using yt-dlp. It provides URLs for both single video parts and video collections, explains how to handle subtitles and danmaku (comments), and suggests using the --cookies-from-browser option for premium access.",
        "type": "comment"
    },
    "3108": {
        "file_id": 359,
        "content": "r --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp \n# not working for chromium on kali? (no bilibili cookie found) maybe it is relocated.\n# cookies = yt_dlp.cookies.extract_cookies_from_browser(BROWSER_NAME) -> YourubeDLCookieJar\n# save as Netscape HTTP Cookie File.\n# cookies.save(OUTPUT_FILE_PATH) \n# since we have issue playing content at tail of video, we do this.\n# yt-dlp --download-sections \"*0:05:00-0:06:30\" --playlist-items \"1\" --cookies-from-browser firefox --force-keyframes-at-cuts \"$URL\" # pass cookies.\n# forcing keyframe is much slower. but it produces better results.\n# yt-dlp --download-sections \"*0:05:00-0:06:30\" --playlist-items \"1\" --cookies-from-browser firefox --force-keyframes-at-cuts \"$URL\" # pass cookies.\n# you may want to add some margin at tail (or head) if not using \"--force-keyframes-at-cuts\", be it 10 seconds. usually jigs happens at 5 secs. but we are careful.\n# yt-dlp --download-sections \"*0:04:50-0:06:40\" --playlist-items \"1\" --cookies-from-browser firefox \"$URL\" # pass cookies.",
        "type": "code",
        "location": "/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh:26-42"
    },
    "3109": {
        "file_id": 359,
        "content": "The code is trying to download a specific portion of a Bilibili video, ensuring authentication by passing cookies from the browser (Firefox in this case) to yt-dlp. It forces keyframes at cuts for better results but notes that it's slower. The code provides different options to account for potential issues and suggests adding margin at tail or head if not using --force-keyframes-at-cuts, with a recommended 10 seconds or even 5 seconds depending on the need for caution.",
        "type": "comment"
    },
    "3110": {
        "file_id": 359,
        "content": "# what if we download multiple sections?\n# no combination? shit.\n# if not at the very tail, other tails can be better than the last tail. but it is just my guess. better to keep all these margins!\n# yt-dlp --download-sections \"*0:04:50-0:05:40\" --download-sections \"*0:05:50-0:06:40\" --playlist-items \"1\" --cookies-from-browser firefox -o \"%(uploader_id)s-%(id)s-%(title)s-%(autonumber)s.%(ext)s\" \"$URL\" # pass cookies.\n# since we have cron job now, no need to do the old-school thing.\nyt-dlp --download-sections \"*0:04:50-0:05:40\" --download-sections \"*0:05:50-0:06:40\" --playlist-items \"1\" --cookies /root/.browser_cookies_exported/firefox.cookies -o \"%(uploader_id)s-%(id)s-%(title)s-%(autonumber)s.%(ext)s\" \"$URL\" # pass cookies in different way\n# like this: '2142762-BV1Fs411k7e9_p1-老戴《马克思佩恩 3》全收集流程攻略【共14期完结】 p01 EP-01-00002.mp4'\n# https://github.com/yt-dlp/yt-dlp#readme -> \"OUTPUT TEMPLATE\"\n# https://github.com/yt-dlp/yt-dlp/issues/4579\n# you better use stored cookies instead of retrieving cookies every time.",
        "type": "code",
        "location": "/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh:44-59"
    },
    "3111": {
        "file_id": 359,
        "content": "The code tests downloading multiple video portions from Bilibili using yt-dlp with cookies stored, instead of retrieving them every time. It mentions that keeping all margins is better and suggests using a different format for the output file name.",
        "type": "comment"
    },
    "3112": {
        "file_id": 359,
        "content": "# or you can update cookies regularly with cronjob.\n# just want metadata?\n# if you want title for each video in playlist, you just get it from elsewhere or parse the damn output filename (slow, man!)\n# this seems to only have video description. nothing else! not even video length.\n# yt-dlp --write-description --write-playlist-metafiles --skip-download \"$URL\"\n# hey i don't want many download links. i just want title.\n# yt-dlp --write-info-json  --write-playlist-metafiles --skip-download \"$URL\" # this will get metadata main playlist and every video in the playlist in separate json files.\n# this is one of the video in that playlist. \"https://www.bilibili.com/video/BV1Fs411k7e9?p=1\n# you can get comments with this tool.\n## no comments?\n# yt-dlp --write-info-json --skip-download \"$URL\"\n# download-sections can be used multiple times?",
        "type": "code",
        "location": "/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh:60-75"
    },
    "3113": {
        "file_id": 359,
        "content": "This code snippet provides various options for downloading or obtaining metadata from a Bilibili playlist using yt-dlp. The user can choose to update cookies regularly, download only the video title, or retrieve metadata for the entire playlist and each individual video in separate JSON files. The user can also use specific URLs to obtain comments without actually downloading the videos. The code suggests multiple usage scenarios for the 'download-sections' functionality.",
        "type": "comment"
    },
    "3114": {
        "file_id": 360,
        "content": "/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/cron_update_cookies_stored_under_root_home.py",
        "type": "filepath"
    },
    "3115": {
        "file_id": 360,
        "content": "This script creates a directory for cookie storage if it doesn't already exist, and then extracts and saves cookies from Firefox and Chromium browsers.",
        "type": "summary"
    },
    "3116": {
        "file_id": 360,
        "content": "# 0 * * * * /usr/bin/python3 /root/Desktop/works/pyjom/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/cron_update_cookies_stored_under_root_home.py\nimport os\nimport shutil\ncookies_path = \"/root/.browser_cookies_exported\"\nif not (os.path.exists(cookies_path) or os.path.isdir(cookies_path)):\n    if os.path.isfile(cookies_path):\n        os.remove(cookies_path)\n    elif os.path.isdir(cookies_path):\n        shutil.rmtree(cookies_path)\n    elif os.path.islink(cookies_path):\n        os.unlink(cookies_path)\n    os.mkdir(cookies_path)\nimport yt_dlp\nbrowser_names = [\"firefox\",\"chromium\"]\nfor browser_name in browser_names:\n    cookies = yt_dlp.cookies.extract_cookies_from_browser(browser_name)\n    filepath = os.path.join(cookies_path,f\"{browser_name}.cookies\")\n    cookies.save(filepath)",
        "type": "code",
        "location": "/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/cron_update_cookies_stored_under_root_home.py:1-24"
    },
    "3117": {
        "file_id": 360,
        "content": "This script creates a directory for cookie storage if it doesn't already exist, and then extracts and saves cookies from Firefox and Chromium browsers.",
        "type": "comment"
    },
    "3118": {
        "file_id": 361,
        "content": "/tests/black_autopep8_ast_parser_formatter_skipexception/test.py",
        "type": "filepath"
    },
    "3119": {
        "file_id": 361,
        "content": "This code appears to be a mix of unrelated or incomplete fragments. It imports various modules but lacks cohesive structure, making it difficult to determine its purpose or functionality.",
        "type": "summary"
    },
    "3120": {
        "file_id": 361,
        "content": "# may be illegal.\n# use autopep8?\n# first, autopep8, next, black\n# both with 'unlimited' line of code.\n# finally, throw it to our dearly 'skipException'\n    from lib2to3.pgen2.pgen import DFAState\nfrom mimetypes import suffix_map\nfrom os import SCHED_FIFO\nfrom socket import _SendableFile\nfrom xml.dom.pulldom    import \\\n    SAX2DOM\n    print('aaa'\n        ) # there is no repairing on this bracket for autopep8\n# about the dog_or_cat recognition of our cover:\n# 1. throw away unqualified ones (using pop?)\n# 2. lower the threshold of yolo\n# 3. downscale picture before passing to yolo\n# we can go wild here.\n@redisLRUCache(dfsji,\nasdif[dfk,DFAState,\nsdfkg])\ndef shit(aaa, bbb,\nccc,ddd):\n    dd = 2314\n    ee = suffix_map[SAX2DOM,\n    df23, ddd][sdf,\n    sdf,sdf]\n    ss = efldife.dfief(_SendableFile,\n    saif,SCHED_FIFO,\n    asdif[fjisd,\n    sfdsif,sdf])",
        "type": "code",
        "location": "/tests/black_autopep8_ast_parser_formatter_skipexception/test.py:1-36"
    },
    "3121": {
        "file_id": 361,
        "content": "This code appears to be a mix of unrelated or incomplete fragments. It imports various modules but lacks cohesive structure, making it difficult to determine its purpose or functionality.",
        "type": "comment"
    },
    "3122": {
        "file_id": 362,
        "content": "/tests/black_autopep8_ast_parser_formatter_skipexception/format_test.sh",
        "type": "filepath"
    },
    "3123": {
        "file_id": 362,
        "content": "This code is formatting Python files, using autopep8 to enforce maximum line length and Black to ensure consistent formatting. It prevents changes on the original content by redirecting output to a view-only mode.",
        "type": "summary"
    },
    "3124": {
        "file_id": 362,
        "content": "# view only. no change on original content.\n# of course, for lines with long content, we will have trouble.\nMAXINT=1000000000\ncat test.py | autopep8 --max-line-length $MAXINT - | black -l $MAXINT -C - 2>/dev/null",
        "type": "code",
        "location": "/tests/black_autopep8_ast_parser_formatter_skipexception/format_test.sh:1-4"
    },
    "3125": {
        "file_id": 362,
        "content": "This code is formatting Python files, using autopep8 to enforce maximum line length and Black to ensure consistent formatting. It prevents changes on the original content by redirecting output to a view-only mode.",
        "type": "comment"
    },
    "3126": {
        "file_id": 363,
        "content": "/tests/black_autopep8_ast_parser_formatter_skipexception/format_functional.py",
        "type": "filepath"
    },
    "3127": {
        "file_id": 363,
        "content": "This code reads a Python file, encodes it, and then runs it through \"autopep8\" and \"Black\" formatting tools to ensure code follows PEP 8 style guide and is aesthetically pleasing. It also handles exceptions and prints the formatted code for further use.",
        "type": "summary"
    },
    "3128": {
        "file_id": 363,
        "content": "with open(\"test.py\", \"r\") as f:\n    code = f.read()\n# need binary data.\ncode_encoded = code.encode(\"utf-8\")\nimport subprocess\nMAXINT = 10000000000\ncommand = \"autopep8 --max-line-length {MAXINT} - | black -l {MAXINT} -C -\".format(\n    MAXINT=MAXINT\n)\ncommandLine = [\"bash\", \"-c\", command]\nresult = subprocess.run(commandLine, input=code_encoded, capture_output=True)\ntry:\n    assert result.returncode == 0\n    code_formatted = result.stdout.decode(\"utf-8\")\nexcept:\n    import traceback\n    traceback.print_exc()\n    print(\"STDOUT\", result.stdout)\n    print(\"STDERR\", result.stderr)\n    code_formatted = code\nprint(code_formatted)",
        "type": "code",
        "location": "/tests/black_autopep8_ast_parser_formatter_skipexception/format_functional.py:1-26"
    },
    "3129": {
        "file_id": 363,
        "content": "This code reads a Python file, encodes it, and then runs it through \"autopep8\" and \"Black\" formatting tools to ensure code follows PEP 8 style guide and is aesthetically pleasing. It also handles exceptions and prints the formatted code for further use.",
        "type": "comment"
    },
    "3130": {
        "file_id": 364,
        "content": "/tests/audio_volume_meter/test_volume_meter.py",
        "type": "filepath"
    },
    "3131": {
        "file_id": 364,
        "content": "This code calculates audio parameters, generates vocal slices, and clusters segments using KMeans for labeling. It merges adjacent segments with similar labels and stores the updated labels.",
        "type": "summary"
    },
    "3132": {
        "file_id": 364,
        "content": "# usually yelling is not always funny. but we can do speech to text. taking longer time though... pinpoint the cue time.\n# often some exclamation attempts like repetation or louder sounds.\naudio_src = \"/media/root/help/pyjom/samples/audio/dog_with_text/vocals.wav\"\n# heard of dog woooling.\n# import audioop\nimport pydub\ntimestep = 0.1  # my time setting.\naudiofile = pydub.AudioSegment.from_wav(audio_src)\nframe_rate = audiofile.frame_rate\nseconds = audiofile.duration_seconds\nprint(frame_rate)  # 44100.\nprint(seconds)  # sample length\nimport math\nimport numpy as np\nfrom talib import stream\n# frame_rate2 = frame_rate *timestep\nmilistep = 1000 * timestep\nma_step = 10  # one second of buffer size. or more. timeperiod=ma_step\nstd_arr, maxval_arr, abs_nonzero_arr = [], [], []\ndef getPaddingMovingAverage(myarray, timeperiod=10):\n    lt = math.ceil(timeperiod / 2)\n    rt = timeperiod - lt\n    len_myarray = len(myarray)\n    max_index = len_myarray - 1\n    result_array = []\n    for i in range(len_myarray):\n        start_index = i - lt",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:1-37"
    },
    "3133": {
        "file_id": 364,
        "content": "Code imports PyDub, sets timestep and frame rate variables from audio file duration and frame rate. Imports math, numpy and talib.stream. Defines function getPaddingMovingAverage to calculate moving average with padding, taking an array and time period as parameters. Initializes std_arr, maxval_arr and abs_nonzero_arr lists for further calculations.",
        "type": "comment"
    },
    "3134": {
        "file_id": 364,
        "content": "        start_index = max(0, start_index)\n        end_index = i + rt\n        end_index = min(end_index, max_index)\n        array_slice = myarray[start_index:end_index]\n        arr_slice_length = end_index - start_index\n        val = sum(array_slice) / arr_slice_length\n        # val = np.median(array_slice)\n        result_array.append(val)\n    return result_array\nmsteps = math.ceil(seconds / timestep)\nfor i in range(msteps):\n    # print(frame_rate2)\n    # probably in miliseconds.\n    segment = audiofile[i * milistep : (i + 1) * milistep]\n    data = segment.get_array_of_samples()\n    # containes two channels. 4410*2\n    darray = np.array(data)\n    print(darray.shape)\n    std = np.std(darray)\n    abs_darray = abs(darray)\n    maxval = np.max(abs_darray)\n    abs_nonzero = np.average(abs_darray)\n    print(\"STD:{} MAX:{} AVG:{}\".format(std, maxval, abs_nonzero))\n    std_arr.append(std)\n    # ma_std = stream.SMA(np.array(std_arr[-ma_step:]).astype(np.float64))\n    maxval_arr.append(maxval)\n    # ma_maxval = stream.SMA(np.array(maxval_arr[-ma_step:]).astype(np.float64))",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:38-67"
    },
    "3135": {
        "file_id": 364,
        "content": "This code calculates the standard deviation, maximum value, and average of absolute values for a given audio segment. It appends the calculated values to respective lists and potentially calculates moving averages. The code utilizes numpy functions for array processing and the SMA function from the stream module (possibly) for calculating moving averages.",
        "type": "comment"
    },
    "3136": {
        "file_id": 364,
        "content": "    abs_nonzero_arr.append(abs_nonzero)\n    # ma_abs_nonzero = stream.SMA(np.array(abs_nonzero_arr[-ma_step:]).astype(np.float64))\n    # breakpoint()\n    # print(\"MA_STD:{} MA_MAX:{} MA_AVG:{}\".format(ma_std,ma_maxval,ma_abs_nonzero))\n    # print(data)\n    # breakpoint()\n    # maxAudioValue =audioop.max(data,2)\n    # print(\"STEP:\",i,\"VOLUME:\",maxAudioValue)\nstd_arr0 = getPaddingMovingAverage(std_arr, timeperiod=20)\nmaxval_arr0 = getPaddingMovingAverage(maxval_arr, timeperiod=20)\nabs_nonzero_arr0 = getPaddingMovingAverage(abs_nonzero_arr, timeperiod=20)\nma_std_arr = getPaddingMovingAverage(std_arr, timeperiod=60)\nma_maxval_arr = getPaddingMovingAverage(maxval_arr, timeperiod=60)\nma_abs_nonzero_arr = getPaddingMovingAverage(abs_nonzero_arr, timeperiod=60)\n# just use one freaking example as my conclusion.\nstatus = \"end\"\nvocal_slices = []\nvocal_slice = []\nfinal_index = msteps - 1\n# could you use clustering.\n# like time versus duration.\navg_std = []\nfor i in range(msteps):\n    a, b, c = std_arr0[i], maxval_arr0[i], abs_nonzero_arr0[i]",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:68-92"
    },
    "3137": {
        "file_id": 364,
        "content": "This code calculates the moving average for various audio parameters (std_arr, maxval_arr, and abs_nonzero_arr) over different time periods. It then generates a vocal slice based on these moving averages for each step in the range of msteps. The final index is set to be one less than the total number of steps, and an average list is created.",
        "type": "comment"
    },
    "3138": {
        "file_id": 364,
        "content": "    a0, b0, c0 = ma_std_arr[i], ma_maxval_arr[i], ma_abs_nonzero_arr[i]\n    if status == \"end\":\n        # startpoint = a0 < a\n        startpoint = a0 < a or b0 < b or c0 < c\n        if startpoint:\n            vocal_slice.append(i)\n            avg_std.append(a)\n            status = \"start\"\n    else:\n        avg_std.append(a)\n        # endpoint = a0 > a\n        endpoint = a0 > a and b0 > b and c0 > c\n        if endpoint:\n            vocal_slice.append(i)\n            # vocal_slice[1] = i\n            status = \"end\"\n            vocal_slices.append([vocal_slice, np.average(avg_std)])\n            vocal_slice = []\n            avg_std = []\nif len(vocal_slice) == 1:\n    vocal_slice.append(final_index)\n    vocal_slices.append([vocal_slice, np.average(avg_std)])\ntime_rate = timestep\ntimed_vocal_slices = [\n    [[x[0][0] * time_rate, x[0][1] * time_rate], x[1]] for x in vocal_slices\n]\nd2_data = []\nd1_data = []\nfor slice_vocal in timed_vocal_slices:\n    print(slice_vocal)  # it could be two dimentional. both for length and volume?",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:93-123"
    },
    "3139": {
        "file_id": 364,
        "content": "The code is iterating through an array of data and dividing it into segments based on threshold values for average, maximum, and absolute non-zero values. These segments are classified as either \"start\" or \"end\", and the indices of the start and end points are stored in separate lists. If a segment only has one point, it is added to the list of vocal slices along with the average of the threshold values. The code then calculates the time rate and creates two-dimensional lists of timed vocal slices (segment start and end times), and data for d1 and d2. Finally, the code prints the timed vocal slices, which could be in a two-dimensional format representing length and volume.",
        "type": "comment"
    },
    "3140": {
        "file_id": 364,
        "content": "    # to find best shit you need grouping.\n    a, b = slice_vocal[0]\n    length = b - a\n    d2_data.append([length, slice_vocal[1]])\n    d1_data.append([slice_vocal[1]])\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2)\nkm = kmeans.fit(d1_data)\nlabels = km.labels_\nlabel_indexs = {i: labels[i] for i in range(len(labels))}\n# print(label_index)\nnew_labels = []\nmergeTimeGap = 0.5\nlb_new = 0\nlast_elem = None\nfor index, data in enumerate(timed_vocal_slices):\n    # data = timed_vocal_slices\n    [start, end], std = data\n    label = label_indexs[index]\n    if last_elem == None:\n        last_elem = [[start, end], label]\n    else:\n        [[last_start, last_end], last_label] = last_elem\n        if start - last_end < mergeTimeGap and last_label == label:\n            pass\n            # last_elem = [[start,end],label]\n        else:\n            lb_new += 1\n        last_elem = [[start, end], label]\n    new_labels.append(lb_new)\n    print(\"DATA:\", data, \"LABEL:\", label, \"NEW_LABEL:\", lb_new)",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:124-157"
    },
    "3141": {
        "file_id": 364,
        "content": "This code is grouping vocal segments based on their start and end timestamps. It uses KMeans clustering from sklearn to assign labels to each segment, then merges adjacent segments with the same label if they are less than a certain time gap apart. The new_labels list stores the updated labels for each segment.",
        "type": "comment"
    },
    "3142": {
        "file_id": 365,
        "content": "/tests/elastic_search_engine/README.md",
        "type": "filepath"
    },
    "3143": {
        "file_id": 365,
        "content": "The code suggests that there is a need for a memory-efficient search engine, possibly due to limited resources. It also mentions Meilisearch as a potential option but expresses concerns about its memory intensity or the team's mastery of it.",
        "type": "summary"
    },
    "3144": {
        "file_id": 365,
        "content": "we need a memory efficient search engine, under limited memory.\nmeilisearch is memory intensive maybe? or just because we have not properly mastered it",
        "type": "code",
        "location": "/tests/elastic_search_engine/README.md:1-3"
    },
    "3145": {
        "file_id": 365,
        "content": "The code suggests that there is a need for a memory-efficient search engine, possibly due to limited resources. It also mentions Meilisearch as a potential option but expresses concerns about its memory intensity or the team's mastery of it.",
        "type": "comment"
    },
    "3146": {
        "file_id": 366,
        "content": "/tests/moviepy_loop_video_till_target/test.py",
        "type": "filepath"
    },
    "3147": {
        "file_id": 366,
        "content": "This code imports the \"main\" function from the \"loop_till_target\" module and sets the target duration of the video to 20 seconds. It uses a GIF file named \"cute_cat_gif\" as input, applies the main function to it, and saves the resulting video as \"cute_cat_gif_20_secs_plus.gif\". The code also checks if the final duration of the video is greater than or equal to the target duration using an assertion statement.",
        "type": "summary"
    },
    "3148": {
        "file_id": 366,
        "content": "from loop_till_target import main\ntarget_secs = 20\nvideo_in = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif\"\n# no right codec! fuck. GIF not supported?\nvideo_out = f\"/root/Desktop/works/pyjom/samples/video/cute_cat_gif_{target_secs}_secs_plus.gif\"\nfvd = main(video_in, target_secs, f_out=video_out, in_place=False,debug=True)\nassert fvd >= target_secs",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/test.py:1-11"
    },
    "3149": {
        "file_id": 366,
        "content": "This code imports the \"main\" function from the \"loop_till_target\" module and sets the target duration of the video to 20 seconds. It uses a GIF file named \"cute_cat_gif\" as input, applies the main function to it, and saves the resulting video as \"cute_cat_gif_20_secs_plus.gif\". The code also checks if the final duration of the video is greater than or equal to the target duration using an assertion statement.",
        "type": "comment"
    },
    "3150": {
        "file_id": 367,
        "content": "/tests/moviepy_loop_video_till_target/loop_till_target.py",
        "type": "filepath"
    },
    "3151": {
        "file_id": 367,
        "content": "This code uses ffmpeg to create a video clip with repeating segments, splitting the input video into original and reversed parts, and concatenates them based on loop strategy. It replaces sections of the input video until reaching the target duration and saves the output at specified location.",
        "type": "summary"
    },
    "3152": {
        "file_id": 367,
        "content": "import os\n# moviepy's shit.\nfrom moviepy.editor import VideoFileClip  # , concatenate_videoclips\n# import moviepy.video.fx.all as vfx\ndef main(\n    f_in: str,\n    target_secs: float,\n    f_out: str = \"\",\n    in_place: bool = True,\n    debug: bool = False,\n    # accuracy_float:int=4\n    # audio:bool=False, # it will cause trouble?\n):\n    # print(\"___\")\n    # print(\"AUDIO?\",audio)\n    # print(\"IN PLACE?\",in_place)\n    # print(\"___\")\n    assert os.path.exists(f_in)\n    assert target_secs > 0\n    # target_secs_str =(\"{\"+f':.{accuracy_float}f'+\"}\").format(target_secs)\n    targetFilePath = f_out\n    if not in_place:\n        assert f_out != \"\"\n    else:\n        targetFilePath = f_in\n    clip = VideoFileClip(f_in)\n    # if not audio:\n    #     clip = clip.without_audio()\n    # newclip = clip.fx(vfx.time_mirror) # error?\n    # newclip = clip\n    import ffmpeg\n    file_input_split = ffmpeg.input(f_in).filter_multi_output(\n        \"split\"\n    )  # this is infinite split.\n    videoDuration = clip.duration\n    import math\n    import tempfile",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:1-47"
    },
    "3153": {
        "file_id": 367,
        "content": "The code imports necessary libraries and defines a function \"main\" that takes input file, target duration, output file (optional), performs in-place editing (optional), and debug mode (optional). It asserts the existence of the input file and positive target duration. Depending on options, it either splits or mirrors the video using ffmpeg before processing.",
        "type": "comment"
    },
    "3154": {
        "file_id": 367,
        "content": "    import shutil\n    fileExtension = f_in.split(\".\")[-1]\n    assert fileExtension != \"\"\n    loopStrategy = [\n        (-1) ** i for i in range(math.ceil(target_secs / videoDuration))\n    ]  # zero division error?\n    if debug:\n        print(\"Loop strategy:\")\n        print(loopStrategy)\n    clips = []\n    file_input_original = file_input_split[0].filter_multi_output(\"split\")\n    file_input_reverse = (\n        file_input_split[1].filter(\"reverse\").filter_multi_output(\"split\")\n    )\n    for index, signal in enumerate(loopStrategy):\n        mindex = index // 2\n        if signal == 1:\n            file_input = file_input_original[mindex]\n            clips.append(file_input)\n        else:\n            file_input_reverse2 = file_input_reverse[mindex]\n            clips.append(file_input_reverse2)\n    # final = concatenate_videoclips(clips)\n    final = ffmpeg.concat(*clips)\n    finalVideoDuration = len(loopStrategy) * videoDuration\n    with tempfile.NamedTemporaryFile(\n        \"w+\",\n        suffix=f\".{fileExtension}\",\n    ) as f:",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:48-82"
    },
    "3155": {
        "file_id": 367,
        "content": "This code is creating a video clip with repeating segments. It splits the input video into two parts, original and reversed. Then, it loops through a list of loop strategies to determine which segment (original or reversed) should be used for each iteration. The final video is created by concatenating these segments together using ffmpeg. The resulting video's duration will be determined by the length of the loop strategy list multiplied by the original video's duration.",
        "type": "comment"
    },
    "3156": {
        "file_id": 367,
        "content": "        tmpFilePath = f.name\n        # warning! what is the audio shit?\n        # print(\"TMP FILE PATH?\",tmpFilePath)\n        # breakpoint()\n        # final.write_videofile(tmpFilePath, fps=clip.fps)\n        # finalVideoDuration = final.duration\n        final.output(tmpFilePath).run(overwrite_output=True)\n        shutil.copy(tmpFilePath, targetFilePath)\n    return finalVideoDuration\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-i\", \"--input\", help=\"input file\", required=True, type=str)\n    parser.add_argument(\"-o\", \"--output\", help=\"output file\", default=\"\", type=str)\n    parser.add_argument(\n        \"-r\",\n        \"--replace\",\n        help=\"replace original input file\",\n        action=\"store_true\",\n        default=False,\n    )\n    # parser.add_argument(\n    #     \"-a\",\n    #     \"--audio\",\n    #     help=\"include audio from input\",\n    #     action=\"store_true\",\n    #     default=False,\n    # )\n    parser.add_argument(\n        \"-t\", \"--target\", help=\"target seconds\", required=True, type=float",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:83-116"
    },
    "3157": {
        "file_id": 367,
        "content": "This code takes an input video file and replaces a specific section of the video with another video until a target duration is reached. The final output is saved at the specified output location.",
        "type": "comment"
    },
    "3158": {
        "file_id": 367,
        "content": "    )\n    args = parser.parse_args()\n    if not args.replace:\n        assert args.output != \"\"\n    main(\n        args.input,\n        args.target,\n        f_out=args.output,\n        in_place=args.replace,\n        # audio=args.audio\n    )",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:117-128"
    },
    "3159": {
        "file_id": 367,
        "content": "The code initializes a parser, parses command line arguments, asserts the absence of replace flag or an output path specified, and then calls the main function with the input, target, output (if applicable), and replace (if applicable) arguments.",
        "type": "comment"
    },
    "3160": {
        "file_id": 368,
        "content": "/tests/post_numpy_array/server.py",
        "type": "filepath"
    },
    "3161": {
        "file_id": 368,
        "content": "The code sets up a FastAPI server on port 5463, defines an endpoint that receives an image and returns \"good\", and runs a non-blocking Uvicorn server.",
        "type": "summary"
    },
    "3162": {
        "file_id": 368,
        "content": "SERVER_PORT=5463\nif __name__ == '__main__':\n    # from pydantic import BaseModel\n    # import numpy as np\n    import numpy_serializer\n    # from typing import Union\n    # class Image(BaseModel):\n    #     image:Union[str,bytes]\n    from fastapi import FastAPI, Body\n    app = FastAPI()\n    @app.post(\"/\")\n    def receiveImage(image:bytes=Body(default=None),\n        isBytes:bool =False,\n    encoding:str='utf-8', debug:bool=False):\n        # return book\n        # print('image type:',type(image))\n        # print(image)\n        import urllib.parse\n        image = image.removeprefix(b'image=') # fuck man.\n        image = urllib.parse.unquote_to_bytes(image)\n        if debug:\n            print(\"isBytes:\",isBytes)\n        if not isBytes:\n            image = image.decode(encoding) #fuck?\n            # read image from path, url\n        else:\n            image = numpy_serializer.from_bytes(image)\n        if debug:\n            print('shape?',image.shape)\n            print('image?',image)\n        return \"good\"\n    import uvicorn\n ",
        "type": "code",
        "location": "/tests/post_numpy_array/server.py:2-39"
    },
    "3163": {
        "file_id": 368,
        "content": "This code is setting up a FastAPI server on port 5463. It defines an endpoint at the root (\"/\") that receives an image either in bytes or as a string, and returns \"good\" as a response. The image data can be decoded from bytes using numpy_serializer or read from a file or URL if it's received as a string.",
        "type": "comment"
    },
    "3164": {
        "file_id": 368,
        "content": "   # checking: https://9to5answer.com/python-how-to-use-fastapi-and-uvicorn-run-without-blocking-the-thread\n    def run(host='0.0.0.0',port=SERVER_PORT): \n        \"\"\"\n        This function to run configured uvicorn server.\n        \"\"\"\n        uvicorn.run(app=app, host=host, port=port)\n    run()",
        "type": "code",
        "location": "/tests/post_numpy_array/server.py:39-46"
    },
    "3165": {
        "file_id": 368,
        "content": "This function runs a configured Uvicorn server non-blocking, allowing concurrent tasks.",
        "type": "comment"
    },
    "3166": {
        "file_id": 369,
        "content": "/tests/post_numpy_array/client.py",
        "type": "filepath"
    },
    "3167": {
        "file_id": 369,
        "content": "Importing numpy, requests, and numpy_serializer; using SERVER_PORT from server module; creating a test image array; converting the image to bytes using numpy_serializer; sending the image data as a POST request to localhost; printing the response received. Includes a malformatted docstring function with textwrap usage.",
        "type": "summary"
    },
    "3168": {
        "file_id": 369,
        "content": "import numpy as np\nimport requests\nimport numpy_serializer\n# this is pure magic. shit.\nfrom server import SERVER_PORT\nimage = np.array([1,2,3])\nimage_bytes = numpy_serializer.to_bytes(image)\ndata = {'image':image_bytes}\nprint(\"BYTES?\", image_bytes)\nr = requests.post(\"http://localhost:{}\".format(SERVER_PORT),data=data,params={'isBytes':True,'debug':True})\nprint('RESPONSE?',r.text)\ndef docstring(): # malformat\n    import textwrap\n    a =\"\"\"\n    lmn\n    abcdefg \n    hijk\n    \"\"\"\n    print(a)\n    print()\n    print(textwrap.dedent(a))\n    # inspect.cleandoc\n    # https://9to5answer.com/how-to-remove-extra-indentation-of-python-triple-quoted-multi-line-strings\ndocstring()",
        "type": "code",
        "location": "/tests/post_numpy_array/client.py:1-28"
    },
    "3169": {
        "file_id": 369,
        "content": "Importing numpy, requests, and numpy_serializer; using SERVER_PORT from server module; creating a test image array; converting the image to bytes using numpy_serializer; sending the image data as a POST request to localhost; printing the response received. Includes a malformatted docstring function with textwrap usage.",
        "type": "comment"
    },
    "3170": {
        "file_id": 370,
        "content": "/tests/patch_requests_timeout/server.py",
        "type": "filepath"
    },
    "3171": {
        "file_id": 370,
        "content": "This code sets up a FastAPI server using uvicorn, listens on port 9341, and has a single route (\"/\") that returns \"hello world\" after a 10-second delay. The run() function is used to start the configured uvicorn server.",
        "type": "summary"
    },
    "3172": {
        "file_id": 370,
        "content": "SERVER_PORT = 9341\nif __name__ == \"__main__\":\n    from fastapi import FastAPI\n    app = FastAPI()\n    import time\n    @app.get(\"/\")\n    def receiveImage():\n        time.sleep(10)\n        return \"hello world\"\n    import uvicorn\n    # checking: https://9to5answer.com/python-how-to-use-fastapi-and-uvicorn-run-without-blocking-the-thread\n    def run(host='0.0.0.0',port=SERVER_PORT): \n        \"\"\"\n        This function to run configured uvicorn server.\n        \"\"\"\n        uvicorn.run(app=app, host=host, port=port)\n    run()",
        "type": "code",
        "location": "/tests/patch_requests_timeout/server.py:1-21"
    },
    "3173": {
        "file_id": 370,
        "content": "This code sets up a FastAPI server using uvicorn, listens on port 9341, and has a single route (\"/\") that returns \"hello world\" after a 10-second delay. The run() function is used to start the configured uvicorn server.",
        "type": "comment"
    },
    "3174": {
        "file_id": 371,
        "content": "/tests/patch_requests_timeout/client.py",
        "type": "filepath"
    },
    "3175": {
        "file_id": 371,
        "content": "This code patches the requests library to set a default timeout for all requests made using it. It uses patchy module to modify the HTTPAdapter's send method, checking if a timeout is provided and setting it to REQUESTS_TIMEOUT (3 seconds) if none is given. The patch is then applied using the patchy module.",
        "type": "summary"
    },
    "3176": {
        "file_id": 371,
        "content": "import patchy\nfrom requests.adapters import HTTPAdapter\nREQUESTS_TIMEOUT=3 # working! great.\ndef patch_requests_default_timeout() -> None:\n    \"\"\"\n    Set a default timeout for all requests made with “requests”.\n    Upstream is waiting on this longstanding issue:\n    https://github.com/psf/requests/issues/3070\n    \"\"\"\n    patchy.patch(\n        HTTPAdapter.send,\n        f\"\"\"\\\n        @@ -14,6 +14,8 @@\n             :param proxies: (optional) The proxies dictionary to apply to the request.\n             :rtype: requests.Response\n             \\\"\"\"\n        +    if timeout is None:\n        +        timeout = {REQUESTS_TIMEOUT}\n             try:\n                 conn = self.get_connection(request.url, proxies)\n        \"\"\",\n    )\npatch_requests_default_timeout()\nimport requests\nfrom server import SERVER_PORT\nr = requests.get(f\"http://localhost:{SERVER_PORT}\")",
        "type": "code",
        "location": "/tests/patch_requests_timeout/client.py:2-36"
    },
    "3177": {
        "file_id": 371,
        "content": "This code patches the requests library to set a default timeout for all requests made using it. It uses patchy module to modify the HTTPAdapter's send method, checking if a timeout is provided and setting it to REQUESTS_TIMEOUT (3 seconds) if none is given. The patch is then applied using the patchy module.",
        "type": "comment"
    },
    "3178": {
        "file_id": 372,
        "content": "/tests/motion_vector_estimation/test.sh",
        "type": "filepath"
    },
    "3179": {
        "file_id": 372,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "summary"
    },
    "3180": {
        "file_id": 372,
        "content": "bash ./run.sh python3.10 extract_mvs.py vid_h264.mp4 --preview --verbose",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.sh:1-1"
    },
    "3181": {
        "file_id": 372,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "comment"
    },
    "3182": {
        "file_id": 373,
        "content": "/tests/motion_vector_estimation/test.py",
        "type": "filepath"
    },
    "3183": {
        "file_id": 373,
        "content": "The code processes video frames and estimates motion vectors, then plots the results using matplotlib and handles potential errors. It uses pandas, numpy, and OpenCV for calculations.",
        "type": "summary"
    },
    "3184": {
        "file_id": 373,
        "content": "# it contains subpixel motion vectors. fucking hell\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# change source?\n# gif containers does not have motion vectors.\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n# without mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_without_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_without_mestimate.mp4\"\n# with mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"\nsource = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nfrom mvextractor.videocap import VideoCap",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:1-25"
    },
    "3185": {
        "file_id": 373,
        "content": "This code is setting the source video file path for various test cases involving motion vector estimation. The files include different types of videos such as MP4 and GIF, with and without mestimate data, and nearly duplicate frame detection tests. It also initializes custom CV2 build and imports necessary modules.",
        "type": "comment"
    },
    "3186": {
        "file_id": 373,
        "content": "from caer.video.frames_and_fps import count_frames, get_res\nimport cv2\nframesCount = count_frames(source)\nres = get_res(source)  # (width, height)\nprint(\"RES: %s\" % str(res))\nres_x, res_y = res\nframe_common_divisor = min(res_x, res_y)\nimport math\ndef cartesianDistance(d2vector):\n    try:\n        x, y = d2vector\n        return math.sqrt(x**2 + y**2)\n    except:\n        print('item unpackable.', d2vector)\n        return 0\ndef XYWHToDiagonal(x, y, w, h):\n    return (x, y), (x + w, y + h)\n# 如果整除16那么就在这个范围里面 如果不整除范围就要扩大 扩大到相应的16的倍数\ndef get16Value(res_x):\n    rem_x = res_x % 16\n    val = res_x // 16\n    if rem_x != 0:\n        val += 1\n    return val\nx_16val = get16Value(res_x)\ny_16val = get16Value(res_y)\nmotion_render_frame = (x_16val * 16, y_16val * 16)\ntotal_block_weights = x_16val * y_16val * 2 * 2\ncap = VideoCap()\ncap.open(source)  # wtf is going on here?\n# if there is nothing we will breakup\n# visualize, show_picture = True, True\nvisualize, show_picture = False, False\n# so there can only be one such macroblock\ndef checkMacroBlock(value):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:26-75"
    },
    "3187": {
        "file_id": 373,
        "content": "This code is initializing variables and functions related to video processing. It calculates the resolution of a source, determines if it's divisible by 16, adjusts if necessary, and sets up variables for motion vector estimation and visualization. The VideoCap class is opened but its functionality remains unclear. The checkMacroBlock function checks for one macroblock value.",
        "type": "comment"
    },
    "3188": {
        "file_id": 373,
        "content": "    for mod in [16, 8]:\n        modValue = value % mod\n        if modValue == mod / 2:\n            return mod\n    # if not satisfied, we are shit.\nfrom functools import lru_cache\n@lru_cache(maxsize=4)\ndef getModXModYFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = checkMacroBlock(block_x), checkMacroBlock(block_y)\n    if mod_x is not None and mod_y is not None:\n        return mod_x, mod_y\n    else:\n        print(\"block center coordinates\", blockCenterCoordinates)\n        print(\"WTF IS GOING ON WITH THE BLOCK CENTER\")\n        breakpoint()\n        return 0, 0\ndef getRectangleXYWHFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    mod_x_half, mod_y_half = mod_x / 2, mod_y / 2\n    x, y, w, h = block_x - mod_x_half, block_y - mod_y_half, mod_x, mod_y\n    return tuple([int(elem) for elem in [x, y, w, h]])\ndef getBlockWeightFromBlockCenterCoordinates(blockCenterCoordinates):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:76-107"
    },
    "3189": {
        "file_id": 373,
        "content": "This code defines several functions for handling block center coordinates in a specific context. It checks the modulo value of the coordinates to determine the size and position of the blocks, and uses these values to calculate the rectangle's dimensions and the block weight. The `lru_cache` decorator is used to cache the results of the `getModXModYFromBlockCenterCoordinates` function to improve performance.",
        "type": "comment"
    },
    "3190": {
        "file_id": 373,
        "content": "    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    weights = mod_x * mod_y / 8 / 8\n    return weights\nimport progressbar\nimport numpy as np\n# max_dst_x, max_dst_y = 0,0\ndef averageMotionVectors(motion_vector_list):\n    if len(motion_vector_list) == 0:\n        average_tuple = (0, 0)\n    if len(motion_vector_list) > 1:\n        marray = np.array(motion_vector_list)\n        # print(\"MAKING AVERAGE:\")\n        # print(marray)\n        average = np.average(marray, axis=0)\n        # breakpoint()\n        average_tuple = tuple(average)\n    else:\n        average_tuple = tuple(motion_vector_list[0])\n    return average_tuple\nmotion_area_ratio_array = []\n# average_weighted_motion_vector_array = []\n# average_global_weighted_motion_vector_array = []\naverage_weighted_motion_vector_cartesian_array = []\naverage_global_weighted_motion_vector_cartesian_array = []\naverage_weighted_motion_vectors_filtered_cartesian_distance_array = []\naverage_global_weighted_motion_vectors_filtered_cartesian_distance_array = []",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:108-140"
    },
    "3191": {
        "file_id": 373,
        "content": "Function to calculate the average motion vectors based on a list of motion vectors. If the list is empty, returns (0, 0). If the list has more than one vector, calculates the average and returns it as a tuple. Else, returns the first vector in the list.\n\nInitializes arrays for storing average_weighted_motion_vector_cartesian, average_global_weighted_motion_vector_cartesian, average_weighted_motion_vectors_filtered_cartesian_distance, and average_global_weighted_motion_vectors_filtered_cartesian_distance.",
        "type": "comment"
    },
    "3192": {
        "file_id": 373,
        "content": "for _ in progressbar.progressbar(range(framesCount)):\n    success, frame, motion_vectors, frame_type, timestamp = cap.read()\n    height, width, channels = frame.shape\n    # breakpoint()\n    if success:\n        # what is the content of this motion vector?\n        # print(motion_vectors)\n        # import pandas as pd\n        # df = pd.DataFrame(motion_vectors)\n        # df = pd.DataFrame(motion_vectors,index=['source_index','unk0','unk1','src_x','src_y','dst_x','dst_y','motion_x','motion_y','motion_scale'])\n        # breakpoint()\n        # print()\n        # print(\"_____________________________\")\n        condition = motion_vectors[:, 0] < 0\n        # print(condition)\n        # print(condition.shape)\n        # breakpoint()\n        motion_vectors_simplified = motion_vectors[condition, :][:, [0, 5, 6, 7, 8, 9]]\n        motion_vectors_scale = motion_vectors_simplified[:, [5]]\n        motion_vectors_scale_inversed = 1 / motion_vectors_scale\n        motion_vectors_with_scale = motion_vectors_simplified[:, [3, 4]]\n        motion_vectors_scale_inversed_stacked = np.hstack(",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:142-163"
    },
    "3193": {
        "file_id": 373,
        "content": "The code reads frames and motion vectors from a video stream, processes them, and stores selected information in separate arrays. It uses pandas for data processing and numpy for array manipulation.",
        "type": "comment"
    },
    "3194": {
        "file_id": 373,
        "content": "            [motion_vectors_scale_inversed] * 2\n        )\n        motion_vectors_restored = (\n            motion_vectors_scale_inversed_stacked * motion_vectors_with_scale\n        )  # just element wise?\n        # print('STACKED:', motion_vectors_scale_inversed_stacked.shape)\n        # print(\"WITH SCALE:\", motion_vectors_with_scale.shape)\n        # print(\"RESTORED:\",motion_vectors_restored.shape)\n        # print(motion_vectors_simplified.shape)\n        # print(motion_vectors_scale.shape)\n        # breakpoint()\n        motion_vectors_dest_coords_restored = np.hstack(\n            [motion_vectors_simplified[:, [1, 2]], motion_vectors_restored]\n        )\n        # motion_vectors_simplified = motion_vectors[:,[0,5,6,7,8]]\n        # motion_vectors_simplified_unique = np.unique(motion_vectors_simplified, axis=0)\n        # print(motion_vectors_simplified_unique.shape, motion_vectors.shape)\n        # breakpoint()\n        motion_vectors_dict = {}\n        for mv in motion_vectors_dest_coords_restored:\n            # drop duplicates first!",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:164-184"
    },
    "3195": {
        "file_id": 373,
        "content": "This code segment is responsible for restoring the motion vectors after scaling and stacking. It performs element-wise multiplication of two arrays, one containing scaled motion vectors and the other being the stacked motion vectors. The result is stored in \"motion_vectors_restored\". Then, it horizontally stacks the simplified motion vector coordinates and the restored ones using numpy's hstack function, resulting in \"motion_vectors_dest_coords_restored\". Finally, a dictionary named \"motion_vectors_dict\" is initialized but not fully populated in this snippet.",
        "type": "comment"
    },
    "3196": {
        "file_id": 373,
        "content": "            (\n                dst_x,  # corresponding macro block.\n                dst_y,  # for destination only\n                motion_x,\n                motion_y,\n                # motion_scale,  # don't know what the fuck is wrong with the motion scale\n            ) = mv.tolist()\n            # say we just want source_index <0, aka mv compared to previous frame\n            # try:\n            #     assert motion_x / motion_scale == src_x - dst_x\n            #     assert motion_y / motion_scale == src_y - dst_y\n            # except:\n            #     print(src_x, dst_x, motion_x, motion_scale)\n            #     print(src_y, dst_y, motion_y, motion_scale)\n            #     print(\"*\" * 20)\n            # it will be inaccurate if we abandon this subpixel precision.\n            # if source_index >= 0:\n            #     continue\n            # if dst_x>max_dst_x:\n            #     max_dst_x = dst_x\n            # if dst_y>max_dst_y:\n            #     max_dst_y = dst_y\n            destCoord = (dst_x, dst_y)\n            motion_vector = (motion_x, motion_y)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:185-208"
    },
    "3197": {
        "file_id": 373,
        "content": "This code segment is related to motion vector estimation in video processing. It calculates the destination coordinates and motion vector for a macro block, but there seems to be an issue with the motion scale. The code tries to assert that the motion_x and motion_y are scaled correctly based on the motion_scale, but it is causing some problem.",
        "type": "comment"
    },
    "3198": {
        "file_id": 373,
        "content": "            # print(destCoord)\n            # breakpoint()\n            if motion_vector == (0, 0):\n                # print(\"zero motion vector detected. skipping\")\n                # breakpoint()\n                continue\n            # print('destination coords:',destCoord)\n            # print('motion vector:',motion_vector)\n            motion_vectors_dict.update(\n                {destCoord: motion_vectors_dict.get(destCoord, []) + [motion_vector]}\n            )\n            # you know, different frame sources may lead to different results.\n            # these vectors could overlap. which one you want to keep? the smaller ones or the bigger ones?\n            # if destCoord in destCoords:\n            #     print(\"SKIPPING DUPLICATE DESTCOORD:\", destCoord)\n            #     print(\"PREVIOUS MV\",prevMV)\n            #     print(\"CURRENT MV\", mv)\n            #     continue\n            # else:\n            #     destCoords.add(destCoord)\n            # prevMV = mv\n            # try:\n            #     # src_x, src_y may not apply the same rule.",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:209-232"
    },
    "3199": {
        "file_id": 373,
        "content": "This code checks if a motion vector is zero and skips processing if it is. It then updates a dictionary of motion vectors by adding the new motion vector to the destination coordinate, while considering potential overlaps with other motion vectors.",
        "type": "comment"
    }
}