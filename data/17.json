{
    "1700": {
        "file_id": 154,
        "content": "/tests/test_dummy.py",
        "type": "filepath"
    },
    "1701": {
        "file_id": 154,
        "content": "This code imports necessary modules, initializes a ContentProducer and ContentReviewer objects, runs their main methods, and prints their identifier data. It tests content production and reviewing functionality.",
        "type": "summary"
    },
    "1702": {
        "file_id": 154,
        "content": "from test_commons import *\nfrom pyjom.main import *\nproducer = ContentProducer()\nproducer.main()\nprint(producer.identifier.data)\nreviewer = ContentReviewer()\nreviewer.main()\nprint(reviewer.identifier.data)",
        "type": "code",
        "location": "/tests/test_dummy.py:1-10"
    },
    "1703": {
        "file_id": 154,
        "content": "This code imports necessary modules, initializes a ContentProducer and ContentReviewer objects, runs their main methods, and prints their identifier data. It tests content production and reviewing functionality.",
        "type": "comment"
    },
    "1704": {
        "file_id": 155,
        "content": "/tests/test_bilibili_resolve_tid.py",
        "type": "filepath"
    },
    "1705": {
        "file_id": 155,
        "content": "This code imports necessary modules, sets tid to 217, and calls resolveSubTidsFromTid function with the tid. The returned result is then printed. It tests resolving subTids from a given tid in Bilibili platform's database.",
        "type": "summary"
    },
    "1706": {
        "file_id": 155,
        "content": "from test_commons import *\nfrom pyjom.platforms.bilibili.database import resolveSubTidsFromTid\ntid = 217\nresult = resolveSubTidsFromTid(tid)\nprint(\"RESULT?\", result)",
        "type": "code",
        "location": "/tests/test_bilibili_resolve_tid.py:1-6"
    },
    "1707": {
        "file_id": 155,
        "content": "This code imports necessary modules, sets tid to 217, and calls resolveSubTidsFromTid function with the tid. The returned result is then printed. It tests resolving subTids from a given tid in Bilibili platform's database.",
        "type": "comment"
    },
    "1708": {
        "file_id": 156,
        "content": "/tests/test_bilibili_register_video.py",
        "type": "filepath"
    },
    "1709": {
        "file_id": 156,
        "content": "This code imports necessary modules, sets bilibili video ID and user ID, calls the \"registerBilibiliUserVideo\" function to register the video with given parameters, and prints the success status of registration.",
        "type": "summary"
    },
    "1710": {
        "file_id": 156,
        "content": "dedeuserid = str(397424026)\nbvid = \"BV1Gd4y1j7ht\"\nfrom test_commons import *\nfrom pyjom.modules.contentPosting.bilibiliPoster import registerBilibiliUserVideo\nsuccess = registerBilibiliUserVideo(bvid, dedeuserid)\nprint(\"SUCCESS?\", success)",
        "type": "code",
        "location": "/tests/test_bilibili_register_video.py:1-7"
    },
    "1711": {
        "file_id": 156,
        "content": "This code imports necessary modules, sets bilibili video ID and user ID, calls the \"registerBilibiliUserVideo\" function to register the video with given parameters, and prints the success status of registration.",
        "type": "comment"
    },
    "1712": {
        "file_id": 157,
        "content": "/tests/test_auto_local_reviewer.py",
        "type": "filepath"
    },
    "1713": {
        "file_id": 157,
        "content": "The code imports modules, defines detectors' dictionaries, sets template names, and initializes an object wbRev from Main class with specific arguments. The main() method is then called with these arguments for execution.",
        "type": "summary"
    },
    "1714": {
        "file_id": 157,
        "content": "from test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\n# autoArgs = {\"subtitle_detector\": {\"timestep\": 0.2}} # not work for boundary works.\n# autoArgs = {\"subtitle_detector\": {\"timestep\": 0.2},\"yolov5_detector\":{\"model\":\"yolov5x\"}}\n# template_names = [\"subtitle_detector.mdl.j2\"] # test ocr entities first.\n# template_names = [\"yolov5_detector.mdl.j2\"]\nautoArgs = {\n    \"frameborder_detector\": {\n        \"model\": \"huffline_horizontal_vertical\",\n        \"config\": {\"includeBoundaryLines\": True},\n    }\n}\n# autoArgs={\"frameborder_detector\":{\"model\":\"framedifference_talib\",\"config\":{}}}\ntemplate_names = [\"frameborder_detector.mdl.j2\"]\n# template_names = [\"framediff_detector.mdl.j2\"]\n# seems cudnn is causing trouble?\n# CuDNN Version 降到7.6试试，这个问题是环境问题引起的\n# https://pypi.tuna.tsinghua.edu.cn/packages/a4/1f/56dddeb4794137e3f824476ead29806d60a5d5fc20adba9f4d7ca5899900/paddlepaddle_gpu-2.2.2-cp39-cp39-manylinux1_x86_64.whl\n# from pip._internal.cli.main\n# we have modified the pip downloader.\nwbRev = FilesystemAutoContentReviewer(",
        "type": "code",
        "location": "/tests/test_auto_local_reviewer.py:1-24"
    },
    "1715": {
        "file_id": 157,
        "content": "This code is importing necessary modules, defining the autoArgs dictionary for various detectors, and setting template names for testing. It mentions potential issues with CuDNN version and a modified pip downloader.",
        "type": "comment"
    },
    "1716": {
        "file_id": 157,
        "content": "    dirpath=\"./samples/video/\",\n    dummy_auto=False,\n    args=autoArgs,\n    template_names=template_names,\n    semiauto=False,  # i do not want to comment shit.\n)\nwbRev.main()",
        "type": "code",
        "location": "/tests/test_auto_local_reviewer.py:25-32"
    },
    "1717": {
        "file_id": 157,
        "content": "This code initializes an object, wbRev, of the main function from the class Main in the module main.py, and calls its main() method with specific arguments: dirpath set to \"./samples/video/\", dummy_auto as False, args as autoArgs, template_names not mentioned, and semiauto as False. The main() method is then executed.",
        "type": "comment"
    },
    "1718": {
        "file_id": 158,
        "content": "/tests/test_auto_local_producer.py",
        "type": "filepath"
    },
    "1719": {
        "file_id": 158,
        "content": "The code imports modules, sets environment variables, and installs local producers for OCR testing. It creates video processing configurations with completeTest() and partialMedialangRenderTest(). It handles temporary directories, cleans them, and prints save paths for debugging.",
        "type": "summary"
    },
    "1720": {
        "file_id": 158,
        "content": "import os\nos.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/lib\"\nfrom test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\n# let's hack the gl!\n# os.environ[\"DISPLAY\"] = \":1\"\n# os.environ[\"XAUTHORITY\"] = \"/root/.Xauthority\"\n# undefined symbol? wtf? how about use xvfb-run directly?\nautoArgs = {\n    \"subtitle_detector\": {\"timestep\": 0.2}\n}  # what is this? should't you detect all before production?\n# autoArgs = {\"subtitle_detector\": {\"timestep\": 0.2},\"yolov5_detector\":{\"model\":\"yolov5x\"}}\ntemplate_names = [\"subtitle_detector.mdl.j2\"]  # test ocr entities first.\n# template_names = [\"yolov5_detector.mdl.j2\"]\n# template_names = [\"framediff_detector.mdl.j2\"]\n# seems cudnn is causing trouble?\n# CuDNN Version 降到7.6试试，这个问题是环境问题引起的\n# https://pypi.tuna.tsinghua.edu.cn/packages/a4/1f/56dddeb4794137e3f824476ead29806d60a5d5fc20adba9f4d7ca5899900/paddlepaddle_gpu-2.2.2-cp39-cp39-manylinux1_x86_64.whl\n# from pip._internal.cli.main\n# we have modified the pip downloader.\nwbRev = FilesystemAutoContentProducer(",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:1-27"
    },
    "1721": {
        "file_id": 158,
        "content": "This code is importing necessary modules and setting environment variables for a specific purpose. It seems to be testing OCR entities first by using a subtitle detector and possibly other detectors later. The comment mentions potential issues with CUDA libraries and suggests downgrading the CuDNN version to resolve them. Additionally, it notes that the pip downloader has been modified.",
        "type": "comment"
    },
    "1722": {
        "file_id": 158,
        "content": "    dirpath=\"./samples/video/\",\n    reviewerLogs=[\n        \"/root/Desktop/works/pyjom/logs/local/1648576077_705094.log\",  # this is the paddleocr result.\n        \"/root/Desktop/works/pyjom/logs/local/1652502047_091761.json\",  # yolov5\n        \"/root/Desktop/works/pyjom/logs/local/1652856912_480332.json\",  # framedifference_talib\n    ],\n    producer_filters={\n        \"yolov5\": {\"objects\": [\"dog\", \"cat\"], \"min_time\": 2},\n        \"meta\": {\n            \"type\": \"video\",\n            \"timelimit\": {\n                \"min\": 1,\n            },\n        },\n    },\n    path_replacers=[\n        [\n            [\n                \"/media/root/help/pyjom/samples/\",\n                \"/media/root/parrot/pyjom/samples/\",\n                \"/media/root/parrot1/pyjom/samples/\",  # new location of sample media files.\n                \"/root/Desktop/works/pyjom/src/samples/\",\n                \"/media/root/help1/pyjom/samples/\",\n            ],\n            \"/root/Desktop/works/pyjom/samples/\",\n        ]\n    ],\n    template=\"pets_with_music\",\n    template_config={",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:28-56"
    },
    "1723": {
        "file_id": 158,
        "content": "This code sets up a local producer for video files, specifying the directory path, reviewer logs to be considered, and filters based on objects detected and minimum time. It also includes path replacers for sample media file locations and defines a template for the output.",
        "type": "comment"
    },
    "1724": {
        "file_id": 158,
        "content": "        \"music\": {\n            \"filepath\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\",  # these things were not right.\n            \"lyric_path\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.lrc\",\n        },\n        \"font\": \"/root/.local/share/fonts/simhei.ttf\",\n        # \"font\": \"/root/.local/share/fonts/simyou.ttf\", # 幼圆可能打不出来\n        \"policy\": {},\n        \"maxtime\": 4,\n        \"mintime\": 2,\n        \"fast\": True,  # pass this flag to medialang export engine\n    },\n    processor_filters={\n        \"yolov5\": [\"dog\", \"cat\"],\n        \"labels\": [\"dog\", \"cat\"],\n        \"framedifference_talib_detector\": 30,\n        \"ensure\": [\"yolov5\"],\n    }\n    # you can also translate funny videos from youtube.\n    # dummy_auto=False,\n    # args=autoArgs,\n    # semiauto=False # i do not want to comment shit.\n)\ndef completeTest():\n    wbRev.main()\ndef partialMedialangRenderTest(medialangScript, verbose=True):\n    # copy that script to my dear clipboard please?\n    medialangObject = Medialang(script=medialangScript, verbose=verbose)",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:57-87"
    },
    "1725": {
        "file_id": 158,
        "content": "Code is creating a configuration for video processing, specifying file paths, fonts, policy, time parameters, and processor filters. It also mentions that you can translate funny videos from YouTube and includes functions completeTest() and partialMedialangRenderTest().",
        "type": "comment"
    },
    "1726": {
        "file_id": 158,
        "content": "    result = medialangObject.execute()\n    return result\ndef PMRT_0(scriptFilePath=\"\", verbose=True):\n    with open(scriptFilePath, \"r\") as f:\n        medialangScript = f.read()\n    return partialMedialangRenderTest(medialangScript, verbose=verbose)\nfrom contextlib import AbstractContextManager\nclass tmpdir(AbstractContextManager):\n    \"\"\"Context manager to suppress specified exceptions\n    After the exception is suppressed, execution proceeds with the next\n    statement following the with statement.\n         with suppress(FileNotFoundError):\n             os.remove(somefile)\n         # Execution still resumes here if the file was already removed\n    \"\"\"\n    def __init__(self, path=None):\n        assert os.path.isabs(path)\n        self._tmpdir = path\n    def __enter__(self):\n        print(\"temporary directory: %s\" % self._tmpdir)\n        if os.path.exists(self._tmpdir):\n            shutil.rmtree(self._tmpdir)\n        os.makedirs(self._tmpdir)\n        return self._tmpdir\n    def __exit__(self, exctype, excinst, exctb):",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:88-123"
    },
    "1727": {
        "file_id": 158,
        "content": "The code defines a context manager class `tmpdir` that creates and manages temporary directories. It also includes a function `PMRT_0` which takes a script file path and verbose flag as input, reads the script content, and returns the result of partialMedialangRenderTest function. The main function is `execute()` which executes the code within the context manager and returns the result.",
        "type": "comment"
    },
    "1728": {
        "file_id": 158,
        "content": "        # try not to handle exceptions?\n        tempdir = self._tmpdir\n        print(\"cleaning tempdir: %s\" % tempdir)\n        shutil.rmtree(tempdir)\n        return False\nif __name__ == \"__main__\":\n    COMPLETE_TEST = False\n    if COMPLETE_TEST:\n        completeTest()\n    # so we don't have to run it all the time. really?\n    else:\n        scriptFilePath = \"/root/Desktop/works/pyjom/tests/medialang_tests/aef2ab90-6414-4b55-a40e-63014e5648a8.mdl\"  # add random flips, picture enhancement, super resolution and minterpolate\n        # a special hack\n        # import tempfile\n        with tmpdir(path=\"/dev/shm/medialang\") as medialangTmpDir:\n            print(\"MEDIALANG SUPER TMPDIR:\", medialangTmpDir)\n            result = PMRT_0(scriptFilePath, verbose=False)\n            editly_outputPath, medialang_item_list = result  # this just return none!\n            # data -> editly json\n            # this output path is modified. we shall change this.\n            outPath = editly_outputPath  # WE SHALL MUTE IT!\n            # print(editly_json.keys())",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:124-147"
    },
    "1729": {
        "file_id": 158,
        "content": "The code is attempting to clean a temporary directory, but it's trying not to handle exceptions. It then checks if a variable COMPLETE_TEST is True or False and executes the corresponding code block. The script path is specified, and a special hack using tmpdir is used within a with statement to create a medialangTmpDir. The code prints the medialangTmpDir and calls the PMRT_0 function with the scriptFilePath and verbose=False. It stores editly_outputPath and medialang_item_list in variables result, modifies outPath, and ends.",
        "type": "comment"
    },
    "1730": {
        "file_id": 158,
        "content": "            print(\"MEDIA SAVE PATH (MAYBE YOU CAN PLAY IT?):\", outPath)\n            # where is the damn save path???\n            breakpoint()  # HERE IS THE DAMN BREAKPOINT\n            # import json\n            # data_array -> input of dot processor? check it out.\n            # breakpoint() # what is this?",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:149-154"
    },
    "1731": {
        "file_id": 158,
        "content": "The code is trying to display the save path and then using a breakpoint for debugging purposes. The comments are pointing out the location of the save path and mentioning that a breakpoint has been set for debugging.",
        "type": "comment"
    },
    "1732": {
        "file_id": 159,
        "content": "/tests/test_auto_local_producer.sh",
        "type": "filepath"
    },
    "1733": {
        "file_id": 159,
        "content": "Running a Python test script for local producer with custom LD_LIBRARY_PATH environment variable.",
        "type": "summary"
    },
    "1734": {
        "file_id": 159,
        "content": "env LD_LIBRARY_PATH=/usr/local/lib python3 test_auto_local_producer.py ",
        "type": "code",
        "location": "/tests/test_auto_local_producer.sh:1-1"
    },
    "1735": {
        "file_id": 159,
        "content": "Running a Python test script for local producer with custom LD_LIBRARY_PATH environment variable.",
        "type": "comment"
    },
    "1736": {
        "file_id": 160,
        "content": "/tests/test_manual_censor.py",
        "type": "filepath"
    },
    "1737": {
        "file_id": 160,
        "content": "The code imports necessary functions from test_commons and contentCensoring, initiates a test sequence by calling censorInterface with input data for title, content and prints collected data.",
        "type": "summary"
    },
    "1738": {
        "file_id": 160,
        "content": "from test_commons import *\nfrom contentCensoring import *\nprint(\"initiating test sequence...\")\nmdata = censorInterface(\n    \"test_title\",\n    None,\n    \"test_content\",\n)\nprint(\"interface closed.\")\nprint(\"collected data:\", mdata)",
        "type": "code",
        "location": "/tests/test_manual_censor.py:1-11"
    },
    "1739": {
        "file_id": 160,
        "content": "The code imports necessary functions from test_commons and contentCensoring, initiates a test sequence by calling censorInterface with input data for title, content and prints collected data.",
        "type": "comment"
    },
    "1740": {
        "file_id": 161,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.sh",
        "type": "filepath"
    },
    "1741": {
        "file_id": 161,
        "content": "This code sets up an environment and runs tests for a video producer script. It first kills the existing test session, loads a configuration file, and then checks the media language render result. The Python script is used to perform full testing, and there's mention of potentially improving time duration using Gaussian.",
        "type": "summary"
    },
    "1742": {
        "file_id": 161,
        "content": "# env LD_LIBRARY_PATH=/usr/local/lib python3 test_auto_dog_video_giphy_online_producer.py \n#### PHASE 1 ####\n# FULL TEST\nulimit -n 1048576 # to avoid NOF issues.\ntmux kill-session -t online_dog_cat_generator_test && echo \"killed session: online_dog_cat_generator_test\"\ntmuxp load test_auto_dog_video_giphy_online_producer.yaml\n#### PHASE 2 ####\n# check medialang render result.\n# python3 test_auto_dog_video_giphy_online_producer.py -p\n# seems all good. but the time duration is not so good. maybe gaussian will help? set breakpoint after main list is created.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.sh:1-12"
    },
    "1743": {
        "file_id": 161,
        "content": "This code sets up an environment and runs tests for a video producer script. It first kills the existing test session, loads a configuration file, and then checks the media language render result. The Python script is used to perform full testing, and there's mention of potentially improving time duration using Gaussian.",
        "type": "comment"
    },
    "1744": {
        "file_id": 162,
        "content": "/tests/test_commons.py",
        "type": "filepath"
    },
    "1745": {
        "file_id": 162,
        "content": "The code changes the current working directory, adds the current directory to Python's module search path, and removes the proxy environment variables to ignore global proxies during testing.",
        "type": "summary"
    },
    "1746": {
        "file_id": 162,
        "content": "import sys\nimport os\nos.chdir(\"../\")\nsys.path.append(\".\")\n# ignore the global proxy now, we are not going to use that.\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"",
        "type": "code",
        "location": "/tests/test_commons.py:1-8"
    },
    "1747": {
        "file_id": 162,
        "content": "The code changes the current working directory, adds the current directory to Python's module search path, and removes the proxy environment variables to ignore global proxies during testing.",
        "type": "comment"
    },
    "1748": {
        "file_id": 163,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.yaml",
        "type": "filepath"
    },
    "1749": {
        "file_id": 163,
        "content": "This code configures a testing session for the \"online_dog_cat_generator_test\" in Tmux, with two panes. In the first pane, it runs the test script \"test_auto_dog_video_giphy_online_producer.py\". In the second pane, it starts the Uvicorn server for the \"lazzo.network.progressbar.server\" application on port 8576 with critical log level.",
        "type": "summary"
    },
    "1750": {
        "file_id": 163,
        "content": "session_name: online_dog_cat_generator_test\nstart_directory: /root/Desktop/works/pyjom/tests\nwindows:\n- layout: main-horizontal\n  options:\n    main-pane-height: 30\n  panes:\n  - shell_command:\n    - python3 test_auto_dog_video_giphy_online_producer.py\n  - shell_command:\n    # - python3 -m uvicorn --port 8576 lazero.network.progressbar.server:app\n    - python3 -m uvicorn --port 8576 --log-level critical lazero.network.progressbar.server:app\n  window_name: progressbar window",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.yaml:1-13"
    },
    "1751": {
        "file_id": 163,
        "content": "This code configures a testing session for the \"online_dog_cat_generator_test\" in Tmux, with two panes. In the first pane, it runs the test script \"test_auto_dog_video_giphy_online_producer.py\". In the second pane, it starts the Uvicorn server for the \"lazzo.network.progressbar.server\" application on port 8576 with critical log level.",
        "type": "comment"
    },
    "1752": {
        "file_id": 164,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.py",
        "type": "filepath"
    },
    "1753": {
        "file_id": 164,
        "content": "The code patches the \"requests\" library for Bilibili postMetadata, enables debugging, and includes paraphraser function. It also features video recommendation testing, metadata handling, data preprocessing from database, music API, generating subtitles with Giphy's video producer, all tested by OnlineAutoContentProducer. The code defines `partialMedialangRenderTest` function within `PMRT_0`, creating a temporary directory, setting parameters for tests, and returning output path.",
        "type": "summary"
    },
    "1754": {
        "file_id": 164,
        "content": "# changed numpy==1.23.0 to fix compatibility issues.\n# ld_library_path is handled externally using env\n# https://adamj.eu/tech/2022/06/23/how-to-patch-requests-to-have-a-default-timeout/\nREQUESTS_TIMEOUT=30 # monkey patch all requests related things?\nimport patchy\nfrom requests.adapters import HTTPAdapter\n# [DONE] clear milvus image cache database per metadata iteration\ndef patch_requests_default_timeout() -> None:\n    \"\"\"\n    Set a default timeout for all requests made with “requests”.\n    Upstream is waiting on this longstanding issue:\n    https://github.com/psf/requests/issues/3070\n    \"\"\"\n    patchy.patch(\n        HTTPAdapter.send,\n        \"\"\"\\\n        @@ -14,6 +14,8 @@\n             :param proxies: (optional) The proxies dictionary to apply to the request.\n             :rtype: requests.Response\n             \\\"\"\"\n        +    if timeout is None:\n        +        timeout = 5.0\n             try:\n                 conn = self.get_connection(request.url, proxies)\n        \"\"\",\n    )\n# import socket\n# SOCKET_TIMEOUT=60",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:1-37"
    },
    "1755": {
        "file_id": 164,
        "content": "This code patches the \"requests\" library to set a default timeout for all requests made with it. This is done using the \"patchy\" module, and the patch is applied to the \"HTTPAdapter.send\" method. If no timeout is specified, the default timeout will be 5.0 seconds.",
        "type": "comment"
    },
    "1756": {
        "file_id": 164,
        "content": "# socket.setdefaulttimeout(SOCKET_TIMEOUT)\nfrom test_commons import *\nfrom pyjom.primitives import *\nfrom pyjom.medialang.core import *\nfrom pyjom.videotoolbox import resetMilvusVideoDeduplicationCollection\nautoArgs = {\"subtitle_detector\": {\"timestep\": 0.2}}\ntemplate_names = [\"subtitle_detector.mdl.j2\"]\nDEBUG_STATE=False # let's see how far it goes.\n# warning: if you want to post it, you must review, and you must not use 'fast' mode aka preview.\n# you want musictoolbox? well shit...\n# just because you want download music.\n# also where are the places for 'video/audio/voice/artwork' generation?\n# maybe it is not the time to use such kind of things... you know the ram best.\nfrom pyjom.platforms.bilibili.postMetadata import getBilibiliPostMetadataForDogCat\n# decide to do this in sync.\n# preconfigure the dog_or_cat value.\n# dog_or_cat = random.choice([\"dog\", \"cat\"])  # strange.\ndog_or_cat = \"dog\"\n# we need preconfigured things.\nbgmCacheSetName = \"bilibili_cached_bgm_set\"\nfrom pyjom.languagetoolbox import paraphraser",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:38-65"
    },
    "1757": {
        "file_id": 164,
        "content": "This code imports necessary modules, sets default timeout, defines autoArgs and template_names, enables debugging, imports postMetadata for Bilibili, preconfigures dog\\_or\\_cat value as \"dog\", and imports paraphraser from languageToolbox.",
        "type": "comment"
    },
    "1758": {
        "file_id": 164,
        "content": "import random\ndef myParaphraser(content:str):# TODO: limit and chop large group of text into chunks, process them individually.\n    methods = [\"clueai_free\", \n    # till we get it.\n    # \"cn_nlp_online\", \n    \"baidu_translator\"]\n    random.shuffle(methods)\n    for method in methods:\n        output, success = paraphraser(content, method =method )\n        if not success:\n            output = content\n        else:\n            break\n    return output\npostMetadataGeneratorPrimitive = getBilibiliPostMetadataForDogCat(\n    dog_or_cat=dog_or_cat,\n    bgmCacheSetName=bgmCacheSetName,\n    bgmCacheAutoPurge=True,  # autopurge bgm, not sure we are using the latest bgm!\n    customParaphraser=myParaphraser\n)  # metadata you can fetch from database, maybe you can preprocess this.\nMAX_ITER = 10  # stop on ten trials.\nfrom lazero.utils.tools import iteratorWrapper\npostMetadataGenerator = iteratorWrapper(\n    postMetadataGeneratorPrimitive, init_repeat=0, max_iter=MAX_ITER, before_yield = resetMilvusVideoDeduplicationCollection",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:66-90"
    },
    "1759": {
        "file_id": 164,
        "content": "This code defines a function `myParaphraser` that takes a string and paraphrases it using multiple methods in random order. It then applies the paraphrased text if successful, otherwise keeps the original content. The code also sets up a metadata generator for Bilibili dog or cat posts using the `myParaphraser` function, with a maximum of 10 trials before stopping. The metadata can be fetched from a database and preprocessed.",
        "type": "comment"
    },
    "1760": {
        "file_id": 164,
        "content": ")\npostMetadataGenerator.__next__()  # for getting some bgm, just in case.\n# really?\n# [DONE] i think you need some superpower over this postMetadataGenerator.\n# kwargs: init_repeat=0, repeat=0, max_iter=MAX_ITER (take care of \"repeat\" related arguments)\n# [DONE] i also think you should alter the title and intro with paraphraser.\n# TODO: check if video is properly registered to video recommendation server.\n# TODO: check video recommendation server is \"properly\" recommending all related videos\n# [DONE] control dog/cat shits, by stopping the iterator!\nmetaTopics = {\n    \"dog\": {\n        \"static\": [[\"dog\", \"puppy\"]],\n        \"dynamic\": [\n            [\"samoyed\", \"husky\", \"teddy\", \"chiwawa\"],\n            [\"meme\"],\n            [\"funny\", \"cute\", \"love\"],\n        ],\n    },\n    \"cat\": {\n        \"static\": [[\"cat\", \"kitten\"]],\n        \"dynamic\": [[\"purr\", \"paws\", \"meme\"], [\"funny\", \"cute\"]],\n    },\n}\n# when use 'complete test' it stops iterating.\n# maybe because the last one is a generator. goddamn it.\ndef cleanupMedialangTmpdir():",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:91-121"
    },
    "1761": {
        "file_id": 164,
        "content": "This code snippet seems to be responsible for handling different types of metadata related to dogs and cats, as well as testing the functionality of video recommendations. It includes setting up dynamic topics based on specific breeds and actions, using a paraphraser to alter titles and intros, and checking if videos are properly registered and recommended by the video recommendation server. The code also mentions cleaning up temporary files when running a complete test. However, there seems to be some confusion about certain aspects of the postMetadataGenerator and potential issues with iterating through it.",
        "type": "comment"
    },
    "1762": {
        "file_id": 164,
        "content": "    tmpdirPath = \"/dev/shm/medialang\"\n    files_and_dirs = os.listdir(tmpdirPath)\n    for f in files_and_dirs:\n        fpath = os.path.join(tmpdirPath, f)\n        if os.path.isfile(fpath):\n            os.remove(fpath)\nfrom pyjom.commons import getRedisCachedSet\nfrom pyjom.musictoolbox import neteaseMusic\ndef makeTemplateConfigsGenerator():\n    NMClient = neteaseMusic()\n    while True:\n        # download one music, either from hottest songs or from fetched music list.\n        # even if we search for the name, we will randomly choose the song to avoid problems.\n        # you must download the file in a fixed location.\n        while True:\n            bgmCacheSet = getRedisCachedSet(bgmCacheSetName)\n            keywords = random.choice(list(bgmCacheSet)).strip()\n            if len(keywords) > 0:\n                (\n                    music_content,\n                    music_format,\n                ), lyric_string = NMClient.getMusicAndLyricWithKeywords(\n                    keywords, similar=random.choice([True, False])",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:122-148"
    },
    "1763": {
        "file_id": 164,
        "content": "This code generates a random keyword from a Redis set and uses the NeteaseMusic API to download music content, format, and lyric string related to that keyword. The music is downloaded to a fixed location. If no keywords are found or they're empty, it keeps searching for new ones.",
        "type": "comment"
    },
    "1764": {
        "file_id": 164,
        "content": "                )\n                if music_content is not None:\n                    break\n        with tempfile.NamedTemporaryFile(\n            \"wb\", suffix=\".{}\".format(music_format)\n        ) as music_file:\n            with tempfile.NamedTemporaryFile(\"w+\", suffix=\".lrc\") as lyric_file:\n                musicFilePath, lyricPath = music_file.name, lyric_file.name\n                music_file.write(music_content)\n                music_file.seek(0)\n                if lyric_string is not None:\n                    lyric_file.write(lyric_string)\n                    lyric_file.seek(0)\n                else:\n                    lyricPath = None\n                data = {\n                    \"debug\": DEBUG_STATE,  # we need to preview this video.\n                    # use generator instead.\n                    \"music\": {\n                        \"filepath\": musicFilePath,  # these things were not right.\n                        # how to get this music file? by bgm search?\n                        # \"filepath\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\",  # these things were not right.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:149-170"
    },
    "1765": {
        "file_id": 164,
        "content": "This code snippet creates temporary music and lyric files, writes music content and lyric string into them if available, and stores their file paths in a dictionary along with the debug state. It aims to preview a video using the given music and lyrics. The music file path may be set via bgm search or by specifying it directly.",
        "type": "comment"
    },
    "1766": {
        "file_id": 164,
        "content": "                        \"lyric_path\": lyricPath,  ## you can choose not to pass the lyric_path anyway. also format different than .lrc is on the way?\n                    },\n                    \"font\": \"/root/.local/share/fonts/simhei.ttf\",\n                    # \"font\": \"/root/.local/share/fonts/simyou.ttf\", # 幼圆可能打不出来\n                    \"policy\": {},\n                    \"maxtime\": 7.8,\n                    \"mintime\": 2,  # we've write this shit!\n                    \"render_ass\": lyricPath is not None,\n                    # also determine how to translate the lyrics, whether to translate or not.\n                    \"translate\": lyricPath is not None,  # default: False\n                    # are you sure you want to use deepl? this is hard to configure. especially the goddamn proxy.\n                    # you can simply implement the method to cofigure and test ping for websites in lazero library so we can share the same code.\n                    # or you can borrow code from the web. some clash manager library for python.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:171-183"
    },
    "1767": {
        "file_id": 164,
        "content": "This code is defining a video producer for Giphy that generates subtitles for videos. The `lyric_path` can be chosen to not be passed, and different lyric file formats are being considered. The font for the subtitles is set as '/root/.local/share/fonts/simhei.ttf'. The policy, maximum time (`maxtime`), minimum time (`mintime`) and whether to render assubtitles (`render_ass`) are determined based on `lyricPath`. Translation is set to be done if the `lyricPath` is not None.",
        "type": "comment"
    },
    "1768": {
        "file_id": 164,
        "content": "                    \"translate_method\": \"baidu\",  # default: baidu, random, deepl\n                    # damn cold for this mac!\n                    \"ass_template_configs\": {},\n                    \"assStyleConfig\": {},\n                }\n                yield data\ntemplateConfigsGenerator = makeTemplateConfigsGenerator()\nwbRev = OnlineAutoContentProducer(\n    afterPosting=cleanupMedialangTmpdir,\n    source=\"giphy\",\n    fast=False,\n    metaTopic=metaTopics[dog_or_cat],\n    # fast= True,  # pass this flag to medialang export engine\n    template=\"pets_with_music_online\",\n    postMetadataGenerator=postMetadataGenerator,\n    template_configs=templateConfigsGenerator,\n    # you can also translate funny videos from youtube.\n    # dummy_auto=False,\n    # args=autoArgs,\n    # semiauto=False # i do not want to comment shit.\n)\ndef completeTest():\n    wbRev.main()\ndef partialMedialangRenderTest(medialangScript, medialangTmpdir, verbose=True):\n    # copy that script to my dear clipboard please?\n    medialangObject = Medialang(",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:184-215"
    },
    "1769": {
        "file_id": 164,
        "content": "This code is creating an instance of the OnlineAutoContentProducer class with specific arguments. The producer is set to work with Giphy content and use the \"pets_with_music_online\" template. It also yields data, generates template configs, and provides a postMetadataGenerator. The completeTest function calls the main method on the producer instance, while partialMedialangRenderTest takes a medialangScript and renders it in the given temporary directory (medialangTmpdir).",
        "type": "comment"
    },
    "1770": {
        "file_id": 164,
        "content": "        script=medialangScript, verbose=verbose, medialangTmpdir=medialangTmpdir\n    )\n    result = medialangObject.execute()\n    return result\ndef PMRT_0(scriptFilePath, medialangTmpdir, verbose=True):\n    with open(scriptFilePath, \"r\") as f:\n        medialangScript = f.read()\n    return partialMedialangRenderTest(medialangScript, medialangTmpdir, verbose=verbose)\nfrom lazero.filesystem import tmpdir\n# from contextlib import AbstractContextManager\n# class tmpdir(AbstractContextManager):\n#     \"\"\"Context manager to suppress specified exceptions\n#     After the exception is suppressed, execution proceeds with the next\n#     statement following the with statement.\n#          with suppress(FileNotFoundError):\n#              os.remove(somefile)\n#          # Execution still resumes here if the file was already removed\n#     \"\"\"\n#     def __init__(self, path=None):\n#         assert os.path.isabs(path)\n#         self._tmpdir = path\n#     def __enter__(self):\n#         print(\"temporary directory: %s\" % self._tmpdir)",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:216-248"
    },
    "1771": {
        "file_id": 164,
        "content": "The code defines a function `partialMedialangRenderTest` that takes a medialang script, temporary directory, and verbosity level as input. It creates an object `medialangObject`, executes it, and returns the result. Additionally, there's another function `PMRT_0` that uses this `partialMedialangRenderTest` function to execute a medialang script provided by a file path in a temporary directory. Finally, there is a class `tmpdir` which seems to be used as a context manager to suppress exceptions.",
        "type": "comment"
    },
    "1772": {
        "file_id": 164,
        "content": "#         if os.path.exists(self._tmpdir): shutil.rmtree(self._tmpdir)\n#         os.makedirs(self._tmpdir)\n#         return self._tmpdir\n#     def __exit__(self, exctype, excinst, exctb):\n#         # try not to handle exceptions?\n#         tempdir = self._tmpdir\n#         print(\"cleaning tempdir: %s\" % tempdir)\n#         shutil.rmtree(tempdir)\n#         return False\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--partial\", action=\"store_true\", default=False)\n    args = parser.parse_args()\n    # print('args.partial:', args.partial)\n    # breakpoint()\n    COMPLETE_TEST = not args.partial\n    if COMPLETE_TEST:\n        completeTest()\n    # so we don't have to run it all the time. really?\n    else:\n        # scriptFilePath = \"/root/Desktop/works/pyjom/tests/medialang_tests/aef2ab90-6414-4b55-a40e-63014e5648a8.mdl\"\n        # set this scriptFilePath to something else.\n        scriptFilePath = \"/root/Desktop/works/pyjom/samples/medialang/dog_cat_test_nofast.mdl\"  # make it real, not preview.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:249-275"
    },
    "1773": {
        "file_id": 164,
        "content": "This code snippet is from a test file that creates a temporary directory, performs some operations within it, and then cleans up by removing the directory. The code also checks whether to run a complete or partial test based on command-line arguments, and sets the script file path accordingly.",
        "type": "comment"
    },
    "1774": {
        "file_id": 164,
        "content": "        # scriptFilePath = \"/root/Desktop/works/pyjom/samples/medialang/dog_cat_test.mdl\" # make it real, not preview.\n        # a special hack\n        # import tempfile\n        with tmpdir(path=\"/dev/shm/medialang\") as medialangTmpdir:\n            print(\n                \"MEDIALANG SUPER TMPDIR:\", medialangTmpdir\n            )  # as some sort of protection.\n            # /dev/shm/medialang/<randomString>/<randomUUID>.mp4 -> /dev/shm/medialang/<randomUUID>.mp4\n            result = PMRT_0(scriptFilePath, medialangTmpdir, verbose=False)\n            editly_outputPath, medialang_item_list = result  # this just return none!\n            # data -> editly json\n            # this output path is modified. we shall change this.\n            outPath = editly_outputPath  # WE SHALL MUTE IT!\n            # print(editly_json.keys())\n            print(\"MEDIA SAVE PATH (MAYBE YOU CAN PLAY IT?):\", outPath)\n            breakpoint()\n            # import json\n            # data_array -> input of dot processor? check it out.\n            # breakpoint() # what is this?",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:276-295"
    },
    "1775": {
        "file_id": 164,
        "content": "The code sets a temporary directory path (medialangTmpdir), uses the PMRT_0 function with scriptFilePath and medialangTmpdir as arguments, and returns editly_outputPath and medialang_item_list. It then modifies outPath and prints it. The code also includes potential use of json and breakpoint() for debugging.",
        "type": "comment"
    },
    "1776": {
        "file_id": 165,
        "content": "/tests/unittest_ffmpeg_overlay_boxblur.py",
        "type": "filepath"
    },
    "1777": {
        "file_id": 165,
        "content": "The code uses ffmpeg library to apply Gaussian blur filter and scale video stream, then creates a second layer, overlays both layers, and outputs the processed video stream. It sets output dimensions, uses \"scale\" and \"gblur\" or \"boxblur\" filters, scales video stream with aspect ratio preservation, and outputs file to temporary directory.",
        "type": "summary"
    },
    "1778": {
        "file_id": 165,
        "content": "# ffmpeg对视频实现高斯模糊，给视频上下加模糊背景\n# ffmpeg实现视频高斯模糊拓边效果\nimport ffmpeg\nsource = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif\"\nstream = ffmpeg.input(source)\nvideo_stream = stream.video\n# the damn thing because they are from the same file! fuck!\n# layer_0 = video_stream.filter(\"scale\", w=1080, h=1920).filter(\"boxblur\", 10) # this is default?\n# however, you need to generalize it here.\n# output_width = 1080\n# output_height = 1920\noutput_height = 1080\noutput_width = 1920\nlayer_0 = video_stream.filter(\"scale\", w=output_width, h=output_height).filter(\n    \"gblur\", sigma=9\n)  # this is default?\n# print('layer_0 args', layer_0.get_args())\nlayer_1 = video_stream.filter(\n    \"scale\",\n    w=\"min(floor(iw*{}/ih),{})\".format(output_height, output_width),\n    h=\"min(floor(ih*{}/iw),{})\".format(output_width, output_height),\n)\n# print('layer_1 args', layer_1.get_args())\n## in case you failed to generalize this shit...\noutput_stream = layer_0.overlay(layer_1, x=\"floor((W-w)/2)\", y=\"floor((H-h)/2)\")\n# print('output_stream args', output_stream.get_args())",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_overlay_boxblur.py:1-40"
    },
    "1779": {
        "file_id": 165,
        "content": "The code uses ffmpeg library to apply Gaussian blur filter and scale video stream. It sets output dimensions, applies \"scale\" filter with given width and height, then applies \"gblur\" or \"boxblur\" filter. Then, it creates a second layer by scaling the video stream with aspect ratio preservation and overlays both layers using specific coordinates. Finally, it outputs the processed video stream.",
        "type": "comment"
    },
    "1780": {
        "file_id": 165,
        "content": "from lazero.filesystem import tmpdir\npath = \"/dev/shm/medialang\"\nimport os\nwith tmpdir(path=path) as T:\n    filepath = os.path.join(path, \"output.mp4\")\n    # args = ffmpeg.get_args(output_stream)\n    # print(args)\n    output_args = {\"preset\": \"veryfast\"}  # seems like it won't speed up so much?\n    ffmpeg.output(output_stream, filepath, **output_args).run(overwrite_output=True)\n    print(\"output file location:\", filepath)\n    breakpoint()",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_overlay_boxblur.py:42-54"
    },
    "1781": {
        "file_id": 165,
        "content": "The code sets a temporary directory path, joins it with the file name, creates FFmpeg output arguments with a fast preset, and then runs an FFmpeg command to output the stream to the file in the temporary directory. The output file location is printed.",
        "type": "comment"
    },
    "1782": {
        "file_id": 166,
        "content": "/tests/unittest_convolution_bilibili_translate_text_detect.py",
        "type": "filepath"
    },
    "1783": {
        "file_id": 166,
        "content": "This code imports libraries, defines image and video processing functions, reads a JSON file, applies these functions to create the final image, processes bounding boxes, creates rectangles, blurs, visualizes, and displays images while waiting for key presses.",
        "type": "summary"
    },
    "1784": {
        "file_id": 166,
        "content": "import json\nfrom test_commons import *\nfrom pyjom.commons import *\nimport cv2\ndef getVideoPixels(videoPath):\n    from MediaInfo import MediaInfo\n    info = MediaInfo(filename=videoPath)\n    infoData = info.getInfo()\n    # print(infoData)\n    # breakpoint()\n    defaultWidth = infoData[\"videoWidth\"]\n    defaultHeight = infoData[\"videoHeight\"]\n    return defaultWidth, defaultHeight\n# easy gig, you said.\n# basePath = \"/Users/jamesbrown/desktop/works/pyjom_remote\"\nbasePath = \"/root/Desktop/works/pyjom\"\ntargetFile = (\n    basePath + \"/tests/bilibili_practices/bilibili_video_translate/japan_day.json\"\n)\noriginalFile = (\n    basePath + \"/tests/bilibili_practices/bilibili_video_translate/japan_day.webm\"\n)\n# visualization can only be done here?\n# where is the original file?\nmJson = json.loads(open(targetFile, \"r\", encoding=\"utf-8\").read())\nimport numpy as np\nwidth, height = getVideoPixels(originalFile)\ndef getBlackPicture(width, height):\n    blackPicture = np.zeros((height, width, 1), dtype=\"uint8\")  # this is grayscale.\n    return blackPicture",
        "type": "code",
        "location": "/tests/unittest_convolution_bilibili_translate_text_detect.py:1-41"
    },
    "1785": {
        "file_id": 166,
        "content": "The code is importing necessary libraries and defining a function `getVideoPixels` to retrieve the default video width and height from a given video file. It then sets the base path, target file, and original file paths. The code reads the target JSON file, loads it into a variable `mJson`, and retrieves the video dimensions using the `getVideoPixels` function. Finally, it defines a function `getBlackPicture` to create a black grayscale image with the specified width and height.",
        "type": "comment"
    },
    "1786": {
        "file_id": 166,
        "content": "mKeys = list(mJson.keys())\nmIntKeys = [int(x) for x in mKeys]\nminKey, maxKey = min(mIntKeys), max(mIntKeys)\n# imutils is created by pyimagesearch.\nfrom imutils.object_detection import non_max_suppression\ndef getConvBlurredCurrentShot(blurredSpan, span=5):\n    # honor the most the latest one.\n    mImage = None\n    for index, blurredImage in enumerate(blurredSpan):\n        ratio = index / span\n        if mImage is None:\n            mImage = blurredImage * ratio\n        else:\n            mImage += blurredImage * ratio\n    # print(mImage.shape)\n    # breakpoint()\n    # change this mImage.\n    mImage = mImage > 128\n    mImage = mImage.astype(np.uint8)\n    mImage = mImage * 255\n    return mImage\n    # return 256*((mImage>128).astype(np.uint8))\nconvolutionSpan = 20\nconvolutionBoundingBoxSpan = []\nconvolutionBlurredSpan = []\nfor intKey in range(minKey, maxKey + 1):\n    strKey = str(intKey)\n    target = mJson[strKey]\n    boundingBoxes = []\n    for item in target:\n        location = item[0]\n        text, confidence = item[1]\n        # print(\"location\",location) # four points. do not know if there is any rotation here.",
        "type": "code",
        "location": "/tests/unittest_convolution_bilibili_translate_text_detect.py:44-86"
    },
    "1787": {
        "file_id": 166,
        "content": "This code defines a function `getConvBlurredCurrentShot` that averages multiple blurred images to create a final image. It also initializes variables for convolution bounding boxes and blurred spans based on a range of keys in `mJson`. The resulting image is then thresholded and converted to 8-bit format before being returned.",
        "type": "comment"
    },
    "1788": {
        "file_id": 166,
        "content": "        if confidence > 0.7:\n            npLocation = np.array(location)\n            xlocs = npLocation[:, 0]\n            ylocs = npLocation[:, 1]\n            # print(xlocs)\n            # print(ylocs)\n            # breakpoint()\n            minX, maxX = min(xlocs), max(xlocs)\n            minY, maxY = min(ylocs), max(ylocs)\n            boundingBox = [minX, minY, maxX, maxY]\n            boundingBoxes.append(boundingBox.copy())\n            # breakpoint()\n        # print(\"text\", text)\n        # print(\"confidence\", confidence)\n    convolutionBoundingBoxSpan.append(boundingBoxes.copy())\n    if len(convolutionBoundingBoxSpan) > convolutionSpan:\n        convolutionBoundingBoxSpan.pop(0)\n    # do your calculation!\n    flatSpan = [y for x in convolutionBoundingBoxSpan for y in x]\n    flatSpan = np.array(flatSpan)\n    currentNonOverlappingBoxes = non_max_suppression(flatSpan)\n    # print(intKey,target)\n    # this time we do not care about the text inside.\n    blackPicture = getBlackPicture(width, height)\n    for rectangle in flatSpan:",
        "type": "code",
        "location": "/tests/unittest_convolution_bilibili_translate_text_detect.py:87-111"
    },
    "1789": {
        "file_id": 166,
        "content": "The code processes bounding boxes from a convolution operation, filters them based on confidence score, and performs non-maximum suppression to eliminate overlapping boxes. It then creates an array of non-overlapping bounding boxes and generates a black picture with the same width and height as the original image.",
        "type": "comment"
    },
    "1790": {
        "file_id": 166,
        "content": "        # make it all int.\n        x0, y0, x1, y1 = [int(num) for num in rectangle]\n        loc0 = (x0, y0)\n        loc1 = (x1, y1)\n        cv2.rectangle(\n            blackPicture, loc0, loc1, 255, cv2.FILLED\n        )  # we fill so we can merge shits.\n    blackPictureBlurred = cv2.GaussianBlur(blackPicture, (33, 33), 0)\n    convolutionBlurredSpan.append(blackPictureBlurred.copy())\n    if len(convolutionBlurredSpan) > convolutionSpan:\n        convolutionBlurredSpan.pop(0)\n    currentBlackPictureBlurred = getConvBlurredCurrentShot(\n        convolutionBlurredSpan, span=convolutionSpan\n    )\n    # print(currentBlackPictureBlurred.shape)\n    print(\"boundingBoxes:\", len(flatSpan))\n    if len(flatSpan) == 0:\n        continue\n    contours = cv2.findContours(\n        currentBlackPictureBlurred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n    )\n    contours = contours[0] if len(contours) == 2 else contours[1]\n    currentBoundingBoxesVisualize = getBlackPicture(width, height)\n    for i in contours:\n        x, y, w, h = cv2.boundingRect(i)",
        "type": "code",
        "location": "/tests/unittest_convolution_bilibili_translate_text_detect.py:112-142"
    },
    "1791": {
        "file_id": 166,
        "content": "The code creates a rectangle from input, fills it in the black picture, blurs the filled image, appends it to a list if length is less than convolutionSpan, pops oldest if length exceeds convolutionSpan, gets the current blurred image from the list, prints the bounding boxes count, and if no elements in flatSpan, continues. It then finds contours in the current blurred image and creates a new image for visualization of bounding rectangles.",
        "type": "comment"
    },
    "1792": {
        "file_id": 166,
        "content": "        cv2.rectangle(currentBoundingBoxesVisualize, (x, y), (x + w, y + h), 255, 4)\n    cv2.imshow(\"IMAGE\", currentBoundingBoxesVisualize)\n    cv2.waitKey(10)\n    print(\"showing image:\", intKey)\n    # print\n    # cv2.waitKey(1000)\n    # print(\"NON OVERLAPPING BOXES:\")\n    # print(currentNonOverlappingBoxes)\n    # we need to visualize this shit.\n    # breakpoint()\ncv2.destroyAllWindows()\nprint(\"THE END\")",
        "type": "code",
        "location": "/tests/unittest_convolution_bilibili_translate_text_detect.py:143-156"
    },
    "1793": {
        "file_id": 166,
        "content": "This code snippet is responsible for visualizing bounding boxes, displaying an image, and waiting for a key press. It prints the non-overlapping boxes but may require visualization. The code will close all windows at the end with a final message \"THE END\".",
        "type": "comment"
    },
    "1794": {
        "file_id": 167,
        "content": "/tests/unittest_cv2_rectangle.py",
        "type": "filepath"
    },
    "1795": {
        "file_id": 167,
        "content": "This code imports necessary libraries, defines a function to create a black image of given dimensions, creates a black image, draws a rectangle on it with white color, displays the image, and waits for any key press before exiting.",
        "type": "summary"
    },
    "1796": {
        "file_id": 167,
        "content": "from test_commons import *\nfrom pyjom.commons import *\nimport cv2\nimport numpy as np\ndef getBlackPicture(width, height):\n    blackPicture = np.zeros((height, width, 3), dtype=\"uint8\")  # this is grayscale.\n    return blackPicture\nblackPicture = getBlackPicture(500, 500)\ncv2.rectangle(blackPicture, (200, 200), (300, 300), (255, 255, 255), 3)\ncv2.imshow(\"image\", blackPicture)\ncv2.waitKey(0)",
        "type": "code",
        "location": "/tests/unittest_cv2_rectangle.py:1-16"
    },
    "1797": {
        "file_id": 167,
        "content": "This code imports necessary libraries, defines a function to create a black image of given dimensions, creates a black image, draws a rectangle on it with white color, displays the image, and waits for any key press before exiting.",
        "type": "comment"
    },
    "1798": {
        "file_id": 168,
        "content": "/tests/unittest_extract_cat_cover_from_video.py",
        "type": "filepath"
    },
    "1799": {
        "file_id": 168,
        "content": "This code downloads Bilibili videos, extracts covers for pet videos, and checks frames to display the cover. It uses yt_dlp, image processing libraries, and OpenCV's imshow function. If a clear frame is found, it breaks the loop and waits for a key press before proceeding.",
        "type": "summary"
    }
}