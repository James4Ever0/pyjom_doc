{
    "1700": {
        "file_id": 153,
        "content": "        \"music\": {\n            \"filepath\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\",  # these things were not right.\n            \"lyric_path\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.lrc\",\n        },\n        \"font\": \"/root/.local/share/fonts/simhei.ttf\",\n        # \"font\": \"/root/.local/share/fonts/simyou.ttf\", # 幼圆可能打不出来\n        \"policy\": {},\n        \"maxtime\": 4,\n        \"mintime\": 2,\n        \"fast\": True,  # pass this flag to medialang export engine\n    },\n    processor_filters={\n        \"yolov5\": [\"dog\", \"cat\"],\n        \"labels\": [\"dog\", \"cat\"],\n        \"framedifference_talib_detector\": 30,\n        \"ensure\": [\"yolov5\"],\n    }\n    # you can also translate funny videos from youtube.\n    # dummy_auto=False,\n    # args=autoArgs,\n    # semiauto=False # i do not want to comment shit.\n)\ndef completeTest():\n    wbRev.main()\ndef partialMedialangRenderTest(medialangScript, verbose=True):\n    # copy that script to my dear clipboard please?\n    medialangObject = Medialang(script=medialangScript, verbose=verbose)",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:57-87"
    },
    "1701": {
        "file_id": 153,
        "content": "Code is creating a configuration for video processing, specifying file paths, fonts, policy, time parameters, and processor filters. It also mentions that you can translate funny videos from YouTube and includes functions completeTest() and partialMedialangRenderTest().",
        "type": "comment"
    },
    "1702": {
        "file_id": 153,
        "content": "    result = medialangObject.execute()\n    return result\ndef PMRT_0(scriptFilePath=\"\", verbose=True):\n    with open(scriptFilePath, \"r\") as f:\n        medialangScript = f.read()\n    return partialMedialangRenderTest(medialangScript, verbose=verbose)\nfrom contextlib import AbstractContextManager\nclass tmpdir(AbstractContextManager):\n    \"\"\"Context manager to suppress specified exceptions\n    After the exception is suppressed, execution proceeds with the next\n    statement following the with statement.\n         with suppress(FileNotFoundError):\n             os.remove(somefile)\n         # Execution still resumes here if the file was already removed\n    \"\"\"\n    def __init__(self, path=None):\n        assert os.path.isabs(path)\n        self._tmpdir = path\n    def __enter__(self):\n        print(\"temporary directory: %s\" % self._tmpdir)\n        if os.path.exists(self._tmpdir):\n            shutil.rmtree(self._tmpdir)\n        os.makedirs(self._tmpdir)\n        return self._tmpdir\n    def __exit__(self, exctype, excinst, exctb):",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:88-123"
    },
    "1703": {
        "file_id": 153,
        "content": "The code defines a context manager class `tmpdir` that creates and manages temporary directories. It also includes a function `PMRT_0` which takes a script file path and verbose flag as input, reads the script content, and returns the result of partialMedialangRenderTest function. The main function is `execute()` which executes the code within the context manager and returns the result.",
        "type": "comment"
    },
    "1704": {
        "file_id": 153,
        "content": "        # try not to handle exceptions?\n        tempdir = self._tmpdir\n        print(\"cleaning tempdir: %s\" % tempdir)\n        shutil.rmtree(tempdir)\n        return False\nif __name__ == \"__main__\":\n    COMPLETE_TEST = False\n    if COMPLETE_TEST:\n        completeTest()\n    # so we don't have to run it all the time. really?\n    else:\n        scriptFilePath = \"/root/Desktop/works/pyjom/tests/medialang_tests/aef2ab90-6414-4b55-a40e-63014e5648a8.mdl\"  # add random flips, picture enhancement, super resolution and minterpolate\n        # a special hack\n        # import tempfile\n        with tmpdir(path=\"/dev/shm/medialang\") as medialangTmpDir:\n            print(\"MEDIALANG SUPER TMPDIR:\", medialangTmpDir)\n            result = PMRT_0(scriptFilePath, verbose=False)\n            editly_outputPath, medialang_item_list = result  # this just return none!\n            # data -> editly json\n            # this output path is modified. we shall change this.\n            outPath = editly_outputPath  # WE SHALL MUTE IT!\n            # print(editly_json.keys())",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:124-147"
    },
    "1705": {
        "file_id": 153,
        "content": "The code is attempting to clean a temporary directory, but it's trying not to handle exceptions. It then checks if a variable COMPLETE_TEST is True or False and executes the corresponding code block. The script path is specified, and a special hack using tmpdir is used within a with statement to create a medialangTmpDir. The code prints the medialangTmpDir and calls the PMRT_0 function with the scriptFilePath and verbose=False. It stores editly_outputPath and medialang_item_list in variables result, modifies outPath, and ends.",
        "type": "comment"
    },
    "1706": {
        "file_id": 153,
        "content": "            print(\"MEDIA SAVE PATH (MAYBE YOU CAN PLAY IT?):\", outPath)\n            # where is the damn save path???\n            breakpoint()  # HERE IS THE DAMN BREAKPOINT\n            # import json\n            # data_array -> input of dot processor? check it out.\n            # breakpoint() # what is this?",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:149-154"
    },
    "1707": {
        "file_id": 153,
        "content": "The code is trying to display the save path and then using a breakpoint for debugging purposes. The comments are pointing out the location of the save path and mentioning that a breakpoint has been set for debugging.",
        "type": "comment"
    },
    "1708": {
        "file_id": 154,
        "content": "/tests/test_commons.py",
        "type": "filepath"
    },
    "1709": {
        "file_id": 154,
        "content": "The code changes the current working directory, adds the current directory to Python's module search path, and removes the proxy environment variables to ignore global proxies during testing.",
        "type": "summary"
    },
    "1710": {
        "file_id": 154,
        "content": "import sys\nimport os\nos.chdir(\"../\")\nsys.path.append(\".\")\n# ignore the global proxy now, we are not going to use that.\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"",
        "type": "code",
        "location": "/tests/test_commons.py:1-8"
    },
    "1711": {
        "file_id": 154,
        "content": "The code changes the current working directory, adds the current directory to Python's module search path, and removes the proxy environment variables to ignore global proxies during testing.",
        "type": "comment"
    },
    "1712": {
        "file_id": 155,
        "content": "/tests/test_auto_local_producer.sh",
        "type": "filepath"
    },
    "1713": {
        "file_id": 155,
        "content": "Running a Python test script for local producer with custom LD_LIBRARY_PATH environment variable.",
        "type": "summary"
    },
    "1714": {
        "file_id": 155,
        "content": "env LD_LIBRARY_PATH=/usr/local/lib python3 test_auto_local_producer.py ",
        "type": "code",
        "location": "/tests/test_auto_local_producer.sh:1-1"
    },
    "1715": {
        "file_id": 155,
        "content": "Running a Python test script for local producer with custom LD_LIBRARY_PATH environment variable.",
        "type": "comment"
    },
    "1716": {
        "file_id": 156,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.yaml",
        "type": "filepath"
    },
    "1717": {
        "file_id": 156,
        "content": "This code configures a testing session for the \"online_dog_cat_generator_test\" in Tmux, with two panes. In the first pane, it runs the test script \"test_auto_dog_video_giphy_online_producer.py\". In the second pane, it starts the Uvicorn server for the \"lazzo.network.progressbar.server\" application on port 8576 with critical log level.",
        "type": "summary"
    },
    "1718": {
        "file_id": 156,
        "content": "session_name: online_dog_cat_generator_test\nstart_directory: /root/Desktop/works/pyjom/tests\nwindows:\n- layout: main-horizontal\n  options:\n    main-pane-height: 30\n  panes:\n  - shell_command:\n    - python3 test_auto_dog_video_giphy_online_producer.py\n  - shell_command:\n    # - python3 -m uvicorn --port 8576 lazero.network.progressbar.server:app\n    - python3 -m uvicorn --port 8576 --log-level critical lazero.network.progressbar.server:app\n  window_name: progressbar window",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.yaml:1-13"
    },
    "1719": {
        "file_id": 156,
        "content": "This code configures a testing session for the \"online_dog_cat_generator_test\" in Tmux, with two panes. In the first pane, it runs the test script \"test_auto_dog_video_giphy_online_producer.py\". In the second pane, it starts the Uvicorn server for the \"lazzo.network.progressbar.server\" application on port 8576 with critical log level.",
        "type": "comment"
    },
    "1720": {
        "file_id": 157,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.py",
        "type": "filepath"
    },
    "1721": {
        "file_id": 157,
        "content": "The code patches the \"requests\" library for Bilibili postMetadata, enables debugging, and includes paraphraser function. It also features video recommendation testing, metadata handling, data preprocessing from database, music API, generating subtitles with Giphy's video producer, all tested by OnlineAutoContentProducer. The code defines `partialMedialangRenderTest` function within `PMRT_0`, creating a temporary directory, setting parameters for tests, and returning output path.",
        "type": "summary"
    },
    "1722": {
        "file_id": 157,
        "content": "# changed numpy==1.23.0 to fix compatibility issues.\n# ld_library_path is handled externally using env\n# https://adamj.eu/tech/2022/06/23/how-to-patch-requests-to-have-a-default-timeout/\nREQUESTS_TIMEOUT=30 # monkey patch all requests related things?\nimport patchy\nfrom requests.adapters import HTTPAdapter\n# [DONE] clear milvus image cache database per metadata iteration\ndef patch_requests_default_timeout() -> None:\n    \"\"\"\n    Set a default timeout for all requests made with “requests”.\n    Upstream is waiting on this longstanding issue:\n    https://github.com/psf/requests/issues/3070\n    \"\"\"\n    patchy.patch(\n        HTTPAdapter.send,\n        \"\"\"\\\n        @@ -14,6 +14,8 @@\n             :param proxies: (optional) The proxies dictionary to apply to the request.\n             :rtype: requests.Response\n             \\\"\"\"\n        +    if timeout is None:\n        +        timeout = 5.0\n             try:\n                 conn = self.get_connection(request.url, proxies)\n        \"\"\",\n    )\n# import socket\n# SOCKET_TIMEOUT=60",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:1-37"
    },
    "1723": {
        "file_id": 157,
        "content": "This code patches the \"requests\" library to set a default timeout for all requests made with it. This is done using the \"patchy\" module, and the patch is applied to the \"HTTPAdapter.send\" method. If no timeout is specified, the default timeout will be 5.0 seconds.",
        "type": "comment"
    },
    "1724": {
        "file_id": 157,
        "content": "# socket.setdefaulttimeout(SOCKET_TIMEOUT)\nfrom test_commons import *\nfrom pyjom.primitives import *\nfrom pyjom.medialang.core import *\nfrom pyjom.videotoolbox import resetMilvusVideoDeduplicationCollection\nautoArgs = {\"subtitle_detector\": {\"timestep\": 0.2}}\ntemplate_names = [\"subtitle_detector.mdl.j2\"]\nDEBUG_STATE=False # let's see how far it goes.\n# warning: if you want to post it, you must review, and you must not use 'fast' mode aka preview.\n# you want musictoolbox? well shit...\n# just because you want download music.\n# also where are the places for 'video/audio/voice/artwork' generation?\n# maybe it is not the time to use such kind of things... you know the ram best.\nfrom pyjom.platforms.bilibili.postMetadata import getBilibiliPostMetadataForDogCat\n# decide to do this in sync.\n# preconfigure the dog_or_cat value.\n# dog_or_cat = random.choice([\"dog\", \"cat\"])  # strange.\ndog_or_cat = \"dog\"\n# we need preconfigured things.\nbgmCacheSetName = \"bilibili_cached_bgm_set\"\nfrom pyjom.languagetoolbox import paraphraser",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:38-65"
    },
    "1725": {
        "file_id": 157,
        "content": "This code imports necessary modules, sets default timeout, defines autoArgs and template_names, enables debugging, imports postMetadata for Bilibili, preconfigures dog\\_or\\_cat value as \"dog\", and imports paraphraser from languageToolbox.",
        "type": "comment"
    },
    "1726": {
        "file_id": 157,
        "content": "import random\ndef myParaphraser(content:str):# TODO: limit and chop large group of text into chunks, process them individually.\n    methods = [\"clueai_free\", \n    # till we get it.\n    # \"cn_nlp_online\", \n    \"baidu_translator\"]\n    random.shuffle(methods)\n    for method in methods:\n        output, success = paraphraser(content, method =method )\n        if not success:\n            output = content\n        else:\n            break\n    return output\npostMetadataGeneratorPrimitive = getBilibiliPostMetadataForDogCat(\n    dog_or_cat=dog_or_cat,\n    bgmCacheSetName=bgmCacheSetName,\n    bgmCacheAutoPurge=True,  # autopurge bgm, not sure we are using the latest bgm!\n    customParaphraser=myParaphraser\n)  # metadata you can fetch from database, maybe you can preprocess this.\nMAX_ITER = 10  # stop on ten trials.\nfrom lazero.utils.tools import iteratorWrapper\npostMetadataGenerator = iteratorWrapper(\n    postMetadataGeneratorPrimitive, init_repeat=0, max_iter=MAX_ITER, before_yield = resetMilvusVideoDeduplicationCollection",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:66-90"
    },
    "1727": {
        "file_id": 157,
        "content": "This code defines a function `myParaphraser` that takes a string and paraphrases it using multiple methods in random order. It then applies the paraphrased text if successful, otherwise keeps the original content. The code also sets up a metadata generator for Bilibili dog or cat posts using the `myParaphraser` function, with a maximum of 10 trials before stopping. The metadata can be fetched from a database and preprocessed.",
        "type": "comment"
    },
    "1728": {
        "file_id": 157,
        "content": ")\npostMetadataGenerator.__next__()  # for getting some bgm, just in case.\n# really?\n# [DONE] i think you need some superpower over this postMetadataGenerator.\n# kwargs: init_repeat=0, repeat=0, max_iter=MAX_ITER (take care of \"repeat\" related arguments)\n# [DONE] i also think you should alter the title and intro with paraphraser.\n# TODO: check if video is properly registered to video recommendation server.\n# TODO: check video recommendation server is \"properly\" recommending all related videos\n# [DONE] control dog/cat shits, by stopping the iterator!\nmetaTopics = {\n    \"dog\": {\n        \"static\": [[\"dog\", \"puppy\"]],\n        \"dynamic\": [\n            [\"samoyed\", \"husky\", \"teddy\", \"chiwawa\"],\n            [\"meme\"],\n            [\"funny\", \"cute\", \"love\"],\n        ],\n    },\n    \"cat\": {\n        \"static\": [[\"cat\", \"kitten\"]],\n        \"dynamic\": [[\"purr\", \"paws\", \"meme\"], [\"funny\", \"cute\"]],\n    },\n}\n# when use 'complete test' it stops iterating.\n# maybe because the last one is a generator. goddamn it.\ndef cleanupMedialangTmpdir():",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:91-121"
    },
    "1729": {
        "file_id": 157,
        "content": "This code snippet seems to be responsible for handling different types of metadata related to dogs and cats, as well as testing the functionality of video recommendations. It includes setting up dynamic topics based on specific breeds and actions, using a paraphraser to alter titles and intros, and checking if videos are properly registered and recommended by the video recommendation server. The code also mentions cleaning up temporary files when running a complete test. However, there seems to be some confusion about certain aspects of the postMetadataGenerator and potential issues with iterating through it.",
        "type": "comment"
    },
    "1730": {
        "file_id": 157,
        "content": "    tmpdirPath = \"/dev/shm/medialang\"\n    files_and_dirs = os.listdir(tmpdirPath)\n    for f in files_and_dirs:\n        fpath = os.path.join(tmpdirPath, f)\n        if os.path.isfile(fpath):\n            os.remove(fpath)\nfrom pyjom.commons import getRedisCachedSet\nfrom pyjom.musictoolbox import neteaseMusic\ndef makeTemplateConfigsGenerator():\n    NMClient = neteaseMusic()\n    while True:\n        # download one music, either from hottest songs or from fetched music list.\n        # even if we search for the name, we will randomly choose the song to avoid problems.\n        # you must download the file in a fixed location.\n        while True:\n            bgmCacheSet = getRedisCachedSet(bgmCacheSetName)\n            keywords = random.choice(list(bgmCacheSet)).strip()\n            if len(keywords) > 0:\n                (\n                    music_content,\n                    music_format,\n                ), lyric_string = NMClient.getMusicAndLyricWithKeywords(\n                    keywords, similar=random.choice([True, False])",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:122-148"
    },
    "1731": {
        "file_id": 157,
        "content": "This code generates a random keyword from a Redis set and uses the NeteaseMusic API to download music content, format, and lyric string related to that keyword. The music is downloaded to a fixed location. If no keywords are found or they're empty, it keeps searching for new ones.",
        "type": "comment"
    },
    "1732": {
        "file_id": 157,
        "content": "                )\n                if music_content is not None:\n                    break\n        with tempfile.NamedTemporaryFile(\n            \"wb\", suffix=\".{}\".format(music_format)\n        ) as music_file:\n            with tempfile.NamedTemporaryFile(\"w+\", suffix=\".lrc\") as lyric_file:\n                musicFilePath, lyricPath = music_file.name, lyric_file.name\n                music_file.write(music_content)\n                music_file.seek(0)\n                if lyric_string is not None:\n                    lyric_file.write(lyric_string)\n                    lyric_file.seek(0)\n                else:\n                    lyricPath = None\n                data = {\n                    \"debug\": DEBUG_STATE,  # we need to preview this video.\n                    # use generator instead.\n                    \"music\": {\n                        \"filepath\": musicFilePath,  # these things were not right.\n                        # how to get this music file? by bgm search?\n                        # \"filepath\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\",  # these things were not right.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:149-170"
    },
    "1733": {
        "file_id": 157,
        "content": "This code snippet creates temporary music and lyric files, writes music content and lyric string into them if available, and stores their file paths in a dictionary along with the debug state. It aims to preview a video using the given music and lyrics. The music file path may be set via bgm search or by specifying it directly.",
        "type": "comment"
    },
    "1734": {
        "file_id": 157,
        "content": "                        \"lyric_path\": lyricPath,  ## you can choose not to pass the lyric_path anyway. also format different than .lrc is on the way?\n                    },\n                    \"font\": \"/root/.local/share/fonts/simhei.ttf\",\n                    # \"font\": \"/root/.local/share/fonts/simyou.ttf\", # 幼圆可能打不出来\n                    \"policy\": {},\n                    \"maxtime\": 7.8,\n                    \"mintime\": 2,  # we've write this shit!\n                    \"render_ass\": lyricPath is not None,\n                    # also determine how to translate the lyrics, whether to translate or not.\n                    \"translate\": lyricPath is not None,  # default: False\n                    # are you sure you want to use deepl? this is hard to configure. especially the goddamn proxy.\n                    # you can simply implement the method to cofigure and test ping for websites in lazero library so we can share the same code.\n                    # or you can borrow code from the web. some clash manager library for python.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:171-183"
    },
    "1735": {
        "file_id": 157,
        "content": "This code is defining a video producer for Giphy that generates subtitles for videos. The `lyric_path` can be chosen to not be passed, and different lyric file formats are being considered. The font for the subtitles is set as '/root/.local/share/fonts/simhei.ttf'. The policy, maximum time (`maxtime`), minimum time (`mintime`) and whether to render assubtitles (`render_ass`) are determined based on `lyricPath`. Translation is set to be done if the `lyricPath` is not None.",
        "type": "comment"
    },
    "1736": {
        "file_id": 157,
        "content": "                    \"translate_method\": \"baidu\",  # default: baidu, random, deepl\n                    # damn cold for this mac!\n                    \"ass_template_configs\": {},\n                    \"assStyleConfig\": {},\n                }\n                yield data\ntemplateConfigsGenerator = makeTemplateConfigsGenerator()\nwbRev = OnlineAutoContentProducer(\n    afterPosting=cleanupMedialangTmpdir,\n    source=\"giphy\",\n    fast=False,\n    metaTopic=metaTopics[dog_or_cat],\n    # fast= True,  # pass this flag to medialang export engine\n    template=\"pets_with_music_online\",\n    postMetadataGenerator=postMetadataGenerator,\n    template_configs=templateConfigsGenerator,\n    # you can also translate funny videos from youtube.\n    # dummy_auto=False,\n    # args=autoArgs,\n    # semiauto=False # i do not want to comment shit.\n)\ndef completeTest():\n    wbRev.main()\ndef partialMedialangRenderTest(medialangScript, medialangTmpdir, verbose=True):\n    # copy that script to my dear clipboard please?\n    medialangObject = Medialang(",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:184-215"
    },
    "1737": {
        "file_id": 157,
        "content": "This code is creating an instance of the OnlineAutoContentProducer class with specific arguments. The producer is set to work with Giphy content and use the \"pets_with_music_online\" template. It also yields data, generates template configs, and provides a postMetadataGenerator. The completeTest function calls the main method on the producer instance, while partialMedialangRenderTest takes a medialangScript and renders it in the given temporary directory (medialangTmpdir).",
        "type": "comment"
    },
    "1738": {
        "file_id": 157,
        "content": "        script=medialangScript, verbose=verbose, medialangTmpdir=medialangTmpdir\n    )\n    result = medialangObject.execute()\n    return result\ndef PMRT_0(scriptFilePath, medialangTmpdir, verbose=True):\n    with open(scriptFilePath, \"r\") as f:\n        medialangScript = f.read()\n    return partialMedialangRenderTest(medialangScript, medialangTmpdir, verbose=verbose)\nfrom lazero.filesystem import tmpdir\n# from contextlib import AbstractContextManager\n# class tmpdir(AbstractContextManager):\n#     \"\"\"Context manager to suppress specified exceptions\n#     After the exception is suppressed, execution proceeds with the next\n#     statement following the with statement.\n#          with suppress(FileNotFoundError):\n#              os.remove(somefile)\n#          # Execution still resumes here if the file was already removed\n#     \"\"\"\n#     def __init__(self, path=None):\n#         assert os.path.isabs(path)\n#         self._tmpdir = path\n#     def __enter__(self):\n#         print(\"temporary directory: %s\" % self._tmpdir)",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:216-248"
    },
    "1739": {
        "file_id": 157,
        "content": "The code defines a function `partialMedialangRenderTest` that takes a medialang script, temporary directory, and verbosity level as input. It creates an object `medialangObject`, executes it, and returns the result. Additionally, there's another function `PMRT_0` that uses this `partialMedialangRenderTest` function to execute a medialang script provided by a file path in a temporary directory. Finally, there is a class `tmpdir` which seems to be used as a context manager to suppress exceptions.",
        "type": "comment"
    },
    "1740": {
        "file_id": 157,
        "content": "#         if os.path.exists(self._tmpdir): shutil.rmtree(self._tmpdir)\n#         os.makedirs(self._tmpdir)\n#         return self._tmpdir\n#     def __exit__(self, exctype, excinst, exctb):\n#         # try not to handle exceptions?\n#         tempdir = self._tmpdir\n#         print(\"cleaning tempdir: %s\" % tempdir)\n#         shutil.rmtree(tempdir)\n#         return False\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--partial\", action=\"store_true\", default=False)\n    args = parser.parse_args()\n    # print('args.partial:', args.partial)\n    # breakpoint()\n    COMPLETE_TEST = not args.partial\n    if COMPLETE_TEST:\n        completeTest()\n    # so we don't have to run it all the time. really?\n    else:\n        # scriptFilePath = \"/root/Desktop/works/pyjom/tests/medialang_tests/aef2ab90-6414-4b55-a40e-63014e5648a8.mdl\"\n        # set this scriptFilePath to something else.\n        scriptFilePath = \"/root/Desktop/works/pyjom/samples/medialang/dog_cat_test_nofast.mdl\"  # make it real, not preview.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:249-275"
    },
    "1741": {
        "file_id": 157,
        "content": "This code snippet is from a test file that creates a temporary directory, performs some operations within it, and then cleans up by removing the directory. The code also checks whether to run a complete or partial test based on command-line arguments, and sets the script file path accordingly.",
        "type": "comment"
    },
    "1742": {
        "file_id": 157,
        "content": "        # scriptFilePath = \"/root/Desktop/works/pyjom/samples/medialang/dog_cat_test.mdl\" # make it real, not preview.\n        # a special hack\n        # import tempfile\n        with tmpdir(path=\"/dev/shm/medialang\") as medialangTmpdir:\n            print(\n                \"MEDIALANG SUPER TMPDIR:\", medialangTmpdir\n            )  # as some sort of protection.\n            # /dev/shm/medialang/<randomString>/<randomUUID>.mp4 -> /dev/shm/medialang/<randomUUID>.mp4\n            result = PMRT_0(scriptFilePath, medialangTmpdir, verbose=False)\n            editly_outputPath, medialang_item_list = result  # this just return none!\n            # data -> editly json\n            # this output path is modified. we shall change this.\n            outPath = editly_outputPath  # WE SHALL MUTE IT!\n            # print(editly_json.keys())\n            print(\"MEDIA SAVE PATH (MAYBE YOU CAN PLAY IT?):\", outPath)\n            breakpoint()\n            # import json\n            # data_array -> input of dot processor? check it out.\n            # breakpoint() # what is this?",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:276-295"
    },
    "1743": {
        "file_id": 157,
        "content": "The code sets a temporary directory path (medialangTmpdir), uses the PMRT_0 function with scriptFilePath and medialangTmpdir as arguments, and returns editly_outputPath and medialang_item_list. It then modifies outPath and prints it. The code also includes potential use of json and breakpoint() for debugging.",
        "type": "comment"
    },
    "1744": {
        "file_id": 158,
        "content": "/tests/test_iterator_generator_wrapper_lazero_utils.py",
        "type": "filepath"
    },
    "1745": {
        "file_id": 158,
        "content": "This code tests the functionality of lazero's iteratorWrapper with different parameters such as init_repeat, repeat, and max_iter. It compares the generated results to predefined objective lists for validation.",
        "type": "summary"
    },
    "1746": {
        "file_id": 158,
        "content": "from lazero.utils.tools import iteratorWrapper, flattenUnhashableList\nsequence = [i for i in range(10)]\nINIT_REPEAT = 3\nobjective_init_repeat = [sequence[0]] * INIT_REPEAT + sequence\nREPEAT = 2\nobjective_repeat = [sequence[0]] * INIT_REPEAT + flattenUnhashableList(\n    list(zip(*([sequence] * (1 + REPEAT))))\n)\nMAX_ITER = 4\nobjective_max_iter = [sequence[0]] * INIT_REPEAT + flattenUnhashableList(\n    list(zip(*([sequence[:MAX_ITER]] * (1 + REPEAT))))\n)\ndef test_init_repeat():\n    result = list(iteratorWrapper((s for s in sequence), init_repeat=INIT_REPEAT))\n    assert result == objective_init_repeat\ndef test_repeat():\n    result = list(\n        iteratorWrapper((s for s in sequence), init_repeat=INIT_REPEAT, repeat=REPEAT)\n    )\n    assert result == objective_repeat\ndef test_max_iter():\n    result = list(\n        iteratorWrapper(\n            (s for s in sequence),\n            init_repeat=INIT_REPEAT,\n            repeat=REPEAT,\n            max_iter=MAX_ITER,\n        )\n    )\n    assert result == objective_max_iter",
        "type": "code",
        "location": "/tests/test_iterator_generator_wrapper_lazero_utils.py:1-42"
    },
    "1747": {
        "file_id": 158,
        "content": "This code tests the functionality of lazero's iteratorWrapper with different parameters such as init_repeat, repeat, and max_iter. It compares the generated results to predefined objective lists for validation.",
        "type": "comment"
    },
    "1748": {
        "file_id": 159,
        "content": "/tests/test_talib_stream_ema.py",
        "type": "filepath"
    },
    "1749": {
        "file_id": 159,
        "content": "This code is testing the speed of two different methods for calculating a Simple Moving Average (SMA) using Talib library. The first method uses Function API and the second method uses Streaming API. It measures the time taken to execute each method and prints the results along with original data.",
        "type": "summary"
    },
    "1750": {
        "file_id": 159,
        "content": "import talib\nfrom talib import stream\nimport numpy as np\n# check the difference\nimport timeit\nclose = np.random.random(100)\nprint(close.dtype)\nbreakpoint()\n# close = np.append(close,10)\nclose = np.append(close[1:], 10)\nmtime = timeit.timeit(lambda: np.append(close, 10), number=1)  # why so many times?\n# the Function API\n# really don't know which is faster.\noutput = timeit.timeit(\n    lambda: talib.SMA(close), number=1\n)  # why you take it so damn long?\n# the Streaming API\nlatest = timeit.timeit(lambda: stream.SMA(close[-20:]), number=1)\nprint(output)\nprint(latest)\nprint(close)\nprint(mtime)  # why taking so long?",
        "type": "code",
        "location": "/tests/test_talib_stream_ema.py:1-28"
    },
    "1751": {
        "file_id": 159,
        "content": "This code is testing the speed of two different methods for calculating a Simple Moving Average (SMA) using Talib library. The first method uses Function API and the second method uses Streaming API. It measures the time taken to execute each method and prints the results along with original data.",
        "type": "comment"
    },
    "1752": {
        "file_id": 160,
        "content": "/tests/unittest_aegisub_ass_configure.py",
        "type": "filepath"
    },
    "1753": {
        "file_id": 160,
        "content": "This code reads a file using `readFile` function and stores its contents as a template in Jinja2. It then configures the template with specific font and size values from the `template_configs` dictionary, and prints the final configured template.",
        "type": "summary"
    },
    "1754": {
        "file_id": 160,
        "content": "from lazero.filesystem.io import readFile\nimport jinja2\ntemplate_configs = {\n    \"defaultFontname\": \"Arial\",\n    \"defaultFontsize\": 48,  # integer?\n    \"translationFontname\": \"Migu 1P\",\n    \"translationFontsize\": 48,\n    \"kanjiFontname\": \"Migu 1P\",\n    \"kanjiFontsize\": 46,\n    \"romajiFontname\": \"Migu 1P\",\n    \"romajiFontsize\": 38,\n}\n# template_configs = {'defaultFontname':'Anonymous Pro'}\ntemplate_path = \"/root/Desktop/works/pyjom/tests/karaoke_effects/in2.ass.j2\"\ntemplate = jinja2.Template(source=readFile(template_path))\ntemplate_configured = template.render(**template_configs)\nprint(template_configured)",
        "type": "code",
        "location": "/tests/unittest_aegisub_ass_configure.py:1-19"
    },
    "1755": {
        "file_id": 160,
        "content": "This code reads a file using `readFile` function and stores its contents as a template in Jinja2. It then configures the template with specific font and size values from the `template_configs` dictionary, and prints the final configured template.",
        "type": "comment"
    },
    "1756": {
        "file_id": 161,
        "content": "/tests/test_ocr_entity_detector.py",
        "type": "filepath"
    },
    "1757": {
        "file_id": 161,
        "content": "The code loads JSON data containing stationary and moving text, checks their locations over time using similarity metrics, and performs forced combination of OCR results, iterating through the combined results to print content and type.",
        "type": "summary"
    },
    "1758": {
        "file_id": 161,
        "content": "from test_commons import *\nfrom pyjom.medialang.functions.detectors.entityDetector import *\nimport json\n# check if text is movement or we have to mark its trajectory.\n# feeling like i am a game maker.\ndataPath = \"/root/Desktop/works/pyjom/logs/local/1649678716_663207.json\"\nmdata = open(dataPath, \"r\", encoding=\"utf8\").read()\nmdata = json.loads(mdata)\n# minMaxThresh = 14 # max difference is ten pixel. or it is considered as moving.\n# strDisThreshold = 1 # or considered as changing?\n# certThreshold = 0.7\n# changingMinMaxThresh = 25\n# changingstrDisThreshold = 2\n# timeThreshold = 0.3 # i intentially set it.\n# blockTimeThreshold = 0.3 # at least last this long?\n# strSimThreshold = 0.8\n# print(mtext, key) # this is stationary.\nfor elem in mdata:\n    # maybe something in a sequence? like location similarity?\n    # if location is similar, but text is different, do we really need to handle it?\n    # we need to collect similar frames, so we can deduct further.\n    try:\n        rev = elem[\"review\"][\"review\"][1]\n        ocrData = rev[\"subtitle_detector\"][\"subtitle_result\"][\"paddleocr\"]",
        "type": "code",
        "location": "/tests/test_ocr_entity_detector.py:1-30"
    },
    "1759": {
        "file_id": 161,
        "content": "This code is loading data from a JSON file and iterating through each element in the data. It appears to be checking if the text is stationary or moving by comparing its location and text over time, and possibly using similarity metrics like string distance and similarity threshold. The code seems to involve subtitle detection using PaddleOCR, as indicated by the \"paddleocr\" attribute in the JSON data.",
        "type": "comment"
    },
    "1760": {
        "file_id": 161,
        "content": "        # here is the core.\n        myresult = makeOCREntity(ocrData, blockTimeThreshold=0, timeThreshold=0.1)\n        myNewResult = staticOCRCombinator(myresult)  # this is forced combination.\n        # print(json.dumps(myNewResult,indent=4))\n        for key in myNewResult.keys():\n            myElem = myNewResult[key]\n            print(myElem[\"content\"], key)\n        breakpoint()\n    except:\n        import traceback\n        traceback.print_exc()\n        breakpoint()",
        "type": "code",
        "location": "/tests/test_ocr_entity_detector.py:31-43"
    },
    "1761": {
        "file_id": 161,
        "content": "Code snippet initializes and performs a forced combination of OCR results, then iterates over the combined results and prints their content and type.",
        "type": "comment"
    },
    "1762": {
        "file_id": 162,
        "content": "/tests/test_weibo_pets.py",
        "type": "filepath"
    },
    "1763": {
        "file_id": 162,
        "content": "This code imports necessary modules, initializes a WeiboPetsReviewer object with specific parameters and then runs its main function to perform an automated review of Weibo Pets data.",
        "type": "summary"
    },
    "1764": {
        "file_id": 162,
        "content": "from test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\ntemplate_names = [\"subtitle_detector.mdl.j2\"]\nautoArgs = {\"subtitle_detector\": {\"timestep\": 0.2}}\nwbRev = WeiboPetsReviewer(\n    auto=True,\n    semiauto=False,\n    dummy_auto=False,\n    args=autoArgs,\n    template_names=template_names,\n)\n# wbRev.main(skip_review=True) # to test feedback.\nwbRev.main()",
        "type": "code",
        "location": "/tests/test_weibo_pets.py:1-15"
    },
    "1765": {
        "file_id": 162,
        "content": "This code imports necessary modules, initializes a WeiboPetsReviewer object with specific parameters and then runs its main function to perform an automated review of Weibo Pets data.",
        "type": "comment"
    },
    "1766": {
        "file_id": 163,
        "content": "/tests/test_medialang.py",
        "type": "filepath"
    },
    "1767": {
        "file_id": 163,
        "content": "This code imports necessary modules, defines test paths, and iterates through each path. It creates a Medialang object with the specified script path and prettifies it in-place.",
        "type": "summary"
    },
    "1768": {
        "file_id": 163,
        "content": "from test_commons import *\nfrom pyjom.medialang.core import *\nimport os\ntestpaths = [\n    \"processor_demo.mdl\",\n    \"processor_multi.mdl\",\n    \"recipe.mdl\",\n    \"audiolang.mdl\",\n    \"videolang.mdl\",\n]\n# testcontent = open(testpath,\"r\").read()\nfor path in testpaths:\n    testpath = os.path.join(\"/root/Desktop/works/pyjom/test/\", path)\n    mdl = Medialang(script_path=testpath)  # will be parsed.\n    mdl.prettify(inplace=True)",
        "type": "code",
        "location": "/tests/test_medialang.py:1-18"
    },
    "1769": {
        "file_id": 163,
        "content": "This code imports necessary modules, defines test paths, and iterates through each path. It creates a Medialang object with the specified script path and prettifies it in-place.",
        "type": "comment"
    },
    "1770": {
        "file_id": 164,
        "content": "/tests/test_remerge_demanded_cut_spans.py",
        "type": "filepath"
    },
    "1771": {
        "file_id": 164,
        "content": "This code defines cut_spans as ranges for processing and creates a test function to check if the list of spans has consistent order, duration, and is remerged correctly.",
        "type": "summary"
    },
    "1772": {
        "file_id": 164,
        "content": "cut_spans = [(0, 1), (1, 2), (2, 9), (9, 100), (100, 101), (101, 102)]\n# cut_spans=[(0, 2.43475), (2.43475, 4.3458125), (4.3458125, 7.543145833333333), (7.543145833333333, 10.7313125), (10.7313125, 13.928645833333333), (13.928645833333333, 16.492041666666665), (16.492041666666665, 22.216020833333335), (22.216020833333335, 25.4225625), (25.4225625, 30.530958333333334), (30.530958333333334, 33.709916666666665), (33.709916666666665, 36.907270833333335), (36.907270833333335, 39.46145833333333), (39.46145833333333, 42.649625), (42.649625, 46.499291666666664), (46.499291666666664, 49.0443125), (49.0443125, 52.54485416666667), (52.54485416666667, 55.10825), (55.10825, 57.65325), (57.65325, 61.806125), (61.806125, 64.99429166666667), (64.99429166666667, 67.55766666666666), (67.55766666666666, 70.1026875), (70.1026875, 73.28164583333333), (73.28164583333333, 76.16660416666667), (76.16660416666667, 79.99791666666667), (79.99791666666667, 82.23054166666667), (82.23054166666667, 85.1063125), (85.10",
        "type": "code",
        "location": "/tests/test_remerge_demanded_cut_spans.py:1-2"
    },
    "1773": {
        "file_id": 164,
        "content": "Code defines a list of cut_spans, where each span represents a range of values for further processing or analysis.",
        "type": "comment"
    },
    "1774": {
        "file_id": 164,
        "content": "63125, 87.97289583333334), (87.97289583333334, 91.1610625), (91.1610625, 93.09047916666667), (93.09047916666667, 96.26945833333333), (96.26945833333333, 100.42233333333333), (100.42233333333333, 102.97652083333334), (102.97652083333334, 106.80783333333333), (106.80783333333333, 111.27308333333333), (111.27308333333333, 117.33702083333333), (117.33702083333333, 119.57883333333334), (119.57883333333334, 123.0701875), (123.0701875, 127.250625), (127.250625, 129.7864375), (129.7864375, 134.57327083333334), (134.57327083333334, 137.7614375), (137.7614375, 140.95877083333335), (140.95877083333335, 146.06716666666668), (146.06716666666668, 150.5324375), (150.5324375, 153.72058333333334), (153.72058333333334, 157.55189583333333), (157.55189583333333, 160.74922916666668), (160.74922916666668, 163.3034375), (163.3034375, 164.25895833333334), (164.25895833333334, 164.89291666666668), (164.89291666666668, 171.576)]\nfrom test_commons import *\nfrom pyjom.lyrictoolbox import remergeDemandedCutSpans\ndef test_cut_spans_valid(list_of_spans, min_span=1.5, max_span=10, no_range_test=False):",
        "type": "code",
        "location": "/tests/test_remerge_demanded_cut_spans.py:2-7"
    },
    "1775": {
        "file_id": 164,
        "content": "This code defines a function `test_cut_spans_valid` that takes a list of spans and optional arguments for minimum and maximum span duration. It calls the `remergeDemandedCutSpans` function from `pyjom.lyrictoolbox`. The code also imports functions from `test_commons` module and defines some variables.",
        "type": "comment"
    },
    "1776": {
        "file_id": 164,
        "content": "    start = list_of_spans[0][0]\n    init_end = list_of_spans[0][1]\n    minit_duration = list_of_spans[0][1] - start\n    if not no_range_test:\n        assert start < list_of_spans[0][1]\n        assert minit_duration >= min_span and minit_duration <= max_span\n    # end = list_of_spans[-1][1]\n    for i, span in enumerate(list_of_spans[1:]):\n        mstart, mend = span\n        try:\n            assert mstart == init_end\n        except:\n            print(mstart, mend, init_end, i + 1)\n            print(list_of_spans[max(0, i - 2) : min(len(list_of_spans), i + 2)])\n            breakpoint()\n        assert mstart < mend\n        duration = mend - mstart\n        if not no_range_test:\n            assert duration >= min_span and duration <= max_span\n        init_end = mend\ntest_cut_spans_valid(cut_spans, no_range_test=True)\nnew_spans = remergeDemandedCutSpans(cut_spans)\nprint(\"new spans?\", new_spans)\ntest_cut_spans_valid(new_spans)\nassert cut_spans[0][0] == new_spans[0][0]\nassert cut_spans[-1][1] == new_spans[-1][1]",
        "type": "code",
        "location": "/tests/test_remerge_demanded_cut_spans.py:8-35"
    },
    "1777": {
        "file_id": 164,
        "content": "This code checks if the list of spans has a consistent order and duration. It asserts that the start of each span is less than its end, and the duration (end - start) adheres to specified minimum and maximum span values. If any assertion fails, it prints the offending span and surrounding spans for debugging. The code then tests if the list of spans has been remerged correctly using the remergeDemandedCutSpans function, ensuring that the first and last spans remain unchanged.",
        "type": "comment"
    },
    "1778": {
        "file_id": 165,
        "content": "/tests/test_manual_censorInterface.py",
        "type": "filepath"
    },
    "1779": {
        "file_id": 165,
        "content": "The code imports necessary modules, defines lists of tags, shuffles them, and uses the censorInterface function to perform content censorship on a title and content with specified tags. It then prints the result.",
        "type": "summary"
    },
    "1780": {
        "file_id": 165,
        "content": "from test_commons import *\nfrom pyjom.modules.contentCensoring.core import censorInterface\nmcounter = 20\nmtags0 = [\"superLongtag{}\".format(x) for x in range(mcounter)]  # must be differet.\nmtags1 = [\"tag{}\".format(x) for x in range(mcounter)]\nmtags = mtags0 + mtags1\nimport random\nrandom.shuffle(mtags)\nresult = censorInterface(\n    \"title\", [\"mytopic\", \"another topic\"], \"mycontent\", mtags=mtags\n)\nprint(result)",
        "type": "code",
        "location": "/tests/test_manual_censorInterface.py:1-18"
    },
    "1781": {
        "file_id": 165,
        "content": "The code imports necessary modules, defines lists of tags, shuffles them, and uses the censorInterface function to perform content censorship on a title and content with specified tags. It then prints the result.",
        "type": "comment"
    },
    "1782": {
        "file_id": 166,
        "content": "/tests/test_dummy.sh",
        "type": "filepath"
    },
    "1783": {
        "file_id": 166,
        "content": "This code is executing a Python script named \"test_dummy.py\" using the default installed Python3 interpreter. It's likely being run in a Unix-like environment as it uses \"python3\" instead of \"python\". The purpose of running this script might be for testing, debugging or execution of the code within \"test_dummy.py\".",
        "type": "summary"
    },
    "1784": {
        "file_id": 166,
        "content": "python3 test_dummy.py",
        "type": "code",
        "location": "/tests/test_dummy.sh:1-1"
    },
    "1785": {
        "file_id": 166,
        "content": "This code is executing a Python script named \"test_dummy.py\" using the default installed Python3 interpreter. It's likely being run in a Unix-like environment as it uses \"python3\" instead of \"python\". The purpose of running this script might be for testing, debugging or execution of the code within \"test_dummy.py\".",
        "type": "comment"
    },
    "1786": {
        "file_id": 167,
        "content": "/tests/test_local_reviewer.py",
        "type": "filepath"
    },
    "1787": {
        "file_id": 167,
        "content": "This code imports necessary modules, initializes a FilesystemContentReviewer object with a directory path, and calls its main() method to perform content review on the specified directory.",
        "type": "summary"
    },
    "1788": {
        "file_id": 167,
        "content": "from test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\nwbRev = FilesystemContentReviewer(dirpath=\"./samples/video/\")\nwbRev.main()",
        "type": "code",
        "location": "/tests/test_local_reviewer.py:1-5"
    },
    "1789": {
        "file_id": 167,
        "content": "This code imports necessary modules, initializes a FilesystemContentReviewer object with a directory path, and calls its main() method to perform content review on the specified directory.",
        "type": "comment"
    },
    "1790": {
        "file_id": 168,
        "content": "/tests/test_dummy.py",
        "type": "filepath"
    },
    "1791": {
        "file_id": 168,
        "content": "This code imports necessary modules, initializes a ContentProducer and ContentReviewer objects, runs their main methods, and prints their identifier data. It tests content production and reviewing functionality.",
        "type": "summary"
    },
    "1792": {
        "file_id": 168,
        "content": "from test_commons import *\nfrom pyjom.main import *\nproducer = ContentProducer()\nproducer.main()\nprint(producer.identifier.data)\nreviewer = ContentReviewer()\nreviewer.main()\nprint(reviewer.identifier.data)",
        "type": "code",
        "location": "/tests/test_dummy.py:1-10"
    },
    "1793": {
        "file_id": 168,
        "content": "This code imports necessary modules, initializes a ContentProducer and ContentReviewer objects, runs their main methods, and prints their identifier data. It tests content production and reviewing functionality.",
        "type": "comment"
    },
    "1794": {
        "file_id": 169,
        "content": "/tests/unittest_caer_get_gif_width_height.py",
        "type": "filepath"
    },
    "1795": {
        "file_id": 169,
        "content": "This code imports the get_res function from caer.video, sets a video path, and calls the get_res function with the video path to retrieve the width and height of the video, then prints them out.",
        "type": "summary"
    },
    "1796": {
        "file_id": 169,
        "content": "from caer.video.frames_and_fps import get_res\nvideoPath = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\nwidth, height = get_res(videoPath)\nprint(width, height)",
        "type": "code",
        "location": "/tests/unittest_caer_get_gif_width_height.py:1-6"
    },
    "1797": {
        "file_id": 169,
        "content": "This code imports the get_res function from caer.video, sets a video path, and calls the get_res function with the video path to retrieve the width and height of the video, then prints them out.",
        "type": "comment"
    },
    "1798": {
        "file_id": 170,
        "content": "/tests/unittest_extract_tags_tfidf.py",
        "type": "filepath"
    },
    "1799": {
        "file_id": 170,
        "content": "This code is processing Chinese text using the Jieba library to tokenize it and filter out stop words. It then extracts the top 5 keywords using NLTK's jieba.analyse module. The output is the extracted tags printed on the console.",
        "type": "summary"
    }
}