{
    "1700": {
        "file_id": 153,
        "content": "from test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\nwbRev = FilesystemContentReviewer(dirpath=\"./samples/video/\")\nwbRev.main()",
        "type": "code",
        "location": "/tests/test_local_reviewer.py:1-5"
    },
    "1701": {
        "file_id": 153,
        "content": "This code imports necessary modules, initializes a FilesystemContentReviewer object with a directory path, and calls its main() method to perform content review on the specified directory.",
        "type": "comment"
    },
    "1702": {
        "file_id": 154,
        "content": "/tests/test_iterator_generator_wrapper_lazero_utils.py",
        "type": "filepath"
    },
    "1703": {
        "file_id": 154,
        "content": "This code tests the functionality of lazero's iteratorWrapper with different parameters such as init_repeat, repeat, and max_iter. It compares the generated results to predefined objective lists for validation.",
        "type": "summary"
    },
    "1704": {
        "file_id": 154,
        "content": "from lazero.utils.tools import iteratorWrapper, flattenUnhashableList\nsequence = [i for i in range(10)]\nINIT_REPEAT = 3\nobjective_init_repeat = [sequence[0]] * INIT_REPEAT + sequence\nREPEAT = 2\nobjective_repeat = [sequence[0]] * INIT_REPEAT + flattenUnhashableList(\n    list(zip(*([sequence] * (1 + REPEAT))))\n)\nMAX_ITER = 4\nobjective_max_iter = [sequence[0]] * INIT_REPEAT + flattenUnhashableList(\n    list(zip(*([sequence[:MAX_ITER]] * (1 + REPEAT))))\n)\ndef test_init_repeat():\n    result = list(iteratorWrapper((s for s in sequence), init_repeat=INIT_REPEAT))\n    assert result == objective_init_repeat\ndef test_repeat():\n    result = list(\n        iteratorWrapper((s for s in sequence), init_repeat=INIT_REPEAT, repeat=REPEAT)\n    )\n    assert result == objective_repeat\ndef test_max_iter():\n    result = list(\n        iteratorWrapper(\n            (s for s in sequence),\n            init_repeat=INIT_REPEAT,\n            repeat=REPEAT,\n            max_iter=MAX_ITER,\n        )\n    )\n    assert result == objective_max_iter",
        "type": "code",
        "location": "/tests/test_iterator_generator_wrapper_lazero_utils.py:1-42"
    },
    "1705": {
        "file_id": 154,
        "content": "This code tests the functionality of lazero's iteratorWrapper with different parameters such as init_repeat, repeat, and max_iter. It compares the generated results to predefined objective lists for validation.",
        "type": "comment"
    },
    "1706": {
        "file_id": 155,
        "content": "/tests/test_medialang.py",
        "type": "filepath"
    },
    "1707": {
        "file_id": 155,
        "content": "This code imports necessary modules, defines test paths, and iterates through each path. It creates a Medialang object with the specified script path and prettifies it in-place.",
        "type": "summary"
    },
    "1708": {
        "file_id": 155,
        "content": "from test_commons import *\nfrom pyjom.medialang.core import *\nimport os\ntestpaths = [\n    \"processor_demo.mdl\",\n    \"processor_multi.mdl\",\n    \"recipe.mdl\",\n    \"audiolang.mdl\",\n    \"videolang.mdl\",\n]\n# testcontent = open(testpath,\"r\").read()\nfor path in testpaths:\n    testpath = os.path.join(\"/root/Desktop/works/pyjom/test/\", path)\n    mdl = Medialang(script_path=testpath)  # will be parsed.\n    mdl.prettify(inplace=True)",
        "type": "code",
        "location": "/tests/test_medialang.py:1-18"
    },
    "1709": {
        "file_id": 155,
        "content": "This code imports necessary modules, defines test paths, and iterates through each path. It creates a Medialang object with the specified script path and prettifies it in-place.",
        "type": "comment"
    },
    "1710": {
        "file_id": 156,
        "content": "/tests/test_dummy.sh",
        "type": "filepath"
    },
    "1711": {
        "file_id": 156,
        "content": "This code is executing a Python script named \"test_dummy.py\" using the default installed Python3 interpreter. It's likely being run in a Unix-like environment as it uses \"python3\" instead of \"python\". The purpose of running this script might be for testing, debugging or execution of the code within \"test_dummy.py\".",
        "type": "summary"
    },
    "1712": {
        "file_id": 156,
        "content": "python3 test_dummy.py",
        "type": "code",
        "location": "/tests/test_dummy.sh:1-1"
    },
    "1713": {
        "file_id": 156,
        "content": "This code is executing a Python script named \"test_dummy.py\" using the default installed Python3 interpreter. It's likely being run in a Unix-like environment as it uses \"python3\" instead of \"python\". The purpose of running this script might be for testing, debugging or execution of the code within \"test_dummy.py\".",
        "type": "comment"
    },
    "1714": {
        "file_id": 157,
        "content": "/tests/test_dummy.py",
        "type": "filepath"
    },
    "1715": {
        "file_id": 157,
        "content": "This code imports necessary modules, initializes a ContentProducer and ContentReviewer objects, runs their main methods, and prints their identifier data. It tests content production and reviewing functionality.",
        "type": "summary"
    },
    "1716": {
        "file_id": 157,
        "content": "from test_commons import *\nfrom pyjom.main import *\nproducer = ContentProducer()\nproducer.main()\nprint(producer.identifier.data)\nreviewer = ContentReviewer()\nreviewer.main()\nprint(reviewer.identifier.data)",
        "type": "code",
        "location": "/tests/test_dummy.py:1-10"
    },
    "1717": {
        "file_id": 157,
        "content": "This code imports necessary modules, initializes a ContentProducer and ContentReviewer objects, runs their main methods, and prints their identifier data. It tests content production and reviewing functionality.",
        "type": "comment"
    },
    "1718": {
        "file_id": 158,
        "content": "/tests/test_bilibili_resolve_tid.py",
        "type": "filepath"
    },
    "1719": {
        "file_id": 158,
        "content": "This code imports necessary modules, sets tid to 217, and calls resolveSubTidsFromTid function with the tid. The returned result is then printed. It tests resolving subTids from a given tid in Bilibili platform's database.",
        "type": "summary"
    },
    "1720": {
        "file_id": 158,
        "content": "from test_commons import *\nfrom pyjom.platforms.bilibili.database import resolveSubTidsFromTid\ntid = 217\nresult = resolveSubTidsFromTid(tid)\nprint(\"RESULT?\", result)",
        "type": "code",
        "location": "/tests/test_bilibili_resolve_tid.py:1-6"
    },
    "1721": {
        "file_id": 158,
        "content": "This code imports necessary modules, sets tid to 217, and calls resolveSubTidsFromTid function with the tid. The returned result is then printed. It tests resolving subTids from a given tid in Bilibili platform's database.",
        "type": "comment"
    },
    "1722": {
        "file_id": 159,
        "content": "/tests/test_bilibili_register_video.py",
        "type": "filepath"
    },
    "1723": {
        "file_id": 159,
        "content": "This code imports necessary modules, sets bilibili video ID and user ID, calls the \"registerBilibiliUserVideo\" function to register the video with given parameters, and prints the success status of registration.",
        "type": "summary"
    },
    "1724": {
        "file_id": 159,
        "content": "dedeuserid = str(397424026)\nbvid = \"BV1Gd4y1j7ht\"\nfrom test_commons import *\nfrom pyjom.modules.contentPosting.bilibiliPoster import registerBilibiliUserVideo\nsuccess = registerBilibiliUserVideo(bvid, dedeuserid)\nprint(\"SUCCESS?\", success)",
        "type": "code",
        "location": "/tests/test_bilibili_register_video.py:1-7"
    },
    "1725": {
        "file_id": 159,
        "content": "This code imports necessary modules, sets bilibili video ID and user ID, calls the \"registerBilibiliUserVideo\" function to register the video with given parameters, and prints the success status of registration.",
        "type": "comment"
    },
    "1726": {
        "file_id": 160,
        "content": "/tests/test_auto_local_reviewer.py",
        "type": "filepath"
    },
    "1727": {
        "file_id": 160,
        "content": "The code imports modules, defines detectors' dictionaries, sets template names, and initializes an object wbRev from Main class with specific arguments. The main() method is then called with these arguments for execution.",
        "type": "summary"
    },
    "1728": {
        "file_id": 160,
        "content": "from test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\n# autoArgs = {\"subtitle_detector\": {\"timestep\": 0.2}} # not work for boundary works.\n# autoArgs = {\"subtitle_detector\": {\"timestep\": 0.2},\"yolov5_detector\":{\"model\":\"yolov5x\"}}\n# template_names = [\"subtitle_detector.mdl.j2\"] # test ocr entities first.\n# template_names = [\"yolov5_detector.mdl.j2\"]\nautoArgs = {\n    \"frameborder_detector\": {\n        \"model\": \"huffline_horizontal_vertical\",\n        \"config\": {\"includeBoundaryLines\": True},\n    }\n}\n# autoArgs={\"frameborder_detector\":{\"model\":\"framedifference_talib\",\"config\":{}}}\ntemplate_names = [\"frameborder_detector.mdl.j2\"]\n# template_names = [\"framediff_detector.mdl.j2\"]\n# seems cudnn is causing trouble?\n# CuDNN Version 降到7.6试试，这个问题是环境问题引起的\n# https://pypi.tuna.tsinghua.edu.cn/packages/a4/1f/56dddeb4794137e3f824476ead29806d60a5d5fc20adba9f4d7ca5899900/paddlepaddle_gpu-2.2.2-cp39-cp39-manylinux1_x86_64.whl\n# from pip._internal.cli.main\n# we have modified the pip downloader.\nwbRev = FilesystemAutoContentReviewer(",
        "type": "code",
        "location": "/tests/test_auto_local_reviewer.py:1-24"
    },
    "1729": {
        "file_id": 160,
        "content": "This code is importing necessary modules, defining the autoArgs dictionary for various detectors, and setting template names for testing. It mentions potential issues with CuDNN version and a modified pip downloader.",
        "type": "comment"
    },
    "1730": {
        "file_id": 160,
        "content": "    dirpath=\"./samples/video/\",\n    dummy_auto=False,\n    args=autoArgs,\n    template_names=template_names,\n    semiauto=False,  # i do not want to comment shit.\n)\nwbRev.main()",
        "type": "code",
        "location": "/tests/test_auto_local_reviewer.py:25-32"
    },
    "1731": {
        "file_id": 160,
        "content": "This code initializes an object, wbRev, of the main function from the class Main in the module main.py, and calls its main() method with specific arguments: dirpath set to \"./samples/video/\", dummy_auto as False, args as autoArgs, template_names not mentioned, and semiauto as False. The main() method is then executed.",
        "type": "comment"
    },
    "1732": {
        "file_id": 161,
        "content": "/tests/test_auto_local_producer.py",
        "type": "filepath"
    },
    "1733": {
        "file_id": 161,
        "content": "The code imports modules, sets environment variables, and installs local producers for OCR testing. It creates video processing configurations with completeTest() and partialMedialangRenderTest(). It handles temporary directories, cleans them, and prints save paths for debugging.",
        "type": "summary"
    },
    "1734": {
        "file_id": 161,
        "content": "import os\nos.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/lib\"\nfrom test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\n# let's hack the gl!\n# os.environ[\"DISPLAY\"] = \":1\"\n# os.environ[\"XAUTHORITY\"] = \"/root/.Xauthority\"\n# undefined symbol? wtf? how about use xvfb-run directly?\nautoArgs = {\n    \"subtitle_detector\": {\"timestep\": 0.2}\n}  # what is this? should't you detect all before production?\n# autoArgs = {\"subtitle_detector\": {\"timestep\": 0.2},\"yolov5_detector\":{\"model\":\"yolov5x\"}}\ntemplate_names = [\"subtitle_detector.mdl.j2\"]  # test ocr entities first.\n# template_names = [\"yolov5_detector.mdl.j2\"]\n# template_names = [\"framediff_detector.mdl.j2\"]\n# seems cudnn is causing trouble?\n# CuDNN Version 降到7.6试试，这个问题是环境问题引起的\n# https://pypi.tuna.tsinghua.edu.cn/packages/a4/1f/56dddeb4794137e3f824476ead29806d60a5d5fc20adba9f4d7ca5899900/paddlepaddle_gpu-2.2.2-cp39-cp39-manylinux1_x86_64.whl\n# from pip._internal.cli.main\n# we have modified the pip downloader.\nwbRev = FilesystemAutoContentProducer(",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:1-27"
    },
    "1735": {
        "file_id": 161,
        "content": "This code is importing necessary modules and setting environment variables for a specific purpose. It seems to be testing OCR entities first by using a subtitle detector and possibly other detectors later. The comment mentions potential issues with CUDA libraries and suggests downgrading the CuDNN version to resolve them. Additionally, it notes that the pip downloader has been modified.",
        "type": "comment"
    },
    "1736": {
        "file_id": 161,
        "content": "    dirpath=\"./samples/video/\",\n    reviewerLogs=[\n        \"/root/Desktop/works/pyjom/logs/local/1648576077_705094.log\",  # this is the paddleocr result.\n        \"/root/Desktop/works/pyjom/logs/local/1652502047_091761.json\",  # yolov5\n        \"/root/Desktop/works/pyjom/logs/local/1652856912_480332.json\",  # framedifference_talib\n    ],\n    producer_filters={\n        \"yolov5\": {\"objects\": [\"dog\", \"cat\"], \"min_time\": 2},\n        \"meta\": {\n            \"type\": \"video\",\n            \"timelimit\": {\n                \"min\": 1,\n            },\n        },\n    },\n    path_replacers=[\n        [\n            [\n                \"/media/root/help/pyjom/samples/\",\n                \"/media/root/parrot/pyjom/samples/\",\n                \"/media/root/parrot1/pyjom/samples/\",  # new location of sample media files.\n                \"/root/Desktop/works/pyjom/src/samples/\",\n                \"/media/root/help1/pyjom/samples/\",\n            ],\n            \"/root/Desktop/works/pyjom/samples/\",\n        ]\n    ],\n    template=\"pets_with_music\",\n    template_config={",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:28-56"
    },
    "1737": {
        "file_id": 161,
        "content": "This code sets up a local producer for video files, specifying the directory path, reviewer logs to be considered, and filters based on objects detected and minimum time. It also includes path replacers for sample media file locations and defines a template for the output.",
        "type": "comment"
    },
    "1738": {
        "file_id": 161,
        "content": "        \"music\": {\n            \"filepath\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\",  # these things were not right.\n            \"lyric_path\": \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.lrc\",\n        },\n        \"font\": \"/root/.local/share/fonts/simhei.ttf\",\n        # \"font\": \"/root/.local/share/fonts/simyou.ttf\", # 幼圆可能打不出来\n        \"policy\": {},\n        \"maxtime\": 4,\n        \"mintime\": 2,\n        \"fast\": True,  # pass this flag to medialang export engine\n    },\n    processor_filters={\n        \"yolov5\": [\"dog\", \"cat\"],\n        \"labels\": [\"dog\", \"cat\"],\n        \"framedifference_talib_detector\": 30,\n        \"ensure\": [\"yolov5\"],\n    }\n    # you can also translate funny videos from youtube.\n    # dummy_auto=False,\n    # args=autoArgs,\n    # semiauto=False # i do not want to comment shit.\n)\ndef completeTest():\n    wbRev.main()\ndef partialMedialangRenderTest(medialangScript, verbose=True):\n    # copy that script to my dear clipboard please?\n    medialangObject = Medialang(script=medialangScript, verbose=verbose)",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:57-87"
    },
    "1739": {
        "file_id": 161,
        "content": "Code is creating a configuration for video processing, specifying file paths, fonts, policy, time parameters, and processor filters. It also mentions that you can translate funny videos from YouTube and includes functions completeTest() and partialMedialangRenderTest().",
        "type": "comment"
    },
    "1740": {
        "file_id": 161,
        "content": "    result = medialangObject.execute()\n    return result\ndef PMRT_0(scriptFilePath=\"\", verbose=True):\n    with open(scriptFilePath, \"r\") as f:\n        medialangScript = f.read()\n    return partialMedialangRenderTest(medialangScript, verbose=verbose)\nfrom contextlib import AbstractContextManager\nclass tmpdir(AbstractContextManager):\n    \"\"\"Context manager to suppress specified exceptions\n    After the exception is suppressed, execution proceeds with the next\n    statement following the with statement.\n         with suppress(FileNotFoundError):\n             os.remove(somefile)\n         # Execution still resumes here if the file was already removed\n    \"\"\"\n    def __init__(self, path=None):\n        assert os.path.isabs(path)\n        self._tmpdir = path\n    def __enter__(self):\n        print(\"temporary directory: %s\" % self._tmpdir)\n        if os.path.exists(self._tmpdir):\n            shutil.rmtree(self._tmpdir)\n        os.makedirs(self._tmpdir)\n        return self._tmpdir\n    def __exit__(self, exctype, excinst, exctb):",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:88-123"
    },
    "1741": {
        "file_id": 161,
        "content": "The code defines a context manager class `tmpdir` that creates and manages temporary directories. It also includes a function `PMRT_0` which takes a script file path and verbose flag as input, reads the script content, and returns the result of partialMedialangRenderTest function. The main function is `execute()` which executes the code within the context manager and returns the result.",
        "type": "comment"
    },
    "1742": {
        "file_id": 161,
        "content": "        # try not to handle exceptions?\n        tempdir = self._tmpdir\n        print(\"cleaning tempdir: %s\" % tempdir)\n        shutil.rmtree(tempdir)\n        return False\nif __name__ == \"__main__\":\n    COMPLETE_TEST = False\n    if COMPLETE_TEST:\n        completeTest()\n    # so we don't have to run it all the time. really?\n    else:\n        scriptFilePath = \"/root/Desktop/works/pyjom/tests/medialang_tests/aef2ab90-6414-4b55-a40e-63014e5648a8.mdl\"  # add random flips, picture enhancement, super resolution and minterpolate\n        # a special hack\n        # import tempfile\n        with tmpdir(path=\"/dev/shm/medialang\") as medialangTmpDir:\n            print(\"MEDIALANG SUPER TMPDIR:\", medialangTmpDir)\n            result = PMRT_0(scriptFilePath, verbose=False)\n            editly_outputPath, medialang_item_list = result  # this just return none!\n            # data -> editly json\n            # this output path is modified. we shall change this.\n            outPath = editly_outputPath  # WE SHALL MUTE IT!\n            # print(editly_json.keys())",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:124-147"
    },
    "1743": {
        "file_id": 161,
        "content": "The code is attempting to clean a temporary directory, but it's trying not to handle exceptions. It then checks if a variable COMPLETE_TEST is True or False and executes the corresponding code block. The script path is specified, and a special hack using tmpdir is used within a with statement to create a medialangTmpDir. The code prints the medialangTmpDir and calls the PMRT_0 function with the scriptFilePath and verbose=False. It stores editly_outputPath and medialang_item_list in variables result, modifies outPath, and ends.",
        "type": "comment"
    },
    "1744": {
        "file_id": 161,
        "content": "            print(\"MEDIA SAVE PATH (MAYBE YOU CAN PLAY IT?):\", outPath)\n            # where is the damn save path???\n            breakpoint()  # HERE IS THE DAMN BREAKPOINT\n            # import json\n            # data_array -> input of dot processor? check it out.\n            # breakpoint() # what is this?",
        "type": "code",
        "location": "/tests/test_auto_local_producer.py:149-154"
    },
    "1745": {
        "file_id": 161,
        "content": "The code is trying to display the save path and then using a breakpoint for debugging purposes. The comments are pointing out the location of the save path and mentioning that a breakpoint has been set for debugging.",
        "type": "comment"
    },
    "1746": {
        "file_id": 162,
        "content": "/tests/test_auto_local_producer.sh",
        "type": "filepath"
    },
    "1747": {
        "file_id": 162,
        "content": "Running a Python test script for local producer with custom LD_LIBRARY_PATH environment variable.",
        "type": "summary"
    },
    "1748": {
        "file_id": 162,
        "content": "env LD_LIBRARY_PATH=/usr/local/lib python3 test_auto_local_producer.py ",
        "type": "code",
        "location": "/tests/test_auto_local_producer.sh:1-1"
    },
    "1749": {
        "file_id": 162,
        "content": "Running a Python test script for local producer with custom LD_LIBRARY_PATH environment variable.",
        "type": "comment"
    },
    "1750": {
        "file_id": 163,
        "content": "/tests/test_manual_censor.py",
        "type": "filepath"
    },
    "1751": {
        "file_id": 163,
        "content": "The code imports necessary functions from test_commons and contentCensoring, initiates a test sequence by calling censorInterface with input data for title, content and prints collected data.",
        "type": "summary"
    },
    "1752": {
        "file_id": 163,
        "content": "from test_commons import *\nfrom contentCensoring import *\nprint(\"initiating test sequence...\")\nmdata = censorInterface(\n    \"test_title\",\n    None,\n    \"test_content\",\n)\nprint(\"interface closed.\")\nprint(\"collected data:\", mdata)",
        "type": "code",
        "location": "/tests/test_manual_censor.py:1-11"
    },
    "1753": {
        "file_id": 163,
        "content": "The code imports necessary functions from test_commons and contentCensoring, initiates a test sequence by calling censorInterface with input data for title, content and prints collected data.",
        "type": "comment"
    },
    "1754": {
        "file_id": 164,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.sh",
        "type": "filepath"
    },
    "1755": {
        "file_id": 164,
        "content": "This code sets up an environment and runs tests for a video producer script. It first kills the existing test session, loads a configuration file, and then checks the media language render result. The Python script is used to perform full testing, and there's mention of potentially improving time duration using Gaussian.",
        "type": "summary"
    },
    "1756": {
        "file_id": 164,
        "content": "# env LD_LIBRARY_PATH=/usr/local/lib python3 test_auto_dog_video_giphy_online_producer.py \n#### PHASE 1 ####\n# FULL TEST\nulimit -n 1048576 # to avoid NOF issues.\ntmux kill-session -t online_dog_cat_generator_test && echo \"killed session: online_dog_cat_generator_test\"\ntmuxp load test_auto_dog_video_giphy_online_producer.yaml\n#### PHASE 2 ####\n# check medialang render result.\n# python3 test_auto_dog_video_giphy_online_producer.py -p\n# seems all good. but the time duration is not so good. maybe gaussian will help? set breakpoint after main list is created.",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.sh:1-12"
    },
    "1757": {
        "file_id": 164,
        "content": "This code sets up an environment and runs tests for a video producer script. It first kills the existing test session, loads a configuration file, and then checks the media language render result. The Python script is used to perform full testing, and there's mention of potentially improving time duration using Gaussian.",
        "type": "comment"
    },
    "1758": {
        "file_id": 165,
        "content": "/tests/test_commons.py",
        "type": "filepath"
    },
    "1759": {
        "file_id": 165,
        "content": "The code changes the current working directory, adds the current directory to Python's module search path, and removes the proxy environment variables to ignore global proxies during testing.",
        "type": "summary"
    },
    "1760": {
        "file_id": 165,
        "content": "import sys\nimport os\nos.chdir(\"../\")\nsys.path.append(\".\")\n# ignore the global proxy now, we are not going to use that.\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"",
        "type": "code",
        "location": "/tests/test_commons.py:1-8"
    },
    "1761": {
        "file_id": 165,
        "content": "The code changes the current working directory, adds the current directory to Python's module search path, and removes the proxy environment variables to ignore global proxies during testing.",
        "type": "comment"
    },
    "1762": {
        "file_id": 166,
        "content": "/tests/unittest_caer_fps_kitty_9.5.py",
        "type": "filepath"
    },
    "1763": {
        "file_id": 166,
        "content": "The code imports necessary modules, finds the correct OpenCV library file, adds its parent directory to the system path, and retrieves the frame rate of a video file using the caer.video module. The FPS value is then printed.",
        "type": "summary"
    },
    "1764": {
        "file_id": 166,
        "content": "src = \"/root/Desktop/works/pyjom/samples/video/kitty_flash.gif\"\nimport pathlib, sys  # great.\nsite_path = pathlib.Path(\"/usr/local/lib/python3.9/site-packages\")\ncv2_libs_dir = (\n    site_path / \"cv2\" / f\"python-{sys.version_info.major}.{sys.version_info.minor}\"\n)\nprint(cv2_libs_dir)\ncv2_libs = sorted(cv2_libs_dir.glob(\"*.so\"))\nif len(cv2_libs) == 1:\n    print(\"INSERTING:\", cv2_libs[0].parent)\n    sys.path.insert(1, str(cv2_libs[0].parent))\nfrom caer.video.frames_and_fps import get_fps_float\nfps = get_fps_float(src)\nprint(\"FPS:\", fps)  # 10? was very inaccurate for me\n# now it is good. 9.5",
        "type": "code",
        "location": "/tests/unittest_caer_fps_kitty_9.5.py:1-19"
    },
    "1765": {
        "file_id": 166,
        "content": "The code imports necessary modules, finds the correct OpenCV library file, adds its parent directory to the system path, and retrieves the frame rate of a video file using the caer.video module. The FPS value is then printed.",
        "type": "comment"
    },
    "1766": {
        "file_id": 167,
        "content": "/tests/unittest_ffmpeg_cropdetect_from_image_parse_log.py",
        "type": "filepath"
    },
    "1767": {
        "file_id": 167,
        "content": "This code uses ffmpeg and OpenCV to detect cropped areas, calculates the cropped area ratio, and decides whether to crop the image based on a threshold. The result depends on the specified threshold value.",
        "type": "summary"
    },
    "1768": {
        "file_id": 167,
        "content": "import ffmpeg\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\n# mediaPath = \"/root/Desktop/works/pyjom/samples/image/dog_blue_sky_split_line.png\"\nmediaPath = \"/root/Desktop/works/pyjom/samples/image/dog_with_black_borders.png\"  # use the image with black background.\n# ffmpeg -loop 1 -i /root/Desktop/works/pyjom/samples/image/dog_blue_sky_split_line.png -t 15 -vf cropdetect -f null -\nimport cv2\nimage = cv2.imread(mediaPath)\nheight, width = image.shape[:2]\ntotal_area = height * width\nareaThreshold = 0\nstdout, stderr = (\n    ffmpeg.input(mediaPath, loop=1, t=15)\n    .filter(\"cropdetect\")\n    .output(\"null\", f=\"null\")\n    .run(capture_stdout=True, capture_stderr=True)\n)\nstdout_decoded = stdout.decode(\"utf-8\")\nstderr_decoded = stderr.decode(\"utf-8\")\n# nothing here.\n# for line in stdout_decoded.split(\"\\n\"):\n#     print(line)\n# breakpoint()\nimport parse\ncropped_area_threshold = 0.1\ncommon_crops = []\nfor line in stderr_decoded.split(\"\\n\"):\n    line = line.replace(\"\\n\", \"\").strip()\n    for",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_cropdetect_from_image_parse_log.py:1-40"
    },
    "1769": {
        "file_id": 167,
        "content": "The code imports necessary libraries and initializes them, sets the media path to an image with a black background, runs ffmpeg on the image with a cropdetect filter, decodes the output and errors, iterates over the stderr output lines to extract cropped areas, and defines a variable for common_crops.",
        "type": "comment"
    },
    "1770": {
        "file_id": 167,
        "content": "matString = \"[{}] x1:{x1:d} x2:{x2:d} y1:{y1:d} y2:{y2:d} w:{w:d} h:{h:d} x:{x:d} y:{y:d} pts:{pts:g} t:{t:g} crop={}:{}:{}:{}\"\n    # print(line)\n    result = parse.parse(formatString, line)\n    if result is not None:\n        # print(result)\n        cropString = \"{}_{}_{}_{}\".format(\n            *[result[key] for key in [\"w\", \"h\", \"x\", \"y\"]]\n        )\n        # print(cropString)\n        # breakpoint()\n        common_crops.append(cropString)\n    # [Parsed_cropdetect_0 @ 0x56246a16cbc0] x1:360 x2:823 y1:0 y2:657 w:464 h:656 x:360 y:2 pts:3 t:0.120000 crop=464:656:360:2\n    # this crop usually will never change. but let's count?\narea = 0\nx, x1, y, y1 = 0, width, 0, height\nif len(common_crops) > 0:\n    common_crops_count_tuple_list = [\n        (cropString, common_crops.count(cropString)) for cropString in set(common_crops)\n    ]\n    common_crops_count_tuple_list.sort(key=lambda x: -x[1])\n    selected_crop_string = common_crops_count_tuple_list[0][0]\n    result = parse.parse(\"{w:d}_{h:d}_{x:d}_{y:d}\", selected_crop_string)",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_cropdetect_from_image_parse_log.py:40-62"
    },
    "1771": {
        "file_id": 167,
        "content": "Code parses a log line, extracts crop information and stores it in common_crops list. It then counts the occurrence of each unique crop string and selects the most frequent one (selected_crop_string). Finally, it parses the selected_crop_string to get the crop dimensions (w, h, x, y) and assigns them to their respective variables.",
        "type": "comment"
    },
    "1772": {
        "file_id": 167,
        "content": "    w, h, x, y = [result[key] for key in [\"w\", \"h\", \"x\", \"y\"]]\n    x1, y1 = min(x + w, width), min(y + h, height)\n    if x < x1 and y < y1:\n        # allow to calculate the area.\n        area = (x1 - x) * (y1 - y)\ncropped_area_ratio = 1 - (area / total_area)  # 0.5652352766414517\n# use 0.1 as threshold?\nprint(\"CROPPED AREA RATIO:\", cropped_area_ratio)\nif cropped_area_ratio > cropped_area_threshold:\n    print(\"we need to crop this. no further processing needed\")\n    image_black_cropped = image[y:y1, x:x1]\n    cv2.imshow(\"CROPPED IMAGE\", image_black_cropped)\n    cv2.waitKey(0)\nelse:\n    print(\"image no need to crop black borders. further processing needed\")",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_cropdetect_from_image_parse_log.py:63-78"
    },
    "1773": {
        "file_id": 167,
        "content": "This code calculates the cropped area ratio of an image and decides whether to crop it or not based on a threshold. If the ratio is greater than the threshold, it crops the image using OpenCV and displays the cropped image. Otherwise, it proceeds with further processing. The result depends on the specified threshold value.",
        "type": "comment"
    },
    "1774": {
        "file_id": 168,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.yaml",
        "type": "filepath"
    },
    "1775": {
        "file_id": 168,
        "content": "This code configures a testing session for the \"online_dog_cat_generator_test\" in Tmux, with two panes. In the first pane, it runs the test script \"test_auto_dog_video_giphy_online_producer.py\". In the second pane, it starts the Uvicorn server for the \"lazzo.network.progressbar.server\" application on port 8576 with critical log level.",
        "type": "summary"
    },
    "1776": {
        "file_id": 168,
        "content": "session_name: online_dog_cat_generator_test\nstart_directory: /root/Desktop/works/pyjom/tests\nwindows:\n- layout: main-horizontal\n  options:\n    main-pane-height: 30\n  panes:\n  - shell_command:\n    - python3 test_auto_dog_video_giphy_online_producer.py\n  - shell_command:\n    # - python3 -m uvicorn --port 8576 lazero.network.progressbar.server:app\n    - python3 -m uvicorn --port 8576 --log-level critical lazero.network.progressbar.server:app\n  window_name: progressbar window",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.yaml:1-13"
    },
    "1777": {
        "file_id": 168,
        "content": "This code configures a testing session for the \"online_dog_cat_generator_test\" in Tmux, with two panes. In the first pane, it runs the test script \"test_auto_dog_video_giphy_online_producer.py\". In the second pane, it starts the Uvicorn server for the \"lazzo.network.progressbar.server\" application on port 8576 with critical log level.",
        "type": "comment"
    },
    "1778": {
        "file_id": 169,
        "content": "/tests/unittest_ffmpeg_args.py",
        "type": "filepath"
    },
    "1779": {
        "file_id": 169,
        "content": "The code processes video files using FFmpeg for tasks like cropping and scaling, with a specific command to map and filter video/audio streams. This is part of a larger script that uses the subprocess module.",
        "type": "summary"
    },
    "1780": {
        "file_id": 169,
        "content": "command_original = [\n    \"ffmpeg\",\n    \"-y\",\n    \"-ss\",\n    \"0\",\n    \"-to\",\n    \"59.3942553191489\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-ss\",\n    \"59.3942553191489\",\n    \"-to\",\n    \"62.0340000000000\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-ss\",\n    \"0\",\n    \"-to\",\n    \"62.034\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-filter_complex\",\n    \"[0:v]crop=h=1099:w=717:x=1:y=72[s0];[s0]pad=color=black:height=max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw))):width=max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih))):x=floor((max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih)))-iw)/2):y=floor((max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw)))-ih)/2)[s1];[s1]scale=1920:1080[s2];[s2]scale=ceil((iw*0.15555555555555556)/4)*4:ceil((ih*0.15555555555555556)/4)*4[s3];[1:v]pad=color=black:height=max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw))):width=max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih))):x=floor((max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih)))-iw",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_args.py:1-23"
    },
    "1781": {
        "file_id": 169,
        "content": "This code uses FFmpeg to split a video file into segments, applies various filters and transformations to the segments, and finally scales and pads them before saving the final output.",
        "type": "comment"
    },
    "1782": {
        "file_id": 169,
        "content": ")/2):y=floor((max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw)))-ih)/2)[s4];[s4]scale=1920:1080[s5];[s5]scale=ceil((iw*0.15555555555555556)/4)*4:ceil((ih*0.15555555555555556)/4)*4[s6];[s3][s6]concat=n=2[s7]\",\n    \"-map\",\n    \"[s7]\",\n    \"-map\",\n    \"2:a\",\n    \"/dev/shm/2c6b1466-6186-41dd-9ce3-2f757c082c5a.mp4\",\n]\ncommand2 = [\n    \"ffmpeg\",\n    \"-y\",\n    \"-ss\",\n    \"0\",\n    \"-to\",\n    \"59.3942553191489\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-ss\",\n    \"0\",\n    \"-to\",\n    \"62.034\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-filter_complex\",\n    \"[0:v]crop=h=1099:w=717:x=1:y=72[s0];[s0]pad=color=black:height=max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw))):width=max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih))):x=floor((max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih)))-iw)/2):y=floor((max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw)))-ih)/2)[s1];[s1]scale=1920:1080[s2];[s2]scale=ceil((iw*0.15555555555555556)/4)*4:ceil((ih*0.15555555555555556)/4)*4[s3]\",\n    \"-map\",\n    \"[s3]\",",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_args.py:23-48"
    },
    "1783": {
        "file_id": 169,
        "content": "The code is constructing a command for the ffmpeg tool to process and concatenate multiple video inputs. It applies filters such as cropping, padding, scaling, and extracts specific parts of videos before concatenating them into a single output video file. The resulting command is being stored in `command1` and `command2`.",
        "type": "comment"
    },
    "1784": {
        "file_id": 169,
        "content": "    \"-map\",\n    \"1:a\",\n    \"/dev/shm/2c6b1466-6186-41dd-9ce3-2f757c082c5a.mp4\",\n]\ncommand3 = [\n    \"ffmpeg\",\n    \"-y\",\n    \"-ss\",\n    \"59.3942553191489\",\n    \"-to\",\n    \"62.0340000000000\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-ss\",\n    \"0\",\n    \"-to\",\n    \"62.034\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-filter_complex\",\n    \"[0:v]pad=color=black:height=max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw))):width=max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih))):x=floor((max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih)))-iw)/2):y=floor((max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw)))-ih)/2)[s4];[s4]scale=1920:1080[s5];[s5]scale=ceil((iw*0.15555555555555556)/4)*4:ceil((ih*0.15555555555555556)/4)*4[s6]\",\n    \"-map\",\n    \"[s6]\",\n    \"-map\",\n    \"1:a\",\n    \"/dev/shm/2c6b1466-6186-41dd-9ce3-2f757c082c5a.mp4\",\n]\ncommandImprovised = command_original = [\n    \"ffmpeg\",\n    \"-y\",\n    \"-ss\",\n    \"0\",\n    \"-to\",\n    \"59.3942553191489\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_args.py:49-84"
    },
    "1785": {
        "file_id": 169,
        "content": "This code is using FFmpeg command line arguments to perform operations on video files. It's mapping streams, applying filters for scaling and padding, setting start/end times, and specifying output file paths. The code is likely involved in video processing or manipulation tasks.",
        "type": "comment"
    },
    "1786": {
        "file_id": 169,
        "content": "    \"-ss\",\n    \"59.3942553191489\",\n    \"-to\",\n    \"62.0340000000000\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-ss\",\n    \"0\",\n    \"-to\",\n    \"62.034\",\n    \"-i\",\n    \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\",\n    \"-filter_complex\",\n    \"[0:v]crop=h=1099:w=717:x=1:y=72[s0];[s0]pad=color=black:height=max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw))):width=max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih))):x=floor((max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih)))-iw)/2):y=floor((max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw)))-ih)/2)[s1];[s1]scale=1920:1080[s2];[s2]scale=ceil((iw*0.15555555555555556)/4)*4:ceil((ih*0.15555555555555556)/4)*4,setsar=1[s3];[1:v]pad=color=black:height=max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw))):width=max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih))):x=floor((max(iw\\\\, ceil(ih*max(1920/1080\\\\, iw/ih)))-iw)/2):y=floor((max(ih\\\\, ceil(iw*max(1080/1920\\\\, ih/iw)))-ih)/2)[s4];[s4]scale=1920:1080[s5];[s5]scale=ceil((iw*0.15555555555555556)/4)*4:ceil((ih*0.15555555555555556)/4)*4,setsar=1[s6];[s3][s6]concat=n=2[s7]\",",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_args.py:85-98"
    },
    "1787": {
        "file_id": 169,
        "content": "This code is using FFmpeg to crop, scale, and concatenate video streams. It first specifies start and end times for the input video file \"/root/Desktop/works/pyjom/samples/video/LiGlReJ4i.mp4\", then applies a series of filters including cropping, padding, scaling, and setting aspect ratio. Finally, it concatenates the resulting streams for output.",
        "type": "comment"
    },
    "1788": {
        "file_id": 169,
        "content": "    \"-map\",\n    \"[s7]\",\n    \"-map\",\n    \"2:a\",\n    \"/dev/shm/2c6b1466-6186-41dd-9ce3-2f757c082c5a.mp4\",\n]\nimport subprocess\nsubprocess.run(commandImprovised)",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_args.py:99-107"
    },
    "1789": {
        "file_id": 169,
        "content": "This code chunk is part of a larger script that uses the subprocess module to run an FFmpeg command. The command maps video stream from input file \"[s7]\" and audio stream from track 2 to output \"/dev/shm/2c6b1466-6186-41dd-9ce3-2f757c082c5a.mp4\".",
        "type": "comment"
    },
    "1790": {
        "file_id": 170,
        "content": "/tests/unittest_bilibili_recommendation_server.py",
        "type": "filepath"
    },
    "1791": {
        "file_id": 170,
        "content": "This code imports requests, sets up a base URL for the bilibili recommendation server and waits for it to be up. It defines objectives such as searching registered videos or user videos and creates parameters using dictionaries. After setting specific values, it sends POST requests with JSON format data and prints the objective and response text.",
        "type": "summary"
    },
    "1792": {
        "file_id": 170,
        "content": "import requests\nport = 7341\nbaseurl = \"http://localhost:{}\".format(port)\nfrom lazero.network.checker import waitForServerUp\nmessage = \"bilibili recommendation server\"\nwaitForServerUp(port, message=message)\n# objective = \"searchRegisteredVideos\"\n# objective = \"searchVideos\"\nobjective = \"searchUserVideos\"\n# objective = \"registerUserVideo\"\nif objective == \"searchVideos\":\n    params = {\n        # \"params\": {\"hop\": 1}, # there is no such parameter here.\n        # can we pass shit without params?\n        \"params\": ...,\n        \"query\": \"hello world\",\n        \"iterate\": False,  # not all pages, you dumb fool!\n        \"page_num\": 1,\n    }  # check if this works?\nelif objective == \"searchRegisteredVideos\":\n    # params = dict(query='hello world') # does not remove ellipsis?\n    params = dict(\n        query=\"hello world\", tid=..., dedeuserid=..., videoOrder=..., page_num=2\n    )  # does not remove ellipsis?\n    # print(j)\n    # exit()\nelif objective == \"searchUserVideos\":\n    # it is good.\n    # params = dict(query=\"猫\", method=\"bm25\", videoOrder=\"click\")",
        "type": "code",
        "location": "/tests/unittest_bilibili_recommendation_server.py:1-33"
    },
    "1793": {
        "file_id": 170,
        "content": "The code imports the requests library, sets up a base URL for the bilibili recommendation server, uses the waitForServerUp function to ensure the server is running before executing further commands. It defines different objectives such as searching registered videos, searching videos, and searching user videos. Depending on the objective, it creates a dictionary of parameters (including query, page_num, etc.) to pass to the server API.",
        "type": "comment"
    },
    "1794": {
        "file_id": 170,
        "content": "    params = dict(query=\"猫\", method=\"bm25\")\n    # params = dict(query='猫',method='bm25', dedeuserid=None)\nelif objective == \"registerUserVideo\":\n    params = dict(\n        bvid=\"BV1MN4y1P7mq\", dedeuserid=\"397424026\", is_mine=True, visible=False\n    )\nelse:\n    raise Exception(\"invalid objective: %s\" % objective)\nfrom lazero.utils.json import jsonify\nparams = jsonify(params)\nr = requests.post(baseurl + \"/\" + objective, json=params)\nprint(\"objective: %s\" % objective)\nprint(\"response:\", r.text)\nbreakpoint()",
        "type": "code",
        "location": "/tests/unittest_bilibili_recommendation_server.py:34-50"
    },
    "1795": {
        "file_id": 170,
        "content": "This code is setting parameters for a function depending on the objective. It uses dictionary to store query, method, dedeuserid and other information. If 'registerUserVideo' is the objective, it sets specific values. The code converts params to json format and sends a POST request to the server with the base URL and objective as parameters. The code also prints the objective and response text.",
        "type": "comment"
    },
    "1796": {
        "file_id": 171,
        "content": "/tests/test_auto_dog_video_giphy_online_producer.py",
        "type": "filepath"
    },
    "1797": {
        "file_id": 171,
        "content": "The code patches the \"requests\" library for Bilibili postMetadata, enables debugging, and includes paraphraser function. It also features video recommendation testing, metadata handling, data preprocessing from database, music API, generating subtitles with Giphy's video producer, all tested by OnlineAutoContentProducer. The code defines `partialMedialangRenderTest` function within `PMRT_0`, creating a temporary directory, setting parameters for tests, and returning output path.",
        "type": "summary"
    },
    "1798": {
        "file_id": 171,
        "content": "# changed numpy==1.23.0 to fix compatibility issues.\n# ld_library_path is handled externally using env\n# https://adamj.eu/tech/2022/06/23/how-to-patch-requests-to-have-a-default-timeout/\nREQUESTS_TIMEOUT=30 # monkey patch all requests related things?\nimport patchy\nfrom requests.adapters import HTTPAdapter\n# [DONE] clear milvus image cache database per metadata iteration\ndef patch_requests_default_timeout() -> None:\n    \"\"\"\n    Set a default timeout for all requests made with “requests”.\n    Upstream is waiting on this longstanding issue:\n    https://github.com/psf/requests/issues/3070\n    \"\"\"\n    patchy.patch(\n        HTTPAdapter.send,\n        \"\"\"\\\n        @@ -14,6 +14,8 @@\n             :param proxies: (optional) The proxies dictionary to apply to the request.\n             :rtype: requests.Response\n             \\\"\"\"\n        +    if timeout is None:\n        +        timeout = 5.0\n             try:\n                 conn = self.get_connection(request.url, proxies)\n        \"\"\",\n    )\n# import socket\n# SOCKET_TIMEOUT=60",
        "type": "code",
        "location": "/tests/test_auto_dog_video_giphy_online_producer.py:1-37"
    },
    "1799": {
        "file_id": 171,
        "content": "This code patches the \"requests\" library to set a default timeout for all requests made with it. This is done using the \"patchy\" module, and the patch is applied to the \"HTTPAdapter.send\" method. If no timeout is specified, the default timeout will be 5.0 seconds.",
        "type": "comment"
    }
}