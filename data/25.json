{
    "2500": {
        "file_id": 270,
        "content": "ps aux | grep '[Kamigami&VCB-Studio] Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' | grep -v grep | awk '{print $1}' | xargs -Iabc kill -s INT abc",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/kill_aria2c.sh:1-1"
    },
    "2501": {
        "file_id": 270,
        "content": "This command is killing the aria2c process with a SIGINT signal, specifically targeting the specified anime episode titled 'Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' from the Kamigami & VCB-Studio group.",
        "type": "comment"
    },
    "2502": {
        "file_id": 271,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/dynamic_import.mjs",
        "type": "filepath"
    },
    "2503": {
        "file_id": 271,
        "content": "Code imports and initializes two modules, FfmpegCommand and WebTorrent, using dynamic import. The code checks the data types of the imported functions, with FfmpegCommand being a function and WebTorrent appearing as a class in the console despite its data type being \"function\".",
        "type": "summary"
    },
    "2504": {
        "file_id": 271,
        "content": "const FfmpegCommand = (await import(`${process.env.NODE_PATH}/fluent-ffmpeg/index.js`)).default \nconst WebTorrent = (await import(`${process.env.NODE_PATH}/webtorrent/index.js`)).default \n// promise!\n// shit this ESM can directly use await statements.\nconsole.log(FfmpegCommand)\nconsole.log(typeof(FfmpegCommand)) // \"function\", with default name.\nconsole.log(WebTorrent)\nconsole.log(typeof(WebTorrent)) // \"function\"? why i see \"class\" in console.log?\n// this syntax is not recommended. autocompletion will not work.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/dynamic_import.mjs:1-12"
    },
    "2505": {
        "file_id": 271,
        "content": "Code imports and initializes two modules, FfmpegCommand and WebTorrent, using dynamic import. The code checks the data types of the imported functions, with FfmpegCommand being a function and WebTorrent appearing as a class in the console despite its data type being \"function\".",
        "type": "comment"
    },
    "2506": {
        "file_id": 272,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/download_given_file_to_given_name.sh",
        "type": "filepath"
    },
    "2507": {
        "file_id": 272,
        "content": "This script downloads a torrent file using aria2c and removes temporary files once finished. The script sets the base path, torrent name, and file ID for the download. It also includes two different command variations for stopping the download after completion with timeout options. The commands use kill and grep to end the aria2c process with a signal and remove temporary files.",
        "type": "summary"
    },
    "2508": {
        "file_id": 272,
        "content": "# how to end downloading when finished?\n# using some command?\nBASE_PATH=\"/Users/jamesbrown/Downloads/anime_download\"\n# DOWNLOAD_FILE_PATH=\"$BASE_PATH/sample.webp\"\nTORRENT_NAME=\"[Kamigami&VCB-Studio] Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]\"\n# torrent name might be different.\nTORRENT_PATH=\"$BASE_PATH/$TORRENT_NAME.torrent\"\n# echo \"ps aux | grep '$TORRENT_NAME' | grep -v grep | awk '{print \\$1}' | xargs -Iabc kill -s INT abc\" > kill_aria2c.sh\nFILE_ID=\"117\"\n# timeout set to what?\n# rm \"$DOWNLOAD_FILE_PATH\"\nrm -rf \"$TORRENT_NAME\"\nrm -rf \"$TORRENT_NAME.aria2\"\n# this will be ignored.\n# change directory to our temp directory.\n# this speed shall be precalculated.\n# \n# you may check integrity.\n# just count seeders.\n# aria2c -x 16 --select-file=\"$FILE_ID\" --seed-time=0 --file-allocation=none \"$TORRENT_PATH\"\n# aria2c -x 16 --select-file=\"$FILE_ID\" --seed-time=0 --file-allocation=none --lowest-speed-limit=300K --bt-stop-timeout=60 \"$TORRENT_PATH\"",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/download_given_file_to_given_name.sh:1-27"
    },
    "2509": {
        "file_id": 272,
        "content": "This script downloads a torrent file using aria2c and removes temporary files once finished. The script sets the base path, torrent name, and file ID for the download. It also includes two different command variations for stopping the download after completion with timeout options. The commands use kill and grep to end the aria2c process with a signal and remove temporary files.",
        "type": "comment"
    },
    "2510": {
        "file_id": 273,
        "content": "/tests/anime_highlight_cuts/theme_collector/anidb_search_parse.py",
        "type": "filepath"
    },
    "2511": {
        "file_id": 273,
        "content": "This code searches AniDB for anime using a specified query and fake user agent, extracting title and link from the resulting HTML table. It then uses pandas to convert the table data into a DataFrame, retrieves video data as dictionaries, and prints keys of each dictionary.",
        "type": "summary"
    },
    "2512": {
        "file_id": 273,
        "content": "url = \"https://anidb.net/anime/\"\n# query = \"Yahari Ore no Seishun Lovecome wa Machigatte Iru.\"\nquery = \"Yahari Ore no Seishun Love Come wa Machigatteiru.\"  # this will guide you to something different.\nparams = {\"adb.search\": query, \"do.update\": \"Search\", \"noalias\": 1}\nimport pandas\nimport requests\nimport fake_useragent\nua = fake_useragent.UserAgent()\nr = requests.get(\n    url, params=params, headers={\"User-Agent\": ua.random}\n)  # beautiful. really?\nstatus_code = r.status_code\nprint(\"STATUS CODE?\", status_code)\nassert status_code == 200\ntext = r.text\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(text, \"html.parser\")\n# print(soup) # forbidden? wtf?\n# breakpoint()\nimport pandas\n# table = soup.find('table')\ntable = soup.find(\"table\", attrs={\"class\": \"animelist\"})\nif not table:\n    print(\"table not found.\")\n    # you may want to change user agent.\n    breakpoint()\n    # or it is just a page jump. directly to your anime.\nelse:\n    table_str = str(table)\n    # ['No', 'Image', 'Title', 'Award', 'Type', 'Eps', 'Rating', 'Average', 'Reviews', 'User', 'Aired', 'Ended']",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anidb_search_parse.py:1-38"
    },
    "2513": {
        "file_id": 273,
        "content": "This code is searching for anime on AniDB using the specified query. It makes a GET request with the query and fake user agent to ensure an accurate search result. The code checks if a table containing the search results is found, and if not, it may suggest changing the user agent or the page could be a page jump directly to the anime. The code uses BeautifulSoup to parse the HTML content of the response.",
        "type": "comment"
    },
    "2514": {
        "file_id": 273,
        "content": "    # where is the damn link?\n    for title in table.find_all(\"td\", attrs={\"data-label\": \"Title\"}):\n        title_ref = table.find(\"a\")\n        title_text = title_ref.text\n        title_link = title_ref[\"href\"]\n        print(f\"[{title_link}] - {title_text}\")\n    data = pandas.read_html(table_str)[0]  # must be the first table.\n    # now you have it. sorted?\n    # print(data)\n    # breakpoint()\n    for index, videoDataFrame in data.iterrows():\n        videoData = videoDataFrame.to_dict()\n        print(videoData.keys())\n        # Main Title?\n        breakpoint()\n        # title = videoData['Title']\n        # # where's the damn link? we don't need such thing.\n        # aired, ended = videoData['Aired'], videoData['Ended']\n        # print(f'[{index}] - {title}')",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anidb_search_parse.py:39-57"
    },
    "2515": {
        "file_id": 273,
        "content": "The code is searching for a specific table on an anime website, extracting the title and link from each row. It then reads the HTML table into a pandas DataFrame, iterates over the rows to obtain the video data as a dictionary, and finally prints the keys of each video's data dictionary.",
        "type": "comment"
    },
    "2516": {
        "file_id": 274,
        "content": "/tests/anime_highlight_cuts/theme_collector/anidb_anime_parse.py",
        "type": "filepath"
    },
    "2517": {
        "file_id": 274,
        "content": "Code imports libraries and functions, uses BeautifulSoup to parse AniDB webpage for specific elements, handles potential null values with 'maybe' function, and reads data into a DataFrame using pandas.",
        "type": "summary"
    },
    "2518": {
        "file_id": 274,
        "content": "# -*- parsing: pep505 -*-\n# import pep505\n# pep505.activate()\n# shit?\nurl = \"https://anidb.net/anime/9310\"\n# from pymonad.maybe import Nothing, Just\n# https://github.com/acaos/python-pep505\nfrom pymaybe import maybe\n# def checkNothing(value):\n#     if value in [None, 0, -1, [], {}, ()]:\n#         return Nothing\n#     return Just(value)\nimport requests\nimport fake_useragent\nua = fake_useragent.UserAgent()\n# r = requests.get(url, headers={\"User-Agent\": ua.random})\n# r.raise_for_status()\n# # assert r.status_code == 200\n# text = r.text\n# with open(\"anidb_info.html\", \"w+\") as f:\n#     f.write(text)\nwith open(\"anidb_info.html\", \"r\") as f:\n    text = f.read()\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(text, \"html.parser\")\n# must be non-empty.\nsimilarAnime = soup.find(attrs={\"id\": \"similaranime\"})\nindirectRelated = soup.find(attrs={\"id\": \"relations_indirect\"})\ndirectRelated = soup.find(attrs={\"id\": \"relations_direct\"})  # it could be none.\ntables = soup.find_all(\"table\")  # shit.\n# null safety?\n# pep 505:\n# https://peps.python.org/pep-0505/",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anidb_anime_parse.py:1-43"
    },
    "2519": {
        "file_id": 274,
        "content": "The code is importing necessary libraries and functions, parsing a webpage's HTML using BeautifulSoup, and finding specific elements on the page. It appears to be scraping data from AniDB for similar or related anime information. The use of 'maybe' might indicate null safety measures are being implemented, possibly for handling potential None values in the data.",
        "type": "comment"
    },
    "2520": {
        "file_id": 274,
        "content": "# videoInfo = checkNothing(soup.find(\"div\", attrs={\"class\": [\"pane\", \"info\"]})).maybe(\n#     Nothing, lambda x: x.find(\"table\")\n# )\nvideoInfo = maybe(soup.find(\"div\", attrs={\"class\": [\"pane\", \"info\"]})).find(\"table\")\n# if videoInfo:\n# videoInfo = videoInfo.find('table')\n# videoTitles = checkNothing(soup.find(\"div\", attrs={\"class\": [\"pane\", \"titles\"]})).maybe(\n#     Nothing, lambda x: x.find(\"table\")\n# )\nvideoTitles = maybe(soup.find(\"div\", attrs={\"class\": [\"pane\", \"titles\"]})).find(\"table\")\n# if videoTitles:\n# videoTitles = videoTitles.find('table')\n# i think monad is good.\n# import pandas\n# SAData = pandas.read_html(similarAnime)\n# print(SAData)\nbreakpoint()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anidb_anime_parse.py:45-67"
    },
    "2521": {
        "file_id": 274,
        "content": "Code snippet is parsing HTML using BeautifulSoup to find specific elements (videoInfo and videoTitles) from a webpage. It uses maybe() function for handling potential missing or null values, and it imports pandas library to potentially read HTML data into a DataFrame.",
        "type": "comment"
    },
    "2522": {
        "file_id": 275,
        "content": "/tests/anime_highlight_cuts/theme_collector/bilibili_anime_compilation_finder.py",
        "type": "filepath"
    },
    "2523": {
        "file_id": 275,
        "content": "This code defines a dictionary of tags related to video themes for Bilibili anime compilations. The \"static\" tags include general anime and manga categories, while the \"optional\" tags have more specific recommendations or lists. These tags serve as seeds for analyzing and categorizing videos during compilation processing.",
        "type": "summary"
    },
    "2524": {
        "file_id": 275,
        "content": "# find our target video.\n# you may find uploaders, keywords, tags, recommended videos, video collections/playlists and filter by analyzers (check if is in the target format)\n# how did vscode recommend this shit to me?\n# from sklearn.semi_supervised import LabelSpreading\n# 其他标签就是和视频主题有关的 属于小分类\ntags = {  # select 1 for each.\n    \"static\": [\n        [\"二次元\", \"动画\", \"动漫\"],\n        [\n            \"综合\",\n            \"多素材\",\n            \"动漫杂谈\",\n            \"动画嘉年华\",\n            \"综漫\",\n        ],\n    ],\n    \"optional\": [  # select one or not select any.\n        [\"动漫推荐\", \"补番推荐\", \"动漫盘点\", \"盘点排行\", \"盘点推荐\", \"新番推荐\"],\n        [\"名场\", \"名场面\", \"万恶之源\"],\n    ],\n    # these are seeds. you may have different tags added along the way.\n}",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/bilibili_anime_compilation_finder.py:1-24"
    },
    "2525": {
        "file_id": 275,
        "content": "This code defines a dictionary of tags related to video themes for Bilibili anime compilations. The \"static\" tags include general anime and manga categories, while the \"optional\" tags have more specific recommendations or lists. These tags serve as seeds for analyzing and categorizing videos during compilation processing.",
        "type": "comment"
    },
    "2526": {
        "file_id": 276,
        "content": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py",
        "type": "filepath"
    },
    "2527": {
        "file_id": 276,
        "content": "The code reads video frames, selects the region of interest (ROI), and writes data to a CSV file for each frame in the list. It handles default values if ROI is not found and releases resources upon completion.",
        "type": "summary"
    },
    "2528": {
        "file_id": 276,
        "content": "# check if is the video we want and extract data or discard.\n# maybe you want some challange, so you can make one, right?\n# videos = [\n#     \"286760784_part1-00001.mp4\",\n#     \"329297394_part1-00001.mp4\",\n#     \"541755429_part1-00001.mp4\",\n#     \"842224692_part1-00001.mp4\",\n# ]\nimport os\n# videos = [fpath for fpath in os.listdir(\".\") if fpath.endswith(\".mp4\")]\nvideos = [\"480138800_part1.mp4\"] # mine video, classic!\n# we create dataset here.\n# use some short cuts for progression.\nframe_step = 10\nimport cv2\nimport progressbar\nfrom pynput.keyboard import Listener\nlastKey = [\"not_c\"]\ndef on_press(key):\n    lastKey[0] = \"not_c\"\n    try:\n        # print(\"alphanumeric key {0} pressed\".format(key.char))\n        if key.char in [\"c\", \"C\"]:\n            lastKey[0] = \"c\"\n    except AttributeError:\n        # print(\"special key {0} pressed\".format(key))\n        ...\ndef on_release(key):\n    # print(\"{0} released\".format(key))\n    ...\nlistener = Listener(on_press=on_press, on_release=on_release)\nlistener.start()\n# with listener:\n#     listener.join()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py:1-48"
    },
    "2529": {
        "file_id": 276,
        "content": "This code checks if the video file matches the desired format, creates a dataset, and uses shortcuts for progression. It also listens for keyboard input to determine when to stop running.",
        "type": "comment"
    },
    "2530": {
        "file_id": 276,
        "content": "# how do you arrange such data?\nfields = [\"filename\", \"frame_index\", \"x\", \"y\", \"w\", \"h\"]\nimport csv\nfor index, video in enumerate(videos):\n    with open(f'{video.split(\".\")[0]}.csv', \"w+\") as csvfile:\n        csvwriter = csv.writer(csvfile)\n        csvwriter.writerow(fields)\n        print(\"reading video:\", index)\n        roi = None\n        cap = cv2.VideoCapture(video)\n        for vindex in progressbar.progressbar(\n            range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), frame_step)\n        ):\n            cap.set(cv2.CAP_PROP_POS_FRAMES, vindex)\n            succ, image = cap.read()\n            if succ:\n                roi_new = cv2.selectROI(\"roi\", image)\n                # key=cv2.waitKey(0)\n                print(\"roi_new:\", roi_new)\n                print(\"last key:\", lastKey[0])\n                # print()\n                # print('keycode:',key)\n                if roi_new == (0, 0, 0, 0):\n                    if lastKey[0] == \"c\":\n                        # this is cancelled. roi will be nothing!\n                        roi = None",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py:50-77"
    },
    "2531": {
        "file_id": 276,
        "content": "This code reads a video and allows the user to select a region of interest (ROI) from each frame. It then writes the frame index, x, y, width, and height of the ROI in a CSV file for each frame of the video. The process is repeated for each video in the list.",
        "type": "comment"
    },
    "2532": {
        "file_id": 276,
        "content": "                else:\n                    roi = roi_new\n                print(\"roi:\", roi)\n                for i in range(frame_step):\n                    roi_index = vindex + i\n                    data = [video, roi_index]\n                    if roi == None:\n                        data += [0, 0, 0, 0]\n                    else:\n                        data += list(roi)\n                    csvwriter.writerow(data)\n        cap.release()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py:78-89"
    },
    "2533": {
        "file_id": 276,
        "content": "This code reads video frames, determines the region of interest (ROI), and writes data to a CSV file. If the ROI is not found, it adds default values. The loop iterates through each frame step, updating the ROI index and writing the data. Finally, it releases the video capture resource.",
        "type": "comment"
    },
    "2534": {
        "file_id": 277,
        "content": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py",
        "type": "filepath"
    },
    "2535": {
        "file_id": 277,
        "content": "Code uses yt-dlp to download Bilibili videos and handles errors. Snippet lists current directory files, checks filenames against \"expectedNamePrefix\", and prints \"TARGET FOUND!\" if a match is found.",
        "type": "summary"
    },
    "2536": {
        "file_id": 277,
        "content": "# we name downloaded video using some agreements.\nimport os\n# yt-dlp --skip-download -j https://www.bilibili.com/video/BV1e54y1y7qy\n# i guess it is because we are using proxies.\n# no? what the heck?\n# remapped /opt/homebrew/bin/yt-dlp from homebrew's (dependency of mpv) to /Users/jamesbrown/Library/Python/3.8/bin/yt-dlp. really annoying when trying to update (will install python 3.11 (heck!))\n# version outdated. fuck man.\n# yt-dlp --download-sections \"*0:00:03-0:01:00\" --playlist-items \"1\" https://www.bilibili.com/video/BV1Fs411k7e9\nvideoIDs = [\n    \"BV1e54y1y7qy\",  # 842224692_part1-00001\n    \"BV1Qf4y197bt\",  # great challange, 286760784\n    \"BV1bi4y1g7Gd\",  # watermark, full screen, 541755429\n    \"BV1PA411n7N6\",  # shit jumping around, 329297394\n]\nvideoID = videoIDs[3]\nfrom bv2av import bv_av_conversion\nvideoIDAlternative = bv_av_conversion(videoID)\nimport re\nif videoIDAlternative is None: # not av or bv. shit happened!\n    raise Exception(\"Possible shit happening when parsing bilibili video id:\", videoID)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py:1-26"
    },
    "2537": {
        "file_id": 277,
        "content": "This code downloads videos from Bilibili using yt-dlp and converts the video ID to a valid format. It handles potential errors by raising exceptions if the conversion fails or if an alternative conversion is required. The code also mentions some issues related to the yt-dlp version, outdated dependencies, and updating Python.",
        "type": "comment"
    },
    "2538": {
        "file_id": 277,
        "content": "else:\n    if videoIDAlternative.startswith(\"av\"):\n        videoAVID, videoBVID = videoIDAlternative, videoID\n    else:\n        videoBVID, videoAVID = videoIDAlternative, videoID\nprint(videoAVID, type(videoAVID))\nvideoAID = re.findall(r\"\\d+\", videoAVID)[0]\nurl = f\"https://www.bilibili.com/video/{videoBVID}\"  # only one single page.\n# 290 seconds.\n# section example:\n# 0:05:00-0:06:30\n# import time\n# secondsToHHMMSS = lambda seconds:time.strftime('%H:%M:%S', time.gmtime(seconds))\n# some formats are not working. fuck.\nplaylistIndex = \"1\"\n# start = secondsToHHMMSS(100)\n# end = secondsToHHMMSS(150)\n# print('TIMESPAN:',start, end)\nnameFormat = \"%(id)s-%(autonumber)s.%(ext)s\"\ncmd = f'yt-dlp --playlist-items \"{playlistIndex}\" -o \"{nameFormat}\" \"{url}\"'\n# cmd=f'yt-dlp --download-sections \"*{start}-{end}\" --playlist-items \"{playlistIndex}\" -o \"{nameFormat}\"  \"{url}\"'\nos.system(cmd)\nautonumber = \"1\".zfill(5)\nexpectedNamePrefix = f\"{videoAID}_part{playlistIndex}-{autonumber}\"\nprint(\"expected filename prefix:\", expectedNamePrefix)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py:27-59"
    },
    "2539": {
        "file_id": 277,
        "content": "Code snippet downloads videos from Bilibili using yt-dlp and saves them as parts with specified video IDs. It converts video IDs to the expected filename prefix and executes the command to download the videos.",
        "type": "comment"
    },
    "2540": {
        "file_id": 277,
        "content": "files = os.listdir(\".\")\nfor fname in files:\n    if fname.startswith(expectedNamePrefix):\n        print(\"TARGET FOUND!\")\n        print(\"FILENAME:\", fname)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py:60-65"
    },
    "2541": {
        "file_id": 277,
        "content": "This code snippet lists all files in the current directory and checks if any filename starts with the given \"expectedNamePrefix\". If a match is found, it prints \"TARGET FOUND!\" along with the filename.",
        "type": "comment"
    },
    "2542": {
        "file_id": 278,
        "content": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py",
        "type": "filepath"
    },
    "2543": {
        "file_id": 278,
        "content": "This Python script utilizes yt-dlp and Bilibili API to retrieve bilibili video metadata, unique identifiers, and related info. Error handling is needed for missing tags.",
        "type": "summary"
    },
    "2544": {
        "file_id": 278,
        "content": "# get video metadata first. we may filter unwanted videos by metadata.\n# let's just view here:\n# https://github.com/SocialSisterYi/bilibili-API-collect\n# i found new format of video shortlink:\n# https://b23.tv/BV1zW4y1p7RT\n# https://b23.tv/<bvid>\nvideoLinks = [\n    \"https://www.bilibili.com/video/BV1e54y1y7qy\",  # 女攻男受 emm\n    \"https://www.bilibili.com/video/BV1P441197oV\",  # in which you shall never find anything interesting. no related video.\n    \"https://www.bilibili.com/video/BV1Fs411k7e9\", # multiple chapters, you shall not find this interesting.\n    \"https://www.bilibili.com/video/av5842509\" # aid version of video link.\n]\n# import fake_useragent\n# ua = fake_useragent.UserAgent()\nimport re\nfrom pymaybe import maybe\nimport requests\nfrom urllib.parse import urlencode\ndef extractBVID(chars:str):\n    bvid = maybe(re.findall(r\"/(BV[a-zA-Z0-9]+)\",chars))[0]\n    return bvid\ndef extractAID(chars:str):\n    aid = maybe(re.findall(r\"/av([0-9]+)\",chars))[0]\n    return aid\n## remember the video is always scrapable via av id.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py:1-31"
    },
    "2545": {
        "file_id": 278,
        "content": "This code retrieves video metadata from bilibili, a Chinese video hosting platform. It uses various video link formats and extracts unique identifiers (BVID or AID) to obtain metadata for further filtering unwanted videos. The code also imports relevant libraries and defines two functions to extract BVID and AID from the video links.",
        "type": "comment"
    },
    "2546": {
        "file_id": 278,
        "content": "## av5842509\n# https://api.bilibili.com/x/web-interface/view?aid=<AID>\n# https://api.bilibili.com/x/web-interface/view?bvid=<BVID>\n# videoDownloadPath = \"\"\n# shit!\n# why i need to download whole damn video? i need to cut it into bite-sized video!\n# for some video there's no possibility to determine the source.\n# let's see the video metadata.\n# import os\n# os.system(f'yt-dlp --dump-metadata --output metadata.json \"{videoLinks[0]}\"') # working?\n# bullshit. we shall get the video metadata first.\nurl = \"https://api.bilibili.com/x/web-interface/view\"\ntags_url = \"https://api.bilibili.com/x/tag/archive/tags\"\nrelated_url = \"https://api.bilibili.com/x/web-interface/archive/related\"\nfor videoLink in videoLinks:\n    bvid = extractBVID(videoLink)\n    if bvid:\n        params = {\"bvid\": bvid}\n    else:\n        aid = extractAID(videoLink)\n        if aid:\n            params = {\"aid\": aid}\n        else:\n            print(\"no valid bilibili video id found.\")\n            print(\"skipping video link:\", videoLink)\n            continue",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py:32-66"
    },
    "2547": {
        "file_id": 278,
        "content": "The code is trying to collect metadata for Bilibili videos using APIs and may download the video if needed. It first checks if there is a valid BVID or AID, then retrieves the video's metadata and possibly related tags. However, it encounters issues with determining the source and currently has a workaround using yt-dlp to get metadata but notes that this method isn't working properly.",
        "type": "comment"
    },
    "2548": {
        "file_id": 278,
        "content": "    # print(\"PARAMS?\",params)\n    # shit.\n    r = requests.get(f\"{url}?{urlencode(params)}\") # why? what the fuck?\n    r_tags = requests.get(f\"{tags_url}?{urlencode(params)}\")\n    # r = requests.get(url,data=params,headers={\"User-Agent\":ua.random})\n    r_related = requests.get(f'{related_url}?{urlencode(params)}')\n    # r = requests.get(\"https://api.bilibili.com/x/web-interface/view?bvid=BV1e54y1y7qy\")\n    r.raise_for_status()\n    r_tags.raise_for_status()\n    r_related.raise_for_status()\n    # \"need_jump_bv\":false\n    # bvid only?\n    response_json = r.json()\n    response_tags_json = r_tags.json()\n    response_related_json = r_related.json()\n    # it must be json.\n    import rich\n    # rich.print(response_json)\n    assert response_json['code'] == 0\n    assert response_tags_json['code'] == 0\n    assert response_related_json['code'] == 0\n    data = response_json['data']\n    tags_data = response_tags_json['data']\n    related_data = response_related_json['data']\n    ## parsing video stats.\n    title = data['title']",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py:68-97"
    },
    "2549": {
        "file_id": 278,
        "content": "This code retrieves video metadata from Bilibili API using Python's `requests` library. It makes three separate requests for the video, tags, and related videos data. The responses are then parsed to extract relevant information such as video title, and the JSON responses are validated to ensure a successful response with status code 0.",
        "type": "comment"
    },
    "2550": {
        "file_id": 278,
        "content": "    pic = data['pic']\n    tid,tname = data['tid'],data['tname']\n    # 27, \"综合\"\n    # 253, \"动漫杂谈\"\n    dynamic = data['dynamic'] # we can copy that.\n    desc = data['desc']\n    owner_mid = data['owner']['mid']\n    state = data['state']\n    assert state == 0 # make sure this video is downloadable.\n    stat =  data['stat']\n    view  = stat['view']\n    reply = stat['reply']\n    danmaku = stat['danmaku']\n    favorite = stat['favorite']\n    coin  = stat['coin']\n    share = stat['share']\n    like  = stat['like']\n    pages = data['pages']\n    page_count = len(pages) # data['videos']\n    for page in pages:\n        page_index = page['page']\n        page_name = page['part']\n        page_dimension = page['dimension']\n        page_width, page_height, page_rotate = page_dimension['width'], page_dimension['height'], page_dimension['rotate']\n        page_duration = page['duration']\n    # subtitle = data['subtitle']\n    # let's just skip.\n    ## parsing tags info.\n    for tag in tags_data:\n        tag_id = tag['tag_id']\n        tag_name = tag['tag_name']",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py:98-135"
    },
    "2551": {
        "file_id": 278,
        "content": "This code is fetching data from an API and extracting various information such as video ID, title, thumbnail URLs, description, owner's mid, video statistics (views, replies, danmaku, favorites, coins, shares, likes), and page dimensions. It also skips parsing subtitle info and processes tags data. The code checks if the state is 0 to ensure the video can be downloaded.",
        "type": "comment"
    },
    "2552": {
        "file_id": 278,
        "content": "        tag_used = tag['count']['use']\n        tag_attention = tag['count']['atten']\n        # introduction of tag.\n        tag_content = tag['content']\n        tag_short_content = tag['short_content']\n    ## extract related video info.\n    related_video_counts = len(related_data)\n    for related_video in related_data:\n        related_aid = related_video['aid']\n        related_bvid = related_video['bvid']\n        related_tid = related_video['tid']\n        related_tname = related_video['tname']\n        related_pic = related_video['pic']\n        related_title = related_video['title']\n        related_page_count = related_video['videos'] # make sure this is 1?\n        related_desc = related_video['desc']\n        related_state = related_video['state']\n        if related_state != 0: continue\n        related_duration = related_video['duration']\n        related_owner_mid = related_video['owner']['mid']\n        related_stat = related_video['stat']\n        related_dynamic = related_video['dynamic']\n        # well, we've got non-standard dimensions.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py:136-160"
    },
    "2553": {
        "file_id": 278,
        "content": "This code section is gathering data related to a video, including tag information, count of times the tags were used or caught attention, and details about related videos. It checks if the related state is not 0 before proceeding to gather more information like duration, owner's mid, statistics, etc.",
        "type": "comment"
    },
    "2554": {
        "file_id": 278,
        "content": "        related_dimension = related_video['dimension']\n        # no tag here? you might want more!\n    breakpoint()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py:161-163"
    },
    "2555": {
        "file_id": 278,
        "content": "Checking video dimension and no tag found, further processing or error handling might be required.",
        "type": "comment"
    },
    "2556": {
        "file_id": 279,
        "content": "/tests/anime_highlight_cuts/theme_collector/make_picture_in_picture_challange.py",
        "type": "filepath"
    },
    "2557": {
        "file_id": 279,
        "content": "This code sets the base path for video files, imports os module, and uses os.path.join() to create file paths for source_video and background_video. It also sets a placeholder value for video duration (10) and comments on using ffplay and saving metadata in filenames.",
        "type": "summary"
    },
    "2558": {
        "file_id": 279,
        "content": "basepath = \"/Users/jamesbrown/Downloads/anime_download\"\nimport os\nsource_video = os.path.join(\n    basepath, \"[Sakurato] Onii-chan wa Oshimai! [未删减][02][AVC-8bit 1080p AAC][CHT].mp4\"\n)\nbackground_video = os.path.join(\n    basepath, \"[MLU-S] Onii-chan wa Oshimai! - 03 [1080p][Multi Subs].mkv\"\n)\nvideo_duration = 10  # just for test.\n# use ffplay?\n# better save metadata in the filename.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/make_picture_in_picture_challange.py:1-16"
    },
    "2559": {
        "file_id": 279,
        "content": "This code sets the base path for video files, imports os module, and uses os.path.join() to create file paths for source_video and background_video. It also sets a placeholder value for video duration (10) and comments on using ffplay and saving metadata in filenames.",
        "type": "comment"
    },
    "2560": {
        "file_id": 280,
        "content": "/tests/anime_highlight_cuts/theme_collector/keyboard_listener.py",
        "type": "filepath"
    },
    "2561": {
        "file_id": 280,
        "content": "This code uses the pynput library to listen for keyboard events. It defines two functions, `on_press` and `on_release`, to handle key presses and releases respectively. The listener object is created with these functions assigned as event handlers, and then the program enters a loop where it continuously listens for keystrokes until the listener is stopped or terminated.",
        "type": "summary"
    },
    "2562": {
        "file_id": 280,
        "content": "from pynput.keyboard import Listener\ndef on_press(key):\n    try:\n        print(\"alphanumeric key {0} pressed\".format(key.char))\n    except AttributeError:\n        print(\"special key {0} pressed\".format(key))\ndef on_release(key):\n    print(\"{0} released\".format(key))\nlistener = Listener(on_press=on_press, on_release=on_release)\n# listener.start()\nwith listener:\n    listener.join()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/keyboard_listener.py:1-18"
    },
    "2563": {
        "file_id": 280,
        "content": "This code uses the pynput library to listen for keyboard events. It defines two functions, `on_press` and `on_release`, to handle key presses and releases respectively. The listener object is created with these functions assigned as event handlers, and then the program enters a loop where it continuously listens for keystrokes until the listener is stopped or terminated.",
        "type": "comment"
    },
    "2564": {
        "file_id": 281,
        "content": "/tests/anime_highlight_cuts/theme_collector/create_rounded_rectangle.py",
        "type": "filepath"
    },
    "2565": {
        "file_id": 281,
        "content": "The code defines a function called \"rectangle\" that creates an 800x400 black image, draws a regular rectangle and a rounded rectangle on it using PIL, converts the image to numpy array, prints its shape, data type, and maximum value, displays the image using OpenCV, and then waits for a key press.",
        "type": "summary"
    },
    "2566": {
        "file_id": 281,
        "content": "from PIL import Image, ImageDraw\nimport cv2\nimport numpy as np\ndef rectangle():\n    image = Image.new(\"RGB\", (800, 400), \"black\")  # width, height?\n    draw = ImageDraw.Draw(image)\n    # Draw a regular rectangle\n    draw.rectangle((200, 100, 300, 200), fill=\"white\")\n    # Draw a rounded rectangle\n    draw.rounded_rectangle((50, 50, 150, 150), fill=\"white\", radius=20)\n    npArray = np.array(image)  # /255\n    # uint8? then float64? great.\n    print(npArray)\n    print(npArray.shape, npArray.dtype, npArray.max())  # 255?\n    cv2.imshow(\"mask\", npArray)\n    # maybe we just want \"1\" instead of \"255\"\n    # divide by 255 then.\n    cv2.waitKey(0)\nrectangle()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_rounded_rectangle.py:1-23"
    },
    "2567": {
        "file_id": 281,
        "content": "The code defines a function called \"rectangle\" that creates an 800x400 black image, draws a regular rectangle and a rounded rectangle on it using PIL, converts the image to numpy array, prints its shape, data type, and maximum value, displays the image using OpenCV, and then waits for a key press.",
        "type": "comment"
    },
    "2568": {
        "file_id": 282,
        "content": "/tests/anime_highlight_cuts/theme_collector/view_boundingbox.py",
        "type": "filepath"
    },
    "2569": {
        "file_id": 282,
        "content": "This code reads a bounding box coordinates, calculates the minimum x and y values, and then uses OpenCV to draw a rectangle on an image at these coordinates. The color of the rectangle is green (0, 255, 0) and the thickness is 3 pixels. Finally, it displays the image with the rectangle drawn in a window named \"PIP\".",
        "type": "summary"
    },
    "2570": {
        "file_id": 282,
        "content": "x, y, w, h = [1118.5, 545.5, 1585, 1069]\nmin_x, min_y = int(x - (w / 2)), int(y - (h / 2))\nimport cv2\nimagePath = \"\"\nimage = cv2.imread(imagePath)\np0, p1 = (min_x, min_y), (min_x + w, min_y + h)\ncv2.rectangle(image, p0, p1, (0, 255, 0), 3)\ncv2.imshow(\"PIP\", image)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/view_boundingbox.py:1-11"
    },
    "2571": {
        "file_id": 282,
        "content": "This code reads a bounding box coordinates, calculates the minimum x and y values, and then uses OpenCV to draw a rectangle on an image at these coordinates. The color of the rectangle is green (0, 255, 0) and the thickness is 3 pixels. Finally, it displays the image with the rectangle drawn in a window named \"PIP\".",
        "type": "comment"
    },
    "2572": {
        "file_id": 283,
        "content": "/tests/anime_highlight_cuts/theme_collector/test_video_overlay.sh",
        "type": "filepath"
    },
    "2573": {
        "file_id": 283,
        "content": "This script combines two video files, scales the first one to specific dimensions, and overlays them. It is used for creating a video highlight with theme overlay. The basepath variable contains the downloaded videos' location. The resulting video is saved as output.mp4 if both inputs are present, or output_1.mp4 if only the second input video is provided.",
        "type": "summary"
    },
    "2574": {
        "file_id": 283,
        "content": "video_0=\"[Sakurato] Onii-chan wa Oshimai! [未删减][02][AVC-8bit 1080p AAC][CHT].mp4\"\nvideo_1=\"[MLU-S] Onii-chan wa Oshimai! - 03 [1080p][Multi Subs].mkv\"\nbasepath=\"/Users/jamesbrown/Downloads/anime_download\"\nvideo_2=\"[Sakurato] Onii-chan wa Oshimai! [01][AVC-8bit 1080p AAC][CHT].mp4\"\n# ffmpeg -y -t 0:04:00 -i \"$basepath/$video_0\" -t 0:04:00 -i \"$basepath/$video_1\" -filter_complex \"[0:v]scale=1152:648[v0];[1:v][v0]overlay=384:216\" output.mp4\nffmpeg -y -t 0:04:00 -i \"$basepath/$video_2\" output_1.mp4",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/test_video_overlay.sh:1-9"
    },
    "2575": {
        "file_id": 283,
        "content": "This script combines two video files, scales the first one to specific dimensions, and overlays them. It is used for creating a video highlight with theme overlay. The basepath variable contains the downloaded videos' location. The resulting video is saved as output.mp4 if both inputs are present, or output_1.mp4 if only the second input video is provided.",
        "type": "comment"
    },
    "2576": {
        "file_id": 284,
        "content": "/tests/anime_highlight_cuts/theme_collector/anilist_to_anidb.py",
        "type": "filepath"
    },
    "2577": {
        "file_id": 284,
        "content": "The code is fetching anime information from Anilist using the AnilistPython API and storing anilist_ids for specific anime. It then prints the anime details, including name_romaji and name_english, and separates them with a horizontal line. The code also mentions a potential step to search for the same anime in anidb but it is not implemented in this snippet.",
        "type": "summary"
    },
    "2578": {
        "file_id": 284,
        "content": "anilist_ids = [\n    112788,  # 海边的异邦人\n    14813,  # Yahari Ore no Seishun Love Come wa Machigatteiru.\n]\n# first let's get name.\nfrom AnilistPython import Anilist\nanilist = Anilist()\nfor anilist_id in anilist_ids:\n    anime = anilist.get_anime_with_id(anilist_id)\n    # what about alias?\n    print(anime)\n    print(\"=\" * 20)\n    romaji = anime.get(\"name_romaji\", None)\n    english = anime.get(\"name_english\", None)\n    # genres = anime.get(\"genres\", []) # not so important. we don't have understanding.\n    # and you will search again.\n    # what is this manual select?\n    # anime2 = anilist.get_anime(romaji) # shit?\n    # print(anime2) # it will just be the same. no shit.\n    # print(\"=\" * 20)\n    # well let's search in anidb. get different names.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anilist_to_anidb.py:1-25"
    },
    "2579": {
        "file_id": 284,
        "content": "The code is fetching anime information from Anilist using the AnilistPython API and storing anilist_ids for specific anime. It then prints the anime details, including name_romaji and name_english, and separates them with a horizontal line. The code also mentions a potential step to search for the same anime in anidb but it is not implemented in this snippet.",
        "type": "comment"
    },
    "2580": {
        "file_id": 285,
        "content": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py",
        "type": "filepath"
    },
    "2581": {
        "file_id": 285,
        "content": "This code generates a COCO PIP dataset, creates background images with stripes, calculates text colors, applies random text overlays using OpenCV's putText function, and performs various image processing tasks to create a COCO-style pip dataset.",
        "type": "summary"
    },
    "2582": {
        "file_id": 285,
        "content": "# use what? better use some standard library.\n# you must know where you have put all these images.\n# DONE: remember to upload dataset creation things to kaggle as separate python scripts and execute it in separate process to prevent memory leaks (hopefully)\nimport cv2\nimport numpy as np\nimport os\nfrom string import punctuation\nimport random\n# import itertools\nfrom PIL import Image, ImageDraw\nimageBasePath = \"/kaggle/input/mscoco/mscoco_resized/train2014\"\nimagePaths = [\n    fpath\n    for fpath in os.listdir(imageBasePath)\n    if fpath.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n]\ntrain_path = \"images/train\"\ntest_path = \"images/test\"\ntrain_label_path = \"labels/train\"\ntest_label_path = \"labels/test\"\nbasepath = \"pip_dataset\"\ntrain_path_relative = os.path.join(basepath, train_path)\ntrain_label_path_relative = os.path.join(basepath, train_label_path)\nwidth = 800\nhalf_width = int(width / 2)  # either use 1,2,4 images.\ntextTotalHeight = 300  # either add to top or bottom.\ngetMarginRatio = lambda: random.choice(\n    [0, random.random() * 0.15, random.random() * 0.1, random.random() * 0.05]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:1-37"
    },
    "2583": {
        "file_id": 285,
        "content": "The code is importing necessary libraries and setting up the required paths for image and label files. It will create a PIP dataset by combining images and labels, resizing them to 800 width, and possibly adding text with a random margin ratio. The final dataset will be saved in a specified directory. Memory leaks are mentioned as a concern, so separate scripts are recommended for execution.",
        "type": "comment"
    },
    "2584": {
        "file_id": 285,
        "content": ")  # this margin is used randomly. we can make it 0 or as is.\ntextOrigin = (-30, 30)\nfontScale = 1\nfont = cv2.FONT_HERSHEY_SIMPLEX\nfontThickness = 2\ngetRadius = lambda: random.randint(1, 30)\nimageIndex = (\n    sorted(\n        [int(fpath.split(\".\")[0]) for fpath in os.listdir(train_path_relative)],\n        key=lambda index: -index,\n    )[0]\n    + 1\n)  # shall be increased on demand.\nprint(\"START MARKING PICTURES WITH INDEX:\", imageIndex)\nMAX_COCO_PIP_IMAGE_COUNT = 10000  # well, super huge. is it?\n# don't insert 20000 cause it will break shit.\nalphabets = \"abcdefghijklmnopqrstuvwxyz\"\nALPHABETS = alphabets.upper()\nnumbers = \"0123456789\"\ncharacterList = list(alphabets + ALPHABETS + numbers + punctuation + \" \")\ngetRandomCharacter = lambda: random.choice(characterList)\ngetRandomCharacters = lambda charCount: \"\".join(\n    [getRandomCharacter() for _ in range(charCount)]\n)\ngetRandomLinesOfCharacters = lambda lineCount, charCount: \"\\r\".join(\n    [getRandomCharacters(charCount) for _ in range(lineCount)]\n)\nimageFormats = [1, 2, 4]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:38-73"
    },
    "2585": {
        "file_id": 285,
        "content": "This code initializes variables for creating a COCO PIP dataset. It sets text origin, font scale, and font type. It defines functions to get random character or characters, and handles image formats. The image index is incremented and the maximum allowed image count is set.",
        "type": "comment"
    },
    "2586": {
        "file_id": 285,
        "content": "textFormats = [\"up\", \"down\", \"none\"]\nbackgroundFormats = [\"solidColor\", \"horizontalStripes\", \"verticalStripes\", \"gradients\"]\ncolors = [\n    (0, 0, 0),\n    (255, 255, 255),\n    (0, 0, 192),\n    (255, 255, 64),\n    (0, 255, 0),\n    (0, 0, 255),\n    (255, 0, 0),\n]\ncolorsNumpyArray = [np.array(color) for color in colors]\ncolorsWithIndex = [(index, color) for index, color in enumerate(colors)]\n# we are not doing this while testing.\n# imageFormat = random.choice(imageFormats)\n# textFormat = random.choice(textFormats)\n# backgroundFormat = random.choice(backgroundFormats)\ndef get_gradient_2d(start, stop, width, height, is_horizontal):\n    if is_horizontal:\n        return np.tile(np.linspace(start, stop, width), (height, 1))\n    else:\n        return np.tile(np.linspace(start, stop, height), (width, 1)).T\ndef get_gradient_3d(width, height, start_list, stop_list, is_horizontal_list):\n    result = np.zeros((height, width, len(start_list)), dtype=np.float64)\n    for i, (start, stop, is_horizontal) in enumerate(\n        zip(start_list, stop_list, is_horizontal_list)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:74-104"
    },
    "2587": {
        "file_id": 285,
        "content": "This code generates a COCO-style dataset for object detection using random color combinations. It includes lists of text formats, background formats, and colors, which are then converted to numpy arrays. The code also defines functions to generate 2D and 3D gradients for backgrounds. However, image format, text format, and background format selections are commented out while testing.",
        "type": "comment"
    },
    "2588": {
        "file_id": 285,
        "content": "    ):\n        result[:, :, i] = get_gradient_2d(start, stop, width, height, is_horizontal)\n    return result.astype(np.uint8)\n# for imageFormat, textFormat, backgroundFormat in itertools.product(\n#     imageFormats, textFormats, backgroundFormats\n# ):  # you can use these things to get test output picture names.\nprint(\"creating coco pip dataset:\")\nimport progressbar\nfor _i in progressbar.progressbar(range(MAX_COCO_PIP_IMAGE_COUNT)):\n    imageFormat = random.choice(imageFormats)\n    textFormat = random.choice(textFormats)\n    backgroundFormat = random.choice(backgroundFormats)\n    colorDistances = {}\n    selectedImages = [\n        cv2.imread(os.path.join(imageBasePath, imagePath), cv2.IMREAD_COLOR)\n        for imagePath in random.sample(imagePaths, k=imageFormat)\n    ]\n    for image in selectedImages:\n        averageColor = np.average(image.reshape((-1, 3)), axis=0)\n        for index, colorNumpyArray in enumerate(colorsNumpyArray):\n            colorDistances[index] = colorDistances.get(index, []) + [\n                np.sum(np.abs(averageColor - colorNumpyArray))",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:105-130"
    },
    "2589": {
        "file_id": 285,
        "content": "Creating a COCO PIP dataset: randomly selects image, text, and background formats to generate test output pictures. Chooses multiple images for each format, averages their colors, compares them with color arrays, and adds distances to the dictionary.",
        "type": "comment"
    },
    "2590": {
        "file_id": 285,
        "content": "            ]\n    sortedColorsWithIndex = sorted(\n        colorsWithIndex, key=lambda element: -np.sum(colorDistances[element[0]])\n    )  # the further the better.\n    # sortedColors = [color for _, color in sortedColorsWithIndex]\n    ## create background first.\n    imageCanvasHeight = half_width if imageFormat == 2 else width\n    textCanvasHeight = 0 if textFormat == \"none\" else textTotalHeight\n    backgroundShape = (imageCanvasHeight + textCanvasHeight, width, 3)  # height, width\n    _, color_main = sortedColorsWithIndex[0]\n    if backgroundFormat in [\"horizontalStripes\", \"verticalStripes\", \"gradients\"]:\n        # fill background with color_main first.\n        _, color_sub = sortedColorsWithIndex[1]\n        if backgroundFormat in [\"horizontalStripes\", \"verticalStripes\"]:\n            backgroundImage = np.zeros(backgroundShape, dtype=np.uint8)\n            backgroundImage[:, :, 0] = color_main[0]\n            backgroundImage[:, :, 1] = color_main[1]\n            backgroundImage[:, :, 2] = color_main[2]\n            stripeCount = random.randint(2, 5)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:131-156"
    },
    "2591": {
        "file_id": 285,
        "content": "Code creates a background for an image based on the furthest color from the given colors. It sorts the colors by distance from their average and chooses the furthest one. If the background format is \"horizontalStripes\", \"verticalStripes\" or \"gradients\", it fills the background with this color and another color chosen from the sorted list, then generates a random stripe count for the background image.",
        "type": "comment"
    },
    "2592": {
        "file_id": 285,
        "content": "            if backgroundFormat == \"verticalStripes\":  # slice width\n                arr = np.linspace(0, backgroundShape[1], stripeCount + 1)\n                for width_start, width_end in [\n                    (int(arr[i]), int(arr[i + 1]))\n                    for i in range(stripeCount)\n                    if i % 2 == 1\n                ]:\n                    backgroundImage[:, width_start:width_end, 0] = color_sub[0]\n                    backgroundImage[:, width_start:width_end, 1] = color_sub[1]\n                    backgroundImage[:, width_start:width_end, 2] = color_sub[2]\n            else:  # horizontal. slice height.\n                arr = np.linspace(0, backgroundShape[0], stripeCount + 1)\n                for height_start, height_end in [\n                    (int(arr[i]), int(arr[i + 1]))\n                    for i in range(stripeCount)\n                    if i % 2 == 1\n                ]:\n                    backgroundImage[height_start:height_end, :, 0] = color_sub[0]\n                    backgroundImage[height_start:height_end, :, 1] = color_sub[1]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:157-176"
    },
    "2593": {
        "file_id": 285,
        "content": "Code snippet generates a background image with vertical or horizontal stripes based on the `backgroundFormat`. For the \"verticalStripes\" format, it creates an array of strip widths and sets the corresponding pixel values for each strip. Otherwise, for the \"horizontal\" format, it creates an array of strip heights and sets the corresponding pixel values for each strip.",
        "type": "comment"
    },
    "2594": {
        "file_id": 285,
        "content": "                    backgroundImage[height_start:height_end, :, 2] = color_sub[2]\n        else:  # gradient!\n            is_horizontal = [False, False, False]\n            is_horizontal[random.randint(0, 2)] = True\n            backgroundImage = get_gradient_3d(\n                backgroundShape[1],\n                backgroundShape[0],\n                color_main,\n                color_sub,\n                is_horizontal,\n            )\n    else:  # pure color.\n        backgroundImage = np.zeros(backgroundShape, dtype=np.uint8)\n        backgroundImage[:, :, 0] = color_main[0]\n        backgroundImage[:, :, 1] = color_main[1]\n        backgroundImage[:, :, 2] = color_main[2]\n    ## next, paint text!\n    if textFormat != \"none\":\n        ## only calculate text color when needed.\n        backgroundAverageColor = np.average(backgroundImage.reshape((-1, 3)), axis=0)\n        textColorNumpyArray = sorted(\n            colorsNumpyArray,\n            key=lambda colorNumpyArray: -np.sum(\n                np.abs(backgroundAverageColor - np.array(colorNumpyArray))",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:177-201"
    },
    "2595": {
        "file_id": 285,
        "content": "This code generates background images based on the given parameters: pure color, gradient, or a combination of both. It also calculates the text color by comparing the background image's average color with a list of colors to find the best match.",
        "type": "comment"
    },
    "2596": {
        "file_id": 285,
        "content": "            ),\n        )[0]\n        textColor = textColorNumpyArray.tolist()\n        # let's paint it all over the place!\n        textShift = 40\n        # TODO: check if string is **just enough** to fill the background.\n        for textLineIndex in range(\n            int((backgroundShape[0] / (textTotalHeight + width)) * 27)\n        ):\n            baseNumber = 50\n            baseNumber2 = random.randint(1, baseNumber)\n            textContent = random.choice(\n                [\n                    \"\",\n                    (\" \" * baseNumber2)\n                    + getRandomCharacters(random.randint(0, baseNumber - baseNumber2)),\n                ]\n            )\n            backgroundImage = cv2.putText(\n                backgroundImage,\n                textContent,\n                (textOrigin[0], textOrigin[1] + textShift * textLineIndex),\n                font,\n                fontScale,\n                textColor,\n                fontThickness,\n                cv2.LINE_AA,\n            )\n    ## put pictures!\n    imageCanvasShape = (imageCanvasHeight, width, 3)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:202-232"
    },
    "2597": {
        "file_id": 285,
        "content": "This code generates a random text overlay on an image using OpenCV's putText function. It randomly selects and modifies a character string, then applies it to the image at various locations. The background shape is used to determine the number of overlays generated.",
        "type": "comment"
    },
    "2598": {
        "file_id": 285,
        "content": "    imageMask = Image.new(\n        \"RGB\", (imageCanvasShape[1], imageCanvasShape[0]), \"black\"\n    )  # width, height?\n    draw = ImageDraw.Draw(imageMask)\n    imageCanvas = np.zeros(imageCanvasShape, dtype=np.uint8)\n    imageCoordinates = []\n    if imageFormat == 1:\n        image = selectedImages[0]\n        imageShape = image.shape\n        margin = getMarginRatio()\n        base = width * (1 - margin * 2)\n        imageHeight, imageWidth = imageShape[:2]\n        if imageHeight > imageWidth:\n            imageShape = (int(base * (imageWidth / imageHeight)), int(base))\n        else:\n            imageShape = (int(base), int(base * (imageHeight / imageWidth)))\n        # print(image.shape)\n        image = cv2.resize(image, imageShape)\n        x0 = int((width - imageShape[0]) / 2)\n        x1 = x0 + imageShape[0]\n        y0 = int((width - imageShape[1]) / 2)\n        y1 = y0 + imageShape[1]\n        if random.random() > 0.5:\n            draw.rectangle((x0, y0, x1, y1), fill=\"white\")\n        else:\n            draw.rounded_rectangle(",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:234-263"
    },
    "2599": {
        "file_id": 285,
        "content": "Creates a mask image for given shape, draws on it based on the image format and random selection, then resizes the selected image according to the new shape. It also determines the coordinates for drawing rounded rectangles on the mask.",
        "type": "comment"
    }
}