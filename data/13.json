{
    "1300": {
        "file_id": 115,
        "content": "                        checkVideoColorCentrality,\n                        \"video_color_centrality\",\n                    ],\n                    [\n                        getEffectiveFPS,\n                        video_effective_fps_filter,\n                        checkMinMaxDict,\n                        \"EffectiveFPS\",\n                    ],  # also, the dog/cat detector! fuck.\n                    [NSFWVideoFilter, None, dummyFilterFunction, \"NSFW\"],\n                    [\n                        vtb.duplicatedVideoFilter,\n                        None,\n                        dummyFilterFunction,\n                        \"video duplication filter\",\n                    ],\n                ]\n                for function, mFilter, filterFunction, flag in mList:\n                    try:\n                        mValue = function(local_video_location)\n                        valid = filterFunction(mValue, mFilter)\n                        if not valid:\n                            print(\"skipping due to invalid %s: %s\" % (flag, mValue))",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/onlineProcessor.py:212-234"
    },
    "1301": {
        "file_id": 115,
        "content": "This code defines a list of filters for processing videos. Each filter is applied in sequence, and if any filter returns an invalid result, the video is skipped with a message. The NSFW detector is also mentioned as part of one of the filters.",
        "type": "comment"
    },
    "1302": {
        "file_id": 115,
        "content": "                            print(\"%s filter:\" % flag, mFilter)\n                            break\n                        else:\n                            print(\"%s test passed.\" % flag)\n                    except:\n                        import traceback\n                        traceback.print_exc()\n                        print(\"skipping due to exception during filtering\")\n                        valid = False\n                        break\n                if not valid:\n                    print(\"abandon video:\", item_id)\n                # breakpoint()\n                if not valid:\n                    if os.path.exists(local_video_location):\n                        print(\"removing abandoned video:\", local_video_location)\n                        os.remove(local_video_location)\n                else:\n                    video_width, video_height = get_res(local_video_location)\n                    yield {\n                        \"location\": local_video_location,\n                        \"item_id\": item_id,\n                        \"meta\": {",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/onlineProcessor.py:235-258"
    },
    "1303": {
        "file_id": 115,
        "content": "This code is testing a filter for an item and either passing or skipping based on exceptions. If it skips, the video file is removed. If it passes, it yields information about the video location and item ID.",
        "type": "comment"
    },
    "1304": {
        "file_id": 115,
        "content": "                            \"duration\": get_duration(local_video_location),\n                            \"width\": video_width,\n                            \"height\": video_height,\n                        },\n                    }\n                    # if you abandon that, better delete it!\n                # do time duration check, effective fps check, color centrality check, then the dog/cat check\n                # what's next? find some audio files? or just use one audio?\n                # print(\"HERE??\",3)\n                # print('flag', flag)",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/onlineProcessor.py:259-268"
    },
    "1305": {
        "file_id": 115,
        "content": "This code snippet is initializing a dictionary with key-value pairs for video duration, width, and height. It also creates another nested dictionary representing the video object. The code mentions time duration check, effective fps check, color centrality check, dog/cat check, and possibly audio file handling in future steps.",
        "type": "comment"
    },
    "1306": {
        "file_id": 116,
        "content": "/pyjom/modules/informationProcessing/localProcessor.py",
        "type": "filepath"
    },
    "1307": {
        "file_id": 116,
        "content": "This code segment processes filesystem information, retrieves metadata, calculates various details, handles GIFs and text files, analyzes YoloV5-detected objects from the \"yolov5\" array, filters file info, discards unwanted files, and returns modified fileinfo dictionary.",
        "type": "summary"
    },
    "1308": {
        "file_id": 116,
        "content": "from pyjom.commons import (\n    decorator,\n    get_media_info,\n    json_media_info,\n    ffprobe_media_info,\n    read_json,\n    getTextFileLength,\n    multi_replacer,\n    append_sublist,\n    extract_span,\n    convoluted,\n    update_subdict,\n)\n# you may want to remove text.\n@decorator\ndef FilesystemProcessor(info, reviewerLogs, filters={}, path_replacers={}):\n    # print(\"FILESYSTEM_PROCESSOR INTERCEPTED INFO\",info)\n    # print(\"REVIEWER LOGS:\", reviewerLogs)\n    # breakpoint()\n    # do not handle meta filters here.\n    protocol, files = info  # source paths.\n    # print(\"FILES\", files)\n    # breakpoint()\n    metainfo = {}\n    for elem in files:\n        _type, path = elem[\"type\"], elem[\"path\"]\n        suffix = path.split(\".\")[-1]\n        metaInfo = {\"type\": _type, \"suffix\": suffix, \"filename\": path.split(\"/\")[-1]}\n        if _type == \"video\":\n            einfo = json_media_info(path)\n            for e in einfo[\"media\"][\"track\"]:  # might be gif. how to solve this?\n                mtype = e[\"@type\"]\n                if mtype == \"Video\":",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:1-38"
    },
    "1309": {
        "file_id": 116,
        "content": "This code imports various functions and defines a FilesystemProcessor function decorated by the decorator function. It processes information and files from the filesystem, intercepts meta filters, and handles video file information for further processing.",
        "type": "comment"
    },
    "1310": {
        "file_id": 116,
        "content": "                    # breakpoint()\n                    resolution = {\"height\": e[\"Height\"], \"width\": e[\"Width\"]}\n                    # color = e[\"ColorSpace\"] # YUV for common video\n            info = get_media_info(path)\n            # print(\"INFO OF %s\", path)\n            # print(info)\n            # breakpoint()\n            video_duration = info[\"videoDuration\"]\n            if \"audioDuration\" not in info.keys():\n                audioInfo = None\n            else:\n                # audioInfo = {}\n                audio_duration = info[\"audioDuration\"]\n                # print(info)\n                # breakpoint()\n                sampleRate = info[\"audioSamplingRate\"]\n                channels = info[\"audioChannel\"]\n                audioInfo = {\n                    \"sampleRate\": sampleRate,\n                    \"channels\": channels,\n                    \"duration\": audio_duration,\n                }\n            resolution = {\"height\": info[\"videoHeight\"], \"width\": info[\"videoWidth\"]}\n            _fps = info[\"videoFrameRate\"]",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:39-62"
    },
    "1311": {
        "file_id": 116,
        "content": "This code retrieves media information from a file path and calculates video and audio duration, as well as the resolution and frame rate of the video. It also checks for audio information and stores it separately if available.",
        "type": "comment"
    },
    "1312": {
        "file_id": 116,
        "content": "            metaInfo.update(\n                {\n                    \"fps\": _fps,\n                    \"duration\": video_duration,\n                    \"resolution\": resolution,\n                    \"audio\": audioInfo,\n                }\n            )\n        elif _type == \"audio\":\n            info = get_media_info(path)\n            duration = info[\"duration\"]\n            sampleRate = info[\"audioSamplingRate\"]\n            channels = info[\"audioChannel\"]\n            metaInfo.update(\n                {\"sampleRate\": sampleRate, \"channels\": channels, \"duration\": duration}\n            )\n        elif _type == \"image\":  # gif is image. check it out!\n            info = json_media_info(path)\n            for e in info[\"media\"][\"track\"]:\n                mtype = e[\"@type\"]\n                if mtype == \"Image\":\n                    resolution = {\"height\": e[\"Height\"], \"width\": e[\"Width\"]}\n                    # color = e[\"ColorSpace\"]\n            if metaInfo[\"suffix\"].lower() == \"gif\":\n                info = ffprobe_media_info(path)",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:63-87"
    },
    "1313": {
        "file_id": 116,
        "content": "This code snippet retrieves media information based on the file type (_type) and updates the metaInfo dictionary accordingly. If it's a video, it fetches fps, video_duration, and resolution. For audio, it gets sampleRate, channels, and duration. Image type checks if it's a GIF, and depending on the result, either uses json_media_info or ffprobe_media_info to get the necessary information.",
        "type": "comment"
    },
    "1314": {
        "file_id": 116,
        "content": "                for e in info[\"streams\"]:\n                    codec_name = e[\"codec_name\"]\n                    if codec_name == \"gif\":\n                        duration = e[\"duration\"]\n                        _fps = e[\"avg_frame_rate\"]\n                        metaInfo.update(\n                            {\"duration\": float(duration), \"fps\": eval(_fps)}\n                        )\n            metaInfo.update({\"resolution\": resolution})\n        elif _type == \"text\":  # are you sure about that?\n            metaInfo.update({\"length\": getTextFileLength(path)})\n        metainfo.update({multi_replacer(path, replacer_list=path_replacers): metaInfo})\n    # breakpoint()# get meta information from here.\n    fileinfo = {}\n    for rlog in reviewerLogs:\n        print(\"READING LOG: %s\" % rlog)\n        content_json = read_json(rlog)\n        for elem in content_json:\n            review_tuple = elem[\"review\"][\"review\"]\n            filename = review_tuple[0]\n            filename = multi_replacer(filename, replacer_list=path_replacers)",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:88-108"
    },
    "1315": {
        "file_id": 116,
        "content": "This code retrieves file metadata and reviewer logs, then updates meta information based on file type (image, video, or text). It handles GIFs specifically by extracting duration and average frame rate. Text files have their length measured with getTextFileLength(). Reviewer logs are read and mapped to corresponding files using multi_replacer function.",
        "type": "comment"
    },
    "1316": {
        "file_id": 116,
        "content": "            sample_review = review_tuple[1]  # convolution with removed text timespan.\n            # print(\"KEYS DUMP:\")\n            primarykey = list(sample_review.keys())[0]  # CHECK THIS KEY FIRST.\n            # print(\"PRIMARYKEY:\",primarykey)\n            primary_sample_content = sample_review[primarykey]\n            # print(primary_sample_content) # hide this shit.\n            if primarykey == \"labels\":\n                discard = sample_review[\"discard\"]\n                if discard:\n                    update_subdict(fileinfo, filename, {\"discard\": True})\n                else:\n                    if primarykey in filters.keys():\n                        if not any(\n                            [x in primary_sample_content for x in filters[primarykey]]\n                        ):\n                            # remove those without the label.\n                            continue\n                    update_subdict(\n                        fileinfo, filename, {\"labels\": primary_sample_content}\n                    )",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:109-128"
    },
    "1317": {
        "file_id": 116,
        "content": "This code processes a sample review, checks if its primary key is \"labels\", discards the file if it contains the \"discard\" label, and updates the file info with labels if they match the specified filters.",
        "type": "comment"
    },
    "1318": {
        "file_id": 116,
        "content": "                    # does it have any filters?\n                # then we have a list of labels down here.\n                # handle the filters.\n            else:\n                sample_content_type, secondary_key = primary_sample_content.keys()\n                secondary_sample_content = primary_sample_content[secondary_key]\n                third_keys = list(secondary_sample_content.keys())\n                thirdkey = third_keys[0]\n                # print(\"SecondaryKey:\",secondary_key)\n                # print(\"THIRD_KEYS:\",third_keys)\n                main_array_content = secondary_sample_content[thirdkey]\n                if secondary_key == \"yolov5\":\n                    # print(\"YOLOV5 DETECTED\")\n                    # get the time step first. or shall we?\n                    # breakpoint()\n                    identity_dict_array = {}\n                    main_time_array = []\n                    for frame in main_array_content:\n                        _time, _frame, yolov5_detector = (\n                            frame[\"time\"],",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:130-149"
    },
    "1319": {
        "file_id": 116,
        "content": "The code checks if the content has any filters. If not, it accesses the sample content type and secondary key, then retrieves the third key. It assigns the main array content based on the secondary key, which is checked for being \"yolov5\". If so, it initializes identity_dict_array and main_time_array, and iterates through the main array content to retrieve time, frame, and yolov5_detector.",
        "type": "comment"
    },
    "1320": {
        "file_id": 116,
        "content": "                            frame[\"frame\"],\n                            frame[\"yolov5_detector\"],\n                        )\n                        main_time_array.append(_time)\n                        for detected in yolov5_detector:\n                            # ignore the location. we do not need this shit till we somehow want to focus on the shit.\n                            confidence = detected[\n                                \"confidence\"\n                            ]  # ignore the confidence.\n                            confidence_threshold = 0.6\n                            if confidence <= confidence_threshold:\n                                continue\n                            identity = detected[\"identity\"][\"name\"]\n                            append_sublist(identity_dict_array, identity, _time)\n                    if secondary_key in filters.keys():\n                        if not any(\n                            [\n                                x in identity_dict_array.keys()\n                                for x in filters[secondary_key]",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:150-168"
    },
    "1321": {
        "file_id": 116,
        "content": "This code processes detected objects from a YoloV5 detector and filters them based on a confidence threshold. It appends the detected identities to an array if they pass the threshold, and checks if there are secondary filters present for further processing.",
        "type": "comment"
    },
    "1322": {
        "file_id": 116,
        "content": "                            ]\n                        ):\n                            continue  # do not have the dogs.\n                    # so check the timespan.\n                    # get consecutive ranges of x == 1. use threshold function like int(x>0.5)\n                    new_identity_array = {}\n                    for t in main_time_array:\n                        for k in identity_dict_array.keys():\n                            if t in identity_dict_array[k]:\n                                # print(\"APPENDING\")\n                                append_sublist(new_identity_array, k, 1)\n                                # print(new_identity_array[k])\n                                # breakpoint()\n                            else:\n                                append_sublist(new_identity_array, k, 0)\n                    # convolution step:\n                    # print(\"NEW IDEITITY ARRAY BEFORE PROCESSING:\", new_identity_array)\n                    main_time_array += [\"FINAL\"]  # add the final time\n                    for k in new_identity_array.keys():",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:169-187"
    },
    "1323": {
        "file_id": 116,
        "content": "This code is iterating through a main_time_array and an identity_dict_array to create a new \"new_identity_array\". For each time in the main_time_array, it checks if that time exists within any of the keys' arrays in the identity_dict_array. If so, it appends that key into the new_identity_array with a value of 1. If not, it appends with a value of 0. Afterwards, it adds a final time to the main_time_array and processes the new_identity_array further.",
        "type": "comment"
    },
    "1324": {
        "file_id": 116,
        "content": "                        new_identity_array[k] = convoluted(\n                            new_identity_array[k], pad=1, k=5\n                        )\n                        new_identity_array[k] = [\n                            int(x > 0.2) for x in new_identity_array[k]\n                        ]\n                        new_identity_array[k] = extract_span(\n                            new_identity_array[k], target=1\n                        )  # this is span.\n                        # print(new_identity_array[k])\n                        # breakpoint()\n                        new_identity_array[k] = [\n                            (main_time_array[a], main_time_array[b])\n                            for a, b in new_identity_array[k]\n                        ]\n                    # print(\"NEW IDENTITY SPAN ARRAY:\", new_identity_array) # not so sure if the yolov5 detector is not working properly or the confidence threshold is too high.\n                    if secondary_key in filters.keys():\n                        if not any(",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:188-205"
    },
    "1325": {
        "file_id": 116,
        "content": "This code segment is processing an identity array by applying convolution, setting values above a threshold, extracting spans from the array based on a target value, and finally rearranging the array elements into pairs of indices. It seems to be part of a larger process involving filters and potentially image or object detection using a YoloV5 detector.",
        "type": "comment"
    },
    "1326": {
        "file_id": 116,
        "content": "                            [\n                                x in new_identity_array.keys()\n                                for x in filters[secondary_key]\n                            ]\n                        ):\n                            continue  # double check.\n                    timestep = secondary_sample_content[\"timestep\"]\n                    result = {\n                        \"detected_objects_timespan\": new_identity_array,\n                        \"timestep\": timestep,\n                    }\n                    update_subdict(fileinfo, filename, {\"yolov5\": result})\n                    # breakpoint()\n                    # TODO: complete the convolutional span extractor.\n                    # pass\n                elif (\n                    secondary_key == \"framedifference_talib_detector\"\n                ):  # this one is detecting the pip. active region.\n                    # print(\"{:*^30}\".format(\"FRAMEDIFFERECE DETECTOR\"))\n                    # breakpoint()\n                    min_frame_threshold = 30",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:206-226"
    },
    "1327": {
        "file_id": 116,
        "content": "This code is filtering data based on keys in new_identity_array and filters, and then assigns the \"detected_objects_timespan\" and \"timestep\" values to a result dictionary. The function continues if the current key is found in the new_identity_array and filters arrays. If the secondary_key is \"framedifference_talib_detector\", it prints a message and sets min_frame_threshold to 30.",
        "type": "comment"
    },
    "1328": {
        "file_id": 116,
        "content": "                    if secondary_key in filters.keys():\n                        min_frame_threshold = filters[secondary_key]\n                    frameborders = []\n                    for k in main_array_content.keys():\n                        frameborder = main_array_content[k]\n                        start, end = frameborder[\"start\"], frameborder[\"end\"]\n                        frame_length = end - start\n                        if frame_length < min_frame_threshold:\n                            continue\n                        frameborders.append(frameborder)\n                    update_subdict(\n                        fileinfo,\n                        filename,\n                        {\"framedifference_talib_detector\": frameborders},\n                    )\n    # finally remove those without filter keys.\n    filterKeys = filters.get(\"ensure\", [y for y in filters.keys() if y != \"meta\"])\n    for k in list(fileinfo.keys()):\n        # do metainfo extraction.\n        # print(\"CORE PATH\")\n        fileinfo[k][\"meta\"] = metainfo[k]",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:227-250"
    },
    "1329": {
        "file_id": 116,
        "content": "The code checks if a secondary key exists in the filters dictionary, then sets a minimum frame threshold based on it. It then loops through the main_array_content, filtering out any frameborders with lengths less than the minimum frame threshold. The filtered frameborders are stored in the frameborders list. Finally, the fileinfo dictionary is updated with the framedifference_talib_detector subdict containing the frameborders, and any keys without the \"meta\" tag or keys not in the filterKeys list are removed.",
        "type": "comment"
    },
    "1330": {
        "file_id": 116,
        "content": "        fileElemKeys = fileinfo[k].keys()\n        if fileinfo[k].get(\"discard\", False):\n            fileinfo.pop(k)\n            continue\n        mbool_condition = all([x in fileElemKeys for x in filterKeys])\n        # print(\"CHECKING:\",k)\n        # print(\"CONDITION:\",mbool_condition)\n        # breakpoint()\n        if not mbool_condition:\n            fileinfo.pop(k)  # why the fuck you pop all of them!\n    # print(fileinfo)\n    # print(\"____________FILEINFO DUMP____________\")\n    # breakpoint()\n    return fileinfo\n    # fileSystemUrl, fileList = info # I need the processed logs!\n    # return {\"husky\": \"cute husky check my youtube\"} # this is dummy return!",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/localProcessor.py:251-266"
    },
    "1331": {
        "file_id": 116,
        "content": "This code checks if a file should be discarded based on certain conditions and removes it from the fileinfo dictionary if it doesn't meet those conditions. It also prints some debug information for specific files. Finally, it returns the modified fileinfo dictionary.",
        "type": "comment"
    },
    "1332": {
        "file_id": 117,
        "content": "/pyjom/modules/informationProcessing/dummyProcessor.py",
        "type": "filepath"
    },
    "1333": {
        "file_id": 117,
        "content": "This code imports the decorator function from pyjom.commons and defines a dummyProcessor function, decorated with the @decorator. It takes an info parameter and returns a dictionary containing a \"husky\" key with the value \"cute husky check my youtube\".",
        "type": "summary"
    },
    "1334": {
        "file_id": 117,
        "content": "from pyjom.commons import decorator\n@decorator\ndef dummyProcessor(info):\n    return {\"husky\": \"cute husky check my youtube\"}",
        "type": "code",
        "location": "/pyjom/modules/informationProcessing/dummyProcessor.py:1-6"
    },
    "1335": {
        "file_id": 117,
        "content": "This code imports the decorator function from pyjom.commons and defines a dummyProcessor function, decorated with the @decorator. It takes an info parameter and returns a dictionary containing a \"husky\" key with the value \"cute husky check my youtube\".",
        "type": "comment"
    },
    "1336": {
        "file_id": 118,
        "content": "/pyjom/modules/globalUpdator/dummyUpdator.py",
        "type": "filepath"
    },
    "1337": {
        "file_id": 118,
        "content": "The code imports necessary modules, defines a function 'dummyUpdator' decorated with an unknown decorator and wrapped in 'iterateWithTempDirectory()'. It returns the string \"updated. since it is pending we will schedule another optimization\".",
        "type": "summary"
    },
    "1338": {
        "file_id": 118,
        "content": "from pyjom.commons import *\nfrom lazero.program.functools import iterateWithTempDirectory\n@decorator\n@iterateWithTempDirectory()\ndef dummyUpdator(optimized_result):\n    return \"updated. since it is pending we will schedule another optimization\"",
        "type": "code",
        "location": "/pyjom/modules/globalUpdator/dummyUpdator.py:1-7"
    },
    "1339": {
        "file_id": 118,
        "content": "The code imports necessary modules, defines a function 'dummyUpdator' decorated with an unknown decorator and wrapped in 'iterateWithTempDirectory()'. It returns the string \"updated. since it is pending we will schedule another optimization\".",
        "type": "comment"
    },
    "1340": {
        "file_id": 119,
        "content": "/pyjom/modules/globalUpdator/__init__.py",
        "type": "filepath"
    },
    "1341": {
        "file_id": 119,
        "content": "This code imports all the functions and classes from the \"dummyUpdator\" module in the \"pyjom.modules.globalUpdator.dummyUpdator\" package, allowing them to be used within this file or other parts of the program as needed.",
        "type": "summary"
    },
    "1342": {
        "file_id": 119,
        "content": "from pyjom.modules.globalUpdator.dummyUpdator import *",
        "type": "code",
        "location": "/pyjom/modules/globalUpdator/__init__.py:1-1"
    },
    "1343": {
        "file_id": 119,
        "content": "This code imports all the functions and classes from the \"dummyUpdator\" module in the \"pyjom.modules.globalUpdator.dummyUpdator\" package, allowing them to be used within this file or other parts of the program as needed.",
        "type": "comment"
    },
    "1344": {
        "file_id": 120,
        "content": "/pyjom/modules/informationGathering/weiboInfo.py",
        "type": "filepath"
    },
    "1345": {
        "file_id": 120,
        "content": "The code fetches and parses Weibo posts related to a keyword, extracting information like title, URL, author, images, and videos. It handles topic-related video searches and uses a generator function for expiry prevention.",
        "type": "summary"
    },
    "1346": {
        "file_id": 120,
        "content": "from pyjom.commons import *\nimport requests\nimport random\nimport jieba\nimport json\nimport parse\nimport urllib.parse\ndef weiboLinkSearch(keyword):\n    links = []\n    myfilter = list(jieba.cut(keyword))\n    myfilter = [x for x in myfilter if chineseDetector(x)]\n    page = random.randint(\n        1, 100\n    )  # just a demo we do not know how to handle this one just yet.\n    url = sinaWeiboApi[\"search_with_page\"].format(keyword, page)\n    with requests.get(url) as r:\n        print(\"STATUS_CODE:\", r.status_code)\n        if r.status_code == 200:\n            content = r.content.decode(\"utf-8\")\n            content = parse.parse(\"initFeed({content})\", content)\n            content = content[\"content\"]\n            # import pyperclip\n            # pyperclip.copy(content)\n            # print(content)\n            content = json.loads(content)\n            data = content[\"data\"]\n            feed1 = data[\"feed1\"]\n            for elem in feed1:\n                url = elem[\"url\"]\n                title = elem[\"title\"]\n                fsum = 0",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/weiboInfo.py:1-33"
    },
    "1347": {
        "file_id": 120,
        "content": "This code is fetching the latest 100 Weibo posts containing a specified keyword. It first tokenizes the keyword using jieba, removes non-Chinese characters using chineseDetector, and randomly selects a page number between 1 to 100. Then, it constructs a URL for Sina Weibo API's search endpoint with the selected page, retrieves the content from the URL using requests, parses the JSON response containing the latest feeds, and extracts the URL and title of each feed. The fetched data is stored in the variables 'url' and 'title', respectively.",
        "type": "comment"
    },
    "1348": {
        "file_id": 120,
        "content": "                for f in myfilter:\n                    if f in title:\n                        fsum += 1\n                if fsum == len(myfilter):\n                    links.append(url)\n            return links\ndef weiboStatusParser(content):\n    mtitle = None\n    if \"topic_struct\" in content.keys():\n        mtopic = [(x[\"topic_title\"], x[\"topic_url\"]) for x in content[\"topic_struct\"]]\n    else:\n        mtopic = None\n    mtext_raw = content[\"text_raw\"]\n    mtext = content[\"text\"]\n    mtime = content[\"created_at\"]\n    mauthor = content[\"user\"][\"screen_name\"]\n    mid = content[\"idstr\"]  # used for fetching comments.\n    mauthor_id = content[\"user\"][\"idstr\"]\n    mblogid = content[\"mblogid\"]\n    reposts_count = content[\"reposts_count\"]\n    comments_count = content[\"comments_count\"]\n    attitudes_count = content[\"attitudes_count\"]\n    mfeedback = {\n        \"reposts_count\": reposts_count,\n        \"comments_count\": comments_count,\n        \"attitudes_count\": attitudes_count,\n    }\n    mcontent = {\n        \"video\": None,\n        \"picture\": None,",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/weiboInfo.py:34-66"
    },
    "1349": {
        "file_id": 120,
        "content": "This code parses a Weibo content, extracting relevant information such as title, author, text, timestamp, and feedback count. It checks for topic structures in the content and appends URLs to a list if specific filters are met. The code returns the parsed Weibo status data and related links.",
        "type": "comment"
    },
    "1350": {
        "file_id": 120,
        "content": "        \"title\": mtitle,\n        \"topic\": mtopic,\n        \"text\": {\"raw\": mtext_raw, \"html\": mtext},\n        \"author\": mauthor,\n        \"meta\": {\"time\": mtime, \"id\": mid, \"mblogid\": mblogid, \"uid\": mauthor_id},\n        \"feedback\": mfeedback,\n    }\n    if len(content[\"pic_ids\"]) > 0 and content[\"pic_num\"] > 0:\n        print(\"picture count:\", content[\"pic_num\"])\n        content[\"picture\"] = []\n        for pid in content[\"pic_ids\"]:\n            pic_srcs = [\n                \"original\",\n                \"mw2000\",\n                \"largest\",\n                \"large\",\n                \"bmiddle\",\n                \"thumbnail\",\n            ]\n            picBase = content[\"pic_infos\"][pid]\n            picUrl = None\n            for src in pic_srcs:\n                if src in picBase.keys():\n                    picUrl = picBase[src]\n                    if \"url\" in picUrl.keys():\n                        picUrl = picUrl[\"url\"]\n                        if picUrl is not None:\n                            print(\"fetched picture [{}]\\n{}\".format(src, picUrl))",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/weiboInfo.py:67-94"
    },
    "1351": {
        "file_id": 120,
        "content": "This code is extracting and organizing information from a Weibo post. It creates a dictionary with various details including title, topic, text, author, time, id, etc. If there are pictures in the post, it fetches them based on different sizes and adds the URL to a list in the dictionary.",
        "type": "comment"
    },
    "1352": {
        "file_id": 120,
        "content": "                            break\n            if picUrl is not None:\n                content[\"picture\"].append(picUrl)\n            # only select the clearest, if possible.\n    elif \"page_info\" in content.keys():\n        print(content[\"page_info\"])  # this is how you print it.\n        videoBase = content[\"page_info\"][\"media_info\"]\n        potential_links = [\n            \"stream_url_hd\",\n            \"mp4_hd_url\",\n            \"h265_mp4_hd\",\n            \"inch_4_mp4_hd\",\n            \"inch_5_mp4_hd\",\n            \"inch_5_5_mp4_hd\",\n            \"mp4_sd_url\",\n            \"stream_url\",\n            \"h265_mp4_ld\",\n            \"mp4_720p_mp4\",\n            \"hevc_mp4_720p\",\n        ]\n        h5_url = videoBase[\"h5_url\"]\n        download_link = [videoBase[x] for x in potential_links if videoBase[x] != \"\"][0]\n        mvideo_info = {\n            \"video_orientation\": videoBase[\"video_orientation\"],\n            \"h5_url\": h5_url,\n            \"download_link\": download_link,\n        }\n        mcontent[\"video\"] = mvideo_info\n        # print(list(videoBase.keys()))",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/weiboInfo.py:95-123"
    },
    "1353": {
        "file_id": 120,
        "content": "The code checks if \"page_info\" exists in content and then proceeds to extract potential video links from the \"videoBase\". It creates a new dictionary, mvideo_info, containing the video orientation, h5_url, and download link. Finally, it adds this new dictionary to the content under the key \"video\".",
        "type": "comment"
    },
    "1354": {
        "file_id": 120,
        "content": "        if \"video_title\" not in videoBase.keys():\n            try:\n                mcontent[\"title\"] = videoBase[\"titles\"][0][\"title\"]\n            except:\n                try:\n                    mcontent[\"title\"] = videoBase[\"content2\"]\n                except:\n                    try:\n                        mcontent[\"title\"] = videoBase[\"video_title\"]\n                    except:\n                        try:\n                            mcontent[\"title\"] = videoBase[\"next_title\"]\n                        except:\n                            try:\n                                mcontent[\"title\"] = videoBase[\"cards\"][0][\"content2\"]\n                            except:\n                                mcontent[\"title\"] = videoBase[\"page_title\"]\n        else:\n            mcontent[\"title\"] = videoBase[\"video_title\"]\n    return mcontent\ndef weiboVideoSearch(keyword):\n    links = weiboLinkSearch(keyword)\n    # info = []\n    for link in links:  # use yleid here.\n        myId = link.split(\"/\")[-1]\n        # need cookie to do the job?",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/weiboInfo.py:124-151"
    },
    "1355": {
        "file_id": 120,
        "content": "The code attempts to fetch the video title from various possible keys in the 'videoBase' dictionary. If \"video_title\" doesn't exist, it tries alternative keys. It then returns the 'mcontent' dictionary containing the retrieved or default title. The function 'weiboVideoSearch' performs a keyword-based search for links and processes each link separately with a specific ID extraction method.",
        "type": "comment"
    },
    "1356": {
        "file_id": 120,
        "content": "        videoLink = sinaWeiboApi[\"weibo_status_by_blogid\"].format(\n            myId\n        )  # sina got better grammar?\n        # videoLink = \"https://www.weibo.com/ajax/status/show?id=\"+myId\n        with requests.get(videoLink) as r:\n            print(\"fetching video link:\", videoLink)\n            print(\"STATUS_CODE:\", r.status_code)\n            if r.status_code == 200:\n                content = r.text\n                # print('response content:',content)\n                # this is not formatted. this is pure json i suppose.\n                # content = parse.parse(\"initFeed({content})\",content)\n                if content == None:\n                    print(\"skipping link:\", videoLink)\n                    continue\n                # content = content[\"content\"]\n                # with open(\"{}.json\".format(myId),\"w+\",encoding=\"utf-8\") as f:\n                #     f.write(content)\n                content = json.loads(content)\n                mcontent = weiboStatusParser(content)  # this is a generator, not a list.",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/weiboInfo.py:152-171"
    },
    "1357": {
        "file_id": 120,
        "content": "Code fetches the video link using the Sina Weibo API and checks if the status code is 200. If successful, it retrieves the response content and parses it as JSON to extract relevant information. The extracted information is then processed by a generator function called weiboStatusParser.",
        "type": "comment"
    },
    "1358": {
        "file_id": 120,
        "content": "                yield mcontent # this is a generator, not a list. how to get our feedback?\n        # return info\n        # make it into generator so links will not expire so damn fast.\ndef weiboInfoLogic(topic):\n    infoDict = {}\n    for elem in topic[\"entities\"]:\n        keyword = elem[\"chinese\"]\n        if keyword is not None:\n            info = weiboVideoSearch(keyword)\n            infoDict.update({keyword: info})\n    return infoDict\n@decorator\ndef weiboInfo(topic):\n    infoDict = weiboInfoLogic(topic)\n    return infoDict\n@decorator\ndef weiboFetcher(topic):\n    mtopic_bytes = json.dumps(topic).encode()\n    protocol = \"sinafetch://{}\".format(\n        urllib.parse.quote(mtopic_bytes)\n    )  # this is the posted_location, submit to feedback. containing the keyword in json.\n    # which is not desired since in this way we will not get the feedback.\n    infoDict = weiboInfoLogic(topic)\n    return protocol, infoDict",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/weiboInfo.py:172-201"
    },
    "1359": {
        "file_id": 120,
        "content": "The code defines a function `weiboInfoLogic` that searches for videos related to a given topic and returns the results in a dictionary. It also defines a decorator (not shown) that is applied to the `weiboInfo` and `weiboFetcher` functions. The `weiboInfo` function calls `weiboInfoLogic` to gather information about the topic, while the `weiboFetcher` function constructs a protocol for submitting the topic and also calls `weiboInfoLogic`. The code uses generator to make the links not expire quickly.",
        "type": "comment"
    },
    "1360": {
        "file_id": 121,
        "content": "/pyjom/modules/informationGathering/onlineFetcher.py",
        "type": "filepath"
    },
    "1361": {
        "file_id": 121,
        "content": "OnlineFetcher is a decorator for retrieving online media assets with specific criteria using lazero libraries. It chains functions, fetches URLs from frame metadata, creates download paths and skips unsuccessful downloads while handling exceptions during Giphy asset fetching.",
        "type": "summary"
    },
    "1362": {
        "file_id": 121,
        "content": "from pyjom.commons import *\nfrom typing import Literal\nfrom lazero.network import download\nfrom lazero.filesystem import tmpdir\n@decorator\ndef OnlineFetcher(\n    infoList,\n    source: Literal[\"giphy\"] = \"giphy\",\n    frame_size_filter: dict = {\n        \"width\": {\"min\": 150, \"max\": 1000},\n        \"height\": {\"min\": 150, \"max\": 1000},\n    },\n    tempdir=\"/dev/shm/medialang/online\",\n    threads=20,\n    # threads=-0.5,\n    use_multithread=True,\n    timeout=120\n):\n    # how do you chain this shit up?\n    assert os.path.isabs(tempdir)\n    with tmpdir(path=tempdir) as TD:\n        assert os.path.isdir(tempdir)\n        assert os.path.exists(tempdir)\n        for info in infoList:  # generator most likely\n            if source == \"giphy\":\n                (source_id, frameMeta) = info\n                width, height = frameMeta[\"width\"], frameMeta[\"height\"]\n                asset_id = \"video_[{}_{}]_[{}x{}]\".format(source, source_id, width, height)\n                flag = frameSizeFilter(frameMeta, frame_size_filter)\n                if flag:",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/onlineFetcher.py:1-32"
    },
    "1363": {
        "file_id": 121,
        "content": "The function, OnlineFetcher, is a decorator that takes in a list of information and retrieves online media assets based on certain criteria such as source, frame size filter, temporary directory path, number of threads for multithreading, and timeout duration. It uses the download and tmpdir functions from lazero libraries for network downloading and temporary directories respectively. The function is chained to perform these operations.",
        "type": "comment"
    },
    "1364": {
        "file_id": 121,
        "content": "                    # this time it is selected.\n                    url = frameMeta[\"url\"]\n                    extension = url.split(\"?\")[0].split(\".\")[-1]\n                    basename = \".\".join([asset_id, extension])\n                    download_path = os.path.join(tempdir, basename)\n                    try:\n                        result = download(\n                            url,\n                            download_path,\n                            threads=threads,\n                            size_filter={\"min\": 0.4, \"max\": 50},\n                            use_multithread=use_multithread,\n                            timeout=timeout\n                        )\n                        if result:\n                            yield source_id, download_path\n                        else:\n                            print(\"not downloading source:\", source_id)\n                            print(\"skipping:\", frameMeta)\n                            # print(\"____WTF IS GOING ON WITH THE DOWNLOADER?____\")\n                            # breakpoint()",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/onlineFetcher.py:33-53"
    },
    "1365": {
        "file_id": 121,
        "content": "Code block fetches the URL from frame metadata, extracts extension and filename, creates download path, attempts to download file using specified parameters (threads, size filter, use_multithread, timeout), yields source ID and download path if successful, skips and logs if unsuccessful.",
        "type": "comment"
    },
    "1366": {
        "file_id": 121,
        "content": "                    except:\n                        import traceback\n                        traceback.print_exc()\n                        print(\"error fetching assets from giphy\")",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/onlineFetcher.py:54-57"
    },
    "1367": {
        "file_id": 121,
        "content": "This code segment catches exceptions during asset fetching from Giphy and prints the error message along with stack trace.",
        "type": "comment"
    },
    "1368": {
        "file_id": 122,
        "content": "/pyjom/modules/informationGathering/localFetcher.py",
        "type": "filepath"
    },
    "1369": {
        "file_id": 122,
        "content": "This code defines a function called filesystemFetcher that takes a topic as input. The function uses the protocol and path from the topic to create a URI. It also iterates over the content in the topic, determining the file type for each item using getLocalFileType. Finally, it adds this information to a list and returns the URI and the content.",
        "type": "summary"
    },
    "1370": {
        "file_id": 122,
        "content": "from pyjom.commons import *\n@decorator\ndef filesystemFetcher(topic):\n    protocol = topic[\"protocol\"]\n    path = topic[\"path\"]\n    content = []\n    for fname in topic[\"content\"]:\n        ftype = getLocalFileType(fname)\n        content.append({\"type\": ftype, \"path\": fname})\n    # maybe using this protocol is a good start to pass things around?\"\n    return \"{}://{}\".format(protocol, path), content",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/localFetcher.py:1-13"
    },
    "1371": {
        "file_id": 122,
        "content": "This code defines a function called filesystemFetcher that takes a topic as input. The function uses the protocol and path from the topic to create a URI. It also iterates over the content in the topic, determining the file type for each item using getLocalFileType. Finally, it adds this information to a list and returns the URI and the content.",
        "type": "comment"
    },
    "1372": {
        "file_id": 123,
        "content": "/pyjom/modules/informationGathering/dummyInfoGather.py",
        "type": "filepath"
    },
    "1373": {
        "file_id": 123,
        "content": "This function, dummyInfo, returns a list of animals (husky, cats, and kitten) without any context. It is likely used in a broader program as a placeholder or dummy information gathering module.",
        "type": "summary"
    },
    "1374": {
        "file_id": 123,
        "content": "from pyjom.commons import *\n@decorator\ndef dummyInfo(topic):\n    return [\"husky\", \"cats\", \"kitten\"]",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/dummyInfoGather.py:1-6"
    },
    "1375": {
        "file_id": 123,
        "content": "This function, dummyInfo, returns a list of animals (husky, cats, and kitten) without any context. It is likely used in a broader program as a placeholder or dummy information gathering module.",
        "type": "comment"
    },
    "1376": {
        "file_id": 124,
        "content": "/pyjom/modules/informationGathering/dummyFetcher.py",
        "type": "filepath"
    },
    "1377": {
        "file_id": 124,
        "content": "The code defines a function \"dummyFetcher\" which takes a topic as input and returns a protocol string along with a dictionary containing information about huskies. This could be used for passing data between different parts of the application.",
        "type": "summary"
    },
    "1378": {
        "file_id": 124,
        "content": "from pyjom.commons import *\n@decorator\ndef dummyFetcher(topic):\n    # maybe using this protocol is a good start to pass things around?\"\n    return \"randomprotocol://randomcontent\", {\"husky\": {\"video\": \"<cute huskies>\"}}",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/dummyFetcher.py:1-7"
    },
    "1379": {
        "file_id": 124,
        "content": "The code defines a function \"dummyFetcher\" which takes a topic as input and returns a protocol string along with a dictionary containing information about huskies. This could be used for passing data between different parts of the application.",
        "type": "comment"
    },
    "1380": {
        "file_id": 125,
        "content": "/pyjom/modules/informationGathering/__init__.py",
        "type": "filepath"
    },
    "1381": {
        "file_id": 125,
        "content": "This code imports various modules for information gathering from different sources, such as dummy, Weibo, and online services. It includes functionality for fetching data locally or from the internet.",
        "type": "summary"
    },
    "1382": {
        "file_id": 125,
        "content": "from pyjom.modules.informationGathering.dummyInfoGather import *\nfrom pyjom.modules.informationGathering.dummyFetcher import *\nfrom pyjom.modules.informationGathering.weiboInfo import *\nfrom pyjom.modules.informationGathering.localFetcher import *\nfrom pyjom.modules.informationGathering.onlineFetcher import *",
        "type": "code",
        "location": "/pyjom/modules/informationGathering/__init__.py:1-5"
    },
    "1383": {
        "file_id": 125,
        "content": "This code imports various modules for information gathering from different sources, such as dummy, Weibo, and online services. It includes functionality for fetching data locally or from the internet.",
        "type": "comment"
    },
    "1384": {
        "file_id": 126,
        "content": "/pyjom/platforms/bilibili/utils.py",
        "type": "filepath"
    },
    "1385": {
        "file_id": 126,
        "content": "The code uses functions for API synchronization, error handling, and list conversions to parse BGM information and durations. It also defines cleaning functions like `clearHtmlTags` and `detectAuthorRelatedKeywords` to remove unwanted characters and author-related keywords from video titles and tags.",
        "type": "summary"
    },
    "1386": {
        "file_id": 126,
        "content": "import types\nfrom bilibili_api import sync\n# import json\nfrom bs4 import BeautifulSoup\nfrom lazero.utils.logger import sprint\n# wtf is async generator type?\ndef bilibiliSync(func):\n    def wrapper(*args, **kwargs):\n        coroutineMaybe = func(*args, **kwargs)\n        if type(coroutineMaybe) == types.CoroutineType:\n            return sync(coroutineMaybe)\n        else:\n            return coroutineMaybe\n    return wrapper\n######## import all below functions to searchDataParser.\n# from pyjom.platforms.bilibili.utils import generatorToList, linkFixer,traceError, extractLinks,videoDurationStringToSeconds,getAuthorKeywords,clearHtmlTags,splitTitleTags,removeAuthorRelatedTags\ndef generatorToList(generator):\n    return [x for x in generator]\ndef linkFixer(link, prefix=\"http:\"):\n    if link.startswith(\"//\"):\n        return prefix + link\n    return link\ndef traceError(errorMsg: str = \"error!\", _breakpoint: bool = False):\n    import traceback\n    traceback.print_exc()\n    sprint(errorMsg)\n    if _breakpoint:\n        return breakpoint()",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/utils.py:1-41"
    },
    "1387": {
        "file_id": 126,
        "content": "This code is related to the bilibili platform and contains functions for synchronizing API calls, converting generator to list, fixing links, handling errors with traceback, and more. It's likely part of a larger project focused on working with the bilibili API.",
        "type": "comment"
    },
    "1388": {
        "file_id": 126,
        "content": "def extractLinks(description, extract_bgm=True):\n    \"\"\"Extract and remove links in description\"\"\"\n    import re\n    # notice, we don't need to go wild here. we just want the title and the cover, and the tags.\n    expression = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n    # expr = re.compile(expression)\n    links = re.findall(expression, description)\n    # if links == None:\n    #     links = []\n    desc_without_link = re.sub(expression, \"\", description)\n    desc_without_link_per_line = [\n        x.replace(\"\\n\", \"\").strip() for x in desc_without_link.split(\"\\n\")\n    ]\n    desc_without_link_per_line = [x for x in desc_without_link_per_line if len(x) > 0]\n    bgms = []\n    final_desc_list = []\n    if not extract_bgm:\n        final_desc_list = desc_without_link_per_line\n    else:\n        for line in desc_without_link_per_line:\n            bgmCandidateTemplates = [\"{}\", \"{}:\", \"{} \"]\n            fixers = [x.format(\"\") for x in bgmCandidateTemplates]\n            bgmCandidates = [x.format(\"bgm\") + \"(.+)\" for x in bgmCandidateTemplates]",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/utils.py:44-67"
    },
    "1389": {
        "file_id": 126,
        "content": "The code defines a function `extractLinks` that takes in a description and optionally extracts background music (BGM) links. It uses regular expressions to find and remove links from the description, then splits the description into lines. If BGM extraction is enabled, it searches for BGM candidates using templates and formats them correctly. The final result is a list of non-empty lines without links or potential BGM information if BGM extraction is disabled.",
        "type": "comment"
    },
    "1390": {
        "file_id": 126,
        "content": "            has_bgm = False\n            for candidate in bgmCandidates:\n                bgm_parse_result = re.findall(candidate, line.lower())\n                if len(bgm_parse_result) > 0:\n                    has_bgm = True\n                    # bgm = line[len(bgmCandidates) :]\n                    bgm = bgm_parse_result[0]\n                    bgm = bgm.strip()\n                    for fixer in fixers:\n                        bgm = bgm.strip(fixer)\n                    if len(bgm) > 0:\n                        bgms.append(bgm)\n                    break\n            if not has_bgm:\n                final_desc_list.append(line)\n    desc_without_link = \"\\n\".join(final_desc_list)\n    return links, bgms, desc_without_link\nfrom typing import Literal\nimport re\nfrom typing import Union\ndef videoDurationStringToSeconds(\n    durationString:Union[str, None], method: Literal[\"vtc\", \"basic\"] = \"vtc\"\n):\n    if durationString in [\"-\", None]:\n        return None\n    if type(durationString) != str:\n        return None\n    if re.findall(r\"\\d\", durationString) == []:",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/utils.py:68-99"
    },
    "1391": {
        "file_id": 126,
        "content": "The code is parsing a line for background music (BGM) information using regular expressions. If BGM is found, it appends to bgms list; if not, the line is added to final_desc_list. The function videoDurationStringToSeconds converts video duration string to seconds based on given method (vtc or basic). It checks for invalid input (empty string or None) and returns None in those cases.",
        "type": "comment"
    },
    "1392": {
        "file_id": 126,
        "content": "        return None\n    try:\n        if method == \"vtc\":\n            import vtc\n            timecode = \"{}:0\".format(durationString)\n            decimal_seconds = vtc.Timecode(timecode, rate=1).seconds\n            seconds = round(decimal_seconds)\n            return seconds\n        elif method == \"basic\":\n            if type(durationString) == int:\n                return durationString  # not string at all.\n            if type(durationString) != str:\n                print(\"unknown durationString type: %s\" % type(durationString))\n                return None\n            durationString = durationString.strip()\n            mList = durationString.split(\":\")[::-1]\n            if len(mList) > 3:\n                print(\"DURATION STRING TOO LONG\")\n                return None\n            seconds = 0\n            for index, elem in enumerate(mList):\n                elem = int(elem)\n                seconds += (60**index) * elem\n            return seconds\n        else:\n            raise Exception(\"method %s does not exist\" % method)",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/utils.py:100-126"
    },
    "1393": {
        "file_id": 126,
        "content": "This function converts a duration string, either in basic format or \"vtc\" method, into seconds. It checks the input type and handles invalid formats, returning None for errors or the converted duration in seconds if successful.",
        "type": "comment"
    },
    "1394": {
        "file_id": 126,
        "content": "    except:\n        import traceback\n        traceback.print_exc()\n        print(\"exception durion video duration string conversion\")\ndef clearHtmlTags(htmlObject):\n    a = BeautifulSoup(htmlObject, features=\"lxml\")\n    return a.text\ndef detectAuthorRelatedKeywords(title_tag, author_keywords):\n    abandon = False\n    for keyword in author_keywords:\n        if len(keyword) > 1:\n            if keyword in title_tag:\n                abandon = True  # detected this thing.\n                break\n    return abandon\ndef getAuthorKeywords(author):\n    author = author.strip()\n    import jieba\n    author_keywords = jieba.lcut(author)\n    author_keywords = [x.strip() for x in author_keywords]\n    author_keywords = [x for x in author_keywords if len(x) > 0]\n    return author_keywords\ndef removeAuthorRelatedTags(description_or_title, author):\n    templates = [\"{}\", \"@{}\", \"{}\"]\n    tags = [template.format(author) for template in templates]\n    for tag in tags:\n        description_or_title = description_or_title.replace(tag, \"\")",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/utils.py:127-163"
    },
    "1395": {
        "file_id": 126,
        "content": "The code defines several functions:\n1. `clearHtmlTags` removes HTML tags from an object using BeautifulSoup and returns the text content.\n2. `detectAuthorRelatedKeywords` checks if a given title contains any keywords from a list of author-related keywords, returning True if detected.\n3. `getAuthorKeywords` takes an author's name, tokenizes it with Jieba, filters out empty strings and returns a list of non-empty tokens.\n4. `removeAuthorRelatedTags` replaces specific author-related tags in the description or title with an empty string.",
        "type": "comment"
    },
    "1396": {
        "file_id": 126,
        "content": "    return description_or_title\ndef splitTitleTags(title, author_keywords):\n    import re\n    pattern = r\".+\"\n    title_tags = re.findall(pattern, title)\n    title = re.sub(pattern, \"\", title)\n    title_tags = [x.lstrip(\"\").rstrip(\"\").strip() for x in title_tags]\n    title_tags = [x for x in title_tags if len(x) > 0]\n    final_title_tags = []\n    for title_tag in title_tags:\n        detected = detectAuthorRelatedKeywords(title_tag, author_keywords)\n        if not detected:\n            final_title_tags.append(title_tag)\n    return title, title_tags",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/utils.py:164-181"
    },
    "1397": {
        "file_id": 126,
        "content": "This function splits the title and tags in a video using regular expressions, removes unnecessary characters, filters out empty strings, and detects author-related keywords. It returns the cleaned title and a list of remaining title tags.",
        "type": "comment"
    },
    "1398": {
        "file_id": 127,
        "content": "/pyjom/platforms/bilibili/uploader.py",
        "type": "filepath"
    },
    "1399": {
        "file_id": 127,
        "content": "This code uses bilibili_api module to create an asynchronous function and class for uploading videos to Bilibili platform. It supports multithreading, retry mechanisms, and profile settings, with exception handling and result validation.",
        "type": "summary"
    }
}