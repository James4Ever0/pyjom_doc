{
    "3400": {
        "file_id": 411,
        "content": "// https://nodejs.org/api/esm.html\n// no template string available. shit.\n// import { Readable } from 'stream'\nimport WebTorrent from 'webtorrent'\n// // const WebTorrent = await import('webtorrent')\nconsole.log(\"WEBTORRENT OBJECT?\",WebTorrent)\nconst client=new WebTorrent({dht: true}) // nothing reading out. guess this is fucked.\n// please cache files under some KNOWN directories. otherwise, i will be fucked.\nconst serverPort=8970\nconst instance=client.createServer()\ninstance.server.listen(serverPort) // not random port? not zero? \nconst config={}\n// https://github.com/webtorrent/webtorrent/blob/master/docs/api.md#clientaddtorrentid-opts-function-ontorrent-torrent-\nconfig.path=process.cwd() // download to current directory?\n// pass different temp directory name for different torrents to prevent name clash? but what about the streaming URL?\n// default=`/tmp/webtorrent/`\n// now i fucking got you!\n// add trackers?\n// config.announce=[\"\"]\nclient.add(torrentPath,config,(torrent) => {\n    var selectedFile=torrent.files.find(file => {",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/webtorrent_streaming_test_cut_partial_download.mjs:42-72"
    },
    "3401": {
        "file_id": 411,
        "content": "Code imports WebTorrent, creates a new client with DHT enabled, starts a server on port 8970, adds a torrent from the specified path using the default configuration, and searches for the desired file in the torrent's files.",
        "type": "comment"
    },
    "3402": {
        "file_id": 411,
        "content": "        // console.log(\"FILENAME?\", file.name)\n        // it will only select the first file matching the criterion.\n        // return file.name.endsWith('.mkv')\n        return file.path==selectedFilePath\n    })\n    // console.log(\"SELECTED FILE?\")\n    // console.log(selectedFile)\n    // exit here?\n    // process.exit()\n    // now pass to fluent-ffmpeg.\n    // https://github.com/leeroybrun/webtorrent-transcode\n    setInterval(() => {console.log(\"SPEED?\",client.downloadSpeed)},2000) // why speed is zero now? wtf? are you finished?\n    // *******************READSTREAM RELATED*******************\n    // https://github.com/webtorrent/webtorrent/issues/2464\n    // const stream = Readable.from(selectedFile) // are you sure?\n    // this sucks. pipe is not seekable. consider something else? (like unix domain socket)\n    // var stream=selectedFile.createReadStream() // not working! fuck.\n    // // // var stream = fs.createReadStream(\"/Users/jamesbrown/Downloads/anime_download/[Sakurato] Onii-chan wa Oshimai! [01][AVC-8bit 1080p AAC][CHT].mp4\")",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/webtorrent_streaming_test_cut_partial_download.mjs:73-95"
    },
    "3403": {
        "file_id": 411,
        "content": "The code is filtering files based on their name or path to match a predetermined file. It then logs the download speed periodically and attempts to create a readable stream from the selected file. The comments indicate frustration with non-working solutions, suggesting alternative approaches like Unix domain sockets or other methods for better performance.",
        "type": "comment"
    },
    "3404": {
        "file_id": 411,
        "content": "    // stream.unpipe=(nodeStream) => { } //doing nothing?\n    // stream.on('error',function(err) {\n    //     console.log('STREAM ERROR?',err);\n    //     // just ignore it?\n    // })\n    // console.log(\"STREAM?\",stream)\n    // while(true) {\n    //     var buffer=stream.read(200)\n    //     console.log(\"READING:\",buffer)\n    // }\n    // var reading=false\n    // stream.on('readable',function() {\n    //     if(!reading) {\n    //         reading=true\n    //         console.log(\"STREAM READABLE\")\n    //         ffmpeg(stream).ffprobe((err,data) => {\n    //             if(err) {\n    //                 console.log(\"FFPROBE ERROR:\",err)\n    //             } else {\n    //                 console.log(\"FFPROBE METADATA:\",data)\n    //             }\n    //             process.exit()\n    //         })\n    //     }\n    // })\n    // duration is fake.\n    // ffmpeg(stream).ffprobe((err,data) => {\n    //     if(err) {\n    //         console.log(\"FFPROBE ERROR:\",err)\n    //     } else {\n    //         console.log(\"FFPROBE METADATA:\",data)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/webtorrent_streaming_test_cut_partial_download.mjs:96-130"
    },
    "3405": {
        "file_id": 411,
        "content": "This code appears to be attempting to read a stream using ffmpeg and retrieve metadata. It handles potential errors, but the unpipe function seems unused, and it might be designed for testing purposes or handling partial downloads. The while loop for continuous reading may not be functional as well.",
        "type": "comment"
    },
    "3406": {
        "file_id": 411,
        "content": "    //     }\n    //     // process.exit()\n    // })\n    // ffmpeg(stream).seekInput('0:10').duration(\"0:15\").on('progress',function(progress) {\n    //     // why not showing progress?\n    //     console.log('FFmpeg Processing: '+progress.percent+'% done');\n    // }).on('end',() => {\n    //     console.log(\"FFMPEG EXECUTION COMPLETE?\")\n    //     // let's rerun.\n    //     // instance.close()\n    //     client.destroy()\n    //     process.exit()\n    //     // the time range simply does not exist.\n    // }).outputOptions(['-c copy','-y']).output('output.mkv').run() // still not working?\n    // *******************READSTREAM RELATED*******************\n    // how about let's use url?\n    // how to urlencode?\n    // var urlSuffix = encodeURIComponent(selectedFilePath)\n    var fileRequestUrl=`http://localhost:${serverPort}`+selectedFile.streamURL\n    // console.log(\"STREAMING URL?\",fileRequestUrl)\n    // http://localhost:8970/webtorrent/421d78cadb5e1bb4fc1fec9dc2d6680e810c13c2/%5BKamigami&VCB-Studio%5D%20Yahari%",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/webtorrent_streaming_test_cut_partial_download.mjs:131-158"
    },
    "3407": {
        "file_id": 411,
        "content": "This code snippet attempts to download a video file, process it using FFmpeg and stream it over Webtorrent. It encodes the streaming URL for the video and logs progress during the FFmpeg processing. The code may have issues with the FFmpeg processing not showing progress and potential problems in the readstream implementation.",
        "type": "comment"
    },
    "3408": {
        "file_id": 411,
        "content": "20Ore%20no%20Seishun%20Lovecome%20wa%20Machigatte%20Iru.%20%5BMa10p_1080p%5D/SPs/%5BKamigami&VCB-Studio%5D%20Yahari%20Ore%20no%20Seishun%20Lovecome%20wa%20Machigatte%20Iru.%20%5BCM01%5D%5BMa10p_1080p%5D%5Bx265_flac%5D.mkv\n    //shit?\n    // ffmpeg(fileRequestUrl).ffprobe((err,data) => {\n    //     if(err) {\n    //         console.log(\"FFPROBE ERROR:\",err)\n    //     } else {\n    //         console.log(\"FFPROBE METADATA:\",data)\n    //         var duration=data.format.duration\n    //         console.log(\"VIDEO DURATION?\",duration)\n    //         // you'd better read this. you fuck!\n    //         // i ask for 10 secs.\n    //         // output still contains metadata. but do we have subtitles?\n    //         // seeking is not so accurate but in minutes? easy.\n    //         // for file under 1 minute, please do not seek ok? (seek locally?)\n    //         // do not seek for segments that are too short. seek larger segments!\n    ffmpeg(fileRequestUrl).seekInput('0:10').duration(\"0:15\").on('progress',function(progress) {",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/webtorrent_streaming_test_cut_partial_download.mjs:158-176"
    },
    "3409": {
        "file_id": 411,
        "content": "This code uses FFmpeg to seek and download a video segment from the given URL. It seeks to 10 seconds, sets the duration to 15 seconds, and handles progress updates.",
        "type": "comment"
    },
    "3410": {
        "file_id": 411,
        "content": "        console.log('FFmpeg Processing: '+progress.percent+'% done');\n    }).on('end',() => {\n        console.log(\"FFMPEG EXECUTION COMPLETE?\")\n        // let's rerun.\n        instance.close()\n        client.destroy()\n        process.exit()\n        // the time range simply does not exist.\n    }).outputOptions(['-c copy',\n        '-y']).output('output.mkv').run()\n    // not top-level function or async function. fuck.\n})",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/webtorrent_streaming_test_cut_partial_download.mjs:177-188"
    },
    "3411": {
        "file_id": 411,
        "content": "The code is closing the FFmpeg instance and destroying the client after a torrent download completes. It also logs progress updates during the download process and ends the program execution upon completion.",
        "type": "comment"
    },
    "3412": {
        "file_id": 412,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/torrent_analyzer.py",
        "type": "filepath"
    },
    "3413": {
        "file_id": 412,
        "content": "The code snippet imports libraries, defines paths and analyzes a torrent file using torrent_parser. It prints the data, checks for multiple files, stores their names and lengths (if applicable), formats size, prints file details, writes filenames to JSON, and prepares the file for further processing.",
        "type": "summary"
    },
    "3414": {
        "file_id": 412,
        "content": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport os\n# single file.\n# torrent_path = \"[桜都字幕組] 不當哥哥了！ _ Onii-chan wa Oshimai! [01][1080p][繁體內嵌].torrent\"\ntorrent_path = \"[Kamigami&VCB-Studio] Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p].torrent\"\nbasepath = \"/Users/jamesbrown/Downloads/anime_download\"\ntorrent_path = os.path.join(basepath, torrent_path)\n# analyze this torrent file.\nimport torrent_parser as tp\ndata = tp.parse_torrent_file(torrent_path)\nimport rich\nrich.print(data)\n# will be complete name later?\nsingle_file = not('files' in data['info'].keys())\n# data['info']['name'] \n# length will be total length?\n# data['info']['length']\n# breakpoint()\n# does it preserve the order?\n# import humanize\n# well.\nfnames=[]\nimport json\nfrom humanfriendly import format_size\nif not single_file:\n    for index, fileInfo in enumerate(data['info']['files']):\n        aria2c_index = index+1\n        length = fileInfo['length']\n        path = fileInfo['path'] # multiple strings in a list\n        joined_path = \"/\".join(path)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/torrent_analyzer.py:1-41"
    },
    "3415": {
        "file_id": 412,
        "content": "Code snippet imports necessary libraries, defines a torrent file path and basepath for downloads, joins the paths, analyzes the torrent file using torrent_parser, prints the parsed data, checks if the torrent contains multiple files or not, stores the name and length of each file (if applicable), converts file paths to single string format, and finally prepares the file for further processing.",
        "type": "comment"
    },
    "3416": {
        "file_id": 412,
        "content": "        filesize_human_readable = format_size(length)\n        print(f\"[{aria2c_index}] ** [{filesize_human_readable}] ** {path[-1]}\")\n        # the index is right.\n        fnames.append(path[-1])\n        print(f\"FULLPATH: {joined_path}\")\nwith open(\"test_filenames.json\",'w+') as f:\n    f.write(json.dumps(fnames))",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/torrent_analyzer.py:42-49"
    },
    "3417": {
        "file_id": 412,
        "content": "This code snippet formats the file size in human-readable format and prints it along with the aria2c index, file name, and full path. It then stores the filenames in a list and writes them to a JSON file named \"test_filenames.json\".",
        "type": "comment"
    },
    "3418": {
        "file_id": 413,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/subtitle_extractor.py",
        "type": "filepath"
    },
    "3419": {
        "file_id": 413,
        "content": "This code references three different tools for extracting subtitles from a video file: mkvextract, ffmpeg, and optical character recognition (OCR). It suggests using the appropriate tool based on the source being processed, with the assumption that it's easier to extract subtitles from fixed locations in Bangumi videos.",
        "type": "summary"
    },
    "3420": {
        "file_id": 413,
        "content": "# use mkvextract:\n# https://github.com/jorti/extract-subs/blob/master/extract-subs.py\n# use ffmpeg:\n# https://github.com/fdenivac/ffextract-subtitles/blob/master/ffextract-subtitles.py\n# use ocr to extract subtitles. since this is bangumi, it is easy to extract from fixed location.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/subtitle_extractor.py:1-7"
    },
    "3421": {
        "file_id": 413,
        "content": "This code references three different tools for extracting subtitles from a video file: mkvextract, ffmpeg, and optical character recognition (OCR). It suggests using the appropriate tool based on the source being processed, with the assumption that it's easier to extract subtitles from fixed locations in Bangumi videos.",
        "type": "comment"
    },
    "3422": {
        "file_id": 414,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_torrent_file_list.py",
        "type": "filepath"
    },
    "3423": {
        "file_id": 414,
        "content": "This code fetches data from the Nyaa.si website using requests library, parses it using NyaaPy's utils and torrent modules, and prints the parsed JSON data and the corresponding data class object.",
        "type": "summary"
    },
    "3424": {
        "file_id": 414,
        "content": "url = \"https://nyaa.si/view/1627038\"\nimport requests\nfrom NyaaPy import utils, torrent\nr = requests.get(url)\nSITE = utils.TorrentSite.NYAASI\njson_data = utils.parse_single(request_text=r.text, site=SITE)\ndata_class = torrent.json_to_class(json_data)\nimport rich\n# json_data['seeders']\n# json_data['title']\n# json_data['files']\nrich.print(json_data)\nprint()\nprint(\"_\"*20)\nprint()\nrich.print(data_class)\nbreakpoint()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_torrent_file_list.py:1-25"
    },
    "3425": {
        "file_id": 414,
        "content": "This code fetches data from the Nyaa.si website using requests library, parses it using NyaaPy's utils and torrent modules, and prints the parsed JSON data and the corresponding data class object.",
        "type": "comment"
    },
    "3426": {
        "file_id": 415,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_api_connector.py",
        "type": "filepath"
    },
    "3427": {
        "file_id": 415,
        "content": "The Python script uses requests and BeautifulSoup to search the Nyaa torrent site for anime with 7+ seeders, retrieves results, stores in \"output.html\", and checks if more pages exist using a template and NyaaPy library for torrent handling.",
        "type": "summary"
    },
    "3428": {
        "file_id": 415,
        "content": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport requests\nurl = \"https://nyaa.si\" # change this to mirror sites.\nMIN_SEEDERS=7 # must be greater than this.\nquery = \"oniichan wa oshimai! 01\"\nsort_term = \"seeders\"\nanime_categories = {\n    \"Anime\": \"1_0\",\n    \"Anime - Anime Music Video\": \"1_1\",\n    \"Anime - English-translated\": \"1_2\",\n    \"Anime - Non-English-translated\": \"1_3\",\n    \"Anime - Raw\": \"1_4\",\n}\ncategory_code = anime_categories[\"Anime\"]  # anime\npage = 1  # start page: 1\nend_of_page = False\n# better not to use rss version since it will not sort terms.\nparams = dict(f=0, c=category_code, q=query, s=sort_term, o=\"desc\", p=page)\n# better parse it yourself first huh?\n# r = requests.get(url, params=params)\n# assert r.code == 200\n# text = r.text\nwith open(\"output.html\", \"r\") as f:\n    text = f.read()\nfrom bs4 import BeautifulSoup\n# with open(\"output.html\",'w+') as f:\n#    f.write(text)\nsoup = BeautifulSoup(text, \"html.parser\")\n# breakpoint()\nimport parse\ntemplate = \"Displaying results {start:d}-{end:d} out of {total:d} results.\"",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_api_connector.py:1-48"
    },
    "3429": {
        "file_id": 415,
        "content": "The code is a Python script that uses the requests library to make an API request to the Nyaa torrent site. It searches for a specific anime with 7 or more seeders, retrieves the results, and stores them in a file named \"output.html\". The BeautifulSoup library is used to parse the HTML response, and the parse module seems to be utilized for further processing.",
        "type": "comment"
    },
    "3430": {
        "file_id": 415,
        "content": "banner = soup.find(\"div\", class_=\"pagination-page-info\").text\npagination_info = banner.split(\"\\n\")[0]\npagination_info_result = parse.parse(template, pagination_info)\nif pagination_info_result:\n    if pagination_info_result[\"total\"] == pagination_info_result[\"end\"]:\n        print(\"Reached end of page.\")\n        end_of_page = True\nfrom NyaaPy import utils\nSITE = utils.TorrentSite.NYAASI\njson_info = utils.parse_nyaa(request_text=text, limit=None, site=SITE)\nimport rich\nrich.print(json_info)\n# breakpoint()\nfor videoInfo in json_info:\n    seeders = int(videoInfo['seeders'])\n    seeders_enough = seeders>=MIN_SEEDERS\n    print('seeders?',seeders)\n    print(\"seeders enough?\", seeders_enough)\n    # videoInfo['id'] -> \"https://nyaa.si/view/{}\"\n# you can also download torrent file for only file info.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_api_connector.py:50-77"
    },
    "3431": {
        "file_id": 415,
        "content": "The code retrieves the banner from a webpage, extracts pagination information, and checks if it has reached the end of the page. It then parses the response using a template and determines if there are enough seeders for each video info. The code prints the number of seeders and whether they are enough based on a minimum seeders threshold. The code uses the NyaaPy library for site-specific torrent handling.",
        "type": "comment"
    },
    "3432": {
        "file_id": 416,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py",
        "type": "filepath"
    },
    "3433": {
        "file_id": 416,
        "content": "The code utilizes ffmpeg to extract subtitles, sets anime series constants, filters series names, and reads filenames from a JSON. It checks for bangume names, identifies episode index location, compares with expected position, and prints the episode index or displays \"EPISODE?\" if not recognized.",
        "type": "summary"
    },
    "3434": {
        "file_id": 416,
        "content": "subtitle_types = [\"ass\", \"srt\"]\nvideo_types = [\n    \"mkv\",\n    \"mov\",\n    \"mp4\",\n    \"flv\",\n    \"avi\",\n    \"ogv\",\n    \"webm\",\n    \"ts\",\n    \"wmv\",\n    \"webm\",\n    \"m4v\",\n    \"3gp\",\n]\n# use ffmpeg for subtitle extraction?\nfiletypes = {\"subtitle\": subtitle_types, \"video\": video_types}\nBangumi_Name = \"Yahari Ore no Seishun Lovecome wa Machigatte Iru.\".strip()\nepisodeIndex = 3\nchinese_simplified_sub_types = [\"chs\", \"简体\", \"简日\"]\nchinese_traditional_sub_types = [\"繁日\", \"繁体\", \"繁體\", \"cht\"]\nimport json\n# replace non-alphanumeric charcters.\nepisode_formatter = lambda episode_index: str(episode_index).zfill(2)\nimport re\n# also replace all double spaces.\ndef double_space_replacer(chars: str):\n    if \"  \" in chars:\n        chars = chars.replace(\"  \", \" \")\n        return double_space_replacer(chars)\n    else:\n        return chars\nalphanumeric_filter = lambda chars: double_space_replacer(\n    re.sub(r\"[^a-z0-9]\", \" \", chars)\n)\nbangume_name_lower_alphanumeric = alphanumeric_filter(Bangumi_Name.lower())\nwith open(\"test_filenames.json\", \"r\") as f:",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py:1-46"
    },
    "3435": {
        "file_id": 416,
        "content": "This code defines file types for subtitles and videos, uses ffmpeg for subtitle extraction, defines constants related to a specific anime series, applies an alphanumeric filter to the anime name, and reads filenames from a JSON file.",
        "type": "comment"
    },
    "3436": {
        "file_id": 416,
        "content": "    fnames = json.loads(f.read())\nfor fname in fnames:\n    fname_lower = fname.lower()\n    fname_lower_alphanumeric = alphanumeric_filter(fname_lower)\n    file_extension = fname_lower.split(\".\")[-1]\n    current_file_type = \"unknown\"\n    for filetype, file_extensions in filetypes.items():\n        if file_extension in file_extensions:\n            current_file_type = filetype\n            break\n    print(f\"<{current_file_type}> {fname}\")\n    print(fname_lower_alphanumeric)\n    substring_location_start = fname_lower_alphanumeric.find(\n        bangume_name_lower_alphanumeric\n    )\n    if substring_location_start!=-1:\n        substring_location_end = substring_location_start + len(\n        bangume_name_lower_alphanumeric\n    )\n        assert fname_lower_alphanumeric[substring_location_start: substring_location_end] == bangume_name_lower_alphanumeric\n        episodeIndexLocation = fname_lower_alphanumeric.find(f\" {episode_formatter(episodeIndex)} \")\n        if episodeIndexLocation!=-1:\n            if episodeIndexLocation+1>=substring_location_end:",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py:47-71"
    },
    "3437": {
        "file_id": 416,
        "content": "Reading file names from a JSON, filtering, and determining their types. Checking if the bangume name substring is present in the filename. Identifying the episode index location and comparing it with the expected position.",
        "type": "comment"
    },
    "3438": {
        "file_id": 416,
        "content": "                print(\"EPISODE?\") # this is the index we want\n                print(episodeIndex)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py:72-73"
    },
    "3439": {
        "file_id": 416,
        "content": "Code snippet checks the episode index and prints it. If the desired index is not recognized, it displays \"EPISODE?\" for clarification.",
        "type": "comment"
    },
    "3440": {
        "file_id": 417,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/name_fuzzy.py",
        "type": "filepath"
    },
    "3441": {
        "file_id": 417,
        "content": "This code initializes two empty lists, 'filenames' and 'bangumi_names'. 'bangumi_names' contains two string values representing anime titles.",
        "type": "summary"
    },
    "3442": {
        "file_id": 417,
        "content": "filenames = []\nbangumi_names= [\"Yahari Ore no Seishun Lovecome wa Machigatte Iru.\",\"Yahari Ore no Seishun Love Come wa Machigatteiru.\"]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_fuzzy.py:1-3"
    },
    "3443": {
        "file_id": 417,
        "content": "This code initializes two empty lists, 'filenames' and 'bangumi_names'. 'bangumi_names' contains two string values representing anime titles.",
        "type": "comment"
    },
    "3444": {
        "file_id": 418,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/make_node_symlink.sh",
        "type": "filepath"
    },
    "3445": {
        "file_id": 418,
        "content": "This script creates a symbolic link named \"node_modules\" pointing to the $NODE_PATH, presumably to resolve or fix an issue with file locations.",
        "type": "summary"
    },
    "3446": {
        "file_id": 418,
        "content": "ln -s $NODE_PATH node_modules # to fix shit.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/make_node_symlink.sh:1-1"
    },
    "3447": {
        "file_id": 418,
        "content": "This script creates a symbolic link named \"node_modules\" pointing to the $NODE_PATH, presumably to resolve or fix an issue with file locations.",
        "type": "comment"
    },
    "3448": {
        "file_id": 419,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/kill_aria2c.sh",
        "type": "filepath"
    },
    "3449": {
        "file_id": 419,
        "content": "This command is killing the aria2c process with a SIGINT signal, specifically targeting the specified anime episode titled 'Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' from the Kamigami & VCB-Studio group.",
        "type": "summary"
    },
    "3450": {
        "file_id": 419,
        "content": "ps aux | grep '[Kamigami&VCB-Studio] Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' | grep -v grep | awk '{print $1}' | xargs -Iabc kill -s INT abc",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/kill_aria2c.sh:1-1"
    },
    "3451": {
        "file_id": 419,
        "content": "This command is killing the aria2c process with a SIGINT signal, specifically targeting the specified anime episode titled 'Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' from the Kamigami & VCB-Studio group.",
        "type": "comment"
    },
    "3452": {
        "file_id": 420,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/dynamic_import.mjs",
        "type": "filepath"
    },
    "3453": {
        "file_id": 420,
        "content": "Code imports and initializes two modules, FfmpegCommand and WebTorrent, using dynamic import. The code checks the data types of the imported functions, with FfmpegCommand being a function and WebTorrent appearing as a class in the console despite its data type being \"function\".",
        "type": "summary"
    },
    "3454": {
        "file_id": 420,
        "content": "const FfmpegCommand = (await import(`${process.env.NODE_PATH}/fluent-ffmpeg/index.js`)).default \nconst WebTorrent = (await import(`${process.env.NODE_PATH}/webtorrent/index.js`)).default \n// promise!\n// shit this ESM can directly use await statements.\nconsole.log(FfmpegCommand)\nconsole.log(typeof(FfmpegCommand)) // \"function\", with default name.\nconsole.log(WebTorrent)\nconsole.log(typeof(WebTorrent)) // \"function\"? why i see \"class\" in console.log?\n// this syntax is not recommended. autocompletion will not work.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/dynamic_import.mjs:1-12"
    },
    "3455": {
        "file_id": 420,
        "content": "Code imports and initializes two modules, FfmpegCommand and WebTorrent, using dynamic import. The code checks the data types of the imported functions, with FfmpegCommand being a function and WebTorrent appearing as a class in the console despite its data type being \"function\".",
        "type": "comment"
    },
    "3456": {
        "file_id": 421,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/download_given_file_to_given_name.sh",
        "type": "filepath"
    },
    "3457": {
        "file_id": 421,
        "content": "This script downloads a torrent file using aria2c and removes temporary files once finished. The script sets the base path, torrent name, and file ID for the download. It also includes two different command variations for stopping the download after completion with timeout options. The commands use kill and grep to end the aria2c process with a signal and remove temporary files.",
        "type": "summary"
    },
    "3458": {
        "file_id": 421,
        "content": "# how to end downloading when finished?\n# using some command?\nBASE_PATH=\"/Users/jamesbrown/Downloads/anime_download\"\n# DOWNLOAD_FILE_PATH=\"$BASE_PATH/sample.webp\"\nTORRENT_NAME=\"[Kamigami&VCB-Studio] Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]\"\n# torrent name might be different.\nTORRENT_PATH=\"$BASE_PATH/$TORRENT_NAME.torrent\"\n# echo \"ps aux | grep '$TORRENT_NAME' | grep -v grep | awk '{print \\$1}' | xargs -Iabc kill -s INT abc\" > kill_aria2c.sh\nFILE_ID=\"117\"\n# timeout set to what?\n# rm \"$DOWNLOAD_FILE_PATH\"\nrm -rf \"$TORRENT_NAME\"\nrm -rf \"$TORRENT_NAME.aria2\"\n# this will be ignored.\n# change directory to our temp directory.\n# this speed shall be precalculated.\n# \n# you may check integrity.\n# just count seeders.\n# aria2c -x 16 --select-file=\"$FILE_ID\" --seed-time=0 --file-allocation=none \"$TORRENT_PATH\"\n# aria2c -x 16 --select-file=\"$FILE_ID\" --seed-time=0 --file-allocation=none --lowest-speed-limit=300K --bt-stop-timeout=60 \"$TORRENT_PATH\"",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/download_given_file_to_given_name.sh:1-27"
    },
    "3459": {
        "file_id": 421,
        "content": "This script downloads a torrent file using aria2c and removes temporary files once finished. The script sets the base path, torrent name, and file ID for the download. It also includes two different command variations for stopping the download after completion with timeout options. The commands use kill and grep to end the aria2c process with a signal and remove temporary files.",
        "type": "comment"
    },
    "3460": {
        "file_id": 422,
        "content": "/tests/apple_prores_encoding_play/test.sh",
        "type": "filepath"
    },
    "3461": {
        "file_id": 422,
        "content": "This script encodes a video file using FFmpeg with the prores_aw encoder and saves it in an Apple ProRes format. The code uses the vulkan hardware acceleration and sets the output container format to .mkv. It also provides alternative options for encoding in ProRes 422 or 4444 HQ, specifying profile, vendor, bits per MB, and pixel format. It mentions allowed container formats for ProRes as .mov, .mkv, and .mxf.",
        "type": "summary"
    },
    "3462": {
        "file_id": 422,
        "content": "videoPath=\"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\n# prores_aw\nffmpeg -hwaccel vulkan -i $videoPath -c:v prores_ks  output.mkv\n# https://ottverse.com/ffmpeg-convert-to-apple-prores-422-4444-hq/#:~:text=FFmpeg%20contains%20two%20ProRes%20encoders%2C%20the%20prores-aw%20and,option%20to%20choose%20the%20ProRes%20profile%20to%20encode.\n# videoPath=\"/Users/jamesbrown/Desktop/works/pyjom_remote/samples/video/cute_cat_gif.mp4\"\n# ffmpeg -hwaccel videotoolbox -i $videoPath -c:v prores_ks  \\\n# -profile:v 4 \\\n# -vendor apl0 \\\n# -bits_per_mb 8000 \\\n# -pix_fmt yuva444p10le \\ \n# output.mov\n# Do remember to store the output in either of these three formats that are allowed as containers for the ProRes format.\n# .mov (QuickTime)\n# .mkv (Matroska)\n# .mxf (Material eXchange Format)",
        "type": "code",
        "location": "/tests/apple_prores_encoding_play/test.sh:1-16"
    },
    "3463": {
        "file_id": 422,
        "content": "This script encodes a video file using FFmpeg with the prores_aw encoder and saves it in an Apple ProRes format. The code uses the vulkan hardware acceleration and sets the output container format to .mkv. It also provides alternative options for encoding in ProRes 422 or 4444 HQ, specifying profile, vendor, bits per MB, and pixel format. It mentions allowed container formats for ProRes as .mov, .mkv, and .mxf.",
        "type": "comment"
    },
    "3464": {
        "file_id": 423,
        "content": "/tests/mmd_human_dance_pose/test_detection_yolo.py",
        "type": "filepath"
    },
    "3465": {
        "file_id": 423,
        "content": "Importing necessary libraries and setting proxy environments to ensure proper model loading. Loading the YOLOv5 model from a local directory, and performing inference on an image file. Saving and displaying results. Some confusion regarding the 'bird' detection category.",
        "type": "summary"
    },
    "3466": {
        "file_id": 423,
        "content": "import torch\nimport os\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"\n# Model\nlocalModelDir = '/root/Desktop/works/pyjom/pyjom/models/yolov5/ultralytics_yolov5_master/'\n# import os\nos.environ[\"YOLOV5_MODEL_DIR\"] = '/root/Desktop/works/pyjom/pyjom/models/yolov5/' # this is strange. must be a hack in the localModelDir\nmodel = torch.hub.load(localModelDir, 'yolov5s',source=\"local\")  # or yolov5m, yolov5l, yolov5x, custom\n# Images\nimg = '/media/root/help/pyjom/samples/image/miku_on_green.png'  # or file, Path, PIL, OpenCV, numpy, list\n# Inference\nresults = model(img)\n# Results\n# results.print() # or .show(),\nresults.save()\n# print(type(results),dir(results))\n# breakpoint()\nimport cv2\nimage = cv2.imread(\"runs/detect/exp3/miku_on_green.jpg\")\ncv2.imshow(\"NONE\",image)\n# results.print()  # or .show(),\n# hold it.\n# image 1/1: 720x1280 1 bird # what the fuck is a bird?\n# os.system(\"pause\")\n# input()\n# this shit has been detected but not in the right category.",
        "type": "code",
        "location": "/tests/mmd_human_dance_pose/test_detection_yolo.py:1-32"
    },
    "3467": {
        "file_id": 423,
        "content": "Importing necessary libraries and setting proxy environments to ensure proper model loading. Loading the YOLOv5 model from a local directory, and performing inference on an image file. Saving and displaying results. Some confusion regarding the 'bird' detection category.",
        "type": "comment"
    },
    "3468": {
        "file_id": 424,
        "content": "/tests/mitm_chatbot_framework/README.md",
        "type": "filepath"
    },
    "3469": {
        "file_id": 424,
        "content": "The code represents the MITM (Man-in-the-Middle) Chatbot, which goes beyond traditional chat applications. This indicates that it likely involves advanced functionality or interactions beyond typical text-based conversations.",
        "type": "summary"
    },
    "3470": {
        "file_id": 424,
        "content": "mitm chatbot, beyond chat",
        "type": "code",
        "location": "/tests/mitm_chatbot_framework/README.md:1-1"
    },
    "3471": {
        "file_id": 424,
        "content": "The code represents the MITM (Man-in-the-Middle) Chatbot, which goes beyond traditional chat applications. This indicates that it likely involves advanced functionality or interactions beyond typical text-based conversations.",
        "type": "comment"
    },
    "3472": {
        "file_id": 425,
        "content": "/tests/nsfw_violence_drug_detection/README.md",
        "type": "filepath"
    },
    "3473": {
        "file_id": 425,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "summary"
    },
    "3474": {
        "file_id": 425,
        "content": "it is related to video content censorship, but really close to video automatic editing.\nwe have violence video dataset, we also have some 'fun video' dataset called blooper dataset",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/README.md:1-3"
    },
    "3475": {
        "file_id": 425,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "comment"
    },
    "3476": {
        "file_id": 426,
        "content": "/tests/nsfw_violence_drug_detection/post_jpg_to_nsfwjs.sh",
        "type": "filepath"
    },
    "3477": {
        "file_id": 426,
        "content": "This code is making multiple POST requests to http://localhost:8511/nsfw, using different image formats and file paths. The purpose appears to be testing the API's response for NSFW content detection with various images. The last comment suggests that BMP format might have an issue, but consistency is maintained with the original model. A real adult content image is being tested next.",
        "type": "summary"
    },
    "3478": {
        "file_id": 426,
        "content": "curl http://localhost:8511/\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_saturday_night.jpg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_saturday_night.bmp' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.png' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.jpg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.bmp' http://localhost:8511/nsfw\necho\necho\n# but the bmp looks right. is that the format issue?\n# we have consistency with the original model. how about a real porno?",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/post_jpg_to_nsfwjs.sh:1-23"
    },
    "3479": {
        "file_id": 426,
        "content": "This code is making multiple POST requests to http://localhost:8511/nsfw, using different image formats and file paths. The purpose appears to be testing the API's response for NSFW content detection with various images. The last comment suggests that BMP format might have an issue, but consistency is maintained with the original model. A real adult content image is being tested next.",
        "type": "comment"
    },
    "3480": {
        "file_id": 427,
        "content": "/tests/nsfw_violence_drug_detection/porndetect_test.sh",
        "type": "filepath"
    },
    "3481": {
        "file_id": 427,
        "content": "This code is making multiple HTTP POST requests with different image files to a local server on port 8511, specifically targeting the \"/nsfw\" endpoint. The images being tested are JPEG and BMP formats, and the script is checking for errors or issues related to the BMP decoder in the response.",
        "type": "summary"
    },
    "3482": {
        "file_id": 427,
        "content": "curl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/porn_shemale.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/porn_shemale.bmp' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick.bmp' http://localhost:8511/nsfw # something is wrong with bmp decoder.\necho\necho\necho '__________________________________________'\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick2.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick3.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick4.jpeg' http://localhost:8511/nsfw\necho\necho",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/porndetect_test.sh:1-22"
    },
    "3483": {
        "file_id": 427,
        "content": "This code is making multiple HTTP POST requests with different image files to a local server on port 8511, specifically targeting the \"/nsfw\" endpoint. The images being tested are JPEG and BMP formats, and the script is checking for errors or issues related to the BMP decoder in the response.",
        "type": "comment"
    },
    "3484": {
        "file_id": 428,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs",
        "type": "filepath"
    },
    "3485": {
        "file_id": 428,
        "content": "The code imports libraries, sets up an Express app and Multer for file uploads, converts images to RGBA format, initializes a model, calculates pixel counts using TensorFlow, handles requests, checks missing files, logs uploaded files, returns server status, loads NSFW image detection model, serves predictions on port 8511.",
        "type": "summary"
    },
    "3486": {
        "file_id": 428,
        "content": "import { createRequire } from \"module\";\nconst require = createRequire(import.meta.url);\nconst express = require('express')\nconst multer = require('multer')\nconst jpeg = require('jpeg-js')\n    // const bmp = require('bmp-js')\nconst bmp = require('bmp-ts');\n// const bmpBuffer = fs.readFileSync('bit24.bmp');\nconst { PNG } = require('pngjs')\nconst tf = require('@tensorflow/tfjs-node')\nconst nsfw = require('nsfwjs')\nconst app = express()\nconst upload = multer()\nlet _model\n// this even works for gif!\n// it will normalize and resize the image if needed.\n// shall we check for gif?\nconst convert = async(img, type) => {\n    // Decoded image in UInt8 Byte array\n    let image\n    if (type == 'image/jpeg') {\n        image = await jpeg.decode(img, true)\n            // RGBA\n    } //wtf?\n    // order: rgba\n    else if (type == 'image/png') {\n        image = PNG.sync.read(img)\n    } else if (type == 'image/bmp') {\n        // image = await bmp.decode(img, true)\n        image = bmp.decode(img, { toRGBA: true });\n    }\n    const numChannels = 3",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:1-40"
    },
    "3487": {
        "file_id": 428,
        "content": "The code imports necessary libraries, sets up an express application and multer middleware for handling file uploads. It also defines a function to convert images of different types (JPEG, PNG, BMP) into the same RGBA format for further processing using TensorFlow.js. The code also initializes a model and mentions that it works for GIFs as well.",
        "type": "comment"
    },
    "3488": {
        "file_id": 428,
        "content": "    const numPixels = image.width * image.height // will raise an error if image is not acquired.\n    const values = new Int32Array(numPixels * numChannels)\n        // are you sure about the width?\n    // can you make this faster? shit?\n    // this shit is no numpy. fuck.\n    for (let i = 0; i < numPixels; i++)\n        for (let c = 0; c < numChannels; ++c)\n        // if (type == 'bmp') {\n        //     // ABGR?\n        //     // values[i * numChannels + c] = image.data[i * 4+c]\n        //     values[i * numChannels + c] = image.data[i * 4 + 3 - c]\n        // } else {\n            values[i * numChannels + c] = image.data[i * 4 + c]\n            // }\n    return tf.tensor3d(values, [image.height, image.width, numChannels], 'int32')\n}\napp.get('/', async(req, res) => {\n    res.send('nsfw nodejs server')\n})\napp.post('/nsfw', upload.single('image'), async(req, res) => {\n    if (!req.file) res.status(400).send('Missing image multipart/form-data')\n    else {\n        try {\n            console.log('file uploaded:', req.file)",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:41-68"
    },
    "3489": {
        "file_id": 428,
        "content": "The code snippet is calculating the number of pixels in an image and storing its values into a TensorFlow tensor. It's then using the NodeJS framework to handle requests for images, checking if a file is missing, logging uploaded files, and returning a response with the server status. The code uses different data access methods based on the image format (BMP or others). However, there are concerns about potential width calculation errors, improving performance, and frustration with working outside of the Python ecosystem.",
        "type": "comment"
    },
    "3490": {
        "file_id": 428,
        "content": "            if (req.file.fieldname == 'image') {\n                type = req.file.mimetype // deal with it later.\n                extension = req.file.originalname.split(\".\").slice(-1)[0].toLowerCase()\n                if (extension == 'gif' || type == 'image/gif') {\n                    let image = req.file.buffer\n                    let predictions = await _model.classifyGif(image, { topk: 3, fps: 1 })\n                        // image.dispose()\n                    predictions.message = 'success'\n                    res.json(predictions)\n                } else {\n                    if (extension == 'bmp') {\n                        type = 'image/bmp'\n                    }\n                    let image = await convert(req.file.buffer, type) // here we have buffer.\n                    let predictions = await _model.classify(image)\n                    predictions.message = 'success'\n                        // image.dispose()\n                    res.json(predictions)\n                }\n            }\n            // we need some file format hints.",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:69-89"
    },
    "3491": {
        "file_id": 428,
        "content": "Checks if the file field is 'image' and deals with GIF files separately by classifying them directly. For other formats, converts the buffer to the appropriate type before classification. Responds with predictions and success message.",
        "type": "comment"
    },
    "3492": {
        "file_id": 428,
        "content": "        } catch (e) {\n            console.log(e)\n            res.json({ message: 'error' })\n        }\n    }\n})\nconst load_model = async() => {\n    _model = await nsfw.load()\n}\n// Keep the model in memory, make sure it's loaded only once\nload_model().then(() => {\n    console.log('server ready')\n    app.listen(8511)\n})\n// curl --request POST localhost:8080/nsfw --header 'Content-Type: multipart/form-data' --data-binary 'image=@/full/path/to/picture.jpg'",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:91-109"
    },
    "3493": {
        "file_id": 428,
        "content": "The code loads an NSFW image detection model, ensures it's only loaded once, and starts a server on port 8511. It accepts POST requests with image data from the client.",
        "type": "comment"
    },
    "3494": {
        "file_id": 429,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js",
        "type": "filepath"
    },
    "3495": {
        "file_id": 429,
        "content": "The function creates a color mask, processes BMP file header info, handles compression types, and supports various color formats. The code converts images to TensorFlow tensor3d arrays, handles file uploads, loads an NSFW model for classification, and runs on port 8511.",
        "type": "summary"
    },
    "3496": {
        "file_id": 429,
        "content": "// import { createRequire } from \"module\";\n// const require = createRequire(import.meta.url);\n// now we are talking\nfunction maskColor(maskRed, maskGreen, maskBlue, maskAlpha) {\n    const maskRedR = (~maskRed + 1) & maskRed;\n    const maskGreenR = (~maskGreen + 1) & maskGreen;\n    const maskBlueR = (~maskBlue + 1) & maskBlue;\n    const maskAlphaR = (~maskAlpha + 1) & maskAlpha;\n    const shiftedMaskRedL = maskRed / maskRedR + 1;\n    const shiftedMaskGreenL = maskGreen / maskGreenR + 1;\n    const shiftedMaskBlueL = maskBlue / maskBlueR + 1;\n    const shiftedMaskAlphaL = maskAlpha / maskAlphaR + 1;\n    return {\n        shiftRed: (x) => (((x & maskRed) / maskRedR) * 0x100) / shiftedMaskRedL,\n        shiftGreen: (x) => (((x & maskGreen) / maskGreenR) * 0x100) / shiftedMaskGreenL,\n        shiftBlue: (x) => (((x & maskBlue) / maskBlueR) * 0x100) / shiftedMaskBlueL,\n        shiftAlpha: maskAlpha !== 0 ?\n            (x) => (((x & maskAlpha) / maskAlphaR) * 0x100) / shiftedMaskAlphaL :\n            () => 255\n    };",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:1-22"
    },
    "3497": {
        "file_id": 429,
        "content": "This function takes four parameters (maskRed, maskGreen, maskBlue, and maskAlpha) to create a color mask. It performs bitwise operations and calculations to shift the color values and returns an object with functions to shift red, green, blue, and alpha components of any given value. If maskAlpha is not zero, it also returns an additional function for shifting alpha values.",
        "type": "comment"
    },
    "3498": {
        "file_id": 429,
        "content": "}\nvar HeaderTypes;\n(function(HeaderTypes) {\n    HeaderTypes[HeaderTypes[\"BITMAP_INFO_HEADER\"] = 40] = \"BITMAP_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V2_INFO_HEADER\"] = 52] = \"BITMAP_V2_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V3_INFO_HEADER\"] = 56] = \"BITMAP_V3_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V4_HEADER\"] = 108] = \"BITMAP_V4_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V5_HEADER\"] = 124] = \"BITMAP_V5_HEADER\";\n})(HeaderTypes || (HeaderTypes = {}));\nclass BmpDecoder {\n    constructor(buffer, { toRGBA } = { toRGBA: false }) {\n        this.buffer = buffer;\n        this.toRGBA = !!toRGBA;\n        this.pos = 0;\n        this.bottomUp = true;\n        this.flag = this.buffer.toString('utf-8', 0, (this.pos += 2));\n        if (this.flag !== 'BM') {\n            throw new Error('Invalid BMP File');\n        }\n        this.locRed = this.toRGBA ? 0 : 3;\n        this.locGreen = this.toRGBA ? 1 : 2;\n        this.locBlue = this.toRGBA ? 2 : 1;\n        this.locAlpha = this.toRGBA ? 3 : 0;\n        this.parseHeader();",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:23-48"
    },
    "3499": {
        "file_id": 429,
        "content": "Class BmpDecoder is created with a buffer and optional toRGBA parameter, which determines the pixel data format. The constructor initializes variables, checks for valid file signature, and sets location indices for RGB(A) values based on toRGBA flag. parseHeader function will be called next.",
        "type": "comment"
    }
}