{
    "4100": {
        "file_id": 520,
        "content": "无视警，憎恨孤独，自卑，担心，幼稚思想，过于慎重导致失败，偏差，不宜旅行。在事业中过多的投入已经让你不愿面对其它事情，因而事业有了突破性的进展。在感情方面，用工作繁忙来逃避这段感情的发展，对伴侣态度冷淡，因为害怕感情的发展而在关键时刻退缩，使对方心寒。\"\"\", 10: \"\"\"【10】命运之轮（The Wheel of Fortune，X)\n关键性的事件，有新的机会，因的潮流，环境的变化，幸运的开端，状况好转，问题解决，幸运之神降临。命运之轮正转到了你人生最低迷的时刻，也许你有些无法接受，但是若能以平常心来看待，这无疑是你成长的最好时机，需要认真面对。感情方面所受到的挫折近乎让你崩溃，然而你还在不断努力。\n虽然你面前是无数的荆棘，但坚持过去将是平坦的大道。你会发现以前所付出的无谓努力，而今反而成了你前进的动力，先前的付出终于有了回报。命运之轮是由命运女神转动的，所以你俩之前的风风雨雨都将过去，关系将进入稳定的发展阶段。\n边疆的不行，挫折，计划泡汤，障碍，无法修正方向，往坏处发展，恶性循环，中断。\"\"\", 11: \"\"\"【11】正义（Justice，XI）\n公正、中立、诚实、心胸坦荡、表里如一、身兼二职、追求合理化、协调者、与法律有关、光明正大的交往、感情和睦。事业上你不会有其它太多的感觉，只是按照以前的计划认真地执行。你对感情生活相当满意，对于你的选择对方都是接受的态度。\n失衡、偏见、纷扰、诉讼、独断专行、问心有愧、无法两全、表里不一、男女性格不合、情感波折、无视社会道德的恋情。长时间的压抑使你在事业最关键的时刻倒下了，需要认真修整一番才能再次前进。感情上你一直忍让着，然而这次你却爆发了，开始指责对方的不是，你们的感情将会有很大的波折。\"\"\", 12: \"\"\"【12】倒吊人（The Hanged Man，XII)\n接受考验、行动受限、牺牲、不畏艰辛、不受利诱、有失必有得、吸取经验教训、浴火重生、广泛学习、奉献的爱。当牌面正立时，你的事业会有短暂的停顿，但你很清楚其中的原因，再次确认自己的目标，做好出发的准备。感情上同样需要反省的时间，你对爱情的牺牲对会给对方很大的触动，也会成为你们关系发展的催化剂。\n无谓的牺牲、骨折、厄运、不够努力、处于劣势、任性、利己主义者、缺乏耐心、受惩罚、逃避爱情、没有结果的恋情。当牌面倒立时，事业上缺乏远见，迷失了努力的目标。感情上你没有了为对方付出的念头，而对方对你的态度依旧，这使你更想逃避。你已经忽略了内心深处正确的判断力，这让你开始遇到很多失败。\"\"\", 13: \"\"\"【13】 死神（Death，XIII)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:47-61"
    },
    "4101": {
        "file_id": 520,
        "content": "Code snippet for Tarot card descriptions.",
        "type": "comment"
    },
    "4102": {
        "file_id": 520,
        "content": "失败、接近毁灭、生病、失业、维持停滞状态、持续的损害、交易停止、枯燥的生活、别离、重新开始、双方有很深的鸿沟、恋情终止。事业上你将放弃一些得到的利益，并获得全新的发展机会。在感情上，你将会发生深刻的变化，将开始新的阶段，接受事实你们会有更加美好的旅程。\n抱有一线希望、起死回生、回心转意、摆脱低迷状态、挽回名誉、身体康复、突然改变计划、逃避现实、斩断情丝、与旧情人相逢。事业上你在试图“两全其美”，希望能够发生奇迹。在感情上，对方已经接受了改变，而你却在逃避现实，你俩的距离正在越来越大。\"\"\", 14: \"\"\"【14】节制（Temperance，XIV)\n单纯、调整、平顺、互惠互利、好感转为爱意、纯爱、深爱。你在事业上小心翼翼，因为处事理智让你的同事感到十分放心。当下你们的感情简简单单，一切都是这么的单纯、平静，正是因为彼此的沟通才让这段感情之路如此通畅。\n消耗、下降、疲劳、损失、不安、不融洽、爱情的配合度不佳。在事业上，你陷入了朝令夕改的怪圈，不妨效仿一下愚人勇往直前，或许能够取得更大的成功。感情上彼此虽然还在不断尝试着沟通，但每次之后总是感觉没有收获，正因为如此你们之间的距离才会越拉越大。\"\"\", 15: \"\"\"【15】恶魔（The Devil ，XV)\n被束缚、堕落、生病、恶意、屈服、欲望的俘虏、不可抗拒的诱惑、颓废的生活、举债度日、不可告人的秘密、私密恋情。你将在事业中得到相当大的名声与财富，你心中的事业就是一切，财富就是你的目标。感情上你们开始被彼此束缚，却不希望改善这种关系，情愿忍受彼此的牵连和不满。\n逃离拘束、解除困扰、治愈病痛、告别过去、暂停、别离、拒绝诱惑、舍弃私欲、别离时刻、爱恨交加的恋情。事业上理性开始支配欲望，找到真正值得努力的目标。感情上开始尝试与对方进行沟通，这让你俩的感情更加牢固。\"\"\", 16: \"\"\"【16】塔（The Tower，XVI)\n破产、逆境、被开除、急病、致命的打击、巨大的变动、受牵连、信念崩溃、玩火自焚、纷扰不断、突然分离，破灭的爱。事业上的困难显而易见，回避不是办法，要勇于挑战，尽管它貌似强大。在感情方面，突然的改变让你陷入深深的痛苦中，接受改变可以让你或你们双方在未来的人生旅途中走得更好。\n困境、内讧、紧迫的状态、状况不佳、趋于稳定、骄傲自大将付出代价、背水一战、分离的预感、爱情危机。事业上开始有稳定的迹象，你不要盲目抵抗改变的发生",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:63-77"
    },
    "4103": {
        "file_id": 520,
        "content": "这段代码是从pyjom/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py文件中截取的，用于描述塔（The Tower，XVI）这张毒诺牌的含义。在事业和感情方面都提到了突然的改变、困难、痛苦等内容，强调接受改变才能在未来的人生旅途中走得更好。",
        "type": "comment"
    },
    "4104": {
        "file_id": 520,
        "content": "，这只会导致更大的改变，无论你如何抵抗，改变终究会发生。在感情上双方的情绪终于平静下来，虽然沟通上还有些困难，但不会有太大的变化了，也许你做些让步，会让你们的感情更融洽。\"\"\", 17: \"\"\"【17】星星（The Star，XVII)\n前途光明、充满希望、想象力、创造力、幻想、满足愿望、水准提高、理想的对象、美好的恋情。代表当你在事业上得到希望的能量时，前途会无比光明。在感情方面，你对自己很有信心，对两人的关系也抱有乐观的态度，相信自己能把握主动权，并努力追求对方，你们很可能就是命中注定的那一对。\n挫折、失望、好高骛远、异想天开、仓皇失措、事与愿违、工作不顺心、情况悲观、秘密恋情、缺少爱的生活。在事业上，你不要全部依靠别人的给予，因为你还有希望在心中燃烧，只有靠自己才有真正的发展动力。感情方面你俩无法彼此信任，感觉无法把自己托付给对方，也许你们退一步，都冷静一下就能找出解决问题的途径，因为答案就在你们的心中。\"\"\", 18: \"\"\"【18】月亮（The Moon，XVIII)\n不安、迷惑、动摇、谎言、欺骗、鬼迷心窍、动荡的爱、三角关系。在事业上，你可能有些不满足，希望能够把自己内在的力量全使出来，于是你开始想要晚上的时间。感情方面，你很敏感害怕被伤害，尽管有伴侣的承诺，你仍然犹豫不决，甚至有逃避的想法。\n逃脱骗局、解除误会、状况好转、预知危险、等待、正视爱情的裂缝。在事业上，你因为外界的压力开始退缩了，并对自己的既定目标产生了怀疑。在感情上，你们之间的问题开始浮现，虽然有些痛，但是只要共同面对存在的困难，问题就解决一半了。\"\"\", 19: \"\"\"【19】太阳（The Sun，XIX)\n活跃、丰富的生命力、充满生机、精力充沛、工作顺利、贵人相助、幸福的婚姻、健康的交际。事业上会有贵人相助，将会有更好的发展机遇。在感情方面，你们已经走出坎坷的感情之路，前面将是洒满歌声和欢乐的坦途，你们将开始规划未来的生活。\n消沉、体力不佳、缺乏连续性、意气消沉、生活不安、人际关系不好、感情波动、离婚。事业上竞争心太急切了，把对手都吓跑了，然而也让合作伙伴感到害怕，或许你该放松些。感情上两人间出现一些小变化，开始在乎对方的态度和自己的付出，这些怀疑也许都是没必要的。\"\"\", 20: \"\"\"【20】审判（Judgement，XX)\n复活的喜悦、康复、坦白、好消息、好运气、初露锋芒、复苏的爱、重逢、爱的奇迹。当牌面正立时，事业上你超越了自我，在过去努力的基础上取得了成功。感情上双方都在认真学习和成长，虽然表面上的变化并不大，但内在的改变已经很大了。",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:77-91"
    },
    "4105": {
        "file_id": 520,
        "content": "This Python code contains descriptions for the 17, 18, 19, and 20 tarot cards. It provides brief interpretations of each card's meaning in terms of future prospects, career, relationships, and personal growth.",
        "type": "comment"
    },
    "4106": {
        "file_id": 520,
        "content": "一蹶不振、幻灭、隐瞒、坏消息、无法决定、缺少目标、没有进展、消除、恋恋不舍。在事业上缺乏清晰的判断，试图用物质填充精神的空虚。在感情上，不断地回忆着过去的美好时光，不愿意去正视眼前的问题，你们的关系已经是貌合神离了。\"\"\", 21: \"\"\"【21】世界（The World，XXI)\n完成、成功、完美无缺、连续不断、精神亢奋、拥有毕生奋斗的目标、完成使命、幸运降临、快乐的结束、模范情侣。在事业上因为努力工作，所以回报丰厚。感情上，你们在彼此的承诺中持续着美好的关系。\n未完成、失败、准备不足、盲目接受、一时不顺利、半途而废、精神颓废、饱和状态、合谋、态度不够融洽、感情受挫。在事业的路上有巨大的障碍，你精神不振，丧失了挑战的动力。感情上，你们不再重视承诺，只是盲目接受对方。彼此最好能沟通一下，不要让痛苦继续纠缠着你们。\"\"\"}\nsmdict = {0: \"【权杖】（The Leangle)代表元素火，象征激情、能量和创造。\", 1: \"【星币】（The Garren)代表元素土，象征金钱、物质和享受。\",\n          2: \"【圣杯】（The Chalice)代表元素水，象征情感、关系、爱和灵感。\", 3: \"【宝剑】（The Blade)代表元素风，象征思想、智慧、交流和冲突。\"}\nsmdict2 = {1:\"COINS\",2:\"CUP\",3:\"SWORDS\",0:\"WANDS\"}\n#mdict 21, smdict 3\n# class py_solution:\ndef int_to_Roman(num):\n    lookup = [\n        (1000, 'M'),\n        (900, 'CM'),\n        (500, 'D'),\n        (400, 'CD'),\n        (100, 'C'),\n        (90, 'XC'),\n        (50, 'L'),\n        (40, 'XL'),\n        (10, 'X'),\n        (9, 'IX'),\n        (5, 'V'),\n        (4, 'IV'),\n        (1, 'I'),\n    ]\n    res = ''\n    for (n, roman) in lookup:\n        (d, num) = divmod(num, n)\n        res += roman * d",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:93-125"
    },
    "4107": {
        "file_id": 520,
        "content": "This code is mapping the Tarot card descriptions and their corresponding numbers to different elements and card suits. It also includes a function int_to_Roman that converts an integer to its Roman numeral representation using lookup values for each Roman numeral value.",
        "type": "comment"
    },
    "4108": {
        "file_id": 520,
        "content": "    return res",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:126-126"
    },
    "4109": {
        "file_id": 520,
        "content": "This code is returning the result (res) after some operation or function execution. It indicates that the previous code block was performing a calculation, query, or transformation, and now it's ready to deliver the outcome.",
        "type": "comment"
    },
    "4110": {
        "file_id": 521,
        "content": "/tests/bilibili_practices/bilibili_tarot/tarot_correspondences.py",
        "type": "filepath"
    },
    "4111": {
        "file_id": 521,
        "content": "This code loads tarot card images, maps them to numbers, checks for matches in directories, and prints the major/minor tarot cards along with their corresponding values.",
        "type": "summary"
    },
    "4112": {
        "file_id": 521,
        "content": "dirs =[\"tarot_pictures\",\"tarot_pictures2\"] \nimport os\nfrom tarot_descriptions import *\nmtarget_0 = {k:None for k in mdict.keys()}\nmtarget_1 = {k:None for k in smdict.keys()}\nfn = []\nfor d in dirs:\n    fnames = os.listdir(d)\n    fnames = [os.path.join(d,f) for f in fnames]\n    fn+= fnames\npopdict = []\nfor k in mtarget_0.keys():\n    if k == 0:\n        kv = \"0\"\n    else:\n        kv = int_to_Roman(k)\n    for f in fn:\n        fb = os.path.basename(f)\n        f0 = fb.split(\".\")[0].split(\"_\")[0]\n        if f0.upper() == kv:\n            mtarget_0[k] = f\n            break\n    if mtarget_0[k] is None:\n        popdict.append(k)\nfor k in popdict:\n    mtarget_0.pop(k)\npopdict = []\nfor k in mtarget_1.keys():\n    kv =  smdict2[k]\n    for f in fn:\n        fb = os.path.basename(f)\n        f0 = fb.split(\".\")[0].split(\"_\")[-1]\n        if kv.upper() in f0.upper():\n            mtarget_1[k] = f\n            break\n    if mtarget_1[k] is None:\n        popdict.append(k)\nfor k in popdict:\n    mtarget_1.pop(k)\n# print()\n# ########printing.\n# pretty good.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_correspondences.py:1-48"
    },
    "4113": {
        "file_id": 521,
        "content": "This code is loading tarot card images and mapping them to their respective numbers. It first defines the directories containing the image files, then iterates over each directory, lists the files, and checks if the file name matches the corresponding tarot card number in Roman or Arabic numeral form. If a match is found, it assigns that image file to the respective dictionary (mtarget_0 for Arabic numbers, mtarget_1 for tarot card names). Finally, it removes any missing mappings from the dictionaries.",
        "type": "comment"
    },
    "4114": {
        "file_id": 521,
        "content": "# if __name__ == \"__main__\":\n#     for k in mtarget_0.keys():\n#         print(\"MAJOR\",k,mtarget_0[k])\n#     for k in mtarget_1.keys():\n#         print(\"MINOR\",k,mtarget_1[k])",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_correspondences.py:49-53"
    },
    "4115": {
        "file_id": 521,
        "content": "Code checks keys in mtarget_0 and mtarget_1 dictionaries, printing \"MAJOR\" followed by key and its value for mtarget_0, and \"MINOR\" followed by key and its value for mtarget_1.",
        "type": "comment"
    },
    "4116": {
        "file_id": 522,
        "content": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py",
        "type": "filepath"
    },
    "4117": {
        "file_id": 522,
        "content": "This code converts text to speech audio using PaddleSpeech, merges and normalizes audio segments, generates voice and video files, and exports final videos with background music.",
        "type": "summary"
    },
    "4118": {
        "file_id": 522,
        "content": "import os\nfrom test_common import *\ndef split_sentences(sent):\n    spliters = \"\\n，。、\"\n    cursent = \"\"\n    results = []\n    for elem in sent:\n        cursent += elem\n        if elem in spliters:\n            results.append(cursent)\n            cursent = \"\"\n    if len(cursent) > 0:\n        results.append(cursent)\n    return results\ndef get_speech(sent,output):\n    assert output.endswith(\".wav\")\n    with open(\"temp.txt\", \"w+\",encoding=\"utf-8\") as f:\n        f.write(sent)\n    os.system(\"cat temp.txt | paddlespeech tts --output {}\".format(output))\nfrom pydub import AudioSegment\nfrom functional_gen_typo_video_seq import gen_video\ndef merge_audio(asegs):\n    audio_3 = AudioSegment.empty() #shit\n    for seg in asegs:\n        try:\n            audio_3 = audio_3.append(seg,crossfade=100) # also shit.\n        except:\n            audio_3 = audio_3.append(seg,crossfade=0) # also shit.\n    return audio_3\n    # audio_3.export(\"audio_3.wav\", format=\"wav\")\nif __name__ == \"__main__\":\n    sents = split_sentences(demo_text)\n    # breakpoint()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py:1-38"
    },
    "4119": {
        "file_id": 522,
        "content": "This code performs text-to-speech (TTS) conversion and merges audio segments. It first splits a given sentence into individual sentences, then uses PaddleSpeech to convert the text to speech audio, which is saved with .wav extension. The resulting audio segments are merged using PyDub's AudioSegment module, allowing for seamless crossfades between audio chunks.",
        "type": "comment"
    },
    "4120": {
        "file_id": 522,
        "content": "    voice_dir = \"voice\"\n    video_dir = \"video\"\n    os.system(\"rm -rf {}\".format(voice_dir))\n    os.system(\"rm -rf {}\".format(video_dir))\n    os.mkdir(\"{}\".format(voice_dir))\n    os.mkdir(\"{}\".format(video_dir))\n    index = 0\n    voice_clips = []\n    video_names = []\n    for i,sent in enumerate(sents):\n        print(\"READING:\",sent)\n        aname = \"{}/{}.wav\".format(voice_dir,i)\n        get_speech(sent,aname)\n        seg = AudioSegment.from_wav(aname)\n        duration = seg.duration_seconds\n        voice_clips.append(seg)\n        # get the duration you fuck.\n        # breakpoint()\n        lsent = len(sent)\n        current_indexs = list(range(index,index+lsent))\n        index += lsent\n        # you can generate video for it.\n        vname = \"{}/{}.mp4\".format(video_dir,i)\n        gen_video(vname,current_indexs,duration)\n        video_names.append(vname)\n    # and finally?\n    final_video = \"{}/final_video.mp4\".format(video_dir)\n    final_audio = \"{}/final_audio.wav\".format(voice_dir)\n    audio_merged = merge_audio(voice_clips)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py:39-68"
    },
    "4121": {
        "file_id": 522,
        "content": "This code clears the \"voice\" and \"video\" directories, creates new ones, reads each sentence from the input, converts it to audio, generates a video for each sentence, appends the corresponding audio clip and video name to their respective lists, and then merges all audio clips. The final video and audio files are named accordingly.",
        "type": "comment"
    },
    "4122": {
        "file_id": 522,
        "content": "    bgm_path = \"/root/Desktop/works/bilibili_tarot/some_bgm.mp3\"\n    bgm = AudioSegment.from_mp3(bgm_path)\n    # duration2 = audio_merged.duration_seconds\n    # bgm = bgm[:duration2*1000] # really?\n    # breakpoint()\n    # audio_merged = audio_merged.overlay(audio_merged,bgm,loop=True)  #wtf?\n    audio_merged = audio_merged.overlay(bgm,loop=True)\n    # audio_merged = audio_merged.normalize()\n    # is it needed?\n    # shit.\n    audio_merged.export(final_audio, format=\"wav\")\n    final_video2 = \"{}/final_video2.mp4\".format(video_dir)\n    with open(\"mylist.txt\",\"w+\") as f:\n        for n in video_names:\n            f.write(\"file \"+n+\"\\n\")\n    os.system(\"ffmpeg -f concat -safe 0 -i mylist.txt -c copy {}\".format(final_video))\n    os.system(\"ffmpeg -i {} -i {} -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 {}\".format(final_video,final_audio,final_video2))",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py:69-87"
    },
    "4123": {
        "file_id": 522,
        "content": "The code imports audio files, merges them, normalizes the volume, and exports the final audio as a wav file. It then creates a mylist.txt file containing the video names, and uses ffmpeg to concatenate videos with the background music and export the final video2 in mp4 format.",
        "type": "comment"
    },
    "4124": {
        "file_id": 523,
        "content": "/tests/bilibili_practices/bilibili_tarot/test_common.py",
        "type": "filepath"
    },
    "4125": {
        "file_id": 523,
        "content": "The code sets the http and https proxies to empty strings, preventing any proxy usage, and assigns a demo text for use in testing.",
        "type": "summary"
    },
    "4126": {
        "file_id": 523,
        "content": "import os\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"\ndemo_text = \"事情的开始，行动的改变，熟练的技术及技巧，贯彻我的意志，运用自然的力量来达到野心。\"",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/test_common.py:1-6"
    },
    "4127": {
        "file_id": 523,
        "content": "The code sets the http and https proxies to empty strings, preventing any proxy usage, and assigns a demo text for use in testing.",
        "type": "comment"
    },
    "4128": {
        "file_id": 524,
        "content": "/tests/bilibili_practices/bilibili_tarot/test_command.sh",
        "type": "filepath"
    },
    "4129": {
        "file_id": 524,
        "content": "This code is using the melt command to combine multiple screenshots into a single video file with transitions. It uses the \"composite\" and \"mix\" transitions, applies distortion effects, and outputs the final result at 60 FPS. The output is saved as a consumer XML file.",
        "type": "summary"
    },
    "4130": {
        "file_id": 524,
        "content": "melt -track \"color:#000000\" out=0 -track /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0000.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -track -blank :0.570312 /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0001.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -track -blank :1.140625 /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0002.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -track -blank :1.710938 /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0003.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -transition composite distort=0 a_track=0 b_track=1 -transition mix a_track=0 b_track=1 -transition composite distort=0 a_track=0 b_track=2 -transition mix a_track=0 b_track=2 -transition composite distort=0 a_track=0 b_track=3 -transition mix a_track=0 b_track=3 -transition composite distort=0 a_track=0 b_track=4 -transition mix a_track=0 b_track=4 -consumer xml",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/test_command.sh:1-1"
    },
    "4131": {
        "file_id": 524,
        "content": "This code is using the melt command to combine multiple screenshots into a single video file with transitions. It uses the \"composite\" and \"mix\" transitions, applies distortion effects, and outputs the final result at 60 FPS. The output is saved as a consumer XML file.",
        "type": "comment"
    },
    "4132": {
        "file_id": 525,
        "content": "/tests/bilibili_practices/bilibili_tarot/temp.txt",
        "type": "filepath"
    },
    "4133": {
        "file_id": 525,
        "content": "This code appears to be a message encouraging users to follow and continue, possibly in the context of social media or a platform like Bilibili. It could be used as a prompt for engagement or interaction.",
        "type": "summary"
    },
    "4134": {
        "file_id": 525,
        "content": "点个关注再走吧～",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/temp.txt:1-1"
    },
    "4135": {
        "file_id": 525,
        "content": "This code appears to be a message encouraging users to follow and continue, possibly in the context of social media or a platform like Bilibili. It could be used as a prompt for engagement or interaction.",
        "type": "comment"
    },
    "4136": {
        "file_id": 526,
        "content": "/tests/bilibili_practices/bilibili_tarot/all_typography.py",
        "type": "filepath"
    },
    "4137": {
        "file_id": 526,
        "content": "This code generates typography for a video and stores it in a specific format, using functions `gen_typography_part1`, `gen_typography_part2`, and `kill_script()`. It imports modules for creating files, executing scripts, and generating intermediate videos.",
        "type": "summary"
    },
    "4138": {
        "file_id": 526,
        "content": "from tarot_descriptions import *\n# mdict, smdict2\nimport os\ndef gen_typography_part1(content):\n    with open(\"demo_text.log\",\"w+\",encoding=\"utf8\") as f:\n        f.write(content)\n    os.system(\"xvfb-run -s '-screen 0 1920x1080x24' python3 scriptable_generate_typography_with_voice.py\")\ndef kill_script():\n    os.system(\"bash kill_xb.sh\")\ntyp_0 = \"typo_0\"\ntyp_1 = \"typo_1\"\n# os.system(\"rm -rf {}\".format(typ_0))\n# os.system(\"rm -rf {}\".format(typ_1))\n# os.mkdir(typ_0)\n# os.mkdir(typ_1)\nfrom functional_voice_with_pictures import gen_typography_part2\ninter_text = \"\"\"再抽取一张牌吧~\"\"\"\nbgm_path = \"/root/Desktop/works/bilibili_tarot/tarot_random_shuffle.mp3\"\ntarget_video = \"intermediate_video.mp4\"\nos.system(\"rm {}\".format(target_video))\nkill_script()\n# v = mdict[k]\nv = inter_text\ngen_typography_part1(v)\n# target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\ngen_typography_part2(v,bgm_path,target_video)\nkill_script()\nintro_text = \"\"\"塔罗牌，是一种针对人、事、物进行分析、预测和提供建议的工具，被称为“大自然的奥秘库”。\n抽取一张塔罗牌，今天的你会是怎样的呢？\"\"\"\n# intro_text =\n# bgm_path = \"/root/Desktop/works/bilibili_tarot/tarot_random_shuffle.mp3\"",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography.py:1-46"
    },
    "4139": {
        "file_id": 526,
        "content": "The code imports modules and defines functions for generating typography with voice and video. It creates files, executes scripts, and generates intermediate videos for a tarot reading process. It also generates a final video after killing the script.",
        "type": "comment"
    },
    "4140": {
        "file_id": 526,
        "content": "# target_video = \"intro_video.mp4\"\n# os.system(\"rm {}\".format(target_video))\n# kill_script()\n# # v = mdict[k]\n# v = intro_text\n# gen_typography_part1(v)\n# # target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\n# gen_typography_part2(v,bgm_path,target_video)\n# kill_script()\nbgms = [\"you_got_me_acc.wav\", \"tarot_desc_acc.wav\"]\n# outro_text = \"\"\"今天的你运气不错哦～\n# 喜欢的话请分享点赞，一键三联哦～\"\"\"\n# bgm_path = bgms[0]\n# target_video = \"outro_video.mp4\"\n# os.system(\"rm {}\".format(target_video))\n# kill_script()\n# # v = mdict[k]\n# v = outro_text\n# gen_typography_part1(v)\n# # target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\n# gen_typography_part2(v,bgm_path,target_video)\n# kill_script()\nimport random\n# for k in mdict.keys():\n#     if k !=16:\n#         continue\n#     kill_script()\n#     v = mdict[k]\n#     gen_typography_part1(v)\n#     target_video = \"/\".join([typ_0,\"{}.mp4\".format(k)])\n#     gen_typography_part2(v,random.choice(bgms),target_video)\n#     kill_script()\n# for k in smdict.keys():\n#     v = smdict[k]\n#     # kill_script()\n#     # v = mdict[k]",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography.py:48-93"
    },
    "4141": {
        "file_id": 526,
        "content": "The code removes the target video, generates typography for intro and outro text using different background music, and randomly selects a background music from the given list for each card in mdict and smdict.",
        "type": "comment"
    },
    "4142": {
        "file_id": 526,
        "content": "#     gen_typography_part1(v)\n#     target_video = \"/\".join([typ_1,\"{}.mp4\".format(k)])\n#     gen_typography_part2(v,random.choice(bgms),target_video)\n#     kill_script()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/all_typography.py:94-97"
    },
    "4143": {
        "file_id": 526,
        "content": "This code section generates typography for a video and stores it in a specific format. It first calls a function `gen_typography_part1` passing some parameter v, then combines the typography name with the video number as the file name. The next step is to call another function `gen_typography_part2`, which takes two parameters: v and a randomly chosen bgm (background music) from some list of choices. It also passes the target video file as an argument. Lastly, it calls the `kill_script()` function to terminate the script execution.",
        "type": "comment"
    },
    "4144": {
        "file_id": 527,
        "content": "/tests/bilibili_practices/bilibili_dollar/fetch_related_content.py",
        "type": "filepath"
    },
    "4145": {
        "file_id": 527,
        "content": "The code imports the \"VideosSearch\" class from the \"youtube-search-python\" package and uses it to search for videos related to drawing realistic US Dollars. It fetches the first 10 results, then prints each video's title, ID, author name, channel ID, and view count.",
        "type": "summary"
    },
    "4146": {
        "file_id": 527,
        "content": "#!pip3 install youtube-search-python\nfrom youtubesearchpython import VideosSearch\n# videosSearch = VideosSearch('画人民币', limit = 10)\nvideosSearch = VideosSearch('Draw realistic US Dollar', limit = 10)\n# videosSearch = VideosSearch('NoCopyrightSounds', limit = 2)\n# print(videosSearch.result())\ndata = videosSearch.result()\nfor elem in data[\"result\"]:\n    title = elem[\"title\"]\n    videoId = elem[\"id\"]\n    contentType = elem[\"type\"]\n    authorName = elem[\"channel\"][\"name\"]\n    channelId = elem[\"channel\"][\"id\"]\n    viewCount = elem[\"viewCount\"][\"text\"]\n    print(\"title\",title)\n    print(\"videoId\",videoId)\n    print(\"author\",authorName)\n    print(\"channel ID\",channelId)\n    print(\"viewCount\",viewCount)\n    print(\"_______________________________________\")",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_dollar/fetch_related_content.py:1-23"
    },
    "4147": {
        "file_id": 527,
        "content": "The code imports the \"VideosSearch\" class from the \"youtube-search-python\" package and uses it to search for videos related to drawing realistic US Dollars. It fetches the first 10 results, then prints each video's title, ID, author name, channel ID, and view count.",
        "type": "comment"
    },
    "4148": {
        "file_id": 528,
        "content": "/tests/motion_vector_estimation/test.sh",
        "type": "filepath"
    },
    "4149": {
        "file_id": 528,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "summary"
    },
    "4150": {
        "file_id": 528,
        "content": "bash ./run.sh python3.10 extract_mvs.py vid_h264.mp4 --preview --verbose",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.sh:1-1"
    },
    "4151": {
        "file_id": 528,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "comment"
    },
    "4152": {
        "file_id": 529,
        "content": "/tests/motion_vector_estimation/test.py",
        "type": "filepath"
    },
    "4153": {
        "file_id": 529,
        "content": "The code processes video frames and estimates motion vectors, then plots the results using matplotlib and handles potential errors. It uses pandas, numpy, and OpenCV for calculations.",
        "type": "summary"
    },
    "4154": {
        "file_id": 529,
        "content": "# it contains subpixel motion vectors. fucking hell\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# change source?\n# gif containers does not have motion vectors.\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n# without mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_without_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_without_mestimate.mp4\"\n# with mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"\nsource = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nfrom mvextractor.videocap import VideoCap",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:1-25"
    },
    "4155": {
        "file_id": 529,
        "content": "This code is setting the source video file path for various test cases involving motion vector estimation. The files include different types of videos such as MP4 and GIF, with and without mestimate data, and nearly duplicate frame detection tests. It also initializes custom CV2 build and imports necessary modules.",
        "type": "comment"
    },
    "4156": {
        "file_id": 529,
        "content": "from caer.video.frames_and_fps import count_frames, get_res\nimport cv2\nframesCount = count_frames(source)\nres = get_res(source)  # (width, height)\nprint(\"RES: %s\" % str(res))\nres_x, res_y = res\nframe_common_divisor = min(res_x, res_y)\nimport math\ndef cartesianDistance(d2vector):\n    try:\n        x, y = d2vector\n        return math.sqrt(x**2 + y**2)\n    except:\n        print('item unpackable.', d2vector)\n        return 0\ndef XYWHToDiagonal(x, y, w, h):\n    return (x, y), (x + w, y + h)\n# 如果整除16那么就在这个范围里面 如果不整除范围就要扩大 扩大到相应的16的倍数\ndef get16Value(res_x):\n    rem_x = res_x % 16\n    val = res_x // 16\n    if rem_x != 0:\n        val += 1\n    return val\nx_16val = get16Value(res_x)\ny_16val = get16Value(res_y)\nmotion_render_frame = (x_16val * 16, y_16val * 16)\ntotal_block_weights = x_16val * y_16val * 2 * 2\ncap = VideoCap()\ncap.open(source)  # wtf is going on here?\n# if there is nothing we will breakup\n# visualize, show_picture = True, True\nvisualize, show_picture = False, False\n# so there can only be one such macroblock\ndef checkMacroBlock(value):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:26-75"
    },
    "4157": {
        "file_id": 529,
        "content": "This code is initializing variables and functions related to video processing. It calculates the resolution of a source, determines if it's divisible by 16, adjusts if necessary, and sets up variables for motion vector estimation and visualization. The VideoCap class is opened but its functionality remains unclear. The checkMacroBlock function checks for one macroblock value.",
        "type": "comment"
    },
    "4158": {
        "file_id": 529,
        "content": "    for mod in [16, 8]:\n        modValue = value % mod\n        if modValue == mod / 2:\n            return mod\n    # if not satisfied, we are shit.\nfrom functools import lru_cache\n@lru_cache(maxsize=4)\ndef getModXModYFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = checkMacroBlock(block_x), checkMacroBlock(block_y)\n    if mod_x is not None and mod_y is not None:\n        return mod_x, mod_y\n    else:\n        print(\"block center coordinates\", blockCenterCoordinates)\n        print(\"WTF IS GOING ON WITH THE BLOCK CENTER\")\n        breakpoint()\n        return 0, 0\ndef getRectangleXYWHFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    mod_x_half, mod_y_half = mod_x / 2, mod_y / 2\n    x, y, w, h = block_x - mod_x_half, block_y - mod_y_half, mod_x, mod_y\n    return tuple([int(elem) for elem in [x, y, w, h]])\ndef getBlockWeightFromBlockCenterCoordinates(blockCenterCoordinates):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:76-107"
    },
    "4159": {
        "file_id": 529,
        "content": "This code defines several functions for handling block center coordinates in a specific context. It checks the modulo value of the coordinates to determine the size and position of the blocks, and uses these values to calculate the rectangle's dimensions and the block weight. The `lru_cache` decorator is used to cache the results of the `getModXModYFromBlockCenterCoordinates` function to improve performance.",
        "type": "comment"
    },
    "4160": {
        "file_id": 529,
        "content": "    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    weights = mod_x * mod_y / 8 / 8\n    return weights\nimport progressbar\nimport numpy as np\n# max_dst_x, max_dst_y = 0,0\ndef averageMotionVectors(motion_vector_list):\n    if len(motion_vector_list) == 0:\n        average_tuple = (0, 0)\n    if len(motion_vector_list) > 1:\n        marray = np.array(motion_vector_list)\n        # print(\"MAKING AVERAGE:\")\n        # print(marray)\n        average = np.average(marray, axis=0)\n        # breakpoint()\n        average_tuple = tuple(average)\n    else:\n        average_tuple = tuple(motion_vector_list[0])\n    return average_tuple\nmotion_area_ratio_array = []\n# average_weighted_motion_vector_array = []\n# average_global_weighted_motion_vector_array = []\naverage_weighted_motion_vector_cartesian_array = []\naverage_global_weighted_motion_vector_cartesian_array = []\naverage_weighted_motion_vectors_filtered_cartesian_distance_array = []\naverage_global_weighted_motion_vectors_filtered_cartesian_distance_array = []",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:108-140"
    },
    "4161": {
        "file_id": 529,
        "content": "Function to calculate the average motion vectors based on a list of motion vectors. If the list is empty, returns (0, 0). If the list has more than one vector, calculates the average and returns it as a tuple. Else, returns the first vector in the list.\n\nInitializes arrays for storing average_weighted_motion_vector_cartesian, average_global_weighted_motion_vector_cartesian, average_weighted_motion_vectors_filtered_cartesian_distance, and average_global_weighted_motion_vectors_filtered_cartesian_distance.",
        "type": "comment"
    },
    "4162": {
        "file_id": 529,
        "content": "for _ in progressbar.progressbar(range(framesCount)):\n    success, frame, motion_vectors, frame_type, timestamp = cap.read()\n    height, width, channels = frame.shape\n    # breakpoint()\n    if success:\n        # what is the content of this motion vector?\n        # print(motion_vectors)\n        # import pandas as pd\n        # df = pd.DataFrame(motion_vectors)\n        # df = pd.DataFrame(motion_vectors,index=['source_index','unk0','unk1','src_x','src_y','dst_x','dst_y','motion_x','motion_y','motion_scale'])\n        # breakpoint()\n        # print()\n        # print(\"_____________________________\")\n        condition = motion_vectors[:, 0] < 0\n        # print(condition)\n        # print(condition.shape)\n        # breakpoint()\n        motion_vectors_simplified = motion_vectors[condition, :][:, [0, 5, 6, 7, 8, 9]]\n        motion_vectors_scale = motion_vectors_simplified[:, [5]]\n        motion_vectors_scale_inversed = 1 / motion_vectors_scale\n        motion_vectors_with_scale = motion_vectors_simplified[:, [3, 4]]\n        motion_vectors_scale_inversed_stacked = np.hstack(",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:142-163"
    },
    "4163": {
        "file_id": 529,
        "content": "The code reads frames and motion vectors from a video stream, processes them, and stores selected information in separate arrays. It uses pandas for data processing and numpy for array manipulation.",
        "type": "comment"
    },
    "4164": {
        "file_id": 529,
        "content": "            [motion_vectors_scale_inversed] * 2\n        )\n        motion_vectors_restored = (\n            motion_vectors_scale_inversed_stacked * motion_vectors_with_scale\n        )  # just element wise?\n        # print('STACKED:', motion_vectors_scale_inversed_stacked.shape)\n        # print(\"WITH SCALE:\", motion_vectors_with_scale.shape)\n        # print(\"RESTORED:\",motion_vectors_restored.shape)\n        # print(motion_vectors_simplified.shape)\n        # print(motion_vectors_scale.shape)\n        # breakpoint()\n        motion_vectors_dest_coords_restored = np.hstack(\n            [motion_vectors_simplified[:, [1, 2]], motion_vectors_restored]\n        )\n        # motion_vectors_simplified = motion_vectors[:,[0,5,6,7,8]]\n        # motion_vectors_simplified_unique = np.unique(motion_vectors_simplified, axis=0)\n        # print(motion_vectors_simplified_unique.shape, motion_vectors.shape)\n        # breakpoint()\n        motion_vectors_dict = {}\n        for mv in motion_vectors_dest_coords_restored:\n            # drop duplicates first!",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:164-184"
    },
    "4165": {
        "file_id": 529,
        "content": "This code segment is responsible for restoring the motion vectors after scaling and stacking. It performs element-wise multiplication of two arrays, one containing scaled motion vectors and the other being the stacked motion vectors. The result is stored in \"motion_vectors_restored\". Then, it horizontally stacks the simplified motion vector coordinates and the restored ones using numpy's hstack function, resulting in \"motion_vectors_dest_coords_restored\". Finally, a dictionary named \"motion_vectors_dict\" is initialized but not fully populated in this snippet.",
        "type": "comment"
    },
    "4166": {
        "file_id": 529,
        "content": "            (\n                dst_x,  # corresponding macro block.\n                dst_y,  # for destination only\n                motion_x,\n                motion_y,\n                # motion_scale,  # don't know what the fuck is wrong with the motion scale\n            ) = mv.tolist()\n            # say we just want source_index <0, aka mv compared to previous frame\n            # try:\n            #     assert motion_x / motion_scale == src_x - dst_x\n            #     assert motion_y / motion_scale == src_y - dst_y\n            # except:\n            #     print(src_x, dst_x, motion_x, motion_scale)\n            #     print(src_y, dst_y, motion_y, motion_scale)\n            #     print(\"*\" * 20)\n            # it will be inaccurate if we abandon this subpixel precision.\n            # if source_index >= 0:\n            #     continue\n            # if dst_x>max_dst_x:\n            #     max_dst_x = dst_x\n            # if dst_y>max_dst_y:\n            #     max_dst_y = dst_y\n            destCoord = (dst_x, dst_y)\n            motion_vector = (motion_x, motion_y)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:185-208"
    },
    "4167": {
        "file_id": 529,
        "content": "This code segment is related to motion vector estimation in video processing. It calculates the destination coordinates and motion vector for a macro block, but there seems to be an issue with the motion scale. The code tries to assert that the motion_x and motion_y are scaled correctly based on the motion_scale, but it is causing some problem.",
        "type": "comment"
    },
    "4168": {
        "file_id": 529,
        "content": "            # print(destCoord)\n            # breakpoint()\n            if motion_vector == (0, 0):\n                # print(\"zero motion vector detected. skipping\")\n                # breakpoint()\n                continue\n            # print('destination coords:',destCoord)\n            # print('motion vector:',motion_vector)\n            motion_vectors_dict.update(\n                {destCoord: motion_vectors_dict.get(destCoord, []) + [motion_vector]}\n            )\n            # you know, different frame sources may lead to different results.\n            # these vectors could overlap. which one you want to keep? the smaller ones or the bigger ones?\n            # if destCoord in destCoords:\n            #     print(\"SKIPPING DUPLICATE DESTCOORD:\", destCoord)\n            #     print(\"PREVIOUS MV\",prevMV)\n            #     print(\"CURRENT MV\", mv)\n            #     continue\n            # else:\n            #     destCoords.add(destCoord)\n            # prevMV = mv\n            # try:\n            #     # src_x, src_y may not apply the same rule.",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:209-232"
    },
    "4169": {
        "file_id": 529,
        "content": "This code checks if a motion vector is zero and skips processing if it is. It then updates a dictionary of motion vectors by adding the new motion vector to the destination coordinate, while considering potential overlaps with other motion vectors.",
        "type": "comment"
    },
    "4170": {
        "file_id": 529,
        "content": "            #     # assert src_x % 16 == 8\n            #     # assert src_y % 16 == 8\n            #     assert checkMacroBlock(dst_x) is not None\n            #     assert checkMacroBlock(dst_y) is not None\n            #     # assert dst_x<=res_x # dst_x can go beyond the res_x\n            #     # assert dst_y<=res_y\n            #     # so all rules applied.\n            # except:\n            #     # print('source',src_x, src_y)\n            #     print(\"res\", res_x, res_y)\n            #     print('destionation',dst_x, dst_y)\n            #     print('motion',motion_x, motion_y)\n            #     print(\"scale\",motion_scale)\n        motion_vectors_dict_averaged = {\n            key: averageMotionVectors(motion_vectors_dict[key])\n            for key in motion_vectors_dict.keys()\n        }\n        # assuming no duplicates?\n        weighted_motion_vectors = []\n        weights = []\n        rectangles = []\n        motion_vectors_filtered = []  # for getting data later?\n        for (\n            blockCenterCoordinates,\n            average_motion_vector,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:233-257"
    },
    "4171": {
        "file_id": 529,
        "content": "Testing macro block placement, asserting non-null checkMacroBlock results for dst_x and dst_y, asserting within res limits (dst_x <= res_x), and handling exceptions with error printing. Averages motion vectors using averageMotionVectors function. Creates weightedMotionVectors list and weights list. Initializing rectangles and motionVectorsFiltered for later use.",
        "type": "comment"
    },
    "4172": {
        "file_id": 529,
        "content": "        ) in motion_vectors_dict_averaged.items():\n            if average_motion_vector == (0, 0):\n                continue\n                # wtf is this? why fucking zero?\n                # print('skipping zero average motion vector')\n                # print(\"destination coords\", key)\n                # print('average motion vector', average_motion_vector)\n            else:\n                m_x, m_y = average_motion_vector\n                motion_vectors_filtered.append(average_motion_vector)\n                rectangle_XYWH = getRectangleXYWHFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                rectangles.append(rectangle_XYWH)\n                blockWeight = getBlockWeightFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                weights.append(blockWeight)\n                weighted_motion_vectors.append(\n                    (\n                        m_x * blockWeight / frame_common_divisor,\n                        m_y * blockWeight / frame_common_divisor,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:258-279"
    },
    "4173": {
        "file_id": 529,
        "content": "This code block is filtering and processing motion vectors from a dictionary. It skips any average motion vector that is (0, 0) and then proceeds to calculate the weighted motion vectors by multiplying the motion vector with block weight and dividing it by a frame common divisor. The resulting coordinates are stored in 'weighted_motion_vectors'.",
        "type": "comment"
    },
    "4174": {
        "file_id": 529,
        "content": "                    )\n                )\n        weighted_motion_vectors = np.array(weighted_motion_vectors)\n        sum_weighted_motion_vector = np.sum(weighted_motion_vectors, axis=0)\n        average_global_weighted_motion_vector = (\n            sum_weighted_motion_vector / total_block_weights\n        )\n        sum_weights = sum(weights)\n        average_weighted_motion_vector = sum_weighted_motion_vector / sum_weights\n        motion_area_ratio = sum_weights / total_block_weights\n        # print(motion_vectors.shape)\n        motion_vectors_filtered_cartesian_distance = [\n            cartesianDistance(vector) for vector in motion_vectors_filtered\n        ] + [\n            0\n        ]  # to avoid errors.\n        motion_vectors_filtered_cartesian_distance = np.array(\n            motion_vectors_filtered_cartesian_distance\n        )\n        cartesianWeights = weights + [0]\n        cartesianWeights = np.array(cartesianWeights)\n        cartesianWeightsSum = np.sum(cartesianWeights)\n        weighted_motion_vectors_filtered_cartesian_distance = (",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:280-304"
    },
    "4175": {
        "file_id": 529,
        "content": "This code calculates the weighted average motion vector and the average weighted motion vector for motion vectors in a block. It also determines the motion area ratio, applies cartesian distance to filtered motion vectors, and stores them with corresponding weights.",
        "type": "comment"
    },
    "4176": {
        "file_id": 529,
        "content": "            motion_vectors_filtered_cartesian_distance * cartesianWeights\n        )\n        sum_weighted_motion_vectors_filtered_cartesian_distance = np.sum(\n            weighted_motion_vectors_filtered_cartesian_distance\n        )\n        # print(\"SUM\", sum_weighted_motion_vectors_filtered_cartesian_distance)\n        # breakpoint()\n        average_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance / cartesianWeightsSum\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance\n            / total_block_weights # this is a number, not array!\n        )\n        min_cartesian = min(motion_vectors_filtered_cartesian_distance)\n        max_cartesian = max(motion_vectors_filtered_cartesian_distance)\n        motion_area_ratio_array.append(motion_area_ratio)\n        # print()\n        # print(average_weighted_motion_vector)\n        # print(average_global_weighted_motion_vector)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:305-329"
    },
    "4177": {
        "file_id": 529,
        "content": "This code calculates the average and global-weighted motion vectors for a set of motion vectors, considering their weights and distances. It also finds the minimum and maximum cartesian distance in the list and appends the motion area ratio to an array.",
        "type": "comment"
    },
    "4178": {
        "file_id": 529,
        "content": "        # breakpoint()\n        average_weighted_motion_vector_cartesian=cartesianDistance(average_weighted_motion_vector)\n        average_weighted_motion_vector_cartesian_array.append(average_weighted_motion_vector_cartesian)\n        average_global_weighted_motion_vector_cartesian = cartesianDistance(average_global_weighted_motion_vector)\n        average_global_weighted_motion_vector_cartesian_array.append(\n        average_global_weighted_motion_vector_cartesian\n        )\n        average_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_global_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        if motion_vectors_dict_averaged != {}:\n            # breakpoint()\n            if visualize:\n                print(\"motion_area_ratio\", motion_area_ratio)\n                print(\"average_weighted_motion_vector_cartesian\", average_weighted_motion_vector_cartesian)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:330-348"
    },
    "4179": {
        "file_id": 529,
        "content": "Calculates the average weighted motion vector cartesian distance, appends it to the array and does the same for global vectors. If motion_vectors_dict_averaged is not empty, prints motion_area_ratio and average_weighted_motion_vector_cartesian if visualize is True.",
        "type": "comment"
    },
    "4180": {
        "file_id": 529,
        "content": "                print(\n                    \"average_global_weighted_motion_vecto_cartesianr\",\n                    average_global_weighted_motion_vector_cartesian,\n                )\n                print(\n                    \"average_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                print(\n                    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_global_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                motion_mask = np.zeros(\n                    (motion_render_frame[1], motion_render_frame[0], 1)\n                )\n                for index, (x, y, w, h) in enumerate(rectangles):\n                    pt1, pt2 = XYWHToDiagonal(x, y, w, h)\n                    # print(pt1, pt2)\n                    current_cartesian = motion_vectors_filtered_cartesian_distance[\n                        index\n                    ]",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:349-369"
    },
    "4181": {
        "file_id": 529,
        "content": "Calculates and prints average motion vector metrics. Creates a zeroed motion mask. Iterates through rectangles to calculate the current cartesian distance.",
        "type": "comment"
    },
    "4182": {
        "file_id": 529,
        "content": "                    # print(type(pt1), type(pt1[0]))\n                    relative_motion_cartesian = (current_cartesian - min_cartesian) / (\n                        max_cartesian - min_cartesian\n                    )  # must from 0 to 1 so we can plot this,\n                    # relative_motion_cartesian = 255*((current_cartesian-min_cartesian)/(max_cartesian-min_cartesian))\n                    # relative_motion_cartesian = int(relative_motion_cartesian)\n                    # relative_motion_cartesian = min(255,max(0, relative_motion_cartesian))\n                    # breakpoint()\n                    cv2.rectangle(\n                        motion_mask,\n                        pt1,\n                        pt2,\n                        color=(relative_motion_cartesian,),\n                        thickness=-1,\n                    )\n                # should we gaussian blur, threshold this, do convolution and then apply bounding box on it?\n                # # visualize this.\n                if show_picture:\n                    cv2.imshow(\"motion_mask\", motion_mask)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:370-388"
    },
    "4183": {
        "file_id": 529,
        "content": "This code calculates the relative motion vectors for a set of points and plots them on an image using OpenCV. It converts the motion vectors to a range of 0-255, representing the pixel intensity values used in the image plotting. The resulting image is then displayed if the \"show_picture\" flag is set.",
        "type": "comment"
    },
    "4184": {
        "file_id": 529,
        "content": "                    cv2.waitKey(100)\n            # may you create bounding box for this? for tracking motion? or not?\n        # breakpoint()\n    else:\n        break\n# print('max_dst_x', max_dst_x)\n# print('max_dst_y', max_dst_y)\nimport matplotlib.pyplot as plt\n# plt.style.use('dark_background')\na, b = 5,1\nfigure, axis = plt.subplots(a, b)\ndata = [\n    motion_area_ratio_array,\n    # average_weighted_motion_vector_array,\n    # average_global_weighted_motion_vector_array,\n    average_weighted_motion_vector_cartesian_array,\n    average_global_weighted_motion_vector_cartesian_array,\n    average_weighted_motion_vectors_filtered_cartesian_distance_array,\n    average_global_weighted_motion_vectors_filtered_cartesian_distance_array,\n]\ntitles = [\n    \"motion_area_ratio\",\n    # \"average_weighted_motion_vector\",\n    # \"average_global_weighted_motion_vector\",\n    \"average_weighted_motion_vector_cartesian\",\n    \"average_global_weighted_motion_vector_cartesian\",\n    \"average_weighted_motion_vectors_filtered_cartesian_distance\",",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:389-419"
    },
    "4185": {
        "file_id": 529,
        "content": "The code imports matplotlib and creates a figure with subplots. It stores various motion vector related arrays in the \"data\" list, presumably for plotting. These arrays are likely different representations of motion vectors at each point. The code then defines titles corresponding to each array's content.",
        "type": "comment"
    },
    "4186": {
        "file_id": 529,
        "content": "    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n]\n# breakpoint()\nassert len(titles) == len(data)\nassert a*b >= len(titles)\nfor _a in range(a):\n    for _b in range(b):\n        index = _a * b + _b\n        if index > len(data) - 1:\n            break\n        if a == 1:\n            if b == 1:\n                axis[0].plot(data[index])\n                axis[0].set_title(titles[index])\n            else:\n                axis[_b].plot(data[index])\n                axis[_b].set_title(titles[index])\n        elif b == 1:\n            axis[_a].plot(data[index])\n            axis[_a].set_title(titles[index])\n        else:\n            axis[_a, _b].plot(data[index])\n            axis[_a, _b].set_title(titles[index])\nplt.show()",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:420-444"
    },
    "4187": {
        "file_id": 529,
        "content": "This code plots the data using matplotlib and sets titles for each plot based on the corresponding title from the provided list. It checks for potential errors like unequal lengths of 'titles' and 'data', and also handles cases when 'a' or 'b' is 1, adjusting the number of axes accordingly.",
        "type": "comment"
    },
    "4188": {
        "file_id": 530,
        "content": "/tests/motion_vector_estimation/run.sh",
        "type": "filepath"
    },
    "4189": {
        "file_id": 530,
        "content": "This code runs a Docker container using lubo1994/mv-extractor image, mounting the current directory to /home/video_cap within the container and allowing X11 forwarding for graphical user interface support.",
        "type": "summary"
    },
    "4190": {
        "file_id": 530,
        "content": "#!/bin/bash\nxhost +\ndocker run \\\n    -it \\\n    --ipc=host \\\n    --env=\"DISPLAY\" \\\n    -v $(pwd):/home/video_cap \\\n    -v /tmp/.X11-unix:/tmp/.X11-unix:rw \\\n    lubo1994/mv-extractor:latest \\\n    \"$@\"",
        "type": "code",
        "location": "/tests/motion_vector_estimation/run.sh:1-12"
    },
    "4191": {
        "file_id": 530,
        "content": "This code runs a Docker container using lubo1994/mv-extractor image, mounting the current directory to /home/video_cap within the container and allowing X11 forwarding for graphical user interface support.",
        "type": "comment"
    },
    "4192": {
        "file_id": 531,
        "content": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py",
        "type": "filepath"
    },
    "4193": {
        "file_id": 531,
        "content": "The code initializes motion vector estimation, filters horizontal movement, improves accuracy using various techniques, processes motion vectors from coordinates, visualizes motion with OpenCV, creates bounding boxes, and handles further options. The code plots multiple sets of data onto a graph, iterating through lists using nested for loops, creating separate plots if desired, and then displays the graph.",
        "type": "summary"
    },
    "4194": {
        "file_id": 531,
        "content": "###################################################\n# aim to create optical flow here, with directions and convolution\n###################################################\n# it contains subpixel motion vectors. fucking hell\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# change source?\n# gif containers does not have motion vectors.\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n# without mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_without_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_without_mestimate.mp4\"\n# with mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:1-22"
    },
    "4195": {
        "file_id": 531,
        "content": "This code aims to create optical flow with motion vectors and convolution, using video files as input. The source file changes depending on the specific test case (with or without mestimate, different videos).",
        "type": "comment"
    },
    "4196": {
        "file_id": 531,
        "content": "source = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\nfrom lazero.utils.importers import cv2_custom_build_init\n# from sniffio import current_async_library\ncv2_custom_build_init()\nfrom mvextractor.videocap import VideoCap\nfrom caer.video.frames_and_fps import count_frames, get_res\nimport cv2\nframesCount = count_frames(source)\nres = get_res(source)  # (width, height)\nprint(\"RES: %s\" % str(res))\nres_x, res_y = res\nframe_common_divisor = min(res_x, res_y)\nimport math\ndef cartesianDistance(d2vector):\n    try:\n        x, y = d2vector\n        return math.sqrt(x**2 + y**2)\n    except:\n        print('item unpackable.', d2vector)\n        return 0\ndef XYWHToDiagonal(x, y, w, h):\n    return (x, y), (x + w, y + h)\n# 如果整除16那么就在这个范围里面 如果不整除范围就要扩大 扩大到相应的16的倍数\ndef get16Value(res_x):\n    rem_x = res_x % 16\n    val = res_x // 16\n    if rem_x != 0:\n        val += 1\n    return val\nx_16val = get16Value(res_x)\ny_16val = get16Value(res_y)\nmotion_render_frame = (x_16val * 16, y_16val * 16)\ntotal_block_weights = x_16val * y_16val * 2 * 2",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:24-70"
    },
    "4197": {
        "file_id": 531,
        "content": "This code initializes necessary libraries and imports, gets the resolution of a video source, calculates the frame count, and sets up variables for motion vector estimation. The functions cartesianDistance and XYWHToDiagonal are defined for spatial calculations, and get16Value is used to ensure the resolution is a multiple of 16 for the motion vector estimation process. The total number of block weights is calculated based on the video's resolution.",
        "type": "comment"
    },
    "4198": {
        "file_id": 531,
        "content": "cap = VideoCap()\ncap.open(source)  # wtf is going on here?\n# if there is nothing we will breakup\n# visualize, show_picture = True, True\nvisualize, show_picture = False, False\n# so there can only be one such macroblock\ndef checkMacroBlock(value):\n    for mod in [16, 8]:\n        modValue = value % mod\n        if modValue == mod / 2:\n            return mod\n    # if not satisfied, we are shit.\nfrom functools import lru_cache\n@lru_cache(maxsize=4)\ndef getModXModYFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = checkMacroBlock(block_x), checkMacroBlock(block_y)\n    if mod_x is not None and mod_y is not None:\n        return mod_x, mod_y\n    else:\n        print(\"block center coordinates\", blockCenterCoordinates)\n        print(\"WTF IS GOING ON WITH THE BLOCK CENTER\")\n        breakpoint()\n        return 0, 0\ndef getRectangleXYWHFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:72-106"
    },
    "4199": {
        "file_id": 531,
        "content": "The code initializes a VideoCap object and opens a specified source. It then defines two functions: `checkMacroBlock` to determine the macroblock size based on given values, and `getModXModYFromBlockCenterCoordinates` to get the modX and modY from block center coordinates using `checkMacroBlock`. The code also includes error handling in case of unexpected block center coordinates.",
        "type": "comment"
    }
}