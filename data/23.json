{
    "2300": {
        "file_id": 236,
        "content": "/tests/qq_share_autojs/appium_test.py",
        "type": "filepath"
    },
    "2301": {
        "file_id": 236,
        "content": "Code sets up Appium test for Android device using the uiautomator2 automation, launches com.android.settings app, searches for \"Battery\" and clicks it, then quits the driver if open.",
        "type": "summary"
    },
    "2302": {
        "file_id": 236,
        "content": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom appium import webdriver\nfrom appium.webdriver.common.appiumby import AppiumBy\ncapabilities = dict(\n    platformName='Android',\n    automationName='uiautomator2',\n    deviceName='Android',\n    appPackage='com.android.settings',\n    appActivity='.Settings',\n    language='en',\n    locale='US',\n    noSign=True\n)\nappium_server_url = 'http://localhost:4723'\ndriver = webdriver.Remote(appium_server_url, capabilities)\nel = driver.find_element(by=AppiumBy.XPATH, value='//*[@text=\"Battery\"]')\nel.click()\nif driver:\n    driver.quit()",
        "type": "code",
        "location": "/tests/qq_share_autojs/appium_test.py:1-27"
    },
    "2303": {
        "file_id": 236,
        "content": "Code sets up Appium test for Android device using the uiautomator2 automation, launches com.android.settings app, searches for \"Battery\" and clicks it, then quits the driver if open.",
        "type": "comment"
    },
    "2304": {
        "file_id": 237,
        "content": "/tests/qq_share_autojs/adb_unlock.sh",
        "type": "filepath"
    },
    "2305": {
        "file_id": 237,
        "content": "This code uses ADB to simulate touch events on an Android device. It performs a power button press, a swipe gesture, enters text, and presses the back key.",
        "type": "summary"
    },
    "2306": {
        "file_id": 237,
        "content": "adb -s 192.168.10.3:5555 shell input keyevent 26\nadb -s 192.168.10.3:5555 shell input swipe 500 500 500 0\nadb -s 192.168.10.3:5555 shell input text \"Bumper\\&Mountains\"\nadb -s 192.168.10.3:5555 shell input keyevent 66",
        "type": "code",
        "location": "/tests/qq_share_autojs/adb_unlock.sh:1-4"
    },
    "2307": {
        "file_id": 237,
        "content": "This code uses ADB to simulate touch events on an Android device. It performs a power button press, a swipe gesture, enters text, and presses the back key.",
        "type": "comment"
    },
    "2308": {
        "file_id": 238,
        "content": "/tests/qq_share_autojs/adb_check_lock.sh",
        "type": "filepath"
    },
    "2309": {
        "file_id": 238,
        "content": "This script checks if the phone is locked or unlocked by running \"adb -s 192.168.10.3:5555 shell dumpsys window | grep mDreamingLockscreen=false\" and then executes \"bash adb_unlock.sh\" if locked, otherwise exits. The check is performed in an infinite loop using a \"while true\" statement.",
        "type": "summary"
    },
    "2310": {
        "file_id": 238,
        "content": "function checkScreen {\n  adb -s 192.168.10.3:5555 shell dumpsys window | grep mDreamingLockscreen=false\n  if [[ $? -eq 1 ]]; then\n    echo \"phone locked\"\n    bash adb_unlock.sh\n    sleep 2\n  else\n    echo \"phone unlocked\"\n    exit\n  fi\n}\nwhile true\ndo\n  checkScreen\ndone",
        "type": "code",
        "location": "/tests/qq_share_autojs/adb_check_lock.sh:1-16"
    },
    "2311": {
        "file_id": 238,
        "content": "This script checks if the phone is locked or unlocked by running \"adb -s 192.168.10.3:5555 shell dumpsys window | grep mDreamingLockscreen=false\" and then executes \"bash adb_unlock.sh\" if locked, otherwise exits. The check is performed in an infinite loop using a \"while true\" statement.",
        "type": "comment"
    },
    "2312": {
        "file_id": 239,
        "content": "/tests/qq_share_autojs/adb_autox_launch.sh",
        "type": "filepath"
    },
    "2313": {
        "file_id": 239,
        "content": "This code is using the 'adb' command to launch the 'ShortcutActivity' in AutoJS v6 on a specific device (192.168.10.3:5555). It starts an activity and passes an intent action with the path to the 'qq_share_auto.js' script as an extra parameter.",
        "type": "summary"
    },
    "2314": {
        "file_id": 239,
        "content": "adb -s 192.168.10.3:5555 shell am start -n org.autojs.autoxjs.v6/org.autojs.autojs.external.shortcut.ShortcutActivity -a android.intent.action.MAIN -e path \"/storage/emulated/0/脚本/qq_share_auto.js\"",
        "type": "code",
        "location": "/tests/qq_share_autojs/adb_autox_launch.sh:1-1"
    },
    "2315": {
        "file_id": 239,
        "content": "This code is using the 'adb' command to launch the 'ShortcutActivity' in AutoJS v6 on a specific device (192.168.10.3:5555). It starts an activity and passes an intent action with the path to the 'qq_share_auto.js' script as an extra parameter.",
        "type": "comment"
    },
    "2316": {
        "file_id": 240,
        "content": "/tests/qq_share_autojs/account_management.sh",
        "type": "filepath"
    },
    "2317": {
        "file_id": 240,
        "content": "The code is starting the \"com.tencent.mobileqq.activity.AccountManageActivity\" activity, which likely pertains to account management in a mobile application named MobileQQ.",
        "type": "summary"
    },
    "2318": {
        "file_id": 240,
        "content": "am start  com.tencent.mobileqq.activity.AccountManageActivity",
        "type": "code",
        "location": "/tests/qq_share_autojs/account_management.sh:1-1"
    },
    "2319": {
        "file_id": 240,
        "content": "The code is starting the \"com.tencent.mobileqq.activity.AccountManageActivity\" activity, which likely pertains to account management in a mobile application named MobileQQ.",
        "type": "comment"
    },
    "2320": {
        "file_id": 241,
        "content": "/tests/qq_share_autojs/autojs_scripts/wesee_search.js",
        "type": "filepath"
    },
    "2321": {
        "file_id": 241,
        "content": "This code initiates the WeSee app, starts the GlobalSearchActivity, and inputs the search term \"猫猫\" before triggering a search with KEYCODE_ENTER.",
        "type": "summary"
    },
    "2322": {
        "file_id": 241,
        "content": "pkg=\"com.tencent.weishi\"\nact=\"com.tencent.oscar.module.discovery.ui.GlobalSearchActivity\"\napp.startActivity({root:true,\npackageName:pkg,className:act,\naction:\"View\"})\nwaitForActivity(act)\nsetText(\"猫猫\")\nKeyCode(\"KEYCODE_ENTER\")",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/wesee_search.js:1-12"
    },
    "2323": {
        "file_id": 241,
        "content": "This code initiates the WeSee app, starts the GlobalSearchActivity, and inputs the search term \"猫猫\" before triggering a search with KEYCODE_ENTER.",
        "type": "comment"
    },
    "2324": {
        "file_id": 242,
        "content": "/tests/qq_share_autojs/autojs_scripts/taobao_gg_search.js",
        "type": "filepath"
    },
    "2325": {
        "file_id": 242,
        "content": "This code reduces music volume, opens Taobao app with custom URL, handles session ID and video player settings using item ID, GG search request, and referer origin, while waiting for prompts and handling expired ones by polling, clicking \"I know\" button, setting specific text, searching for \"猫猫\", and managing volume settings.",
        "type": "summary"
    },
    "2326": {
        "file_id": 242,
        "content": "package=\"com.taobao.taobao\";\nactivity=\"com.taobao.search.searchdoor.SearchDoorActivity\";\n//activity=\"com.taobao.search.searchdoor.MultipleSearchDoorActivity\";\nvar vol=device.getMusicVolume()\ndevice.setMusicVolume(0)\n// mute the thing please?\napp.startActivity({action:\"View\",\npackageName:package,className:activity,\nroot:true,\n//category:[\"com.taobao.intent.category.search.MULTI_SEARCHDOOR\"],\ndata:\"http://s.m.taobao.com/...\",})\n // not launching 淘宝逛逛\n /*\n 2221:2022-11-02 13:02:20.328 | startActivity { calling=com.taobao.taobao:-1--1, rc=10159-1987, iTS=false, requestCode=-1, startFlags=0, target=com.taobao.taobao/com.taobao.search.searchdoor.SearchDoorActivity<true>, intent=Intent { act=android.intent.action.VIEW dat=http://s.m.taobao.com/... pkg=com.taobao.taobao cmp=com.taobao.taobao/com.taobao.search.searchdoor.SearchDoorActivity (has extras) }, extras={ NAV_START_ACTIVITY_TIME:(java.lang.Long)1667365340316, ad_type:(java.lang.String)1.0, NAV_TO_URL_START_TIME:(java.lang.Long)1667365340268, referr",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/taobao_gg_search.js:1-19"
    },
    "2327": {
        "file_id": 242,
        "content": "The code sets the music volume to 0 and then launches the Taobao app's search function by starting the specified activity with a specific URL. The intent action is VIEW, and it targets com.taobao.taobao/com.taobao.search.searchdoor.SearchDoorActivity.",
        "type": "comment"
    },
    "2328": {
        "file_id": 242,
        "content": "er:(java.lang.String)http://market.m.taobao.com/app/tb-source-app/video-fullpage/pages/index2?wh_weex=false&wx_navbar_transparent=true&wx_navbar_hidden=true&id=380201806724&bizParameters=%7B%22itemIds%22%3A%22681366994883%22%2C%22contentId%22%3A%22380201806724%22%2C%22videoId%22%3A%22380201806724%22%7D&videoUrl=http%3A%2F%2Fcloud.video.taobao.com%2Fplay%2Fu%2F2208882892036%2Fp%2F1%2Fe%2F6%2Ft%2F1%2F380201806724.mp4&type=cainixihuansy&source=cainixihuansy&business_spm=a211r6.cjvideo&hideAccountInfo=false&extParams=%7B%2288_bucket%22%3A%220%22%7D&scm=1007.10088.311498.0&spm=a2141.1.guessitemtab_1.5&pvid=b9ca1499-6a25-4913-9b4a-a2c703576f45&utparam=%7B%22x_sid%22%3A%2252aa36213ede47006361f9b21dbc602d%22%2C%22card_subtype%22%3A%22xgc%22%2C%22up_pvid%22%3A%22f88bbfa6-c859-44a5-94bb-e0599c889e5a%22%2C%22x_sid_cpm%22%3A%22be353521ca7fc7006361f9b20c542845%22%2C%22x_object_type%22%3A%22VIDEO_916%22%2C%22x_ad_bucketid_cpm%22%3A%2212676854%2C17296858%22%2C%22hybrid_score%22%3A0.303358%2C%22x_biz%",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/taobao_gg_search.js:19-19"
    },
    "2329": {
        "file_id": 242,
        "content": "This code appears to be a URL for a Taobao video page, containing various parameters and identifiers for tracking and customization purposes.",
        "type": "comment"
    },
    "2330": {
        "file_id": 242,
        "content": "22%3A%22VIDEO_916%22%2C%22sessionid%22%3A%22b9ca1499-6a25-4913-9b4a-a2c703576f45%22%2C%22tpp_buckets%22%3A%22%7E9%7EU2wG6g9N1IaCq1M7J1Ia11K6A2Tg4x4I02E6nIfMi-u9KM9NveH1FhPjhxK7AniKCnO3mIO8Kj2dCQ6NhoMCwioGO1X6ddGN2W5qOUcWe41W2PePv31PMlSe11O2XcVr31EA5_s41zO2NubdRr-Z851Q1I7Li2dFU4S93dGSkxl5dU2TcFf7dBN8Cf8d_2ImFqbdY2A1JvbdM1U1P3cdX1y4IlcdZ1L6w9ddyCN9ddBN9AeedJL7Htgd_2Qpx2jdCW2QgjdzC4w2kdDJ8B6ldF%7EwpwFaf9z%7EZb7wWs29B%7EJhwQ4f9-B22y65-1Gp2BfmB2%7EGdwGfh9O1K52Nj5GSg2RplCB4V3mIN61FhfdIGcW041AEuHshdEDn1Lj7dFY5y98dB1O4H29dz-hw3cdPL1MqbdDVj1V4mdZ2C1WfkdFEp-4mdOF1IemdU%7EXk1wC0d9G%7EPi3wJh59wNeUo1Xp%7Ezv1wYcn5wEt7Uv2dD2C7Li3dGqKuQp7dU4zk1AcedZ4W7W0idRp%7EWecwFq49HPt8Dv9dNZ82U8gdKNqS6kdQWIbkdYU4VskdQ%7EFt4wG8g9A%22%2C%22miniapphc_score%22%3A0.0%2C%22x_summary_trackInfo%22%3A%22380569870474---380569870474-new_vp_4_3-new_vp_4_3%22%2C%22pvid%22%3A%22b9ca1499-6a25-4913-9b4a-a2c703576f45%22%2C%22evo_buckets%22%3A%22evo263227_118977%23275047_321220%23286254_324141%23337973_477247evo%22%2C%22auction_sco",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/taobao_gg_search.js:19-19"
    },
    "2331": {
        "file_id": 242,
        "content": "The code seems to be related to tracking information, session ID, and possibly video player settings for a specific platform or application.",
        "type": "comment"
    },
    "2332": {
        "file_id": 242,
        "content": "re%22%3A0.0%2C%22scm%22%3A%221007.10088.311498.428654_37338_4631_438253_439584_428623_446528_434662_23752_438956_34262_433641_443307_25137_36851_22642_38173_25152_431777_445505_440772_438225_439515_37791_36729_1862_34124_26810_438089_445972_429366_447685_15345_10206_438387_19172_18035_439601%22%2C%22glc%22%3A%221%22%2C%22guessModelVersion%22%3A%2220211016%22%2C%22mtx_c%22%3A380201806724%2C%22matrix_score%22%3A0.0%2C%22miniapp_score%22%3A0.0%2C%22card_type%22%3A%22xgc%22%2C%22x_item_ids%22%3A%22681366994883%22%2C%22author_id%22%3A%222208882892036%22%2C%22guess_buckets%22%3A%226595_11513_11609_12894_13440_17348_19178_21337_21230_20634_22262%22%2C%22x_sytab%22%3A%221001%22%2C%22x_object_id%22%3A380201806724%7D&itemid=681366994883&item_id=681366994883&noDynamicRec=1&newItemList=1&utabtest=aliabtest184572_25123, URL_REFERER_ORIGIN:(java.lang.String)//s.m.taobao.com/h5entry?g_channelSrp=videointeract&g_tab=tbexperience&g_pfilter=daren&g_closeModues=tab&closeExpSubTab=true&g_csearchdoor_spm=a",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/taobao_gg_search.js:19-19"
    },
    "2333": {
        "file_id": 242,
        "content": "Code contains various parameters for a Taobao GG search request, including scm, glc, guessModelVersion, mtx_c, matrix_score, miniapp_score, card_type, x_item_ids, author_id, guess_buckets, x_sytab, and x_object_id. The item ID is 681366994883. It also includes parameters for noDynamicRec, newItemList, and utabtest, and the URL referer origin is s.m.taobao.com/h5entry.",
        "type": "comment"
    },
    "2334": {
        "file_id": 242,
        "content": "310p.14955560&spm=a310p.13800399&launchMode=android_new_task&g_closeExpSubTab=true, WEEX_NAV_PROCESSOR_TIME:(java.lang.Long)1667365340292 } }.../xintent/logs #\n */\n waitForPackage(package);\n //跳转之后可能出现过期的提示\n //可能需要轮询\n for (var i=0;i<5;i++){//triple check?\n while (true){\n     sleep(200);\n  var succ=click(\"我知道了\");\n  if (succ){break;}\n if (currentActivity() ==activity)break;\n }\n }\n mytext=\"【淘宝】https://m.tb.cn/h.UfbOyIi?sm=26a80a?tk=XjXUd0OFtMN CZ0001 「这就是：我预判了你的预判吗」点击链接直接打开\"\n setText(mytext)\n //淘宝直接输入到搜索框里面 然后用这个进入视频搜索界面\n while(!click(\"搜索\"));\nwaitForActivity(\"com.taobao.android.interactive.timeline.VideoListActivity2\")\nid(\"imgSearch\").findOne().click()\nwaitForActivity(\"com.taobao.search.searchdoor.MultipleSearchDoorActivity\")\nsetText(\"猫猫\")\n//Text(\"猫猫\")\nwhile(!click(\"搜索\"));\n//可能出现搜索失败的情况 请注意\ndevice.setMusicVolume(vol)",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/taobao_gg_search.js:19-54"
    },
    "2335": {
        "file_id": 242,
        "content": "Code snippet is performing actions in a Taobao app. It waits for the package, handles expired prompts by polling, clicks \"I know\" button, sets a specific text and searches for \"猫猫\". It ensures volume settings by setting music volume and possibly handles search failure scenarios.",
        "type": "comment"
    },
    "2336": {
        "file_id": 243,
        "content": "/tests/qq_share_autojs/autojs_scripts/show_toast.js",
        "type": "filepath"
    },
    "2337": {
        "file_id": 243,
        "content": "This code displays a toast notification with the message \"hello\" in the autojs_scripts directory.",
        "type": "summary"
    },
    "2338": {
        "file_id": 243,
        "content": "toast(\"hello\");",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/show_toast.js:1-1"
    },
    "2339": {
        "file_id": 243,
        "content": "This code displays a toast notification with the message \"hello\" in the autojs_scripts directory.",
        "type": "comment"
    },
    "2340": {
        "file_id": 244,
        "content": "/tests/qq_share_autojs/autojs_scripts/qq_share_auto.js",
        "type": "filepath"
    },
    "2341": {
        "file_id": 244,
        "content": "This script performs activities for QQ Share, searches \"卷王培训基地\", clicks the contact number, attempts to find and click \"发送\" while waiting for \"返回哔哩哔哩\", then removes 'flag' file using AutoJS.",
        "type": "summary"
    },
    "2342": {
        "file_id": 244,
        "content": "auto();\nvar cmd = \"am start -S -n com.tencent.mobileqq/com.tencent.mobileqq.activity.JumpActivity -a android.intent.action.VIEW -d 'mqqapi://share/to_fri?src_type=app&version=1&file_type=news&file_data=L3N0b3JhZ2UvZW11bGF0ZWQvMC9QaWN0dXJlcy9zaGFyZS9jYXQuZ2lm&file_uri=ZmlsZTovLy9zdG9yYWdlL2VtdWxhdGVkLzAvUGljdHVyZXMvc2hhcmUvY2F0LmdpZg%3D%3D&title=5ZOU5ZOp5ZOU5ZOp&description=5Za15Za15Za1&share_id=100951776&url=aHR0cHM6Ly9iMjMudHYvdUhNTDVtaQ%3D%3D&app_name=5ZOU5ZOp5ZOU5ZOp&req_type=Nw%3D%3D&mini_program_appid=MTEwOTkzNzU1Nw%3D%3D&mini_program_path=cGFnZXMvdmlkZW8vdmlkZW8%2FYnZpZD1CVjF6ZDR5MTE3V0Y%3D&mini_program_type=Mw%3D%3D&cflag=MA%3D%3D&third_sd=dHJ1ZQ%3D%3D' -e pkg_name tv.danmaku.bili\";\nshell(cmd,true);\nwaitForActivity(\"com.tencent.mobileqq.activity.ForwardRecentActivity\");\nwhile(!click(\"搜索\"));\nsetText(\"卷王培训基地\");\nwhile(!click(\"543780931\"));\nwhile(true){\nvar send =text(\"发送\").findOne(1000);\nif (send !=null){send.click();}\n// will be null.\nvar ret=text(\"返回哔哩哔哩\").findOne(1000);\nif (ret != null){ret.click();break;}",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/qq_share_auto.js:1-21"
    },
    "2343": {
        "file_id": 244,
        "content": "The script starts an activity for QQ Share, sets text, and waits for a specific activity to launch. It then clicks on \"搜索\", enters the search term \"卷王培训基地\", clicks on the contact number \"543780931\", and repeatedly tries to find the \"发送\" button while waiting for the \"返回哔哩哔哩\" button to appear before finally clicking it and breaking the loop.",
        "type": "comment"
    },
    "2344": {
        "file_id": 244,
        "content": "}\nshell(\"rm /storage/emulated/0/flag\")",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/qq_share_auto.js:22-24"
    },
    "2345": {
        "file_id": 244,
        "content": "Removes the 'flag' file from storage using AutoJS script.",
        "type": "comment"
    },
    "2346": {
        "file_id": 245,
        "content": "/tests/qq_share_autojs/autojs_scripts/qq_account_switch.js",
        "type": "filepath"
    },
    "2347": {
        "file_id": 245,
        "content": "This code starts the \"com.tencent.mobileqq\" application, specifically the AccountManageActivity, which allows switching between different QQ accounts.",
        "type": "summary"
    },
    "2348": {
        "file_id": 245,
        "content": "app.startActivity({\n    root:true,\n        action: \"View\",\n        packageName:\"com.tencent.mobileqq\",\n        className: \"com.tencent.mobileqq.activity.AccountManageActivity\"\n    });",
        "type": "code",
        "location": "/tests/qq_share_autojs/autojs_scripts/qq_account_switch.js:1-6"
    },
    "2349": {
        "file_id": 245,
        "content": "This code starts the \"com.tencent.mobileqq\" application, specifically the AccountManageActivity, which allows switching between different QQ accounts.",
        "type": "comment"
    },
    "2350": {
        "file_id": 246,
        "content": "/tests/cpm_chinese_chitchat_model_gpt2/test.sh",
        "type": "filepath"
    },
    "2351": {
        "file_id": 246,
        "content": "This code changes the directory to GPT2-chitchat, checks RAM consumption and urges to buy new RAM for CPU model testing. It runs 'interact.py' with no CUDA and using a specific model path.",
        "type": "summary"
    },
    "2352": {
        "file_id": 246,
        "content": "# no fucking gpu. just test how much RAM it consumes.\ncd GPT2-chitchat # 1.8GB mem consumption. freaking hell.\n# BUY NEW RAM AND RUN MODELS ON CPU!\npython3 interact.py --no_cuda --model_path ../model",
        "type": "code",
        "location": "/tests/cpm_chinese_chitchat_model_gpt2/test.sh:1-4"
    },
    "2353": {
        "file_id": 246,
        "content": "This code changes the directory to GPT2-chitchat, checks RAM consumption and urges to buy new RAM for CPU model testing. It runs 'interact.py' with no CUDA and using a specific model path.",
        "type": "comment"
    },
    "2354": {
        "file_id": 247,
        "content": "/tests/cpm_chinese_chitchat_model_gpt2/init.sh",
        "type": "filepath"
    },
    "2355": {
        "file_id": 247,
        "content": "Code is cloning the GPT2-chitchat repository with a single commit from GitHub.",
        "type": "summary"
    },
    "2356": {
        "file_id": 247,
        "content": "git clone --depth 1 https://github.com/yangjianxin1/GPT2-chitchat",
        "type": "code",
        "location": "/tests/cpm_chinese_chitchat_model_gpt2/init.sh:1-1"
    },
    "2357": {
        "file_id": 247,
        "content": "Code is cloning the GPT2-chitchat repository with a single commit from GitHub.",
        "type": "comment"
    },
    "2358": {
        "file_id": 248,
        "content": "/tests/anime_highlight_cuts/theme_collector/yolov8_train_save_test.py",
        "type": "filepath"
    },
    "2359": {
        "file_id": 248,
        "content": "The code is training a YOLO object detection model, validating its performance, and then exporting it to be used later. It uses the \"yolov8n.pt\" pre-trained model, trains it for 3 epochs with the provided dataset, evaluates its validation accuracy, displays the results, and finally exports the trained model as \"pip_detector.pth\".",
        "type": "summary"
    },
    "2360": {
        "file_id": 248,
        "content": "from ultralytics import YOLO\n# pip install opencv-python==4.5.5.64\n# shit?\n# https://github.com/asweigart/pyautogui/issues/706\nmodel = YOLO(\"yolov8n.pt\")\n# print(model)\n# model.to('mps')\n# The operator 'aten::_slow_conv2d_forward' is not current implemented for the MPS device.\n# fuck.\n# breakpoint()\nimport rich\ntrain_result = model.train(epochs=3, data=\"./pip_dataset/pip_dataset.yaml\")\nprint(\"TRAIN RESULT?\")\nrich.print(train_result)\nval_result = model.val()\nprint(\"VALIDATION RESULT?\")\nrich.print(val_result)\ntest_result = model(\"./pip_dataset/images/test/000000003099.png\")\ntest_boxes = test_result[0].boxes\ntest_classes, test_xywh, test_confidence = (\n    test_boxes.cls.numpy(),\n    test_boxes.xywh.numpy(), # the xy in this xywh means the center of the bounding box.\n    test_boxes.conf.numpy(),\n)\nprint(\"XYWH?\", test_xywh)\nprint(\"CLASSES?\", test_classes)\nprint(\"CONFIDENCE?\", test_confidence)\n# model.export(format=\"pytorch\", path=\"./pip_detector.pth\")",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/yolov8_train_save_test.py:1-39"
    },
    "2361": {
        "file_id": 248,
        "content": "The code is training a YOLO object detection model, validating its performance, and then exporting it to be used later. It uses the \"yolov8n.pt\" pre-trained model, trains it for 3 epochs with the provided dataset, evaluates its validation accuracy, displays the results, and finally exports the trained model as \"pip_detector.pth\".",
        "type": "comment"
    },
    "2362": {
        "file_id": 249,
        "content": "/tests/anime_highlight_cuts/theme_collector/yolov8_test.py",
        "type": "filepath"
    },
    "2363": {
        "file_id": 249,
        "content": "This code imports and processes images using the YOLO model, filters frames based on criteria, selects candidates for main frame detection, draws a rectangle around the detected frame, and displays an image with the PIP frame.",
        "type": "summary"
    },
    "2364": {
        "file_id": 249,
        "content": "from ultralytics import YOLO\n## yolov8 tracking needs special ultralytics version. it is been updated too damn often. you need to downgrade.\n## https://github.com/mikel-brostrom/yolov8_tracking\n## this might add unwanted overheads. warning!\n# no one will miss `genesis.pt`, right?\nmodel = YOLO(\"general_ver1.pt\")\n## TODO: create dataset to prevent detection of pure color/gradient borders\n# model = YOLO(\"ver3.pt\")\n# find trained weights on huggingface:\n# https://huggingface.co/James4Ever0/yolov8_pip_ultralytics\n# imagePaths = [\n#     \"000000003099.png\",\n#     \"simple_pip.png\",\n#     \"no_border_0.jpg\",\n#     \"has_border_0.jpg\",\n#     \"has_border_1.jpg\",\n#     \"has_border_2.jpg\",\n# ]\nimport os\nimagePaths = [\n    fpath\n    for fpath in os.listdir(\".\")\n    if fpath.split(\".\")[-1].lower() in (\"jpg\", \"jpeg\", \"png\")\n]\nimport cv2\nframeRatioFilters = [(16 / 9, 0.2, \"landscape\")]\nframeAreaThreshold = 0.15\nfor imagePath in imagePaths:\n    image = cv2.imread(imagePath)\n    output = model(image)\n    height, width, _ = image.shape\n    center = (width / 2, height / 2)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/yolov8_test.py:1-43"
    },
    "2365": {
        "file_id": 249,
        "content": "This code imports the YOLO model from ultralytics, loads a specific model file, and defines image paths. It also retrieves all image files in the current directory, filters frames based on aspect ratio and area threshold, and processes each image using the loaded YOLO model. This might involve downgrading the ultralytics version due to frequent updates and creating a dataset to prevent detection of pure color/gradient borders as TODO tasks.",
        "type": "comment"
    },
    "2366": {
        "file_id": 249,
        "content": "    # print(\"CENTER:\",center)\n    candidates = []\n    for xyxy in output[0].boxes.xyxy.numpy().astype(int).tolist():\n        x0, y0, x1, y1 = xyxy\n        currentFrameWidth = x1 - x0\n        currentFrameHeight = y1 - y0\n        currentFrameArea = currentFrameWidth * currentFrameHeight\n        # area filter? a must.\n        if currentFrameArea / (height * width) < frameAreaThreshold:\n            continue\n        else:\n            # filter out malformed frames? just for anime?\n            currentFrameRatio = currentFrameWidth / currentFrameHeight\n            if all(\n                [\n                    (\n                        currentFrameRatio < frameRatioStandard - frameRatioMargin\n                        or currentFrameRatio > frameRatioStandard + frameRatioMargin\n                    )\n                    for frameRatioStandard, frameRatioMargin, _ in frameRatioFilters\n                ]\n            ):\n                continue\n            candidates.append((x0, y0, x1, y1))\n    # sort it by area, then by centrality?",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/yolov8_test.py:44-69"
    },
    "2367": {
        "file_id": 249,
        "content": "This code filters out detected frames based on area, frame aspect ratio, and possibly malformed frames. It appends valid frames to the 'candidates' list, which may be sorted by area and centrality later in the script.",
        "type": "comment"
    },
    "2368": {
        "file_id": 249,
        "content": "    candidates.sort(\n        key=lambda points: -(points[2] - points[0]) * (points[3] - points[1])\n    )\n    # print(\"SORT_AREA:\", [(points[2] - points[0]) * (points[3] - points[1]) for points in candidates])\n    candidates = candidates[:2]\n    candidates.sort(\n        key=lambda points: (((points[2] + points[0]) / 2) - center[0]) ** 2\n        + (((points[3] + points[1]) / 2) - center[1]) ** 2\n    )\n    # print(\"SORT_CENTRALITY:\", [(((points[2] + points[0]) / 2) - center[0]) ** 2\n    # + (((points[3] + points[1]) / 2) - center[1]) ** 2 for points in candidates])\n    if len(candidates) > 0:\n        print(\"main frame found.\")\n        x0, y0, x1, y1 = candidates[0]\n        cv2.rectangle(image, (x0, y0), (x1, y1), (0, 0, 255), thickness=10)\n    else:\n        print(\"no main frame found.\")\n    cv2.imshow(\"PIP\", image)\n    cv2.waitKey(0)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/yolov8_test.py:71-89"
    },
    "2369": {
        "file_id": 249,
        "content": "The code sorts the candidates by area and centrality, selects two candidates, and if a main frame is found, it draws a rectangle around it. If no main frame is found, it displays a message. Finally, it shows the image with the PIP frame.",
        "type": "comment"
    },
    "2370": {
        "file_id": 250,
        "content": "/tests/anime_highlight_cuts/theme_collector/view_boundingbox.py",
        "type": "filepath"
    },
    "2371": {
        "file_id": 250,
        "content": "This code reads a bounding box coordinates, calculates the minimum x and y values, and then uses OpenCV to draw a rectangle on an image at these coordinates. The color of the rectangle is green (0, 255, 0) and the thickness is 3 pixels. Finally, it displays the image with the rectangle drawn in a window named \"PIP\".",
        "type": "summary"
    },
    "2372": {
        "file_id": 250,
        "content": "x, y, w, h = [1118.5, 545.5, 1585, 1069]\nmin_x, min_y = int(x - (w / 2)), int(y - (h / 2))\nimport cv2\nimagePath = \"\"\nimage = cv2.imread(imagePath)\np0, p1 = (min_x, min_y), (min_x + w, min_y + h)\ncv2.rectangle(image, p0, p1, (0, 255, 0), 3)\ncv2.imshow(\"PIP\", image)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/view_boundingbox.py:1-11"
    },
    "2373": {
        "file_id": 250,
        "content": "This code reads a bounding box coordinates, calculates the minimum x and y values, and then uses OpenCV to draw a rectangle on an image at these coordinates. The color of the rectangle is green (0, 255, 0) and the thickness is 3 pixels. Finally, it displays the image with the rectangle drawn in a window named \"PIP\".",
        "type": "comment"
    },
    "2374": {
        "file_id": 251,
        "content": "/tests/anime_highlight_cuts/theme_collector/test_video_overlay.sh",
        "type": "filepath"
    },
    "2375": {
        "file_id": 251,
        "content": "This script combines two video files, scales the first one to specific dimensions, and overlays them. It is used for creating a video highlight with theme overlay. The basepath variable contains the downloaded videos' location. The resulting video is saved as output.mp4 if both inputs are present, or output_1.mp4 if only the second input video is provided.",
        "type": "summary"
    },
    "2376": {
        "file_id": 251,
        "content": "video_0=\"[Sakurato] Onii-chan wa Oshimai! [未删减][02][AVC-8bit 1080p AAC][CHT].mp4\"\nvideo_1=\"[MLU-S] Onii-chan wa Oshimai! - 03 [1080p][Multi Subs].mkv\"\nbasepath=\"/Users/jamesbrown/Downloads/anime_download\"\nvideo_2=\"[Sakurato] Onii-chan wa Oshimai! [01][AVC-8bit 1080p AAC][CHT].mp4\"\n# ffmpeg -y -t 0:04:00 -i \"$basepath/$video_0\" -t 0:04:00 -i \"$basepath/$video_1\" -filter_complex \"[0:v]scale=1152:648[v0];[1:v][v0]overlay=384:216\" output.mp4\nffmpeg -y -t 0:04:00 -i \"$basepath/$video_2\" output_1.mp4",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/test_video_overlay.sh:1-9"
    },
    "2377": {
        "file_id": 251,
        "content": "This script combines two video files, scales the first one to specific dimensions, and overlays them. It is used for creating a video highlight with theme overlay. The basepath variable contains the downloaded videos' location. The resulting video is saved as output.mp4 if both inputs are present, or output_1.mp4 if only the second input video is provided.",
        "type": "comment"
    },
    "2378": {
        "file_id": 252,
        "content": "/tests/anime_highlight_cuts/theme_collector/strip_optimizer_from_trained_best_model.py",
        "type": "filepath"
    },
    "2379": {
        "file_id": 252,
        "content": "This code imports the \"strip_optimizer\" function from the \"torch_utils\" module, then it specifies the original model path (\"general_ver1_with_optimizer.pt\") and the exported model path (\"general_ver1.pt\"). The \"strip_optimizer\" function is called with these paths to remove any optimizers associated with the original model while saving a new model without them at the specified export path.",
        "type": "summary"
    },
    "2380": {
        "file_id": 252,
        "content": "from ultralytics.yolo.utils.torch_utils import strip_optimizer\nmodel_path = \"general_ver1_with_optimizer.pt\"\nexport_path = \"general_ver1.pt\"\nstrip_optimizer(f=model_path, s=export_path)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/strip_optimizer_from_trained_best_model.py:1-6"
    },
    "2381": {
        "file_id": 252,
        "content": "This code imports the \"strip_optimizer\" function from the \"torch_utils\" module, then it specifies the original model path (\"general_ver1_with_optimizer.pt\") and the exported model path (\"general_ver1.pt\"). The \"strip_optimizer\" function is called with these paths to remove any optimizers associated with the original model while saving a new model without them at the specified export path.",
        "type": "comment"
    },
    "2382": {
        "file_id": 253,
        "content": "/tests/anime_highlight_cuts/theme_collector/screenshot_tracemoe.py",
        "type": "filepath"
    },
    "2383": {
        "file_id": 253,
        "content": "This code sends a JPEG image to the trace.moe API for anime character recognition and stores the results in the 'data' variable. It then prints the data using rich library, handles potential errors, and retrieves necessary information from the results, including anilist ID, filename, episode (if available), start and end timestamps, and similarity rating.",
        "type": "summary"
    },
    "2384": {
        "file_id": 253,
        "content": "# anilist has typo on \"Yahari Ore no Seishun Lovecome wa Machigatte Iru.\" which might be harmful.\n# imagePath = \"/Users/jamesbrown/Downloads/anime_download/dress_test_pictures/女装0.jpeg\"\nimagePath = \"/Users/jamesbrown/Downloads/gay_anime_shot.jpeg\"\nimport requests\ndata =requests.post(\"https://api.trace.moe/search\",\n  data=open(imagePath, \"rb\"), # since this is smallest\n  headers={\"Content-Type\": \"image/jpeg\"}\n).json() # remember you must change your ip later.\nimport rich\nrich.print(data) # the anime character recognition website is not running so well.\nerror = data['error']\nassert error == \"\"\nresults = data.get('result',[])\nfor result in results: # already sorted.\n    anilist_id = result['anilist'] # well. we only got one.\n    filename = result['filename'] # need parsing right?\n    episode = result.get('episode', None) # really we don't have episode here.\n    start, end = result['from'], result['to']\n    similarity = result['similarity']\nbreakpoint()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/screenshot_tracemoe.py:1-25"
    },
    "2385": {
        "file_id": 253,
        "content": "This code sends a JPEG image to the trace.moe API for anime character recognition and stores the results in the 'data' variable. It then prints the data using rich library, handles potential errors, and retrieves necessary information from the results, including anilist ID, filename, episode (if available), start and end timestamps, and similarity rating.",
        "type": "comment"
    },
    "2386": {
        "file_id": 254,
        "content": "/tests/anime_highlight_cuts/theme_collector/screenshot_saucenao.py",
        "type": "filepath"
    },
    "2387": {
        "file_id": 254,
        "content": "This code uses the SauceNao API to identify an anime source from a given image file, displaying results such as similarity and URLs, and extracting relevant data for anime cuts including part, title, estimated time, and IDs from various platforms.",
        "type": "summary"
    },
    "2388": {
        "file_id": 254,
        "content": "# saucenao (if fail, use trace.moe)\n# use proxies, since we are using free tiers.\nimport os\nSAUCENAO_API_KEY=os.environ.get('SAUCENAO_API_KEY') # how to run this without api key?\nprint(\"API KEY?\", SAUCENAO_API_KEY)\n# sauce = SauceNao(api_key=SAUCENAO_API_KEY) # shit. not working!\nfilepath = \"/Users/jamesbrown/Downloads/anime_download/dress_test_pictures/女装0.jpeg\"\n# import asyncio\n# loop = asyncio.get_event_loop()\n# results = loop.run_until_complete(sauce.from_file(filepath))\n# results = await sauce.from_url('https://i.imgur.com/QaKpV3s.png')\n# no api key. fuck.\nfrom saucenao_api import SauceNao\nsauce = SauceNao(SAUCENAO_API_KEY)\nwith open(filepath,'rb') as f:\n    results = sauce.from_file(f)\n    long_remaining = results.long_remaining # wait till next day? wtf?\n    short_remaining = results.short_remaining\n    result_results = len(results)\n    print(results)\n    best = results[0]\n    similarity = best.similarity\n    # just trust anilist.\n    urls = best.urls # https://anilist.co/anime/ https://anidb.net/anime/ https://myanimelist.net/anime/",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/screenshot_saucenao.py:1-25"
    },
    "2389": {
        "file_id": 254,
        "content": "The code aims to use the SauceNao API to identify an anime source from a given image file. It first checks if the SAUCENAO_API_KEY is set in the environment variables and prints it out. Then, it creates a SauceNao object with the API key and tries to find similar images using the image file path. The code then displays the remaining time before the results become available (long_remaining and short_remaining), the number of results found (result_results), the best match's similarity, and the URLs associated with the best match. If no API key is provided, the code indicates that it will not be able to use SauceNao API.",
        "type": "comment"
    },
    "2390": {
        "file_id": 254,
        "content": "    best_data =  best.raw.get('data',{})\n    part = best_data.get('part', None) # not always.\n    title = best.title\n    est_time =best_data.get('est_time',None) # be like: '00:16:21 / 00:25:12'\n    if est_time:\n        start_end = [timestamp.strip() for timestamp in est_time.split(\"/\")]\n        start_time, end_time = start_end\n    # these ids must be the same across different images.\n    anidb_aid = best_data.get('anidb_aid',None)\n    mal_id = best_data.get('mal_id',None)\n    anilist_id = best_data.get('anilist_id',None)\n    breakpoint()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/screenshot_saucenao.py:26-37"
    },
    "2391": {
        "file_id": 254,
        "content": "Extracts relevant data for an anime cut: part (may not always be available), title, estimated time (in the format \"start / end\"), and IDs from different platforms - AniDB (anidb_aid), MyAnimeList (mal_id), and AniList (anilist_id).",
        "type": "comment"
    },
    "2392": {
        "file_id": 255,
        "content": "/tests/anime_highlight_cuts/theme_collector/pack_source_dataset.sh",
        "type": "filepath"
    },
    "2393": {
        "file_id": 255,
        "content": "This command uses 7-Zip (7z) to create a compressed archive named \"pip_source_dataset.7z\" that includes all .mp4 and .csv files in the current directory, likely for efficient storage or transfer.",
        "type": "summary"
    },
    "2394": {
        "file_id": 255,
        "content": "7z a pip_source_dataset.7z *.mp4 *.csv",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/pack_source_dataset.sh:1-1"
    },
    "2395": {
        "file_id": 255,
        "content": "This command uses 7-Zip (7z) to create a compressed archive named \"pip_source_dataset.7z\" that includes all .mp4 and .csv files in the current directory, likely for efficient storage or transfer.",
        "type": "comment"
    },
    "2396": {
        "file_id": 256,
        "content": "/tests/anime_highlight_cuts/theme_collector/make_picture_in_picture_challange.py",
        "type": "filepath"
    },
    "2397": {
        "file_id": 256,
        "content": "This code sets the base path for video files, imports os module, and uses os.path.join() to create file paths for source_video and background_video. It also sets a placeholder value for video duration (10) and comments on using ffplay and saving metadata in filenames.",
        "type": "summary"
    },
    "2398": {
        "file_id": 256,
        "content": "basepath = \"/Users/jamesbrown/Downloads/anime_download\"\nimport os\nsource_video = os.path.join(\n    basepath, \"[Sakurato] Onii-chan wa Oshimai! [未删减][02][AVC-8bit 1080p AAC][CHT].mp4\"\n)\nbackground_video = os.path.join(\n    basepath, \"[MLU-S] Onii-chan wa Oshimai! - 03 [1080p][Multi Subs].mkv\"\n)\nvideo_duration = 10  # just for test.\n# use ffplay?\n# better save metadata in the filename.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/make_picture_in_picture_challange.py:1-16"
    },
    "2399": {
        "file_id": 256,
        "content": "This code sets the base path for video files, imports os module, and uses os.path.join() to create file paths for source_video and background_video. It also sets a placeholder value for video duration (10) and comments on using ffplay and saving metadata in filenames.",
        "type": "comment"
    }
}