{
    "3500": {
        "file_id": 418,
        "content": "ttleTail\":\"\"&#44;\"title\":\"哔哩哔哩\"&#44;\"url\":\"m.q.qq.com\\/a\\/s\\/ea6d34b58a6a6209cd5088c436a254de\"}}&#44;\"config\":{\"autoSize\":0&#44;\"ctime\":1665924338&#44;\"forward\":1&#44;\"height\":0&#44;\"token\":\"a2458ec4231b7b8204c717f3a955a9fc\"&#44;\"type\":\"normal\"&#44;\"width\":0}}\"\"\"\ncontent = \"\"\"{\"app\":\"com.tencent.structmsg\"&#44;\"desc\":\"新闻\"&#44;\"view\":\"news\"&#44;\"ver\":\"0.0.0.1\"&#44;\"prompt\":\"&#91;分享&#93;哔哩哔哩\"&#44;\"meta\":{\"news\":{\"action\":\"\"&#44;\"android_pkg_name\":\"\"&#44;\"app_type\":1&#44;\"appid\":100951776&#44;\"ctime\":1666081902&#44;\"desc\":\"外国博主英文讲解：二十大为什么如此重要？\"&#44;\"jumpUrl\":\"https:\\/\\/b23.tv\\/B64KMQq?share_medium=android&amp;share_source=qq&amp;bbid=XY1BB721B1F97348DBDE4297FE1B4ABE26BAA&amp;ts=1666081860133\"&#44;\"preview\":\"https:\\/\\/pic.ugcimg.cn\\/58a74c8432a80e7e2de612e6e53e37f3\\/jpg1\"&#44;\"source_icon\":\"https:\\/\\/open.gtimg.cn\\/open\\/app_icon\\/00\\/95\\/17\\/76\\/100951776_100_m.png?t=1659061321\"&#44;\"source_url\":\"\"&#44;\"tag\":\"哔哩哔哩\"&#44;\"title\":\"哔哩哔哩\"&#44;\"uin\":1281727431}}&#44;\"config\":{\"ctime\":1666081902&#44;\"forward\":true&#44;\"token\":\"d7cc3a93e7c3a9acd1c8662157e3e5fb\"&#44;\"type\":\"normal\"}}\"\"\"",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/qq_gocqhttp_post_xml.py:18-19"
    },
    "3501": {
        "file_id": 418,
        "content": "This code contains two JSON strings representing messages in a chat application. The first message is from QQ and includes title, URL, and config details, while the second message is for sharing news on bilibili and has app, desc, view, ver, prompt, meta (with news info), config details, and more. Both messages contain timestamps, tokens, and forward options.",
        "type": "comment"
    },
    "3502": {
        "file_id": 418,
        "content": "# content = \"\"\"{\"app\":\"com.tencent.structmsg\"&#44;\"desc\":\"音乐\"&#44;\"view\":\"music\"&#44;\"ver\":\"0.0.0.1\"&#44;\"prompt\":\"\"&#44;\"meta\":{}}\"\"\"\n# content = (\n    # \"\"\"{\"app\":\"com.tencent.structmsg\",\"desc\":\"\",\"view\":\"singleImg\",\"ver\":\"0.0.0.1\",\"prompt\":\"邪少QQXML论坛\",\"appID\":\"\",\"sourceName\":\"\",\"actionData\":\"\",\"actionData_A\":\"\",\"sourceUrl\":\"\",\"meta\":{\"singleImg\":{\"mainImage\":\"https://gchat.qpic.cn/gchatpic_new/3020005669/916530575-2949639428-6E45D21EADE33511C565E25AB432AB59/0?term=2\",\"mainUrl\":\"\"}},\"text\":\"\",\"extraApps\":[],\"sourceAd\":\"\",\"config\":{\"forward\":1}}\"\"\".replace(\n#         \"&\", \"&amp;\"\n#     )\n#     .replace(\",\", \"&#44;\")\n#     .replace(\"[\", \"&#91;\")\n#     .replace(\"]\", \"&#93;\")\n# )\n# the token is likely to be some checksum, md5 or something. some aes/rsa?\nmessage = \"[CQ:json,data={}]\".format(content)  # json thing.\n# message = \"[CQ:tts,text=嘤嘤嘤]\"\n# content = \"\"\"<?xml version='1.0' encoding='UTF-8' standalone='yes' ?><msg serviceID=\"2\" templateID=\"1\" action=\"web\" brief=\"&#91;分享&#93; 十年\" sourceMsgId=\"0\"",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/qq_gocqhttp_post_xml.py:20-34"
    },
    "3503": {
        "file_id": 418,
        "content": "This code is likely related to a messaging application and involves sending messages containing XML or JSON data, possibly for a chat bot or communication tool. It includes functions for formatting the message content and converting it into CQ:json or CQ:tts formats. The content of the messages seems to be dynamic and can contain various types of data like app information, descriptions, images, and text prompts.",
        "type": "comment"
    },
    "3504": {
        "file_id": 418,
        "content": " url=\"http://music.163.com/m/song/409650368\" flag=\"0\" adverSign=\"0\" multiMsgFlag=\"0\" ><item layout=\"2\"><audio cover=\"http://p2.music.126.net/g-Qgb9ibk9Wp_0HWra0xQQ==/16636710440565853.jpg?param=90y90\" src=\"https://music.163.com/song/media/outer/url?id=409650368.mp3\" /><title>十年</title><summary>黄梦之</summary></item><source name=\"网易云音乐\" icon=\"https://pic.rmb.bdstatic.com/911423bee2bef937975b29b265d737b3.png\" url=\"http://web.p.qq.com/qqmpmobile/aio/app.html?id=1101079856\" action=\"app\" a_actionData=\"com.netease.cloudmusic\" i_actionData=\"tencent100495085://\" appid=\"100495085\" /></msg>\"\"\"\n# message = '[CQ:xml,data={}]'.format(content)\ndata = {\"group_id\": group, \"message\": message, \"auto_escape\": False}\nr = requests.post(url, data=data)\nprint(r.json())\n# cannot send json. wtf?\n# 请参考 go-cqhttp 端输出",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/qq_gocqhttp_post_xml.py:34-40"
    },
    "3505": {
        "file_id": 418,
        "content": "The code is constructing an XML message and sending it to a web URL using the Requests library in Python. It uses go-cqhttp for communication, and the code includes a group ID and a message formatted as XML data. The response from the server is printed in JSON format.",
        "type": "comment"
    },
    "3506": {
        "file_id": 419,
        "content": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/print_xml_message.py",
        "type": "filepath"
    },
    "3507": {
        "file_id": 419,
        "content": "The given code uses the xmltodict library to parse an XML message containing Bilibili video sharing information, then prints its details. The \"print_xml_message\" function handles exceptions during parsing and printing.",
        "type": "summary"
    },
    "3508": {
        "file_id": 419,
        "content": "# arc_share\nxml_msg='{\"Content\":\"\\\\u003c?xml version=\\'1.0\\' encoding=\\'UTF-8\\' standalone=\\'yes\\'?\\\\u003e\\\\u003cmsg templateID=\\\\\"123\\\\\" url=\\\\\"https://b23.tv/5K7qh7K?share_medium=android\\\\u0026amp;share_source=qq\\\\u0026amp;bbid=XY46C7C4C74C8D645671EF7E8F4CC7810054A\\\\u0026amp;ts=1657521142233\\\\\" serviceID=\\\\\"1\\\\\" action=\\\\\"web\\\\\" actionData=\\\\\"\\\\\" a_actionData=\\\\\"\\\\\" i_actionData=\\\\\"\\\\\" brief=\\\\\"[QQ小程序]哔哩哔哩\\\\\" flag=\\\\\"0\\\\\"\\\\u003e\\\\u003citem layout=\\\\\"2\\\\\"\\\\u003e\\\\u003cpicture cover=\\\\\"http://pubminishare-30161.picsz.qpic.cn/d4ad36fa-833e-4018-b994-a2da810f2d54\\\\\"/\\\\u003e\\\\u003ctitle\\\\u003e哔哩哔哩\\\\u003c/title\\\\u003e\\\\u003csummary\\\\u003e【C语言】《带你学C带你飞》\\\\u003c/summary\\\\u003e\\\\u003c/item\\\\u003e\\\\u003csource url=\\\\\"https://b23.tv/5K7qh7K?share_medium=android\\\\u0026amp;share_source=qq\\\\u0026amp;bbid=XY46C7C4C74C8D645671EF7E8F4CC7810054A\\\\u0026amp;ts=1657521142233\\\\\" icon=\\\\\"https://open.gtimg.cn/open/app_icon/00/95/17/76/100951776_100_m.png?t=1657091104\\\\\" name=\\\\\"哔哩哔哩\\\\\" appid=\\\\\"0\\\\\" action=\\",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/print_xml_message.py:1-2"
    },
    "3509": {
        "file_id": 419,
        "content": "This code represents an XML message with various attributes and data for sharing a Bilibili video on QQ. It contains the template ID, URL to share the video, service ID, action type and data, brief description of the shared content, and more specific details about the item being shared, such as its cover image and title.",
        "type": "comment"
    },
    "3510": {
        "file_id": 419,
        "content": "\\\"web\\\\\" actionData=\\\\\"\\\\\" a_actionData=\\\\\"tencent0://\\\\\" i_actionData=\\\\\"\\\\\"/\\\\u003e\\\\u003c/msg\\\\u003e\"}'\ncontentDict = eval(xml_msg)\ncontent = contentDict['Content']\nprint(content) # let's understand this shit.\n\"\"\"\n<?xml version='1.0' encoding='UTF-8' standalone='yes'?><msg templateID=\"123\" url=\"https://b23.tv/5K7qh7K?share_medium=android&amp;share_source=qq&amp;bbid=XY46C7C4C74C8D645671EF7E8F4CC7810054A&amp;ts=1657521142233\" serviceID=\"1\" action=\"web\" actionData=\"\" a_actionData=\"\" i_actionData=\"\" brief=\"[QQ小程序]哔哩哔哩\" flag=\"0\"><item layout=\"2\"><picture cover=\"http://pubminishare-30161.picsz.qpic.cn/d4ad36fa-833e-4018-b994-a2da810f2d54\"/><title>哔哩哔哩</title><summary>【C语言】《带你学C带你飞》</summary></item><source url=\"https://b23.tv/5K7qh7K?share_medium=android&amp;share_source=qq&amp;bbid=XY46C7C4C74C8D645671EF7E8F4CC7810054A&amp;ts=1657521142233\" icon=\"https://open.gtimg.cn/open/app_icon/00/95/17/76/100951776_100_m.png?t=1657091104\" name=\"哔哩哔哩\" appid=\"0\" action=\"web\" actionData=\"\" a_actionData=\"tencent0://\" i_actionData=\"\"/></msg>",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/print_xml_message.py:2-9"
    },
    "3511": {
        "file_id": 419,
        "content": "This code is parsing an XML message, specifically for QQ share, extracting the content and printing it. The message contains information about a video recommendation from Bilibili, including title, summary, URL, and more.",
        "type": "comment"
    },
    "3512": {
        "file_id": 419,
        "content": "\"\"\"",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/print_xml_message.py:11-11"
    },
    "3513": {
        "file_id": 419,
        "content": "The code defines a function called \"print_xml_message\" that takes in an XML message and prints it. It uses the xmltodict library to parse the XML message into a Python dictionary format, then iterates over each element in the dictionary and prints its text content. The code also handles any potential exceptions that may occur during parsing or printing of the XML message.",
        "type": "comment"
    },
    "3514": {
        "file_id": 420,
        "content": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/print_bilibili_json.py",
        "type": "filepath"
    },
    "3515": {
        "file_id": 420,
        "content": "The code presents a JSON structure with app details and metadata for a QQ mini-app, and replaces spaces with \"&#44\" potentially for formatting or data manipulation before sending to QQ.",
        "type": "summary"
    },
    "3516": {
        "file_id": 420,
        "content": "content=\"\"\"{\"app\":\"com.tencent.miniapp_01\"&#44;\"desc\":\"哔哩哔哩\"&#44;\"view\":\"view_8C8E89B49BE609866298ADDFF2DBABA4\"&#44;\"ver\":\"1.0.0.19\"&#44;\"prompt\":\"&#91;QQ小程序&#93;哔哩哔哩\"&#44;\"meta\":{\"detail_1\":{\"appType\":0&#44;\"appid\":\"1109937557\"&#44;\"desc\":\"Appium 手机 App 自动化 + Python\"&#44;\"gamePoints\":\"\"&#44;\"gamePointsUrl\":\"\"&#44;\"host\":{\"nick\":\"Yukio\"&#44;\"uin\":1281727431}&#44;\"icon\":\"https:\\/\\/open.gtimg.cn\\/open\\/app_icon\\/00\\/95\\/17\\/76\\/100951776_100_m.png?t=1659061321\"&#44;\"preview\":\"pubminishare-30161.picsz.qpic.cn\\/a0b8d306-5b6d-4b27-9539-021a2adcc264\"&#44;\"qqdocurl\":\"https:\\/\\/b23.tv\\/4hWdtET?share_medium=android&amp;share_source=qq&amp;bbid=XY1BB721B1F97348DBDE4297FE1B4ABE26BAA&amp;ts=1665924308147\"&#44;\"scene\":1036&#44;\"shareTemplateData\":{}&#44;\"shareTemplateId\":\"8C8E89B49BE609866298ADDFF2DBABA4\"&#44;\"showLittleTail\":\"\"&#44;\"title\":\"哔哩哔哩\"&#44;\"url\":\"m.q.qq.com\\/a\\/s\\/ea6d34b58a6a6209cd5088c436a254de\"}}&#44;\"config\":{\"autoSize\":0&#44;\"ctime\":1665924338&#44;\"forward\":1&#44;\"height\":0&#44;\"token\":\"a2458ec4231b7b8204c717f3a955a9fc\"&#44;\"type\":\"normal\"&#44;\"width\":0}}\"\"\"",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/print_bilibili_json.py:1-1"
    },
    "3517": {
        "file_id": 420,
        "content": "This code represents a JSON structure containing various app details and metadata. It includes information such as app name, version, icon URL, description, and share template data for a QQ mini-app with the app ID \"1109937557\" and nickname \"Yukio\".",
        "type": "comment"
    },
    "3518": {
        "file_id": 420,
        "content": "# i can see that all spaces have been replaced by &#44.",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/print_bilibili_json.py:2-2"
    },
    "3519": {
        "file_id": 420,
        "content": "This code snippet is replacing all spaces in the input with \"&#44\" which could be used for formatting or data manipulation purposes before sending it to QQ.",
        "type": "comment"
    },
    "3520": {
        "file_id": 421,
        "content": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/new_xml.py",
        "type": "filepath"
    },
    "3521": {
        "file_id": 421,
        "content": "This code extracts content from a dictionary representing an XML message, assigns it to a variable, and prints it, possibly for debugging or validation purposes.",
        "type": "summary"
    },
    "3522": {
        "file_id": 421,
        "content": "contentDictString = {\"Content\":\"\\u003c?xml version='1.0' encoding='UTF-8' standalone='yes'?\\u003e\\u003cmsg templateID=\\\"123\\\" url=\\\"https://b23.tv/uHML5mi?share_medium=android\\u0026amp;share_source=qq\\u0026amp;bbid=XY1BB721B1F97348DBDE4297FE1B4ABE26BAA\\u0026amp;ts=1666023406285\\\" serviceID=\\\"1\\\" action=\\\"web\\\" actionData=\\\"\\\" a_actionData=\\\"\\\" i_actionData=\\\"\\\" brief=\\\"[QQ小程序]哔哩哔哩\\\" flag=\\\"0\\\"\\u003e\\u003citem layout=\\\"2\\\"\\u003e\\u003cpicture cover=\\\"http://pubminishare-30161.picsz.qpic.cn/c099bdd6-9e61-43d9-b82f-c9d5354ace68\\\"/\\u003e\\u003ctitle\\u003e哔哩哔哩\\u003c/title\\u003e\\u003csummary\\u003e【AI动画】妮露PV动画 风转换【NovelAI】\\u003c/summary\\u003e\\u003c/item\\u003e\\u003csource url=\\\"https://b23.tv/uHML5mi?share_medium=android\\u0026amp;share_source=qq\\u0026amp;bbid=XY1BB721B1F97348DBDE4297FE1B4ABE26BAA\\u0026amp;ts=1666023406285\\\" icon=\\\"http://miniapp.gtimg.cn/public/appicon/432b76be3a548fc128acaa6c1ec90131_200.jpg\\\" name=\\\"哔哩哔哩\\\" appid=\\\"0\\\" action=\\\"web\\\" actionData=\\\"\\\" a_actionData=\\\"tencent0://\\\" i_actionData=\\\"\\\"/\\u003e\\u003c/msg\\u003e\"}",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/new_xml.py:1-1"
    },
    "3523": {
        "file_id": 421,
        "content": "This code contains a dictionary named \"contentDictString\" that represents an XML message with information about a video recommendation from Bilibili, including the template ID, URL, service ID, action, action data, i_actionData, brief, layout, picture, title, summary, source URL, icon, name, appid, and more.",
        "type": "comment"
    },
    "3524": {
        "file_id": 421,
        "content": "contentDict = contentDictString\ncontent = contentDict['Content']\nprint(content)",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/xml_and_json_qq_send/new_xml.py:3-6"
    },
    "3525": {
        "file_id": 421,
        "content": "Content from the string is being assigned to the dictionary variable 'contentDict'. The 'Content' key in this dictionary is then extracted and stored in the variable 'content', which is finally printed. This code appears to print the content of a certain element in a file, potentially for debugging or validation purposes.",
        "type": "comment"
    },
    "3526": {
        "file_id": 422,
        "content": "/tests/bilibili_video_recommendation_server/sample_video/tts.py",
        "type": "filepath"
    },
    "3527": {
        "file_id": 422,
        "content": "This Python script converts text to speech using argparse, argues SSML input, and connects to Microsoft Cognitive Services TTS endpoint. It also handles time fixes, timestamps, and async WebSocket communication with potential API key authentication, runs on an asyncio event loop, and writes audio responses to a file.",
        "type": "summary"
    },
    "3528": {
        "file_id": 422,
        "content": "# 来源 https://github.com/OS984/DiscordBotBackend/blob/3b06b8be39e4dbc07722b0afefeee4c18c136102/NeuralTTS.py\n# A completely innocent attempt to borrow proprietary Microsoft technology for a much better TTS experience\nimport requests\nimport websockets\nimport asyncio\nfrom datetime import datetime\nimport time\nimport re\nimport uuid\nimport argparse\n'''命令行参数解析'''\ndef parseArgs():\n    parser = argparse.ArgumentParser(description='text2speech')\n    parser.add_argument('--input', dest='input', help='SSML(语音合成标记语言)的路径', type=str, required=True)\n    parser.add_argument('--output', dest='output', help='保存mp3文件的路径', type=str, required=False)\n    args = parser.parse_args()\n    return args\n# Fix the time to match Americanisms\ndef hr_cr(hr):\n    corrected = (hr - 1) % 24\n    return str(corrected)\n# Add zeros in the right places i.e 22:1:5 -> 22:01:05\ndef fr(input_string):\n    corr = ''\n    i = 2 - len(input_string)\n    while (i > 0):\n        corr += '0'\n        i -= 1\n    return corr + input_string\n# Generate X-Timestamp all correctly formatted",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:1-35"
    },
    "3529": {
        "file_id": 422,
        "content": "This code is a Python file that utilizes the `argparse` library to parse command-line arguments. The purpose of this script seems to be text-to-speech conversion, where it accepts an SSML (Speech Synthesis Markup Language) input file and outputs an MP3 audio file. It also includes functions for fixing time formats to match American conventions and generating formatted timestamps.",
        "type": "comment"
    },
    "3530": {
        "file_id": 422,
        "content": "def getXTime():\n    now = datetime.now()\n    return fr(str(now.year)) + '-' + fr(str(now.month)) + '-' + fr(str(now.day)) + 'T' + fr(hr_cr(int(now.hour))) + ':' + fr(str(now.minute)) + ':' + fr(str(now.second)) + '.' + str(now.microsecond)[:3] + 'Z'\n# Async function for actually communicating with the websocket\nasync def transferMsTTSData(SSML_text, outputPath):\n    # endpoint1 = \"https://azure.microsoft.com/en-gb/services/cognitive-services/text-to-speech/\"\n    # r = requests.get(endpoint1)\n    # main_web_content = r.text\n    # # They hid the Auth key assignment for the websocket in the main body of the webpage....\n    # token_expr = re.compile('token: \\\"(.*?)\\\"', re.DOTALL)\n    # Auth_Token = re.findall(token_expr, main_web_content)[0]\n    # req_id = str('%032x' % random.getrandbits(128)).upper()\n    # req_id is generated by uuid.\n    req_id = uuid.uuid4().hex.upper()\n    print(req_id)\n    # wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId=577D1E595EEB45979BA26C056A519073",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:36-52"
    },
    "3531": {
        "file_id": 422,
        "content": "This code defines two functions: `getXTime` and `transferMsTTSData`. The `getXTime` function returns the current date and time in a specific format. The `transferMsTTSData` function is an asynchronous function responsible for communicating with a WebSocket endpoint, potentially using an API key to authenticate the request. It generates a unique ID (req_id) and prints it before potentially making the WebSocket connection.",
        "type": "comment"
    },
    "3532": {
        "file_id": 422,
        "content": "    # endpoint2 = \"wss://eastus.tts.speech.microsoft.com/cognitiveservices/websocket/v1?Authorization=\" + \\\n    #     Auth_Token + \"&X-ConnectionId=\" + req_id\n    # 目前该接口没有认证可能很快失效\n    endpoint2 = f\"wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId={req_id}\"\n    async with websockets.connect(endpoint2) as websocket:\n        payload_1 = '{\"context\":{\"system\":{\"name\":\"SpeechSDK\",\"version\":\"1.12.1-rc.1\",\"build\":\"JavaScript\",\"lang\":\"JavaScript\",\"os\":{\"platform\":\"Browser/Linux x86_64\",\"name\":\"Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0\",\"version\":\"5.0 (X11)\"}}}}'\n        message_1 = 'Path : speech.config\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/json\\r\\n\\r\\n' + payload_1\n        await websocket.send(message_1)\n        payload_2 = '{\"synthesis\":{\"audio\":{\"metadataOptions\":{\"sentenceBoundaryEnabled\":false,\"wordBoundaryEnabled\":false},\"outputFormat\":\"audio-16khz-32kbitrate-mono-mp3\"}}}'",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:53-63"
    },
    "3533": {
        "file_id": 422,
        "content": "This code connects to the Microsoft Cognitive Services TTS (Text-to-Speech) websocket endpoint, sends two payloads for speech synthesis, and sets various headers such as Authorization, X-ConnectionId, Content-Type, etc. The current authentication may expire soon, so a new temporary endpoint is used instead of the original one.",
        "type": "comment"
    },
    "3534": {
        "file_id": 422,
        "content": "        message_2 = 'Path : synthesis.context\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/json\\r\\n\\r\\n' + payload_2\n        await websocket.send(message_2)\n        # payload_3 = '<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" version=\"1.0\" xml:lang=\"en-US\"><voice name=\"' + voice + '\"><mstts:express-as style=\"General\"><prosody rate=\"'+spd+'%\" pitch=\"'+ptc+'%\">'+ msg_content +'</prosody></mstts:express-as></voice></speak>'\n        payload_3 = SSML_text\n        message_3 = 'Path: ssml\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/ssml+xml\\r\\n\\r\\n' + payload_3\n        await websocket.send(message_3)\n        # Checks for close connection message\n        end_resp_pat = re.compile('Path:turn.end')\n        audio_stream = b''\n        while(True):\n            response = await websocket.recv()",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:64-78"
    },
    "3535": {
        "file_id": 422,
        "content": "Sends text to TTS service for synthesis and awaits response. Stores the SSML XML for audio customization. Sends SSML XML payload for final audio output generation. Continuously receives response from websocket until 'turn.end' path detected, storing data in audio_stream variable.",
        "type": "comment"
    },
    "3536": {
        "file_id": 422,
        "content": "            print('receiving...')\n            # Make sure the message isn't telling us to stop\n            if (re.search(end_resp_pat, str(response)) == None):\n                # Check if our response is text data or the audio bytes\n                if type(response) == type(bytes()):\n                    # Extract binary data\n                    try:\n                        needle = b'Path:audio\\r\\n'\n                        start_ind = response.find(needle) + len(needle)\n                        audio_stream += response[start_ind:]\n                    except:\n                        pass\n            else:\n                break\n        with open(f'{outputPath}.mp3', 'wb') as audio_out:\n            audio_out.write(audio_stream)\nasync def mainSeq(SSML_text, outputPath):\n    await transferMsTTSData(SSML_text, outputPath)\ndef get_SSML(path):\n    with open(path,'r',encoding='utf-8') as f:\n        return f.read()\nif __name__ == \"__main__\":\n    args = parseArgs()\n    SSML_text = get_SSML(args.input)\n    output_path = args.output if args.output else 'output_'+ str(int(time.time()*1000))",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:79-107"
    },
    "3537": {
        "file_id": 422,
        "content": "This code snippet is a part of a TTS (Text-to-Speech) server implementation. It receives an audio response from the server, checks if it's text or binary data, and writes the audio to a file. The `mainSeq` function initiates the transfer process by calling `transferMsTTSData` function with SSML text and output path. The `get_SSML` function reads SSML text from input file. The code is run as a main program after parsing command-line arguments using `parseArgs()`.",
        "type": "comment"
    },
    "3538": {
        "file_id": 422,
        "content": "    asyncio.get_event_loop().run_until_complete(mainSeq(SSML_text, output_path))\n    print('completed')\n    # python tts.py --input SSML.xml\n    # python tts.py --input SSML.xml --output 保存文件名",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:108-111"
    },
    "3539": {
        "file_id": 422,
        "content": "This code calls the `mainSeq` function with SSML text and output path, using asyncio event loop to run until completion. It prints \"completed\" upon execution. The two command examples show how to input an SSML file and optionally specify an output filename.",
        "type": "comment"
    },
    "3540": {
        "file_id": 423,
        "content": "/tests/bilibili_video_recommendation_server/sample_video/create_sample_video_with_fade_and_metadata.py",
        "type": "filepath"
    },
    "3541": {
        "file_id": 423,
        "content": "This code sets up a video processing task with image overlay, fade transition, and audio, saving a JSON object for Editly template and running the software using xvfb in subprocess.",
        "type": "summary"
    },
    "3542": {
        "file_id": 423,
        "content": "# maybe this time you can burn uploader logo to the video\n# the title of the video, intro, outro.\nvideo_path = \"/root/Desktop/works/pyjom/tests/bilibili_video_recommendation_server/sample_video/sample_video.mp4\"\nup_image_path = (\n    \"/root/Desktop/works/pyjom/tests/bilibili_video_recommendation_server/up_image.jpg\"\n)\noutput_path = \"output.mp4\"\nfontPath = \"/root/Desktop/works/pyjom/tests/bilibili_video_recommendation_server/wqy-microhei0.ttf\"\ncat_image = (\n    \"/root/Desktop/works/pyjom/tests/bilibili_video_recommendation_server/cat_image.jpg\"\n)\ntitle = \"世上所有的小猫\\n\\n都是天使变的！\" # add newline, change it into another catchy title, as compliment.\naudio_path = \"output.mp3.mp3\"\naudio_duration = 3.31\ntemplate_name = \"template.json\"\nfrom caer.video.frames_and_fps import get_duration, get_res\nvideo_duration = get_duration(video_path)\nvideo_width, video_height = get_res(video_path)\n# we shall use editly to do this job shall we?\nmin_video_scalar = min(video_width, video_height)\nup_image_scalar = int(min_video_scalar * 0.2)",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/create_sample_video_with_fade_and_metadata.py:1-24"
    },
    "3543": {
        "file_id": 423,
        "content": "This code is setting up variables for video processing, such as the input video path, uploader logo path, output path, font path, and image path. It also includes a title, audio path, and template name. The code uses the get_duration() function to determine the video duration and get_res() to retrieve the video's width and height. Lastly, it calculates a minimum video scalar value for editing purposes using editly.",
        "type": "comment"
    },
    "3544": {
        "file_id": 423,
        "content": "up_image_width = up_image_scalar / video_width\nup_image_height = up_image_scalar / video_height\n# some parameters are using floating point numbers between 0 and 1\n# image overlay can be done in editly\n# no need to render that silly karaoke effects.\neditlyJson = {\n    \"outPath\": output_path,\n    \"width\": video_width,\n    \"height\": video_height,\n    \"fps\": 30,  # different from the default value.\n    \"fast\": True,  # just for preview. if not turning this on, will be too slow.\n    \"keepSourceAudio\": True,  # it does!\n    \"defaults\": {\n        \"transition\": {\n            \"duration\": 0.5,\n            \"name\": \"fade\",\n            \"audioOutCurve\": \"tri\",\n            \"audioInCurve\": \"tri\",\n        }\n    },\n    \"clips\": [\n        # {\n        #     \"duration\": 0.5,\n        #     \"layers\": [\n        #         # {\"type\": \"fill-color\", \"color\": \"#000000\"},\n        #         # {\"type\": \"detached-audio\", \"path\": audio_path}, # will make sure nothing visual presents.\n        #     ],\n        # },\n        # we disable this clip.\n        {",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/create_sample_video_with_fade_and_metadata.py:25-57"
    },
    "3545": {
        "file_id": 423,
        "content": "This code sets up parameters for an editly job, which involves overlaying an image with specific dimensions and applying a fade transition effect. The video's audio will be kept, and the job is set to a fast preview mode.",
        "type": "comment"
    },
    "3546": {
        "file_id": 423,
        "content": "            \"duration\": audio_duration,\n            \"layers\": [\n                {\n                    \"type\": \"image-overlay\",\n                    \"path\": cat_image,\n                    \"position\": \"center\",\n                    \"width\": 1,\n                    \"height\": 1,\n                },\n                {\n                    # \"type\": \"title-background\",\n                    \"type\": \"title\",\n                    \"text\": title,\n                    # \"background\": \"#000000\",\n                    \"fontPath\": fontPath,\n                    \"textColor\": \"#FFFFFF\",\n                },\n                {\"type\": \"audio\", \"path\": audio_path},  # order matters!\n            ],\n        },\n        {\n            # \"transition\": \"fade\",  # or we just use random?\n            \"duration\": video_duration,\n            \"layers\": [\n                {\"type\": \"video\", \"path\": video_path},  # order is important.\n                {\n                    \"type\": \"image-overlay\",\n                    \"path\": up_image_path,\n                    \"position\": \"top-left\",",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/create_sample_video_with_fade_and_metadata.py:58-86"
    },
    "3547": {
        "file_id": 423,
        "content": "This code is creating a video with a cat image overlay, title text, and an audio track. The order of layers is important, and the audio path comes first. The video is then transitioned with a fade effect and combined with another video file, along with an optional top-left image overlay.",
        "type": "comment"
    },
    "3548": {
        "file_id": 423,
        "content": "                    \"width\": up_image_width,  # float numbers.\n                    \"height\": up_image_height,\n                },\n            ],\n        },\n        {\"duration\": 0.5, \"layers\": [{\"type\": \"fill-color\", \"color\": \"#000000\"}]},\n    ],\n}\nfrom lazero.filesystem.io import writeJsonObjectToFile\nwriteJsonObjectToFile(template_name, editlyJson)\nimport subprocess\n# use xvfb you SOB\ncommand = [\n    \"xvfb-run\",\n    \"editly\",\n    template_name,\n]  # no need to specify --out outputPath here\nsubprocess.run(command)",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/create_sample_video_with_fade_and_metadata.py:87-108"
    },
    "3549": {
        "file_id": 423,
        "content": "Code writes a JSON object for Editly video template, saves it to file, and runs the Editly software using subprocess with xvfb.",
        "type": "comment"
    },
    "3550": {
        "file_id": 424,
        "content": "/tests/image_quality_tests/tiq2.py",
        "type": "filepath"
    },
    "3551": {
        "file_id": 424,
        "content": "The code reads video frames, calculates image quality using BRISQUE algorithm, resizes and converts to grayscale. It then displays the resized frame on a GUI window and checks for user input (exiting upon 'q').",
        "type": "summary"
    },
    "3552": {
        "file_id": 424,
        "content": "import imquality.brisque as brisque\nimport cv2\nimport PIL\nfrom brisque import BRISQUE\n# integrated svmutil.py and svm.py from that git repo.\n# really strange.\nbrisq = BRISQUE()\nvideo = cv2.VideoCapture(\"../../samples/video/dog_with_text.mp4\")\n_,frame = video.read()\n# frame = imutils.resize(frame,width=720) #why?\nindex = 0\nscore = -1\nperiod = 2\nwhile frame is not None:\n    _, frame = video.read()\n    index+=1\n    if frame is None:\n        print(\"VIDEO END.\")\n        break\n    # just get image quality.\n    # the speed is not so damn fast.\n    image = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n    # image = PIL.Image.fromarray(image)\n    if index%period == 0:\n        try:\n            score = brisq.get_score(image) # the lower the better, it was said.\n        except:\n            # this is super fast. but i doubt that.\n            # import traceback\n            # traceback.print_exc()\n            # breakpoint()\n            score = -1 # unknown.\n    cv2.putText(\n        frame,\n        \"[{}]\".format(str(score)[:5]),\n        (200,200),",
        "type": "code",
        "location": "/tests/image_quality_tests/tiq2.py:1-40"
    },
    "3553": {
        "file_id": 424,
        "content": "The code is reading frames from a video file and calculating the image quality using the BRISQUE algorithm. It prints the score for every 'period' number of frames, with a lower score indicating better image quality. If an error occurs while calculating the score, it assigns -1 (unknown) as the value. The code is also resizing the frame to a width of 720 pixels using imutils library and converting it to grayscale using cv2.cvtColor function.",
        "type": "comment"
    },
    "3554": {
        "file_id": 424,
        "content": "        cv2.FONT_HERSHEY_SIMPLEX,\n        2,\n        (0,255,0),\n        3,\n        cv2.LINE_AA,\n    )\n    cv2.imshow('Output',frame)\n    key  =  cv2.waitKey(1) & 0xff\n    if key == ord('q'):\n        break",
        "type": "code",
        "location": "/tests/image_quality_tests/tiq2.py:41-50"
    },
    "3555": {
        "file_id": 424,
        "content": "This code is using OpenCV library to display an image on a GUI window with the title 'Output'. The image is drawn on it using a green color (0,255,0) and a simplex font. It checks for user input (key pressed) and if 'q' is entered, the loop breaks.",
        "type": "comment"
    },
    "3556": {
        "file_id": 425,
        "content": "/tests/image_quality_tests/test_pyiqa.sh",
        "type": "filepath"
    },
    "3557": {
        "file_id": 425,
        "content": "This code is running the pyiqa_inference.py script with the specified image and name argument, which downloads the necessary weights from Torch Hub directory for image quality testing.",
        "type": "summary"
    },
    "3558": {
        "file_id": 425,
        "content": "python3 pyiqa_inference.py -n $1 -i sample.bmp\n# it is downloading weights to torch hub directory.",
        "type": "code",
        "location": "/tests/image_quality_tests/test_pyiqa.sh:1-2"
    },
    "3559": {
        "file_id": 425,
        "content": "This code is running the pyiqa_inference.py script with the specified image and name argument, which downloads the necessary weights from Torch Hub directory for image quality testing.",
        "type": "comment"
    },
    "3560": {
        "file_id": 426,
        "content": "/tests/image_quality_tests/test_image_quality.py",
        "type": "filepath"
    },
    "3561": {
        "file_id": 426,
        "content": "This code reads a video, extracts frames at periodic intervals, calculates the image quality using BRISQUE algorithm and displays it on the frame. The score is displayed in the lower-left corner of each frame, and the user can stop the loop by pressing 'q'.",
        "type": "summary"
    },
    "3562": {
        "file_id": 426,
        "content": "# import imquality.brisque as brisque\nimport cv2\nimport PIL\nvideo = cv2.VideoCapture(\"../../samples/video/dog_with_text.mp4\")\n_,frame = video.read()\n# frame = imutils.resize(frame,width=720) #why?\nindex = 0\nscore = -1\nperiod = 20\nwhile frame is not None:\n    _, frame = video.read()\n    index+=1\n    if frame is None:\n        print(\"VIDEO END.\")\n        break\n    # just get image quality.\n    # the speed is not so damn fast.\n    image = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n    image = PIL.Image.fromarray(image)\n    if index%period == 0:\n        try:\n            score = brisque.score(image) # the lower the better, it was said.\n        except:\n            score = -1 # unknown.\n    cv2.putText(\n        frame,\n        \"[{}]\".format(str(score)[:5]),\n        (200,200),\n        cv2.FONT_HERSHEY_SIMPLEX,\n        2,\n        (0,255,0),\n        3,\n        cv2.LINE_AA,\n    )\n    cv2.imshow('Output',frame)\n    key  =  cv2.waitKey(1) & 0xff\n    if key == ord('q'):\n        break",
        "type": "code",
        "location": "/tests/image_quality_tests/test_image_quality.py:1-40"
    },
    "3563": {
        "file_id": 426,
        "content": "This code reads a video, extracts frames at periodic intervals, calculates the image quality using BRISQUE algorithm and displays it on the frame. The score is displayed in the lower-left corner of each frame, and the user can stop the loop by pressing 'q'.",
        "type": "comment"
    },
    "3564": {
        "file_id": 427,
        "content": "/tests/image_quality_tests/t_pyiqa2.sh",
        "type": "filepath"
    },
    "3565": {
        "file_id": 427,
        "content": "This code is piping the output of `pyiqa_test.py` into `test_pyiqa.sh`, filtering for lines containing \"taking time\", and returning those results.",
        "type": "summary"
    },
    "3566": {
        "file_id": 427,
        "content": "python3 pyiqa_test.py | xargs -iabc bash test_pyiqa.sh abc 2>&1 | grep \"taking time\"",
        "type": "code",
        "location": "/tests/image_quality_tests/t_pyiqa2.sh:1-1"
    },
    "3567": {
        "file_id": 427,
        "content": "This code is piping the output of `pyiqa_test.py` into `test_pyiqa.sh`, filtering for lines containing \"taking time\", and returning those results.",
        "type": "comment"
    },
    "3568": {
        "file_id": 428,
        "content": "/tests/image_quality_tests/README.md",
        "type": "filepath"
    },
    "3569": {
        "file_id": 428,
        "content": "This code provides a solution to ensure image quality for model accuracy, examines ROI using DasiamRPN and siamMask, re-examines for potential loss of mark, applies motion analysis, suggests integrating TA-Lib for statistics, and recommends upscaling video with anime4k or other engines.",
        "type": "summary"
    },
    "3570": {
        "file_id": 428,
        "content": "# princlple\nif the image quality is bad, then no matter what model we use we will get poor result.\n# solution\nuse image quality assessment to examine ROI tracked by DasiamRPN and make sure we will use the best sample and get most accurate result.\n# footnote\nDasiamRPN is a good tracker. so before abandon the tracking data re-examine the ROI for several times to see if it really lost its mark. so as the siamMask.\nYou can also examine the image quality by means of motion. if it heavily moves, we refuse to feed it into model.\nIntegrate TA-Lib for less boilerplates. i mean financial analysis can be applied anywhere. they are basically statistics. anything other than that might just be fake.\nwhere is your dog video?\n# further actions\nyou may upscale video using anime4k or other engines.",
        "type": "code",
        "location": "/tests/image_quality_tests/README.md:1-21"
    },
    "3571": {
        "file_id": 428,
        "content": "This code provides a solution to ensure image quality for model accuracy, examines ROI using DasiamRPN and siamMask, re-examines for potential loss of mark, applies motion analysis, suggests integrating TA-Lib for statistics, and recommends upscaling video with anime4k or other engines.",
        "type": "comment"
    },
    "3572": {
        "file_id": 429,
        "content": "/tests/image_quality_tests/pyiqa_test.py",
        "type": "filepath"
    },
    "3573": {
        "file_id": 429,
        "content": "This code is filtering out certain metric modes from the DEFAULT_CONFIGS dictionary, printing only those not in the allow_lists. The author comments that these methods may not be as useful and seems difficult to determine their effectiveness before downloading all models. They express confusion about the size of some model files.",
        "type": "summary"
    },
    "3574": {
        "file_id": 429,
        "content": "from pyiqa.default_model_configs import DEFAULT_CONFIGS\nmlist = []\nfor key in DEFAULT_CONFIGS.keys():\n    config = DEFAULT_CONFIGS[key]\n    mode = config[\"metric_mode\"]\n    if mode == \"NR\":\n        mlist.append(key)\n# print(mlist)\n# forbid_lists = [\"ilniqe\",\"nima\"]\nallow_lists = [\"niqe\", \"brisque\", \"paq2piq\"]\nfor elem in mlist:\n    if elem not in allow_lists:\n        continue\n    print(elem)\n# i need to say these methods are not as useful as it was said.\n# the objective shall be EMA based.\n# ['niqe', 'ilniqe', 'brisque', 'nrqm', 'pi', 'musiq', 'musiq-ava', 'musiq-koniq', 'musiq-paq2piq', 'musiq-spaq', 'nima', 'paq2piq', 'dbcnn']\n# you may try them all?\n# it is really hard to say before we download all these models.\n# seems not really dependent on the model size?\n# we've got freaking huge shits.\n# like this one, for nima.\n# https://download.pytorch.org/models/vgg16-397923af.pth\n# what is this shit for anyway?",
        "type": "code",
        "location": "/tests/image_quality_tests/pyiqa_test.py:1-31"
    },
    "3575": {
        "file_id": 429,
        "content": "This code is filtering out certain metric modes from the DEFAULT_CONFIGS dictionary, printing only those not in the allow_lists. The author comments that these methods may not be as useful and seems difficult to determine their effectiveness before downloading all models. They express confusion about the size of some model files.",
        "type": "comment"
    },
    "3576": {
        "file_id": 430,
        "content": "/tests/image_quality_tests/pyiqa_inference.py",
        "type": "filepath"
    },
    "3577": {
        "file_id": 430,
        "content": "This code uses pyiqa library to evaluate image quality and compare algorithms, averaging scores for multiple inputs and timing the process. It saves or prints results and handles missing files with errors.",
        "type": "summary"
    },
    "3578": {
        "file_id": 430,
        "content": "import argparse\nimport glob\nimport os\nfrom PIL import Image\nfrom pyiqa.models.inference_model import InferenceModel\nmetric_name = None\ndef main():\n    global metric_name\n    \"\"\"Inference demo for pyiqa.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i', '--input', type=str, default=None, help='input image/folder path.')\n    parser.add_argument('-r', '--ref', type=str, default=None, help='reference image/folder path if needed.')\n    parser.add_argument(\n        '-m',\n        '--metric_mode',\n        type=str,\n        default='FR',\n        help='metric mode Full Reference or No Reference. options: FR|NR.')\n    parser.add_argument('-n', '--metric_name', type=str, default='PSNR', help='IQA metric name, case sensitive.')\n    parser.add_argument('--model_path', type=str, default=None, help='Weight path for CNN based models.')\n    parser.add_argument('--img_range', type=float, default=1.0, help='Max value of image tensor.')\n    parser.add_argument(\n        '--input_size', type=int, nargs='+', default=None, help='size of input image. (H, W) for tuple input.')",
        "type": "code",
        "location": "/tests/image_quality_tests/pyiqa_inference.py:1-26"
    },
    "3579": {
        "file_id": 430,
        "content": "This code defines a main function for inference demo of the pyiqa library. It takes input, reference image or folder paths as arguments, and allows selection of metric mode (Full Reference or No Reference) and metric name (IQA metric). It also accepts optional parameters like model path, maximum value of image tensor, and input size.",
        "type": "comment"
    },
    "3580": {
        "file_id": 430,
        "content": "    parser.add_argument(\n        '--mean', type=float, nargs='+', default=None, metavar='MEAN', help='Override mean pixel value of dataset')\n    parser.add_argument(\n        '--std', type=float, nargs='+', default=None, metavar='STD', help='Override std deviation of of dataset')\n    parser.add_argument('--save_file', type=str, default=None, help='path to save results.')\n    args = parser.parse_args()\n    metric_name = args.metric_name.lower()\n    # set up IQA model\n    iqa_model = InferenceModel(metric_name, args.metric_mode, args.model_path, args.img_range, args.input_size,\n                               args.mean, args.std)\n    metric_mode = iqa_model.metric_mode\n    if os.path.isfile(args.input):\n        input_paths = [args.input]\n        if args.ref is not None:\n            ref_paths = [args.ref]\n    else:\n        input_paths = sorted(glob.glob(os.path.join(args.input, '*')))\n        if args.ref is not None:\n            ref_paths = sorted(glob.glob(os.path.join(args.ref, '*')))\n    if args.save_file:\n        sf = open(args.save_file, 'w')",
        "type": "code",
        "location": "/tests/image_quality_tests/pyiqa_inference.py:27-53"
    },
    "3581": {
        "file_id": 430,
        "content": "This code sets up an IQA (Image Quality Assessment) model for image quality evaluation. It takes in arguments such as the metric name, input and reference file paths, model path, image range, input size, mean, and std deviation values. If any file is missing, it throws an error. Finally, if a save file is specified, it opens the file for writing.",
        "type": "comment"
    },
    "3582": {
        "file_id": 430,
        "content": "    avg_score = 0\n    test_img_num = len(input_paths)\n    for idx, img_path in enumerate(input_paths):\n        img_name = os.path.basename(img_path)\n        tar_img = Image.open(img_path)\n        if metric_mode == 'FR':\n            ref_img_path = ref_paths[idx]\n            ref_img = Image.open(ref_img_path)\n        else:\n            ref_img = None\n        score = iqa_model.test(tar_img, ref_img)\n        avg_score += score\n        print(f'{metric_name} score of {img_name} is: {score}')\n        if args.save_file:\n            sf.write(f'{img_name}\\t{score}\\n')\n    avg_score /= test_img_num\n    if test_img_num > 1:\n        print(f'Average {metric_name} score of {args.input} with {test_img_num} images is: {avg_score}')\n    if args.save_file:\n        sf.close()\n    if args.save_file:\n        print(f'Done! Results are in {args.save_file}.')\n    else:\n        print(f'Done!')\nimport timeit\nif __name__ == '__main__':\n    main() # to eliminate first time error.\n    repeatTime = 10 # just test\n    taketime = timeit.timeit(main,number=repeatTime)",
        "type": "code",
        "location": "/tests/image_quality_tests/pyiqa_inference.py:55-85"
    },
    "3583": {
        "file_id": 430,
        "content": "This code calculates the image quality score using a pre-trained model. It takes input images and optionally references images, then averages the scores for each image if there are multiple inputs. The results can be saved to a file or simply printed out. It also times how long the process took.",
        "type": "comment"
    },
    "3584": {
        "file_id": 430,
        "content": "    print(\"{} taking time:\".format(metric_name),taketime)\n###########SCOREBOARD##############\n# niqe taking time: 0.24909197200031485\n# brisque taking time: 0.1862209509999957\n# nrqm taking time: 18.15363560300466\n# pi taking time: 18.80046885000047\n# musiq taking time: 2.963457034995372\n# musiq-ava taking time: 2.9661162160045933\n# musiq-koniq taking time: 3.0705577400003676\n# musiq-paq2piq taking time: 2.957391322001058\n# musiq-spaq taking time: 2.948993805999635\n# paq2piq taking time: 1.4981017659956706\n# dbcnn taking time: 16.063134230993455",
        "type": "code",
        "location": "/tests/image_quality_tests/pyiqa_inference.py:86-99"
    },
    "3585": {
        "file_id": 430,
        "content": "This code snippet measures the time taken by various image quality assessment algorithms. The output shows the names and respective times for each algorithm in descending order. It can be used to compare the efficiency of these algorithms when evaluating image quality.",
        "type": "comment"
    },
    "3586": {
        "file_id": 431,
        "content": "/tests/image_quality_tests/pybrisque_test.py",
        "type": "filepath"
    },
    "3587": {
        "file_id": 431,
        "content": "This code imports the BRISQUE class from the brisque module, integrates svmutil.py and svm.py files, initializes an instance of BRISQUE as brisq, gets a feature from an image path using brisq.get_feature(), assigns an image path to 'image_path' variable, retrieves a quality score for the image using brisq.get_score(image_path), and prints the obtained score which is very fast.",
        "type": "summary"
    },
    "3588": {
        "file_id": 431,
        "content": "from brisque import BRISQUE\n# integrated svmutil.py and svm.py from that git repo.\n# really strange.\nbrisq = BRISQUE()\n# brisq.get_feature('/path')\nimage_path = \"/root/Desktop/works/pyjom/tests/image_quality_tests/sample.bmp\"\nscore = brisq.get_score(image_path)\nprint(\"score:\",score)\n# this is damn fast.",
        "type": "code",
        "location": "/tests/image_quality_tests/pybrisque_test.py:1-12"
    },
    "3589": {
        "file_id": 431,
        "content": "This code imports the BRISQUE class from the brisque module, integrates svmutil.py and svm.py files, initializes an instance of BRISQUE as brisq, gets a feature from an image path using brisq.get_feature(), assigns an image path to 'image_path' variable, retrieves a quality score for the image using brisq.get_score(image_path), and prints the obtained score which is very fast.",
        "type": "comment"
    },
    "3590": {
        "file_id": 432,
        "content": "/tests/image_quality_tests/pybrisque_init.sh",
        "type": "filepath"
    },
    "3591": {
        "file_id": 432,
        "content": "Installing required dependencies and libraries for pybrisque Python package, including libsvm-dev, pip3 installing pybrisque, alternative options provided for faster installation.",
        "type": "summary"
    },
    "3592": {
        "file_id": 432,
        "content": "apt-get install libsvm-dev\npip3 install pybrisque\n# pip3 install --process-dependency-links pybrisque\npip3 install git+https://github.com/Salinger/libsvm-python.git\n# which is faster?",
        "type": "code",
        "location": "/tests/image_quality_tests/pybrisque_init.sh:1-6"
    },
    "3593": {
        "file_id": 432,
        "content": "Installing required dependencies and libraries for pybrisque Python package, including libsvm-dev, pip3 installing pybrisque, alternative options provided for faster installation.",
        "type": "comment"
    },
    "3594": {
        "file_id": 433,
        "content": "/tests/idlefish_闲鱼_xianyu_spider_scraper_taobao_video_guangguang/README.md",
        "type": "filepath"
    },
    "3595": {
        "file_id": 433,
        "content": "This code snippet is a warning about potentially malicious files from a QQ group and the challenge of safely running a specific software (Wine). The comment suggests caution when dealing with such files.",
        "type": "summary"
    },
    "3596": {
        "file_id": 433,
        "content": "the file from qq group might be virus. be careful!\ndamn wine. how to run this shit safely?",
        "type": "code",
        "location": "/tests/idlefish_闲鱼_xianyu_spider_scraper_taobao_video_guangguang/README.md:1-3"
    },
    "3597": {
        "file_id": 433,
        "content": "This code snippet is a warning about potentially malicious files from a QQ group and the challenge of safely running a specific software (Wine). The comment suggests caution when dealing with such files.",
        "type": "comment"
    },
    "3598": {
        "file_id": 434,
        "content": "/tests/interval_set_math_operations/continual_less_sympy.py",
        "type": "filepath"
    },
    "3599": {
        "file_id": 434,
        "content": "The code utilizes SymPy to handle intervals, merges overlapping ones, and reorganizes finalMappings and sorts finalCats before printing.",
        "type": "summary"
    }
}