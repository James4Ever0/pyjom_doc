{
    "1800": {
        "file_id": 170,
        "content": "/tests/unittest_chain.py",
        "type": "filepath"
    },
    "1801": {
        "file_id": 170,
        "content": "This code seems to be importing a module called \"chain\" for chaining functions, despite the author expressing doubt about its necessity due to list processing power.",
        "type": "summary"
    },
    "1802": {
        "file_id": 170,
        "content": "# how to chain functions?\n# it is hard. we have list processing power. why fucking bother?\nimport chain",
        "type": "code",
        "location": "/tests/unittest_chain.py:1-3"
    },
    "1803": {
        "file_id": 170,
        "content": "This code seems to be importing a module called \"chain\" for chaining functions, despite the author expressing doubt about its necessity due to list processing power.",
        "type": "comment"
    },
    "1804": {
        "file_id": 171,
        "content": "/tests/unittest_async_function_type.py",
        "type": "filepath"
    },
    "1805": {
        "file_id": 171,
        "content": "The code defines two async functions: `randomFunction` and `randomFunctionGenerator`. It determines the types of these functions using `type()`, and compares them to various built-in types. The code prints the results of these comparisons, mentioning that async generators can only be used within async methods, and there is no breakpoint support for async functions. Finally, it assigns a value to `data` by calling `randomFunction`, converts it to sync using `bilibili_api.sync()`, and prints the type and value of `data`.",
        "type": "summary"
    },
    "1806": {
        "file_id": 171,
        "content": "async def randomFunction():\n    return 1\nasync def randomFunctionGenerator():\n    yield await randomFunction()\nfrom bilibili_api import sync\nimport types\ntype0 = type(randomFunction)\ntype1 = type(randomFunction())\ntype2 = types.AsyncGeneratorType\ntype3 = type(randomFunctionGenerator())\ntype4 = types.CoroutineType\ntype5 = type(randomFunctionGenerator)\nprint(type0, type1, type2, type3, type4, type5)\nprint(type1 == type4)\nprint(type2 == type3)\n# async generator can only be used within async methods.\n# no breakpoint support for async functions? wtf?\n# data = randomFunctionGenerator() # this is async generator. different!\ndata = randomFunction()\ndata = sync(data)\n# # not good.\nprint(type(data), data)",
        "type": "code",
        "location": "/tests/unittest_async_function_type.py:1-27"
    },
    "1807": {
        "file_id": 171,
        "content": "The code defines two async functions: `randomFunction` and `randomFunctionGenerator`. It determines the types of these functions using `type()`, and compares them to various built-in types. The code prints the results of these comparisons, mentioning that async generators can only be used within async methods, and there is no breakpoint support for async functions. Finally, it assigns a value to `data` by calling `randomFunction`, converts it to sync using `bilibili_api.sync()`, and prints the type and value of `data`.",
        "type": "comment"
    },
    "1808": {
        "file_id": 172,
        "content": "/tests/test_weibo_pets.py",
        "type": "filepath"
    },
    "1809": {
        "file_id": 172,
        "content": "This code imports necessary modules, initializes a WeiboPetsReviewer object with specific parameters and then runs its main function to perform an automated review of Weibo Pets data.",
        "type": "summary"
    },
    "1810": {
        "file_id": 172,
        "content": "from test_commons import *\nfrom pyjom.primitives import *  # this is capitalized.\ntemplate_names = [\"subtitle_detector.mdl.j2\"]\nautoArgs = {\"subtitle_detector\": {\"timestep\": 0.2}}\nwbRev = WeiboPetsReviewer(\n    auto=True,\n    semiauto=False,\n    dummy_auto=False,\n    args=autoArgs,\n    template_names=template_names,\n)\n# wbRev.main(skip_review=True) # to test feedback.\nwbRev.main()",
        "type": "code",
        "location": "/tests/test_weibo_pets.py:1-15"
    },
    "1811": {
        "file_id": 172,
        "content": "This code imports necessary modules, initializes a WeiboPetsReviewer object with specific parameters and then runs its main function to perform an automated review of Weibo Pets data.",
        "type": "comment"
    },
    "1812": {
        "file_id": 173,
        "content": "/tests/unittest_bezier_evaluate.py",
        "type": "filepath"
    },
    "1813": {
        "file_id": 173,
        "content": "This code initializes a bezier curve and tests it in two cases: plotting with Seaborn and Matplotlib, or evaluating based on user input. It prints the value of 'axis' without context.",
        "type": "summary"
    },
    "1814": {
        "file_id": 173,
        "content": "import bezier\nimport numpy as np\nskew = -0.5  # skew: (-0.5,0.5) otherwise this shit will look ugly.\nx_start, y_start = 0, 0\nx_end, y_end = 1, 1\nx_diff = x_end - x_start\ny_diff = y_end - y_start\nnodes1 = np.asfortranarray(\n    [\n        [x_start, x_diff * (0.5 + skew), x_end],\n        [y_start, y_diff * (0.5 - skew), y_end],\n    ]\n)\ncurve1 = bezier.Curve(nodes1, degree=2)\n# import seaborn\n# seaborn.set()\ntest_case = \"evaluate\"\nif test_case == \"plot\":\n    axis = curve1.plot(num_pts=256)\n    import matplotlib.pyplot as plt\n    # plt.plot(axis)\n    plt.show()\nelif test_case == \"evaluate\":\n    print(\"type q to quit evaluation\")\n    while True:\n        s = input(\"s> \")\n        if s == \"q\":\n            print(\"quitting...\")\n            break\n        try:\n            s = float(s)\n            points = curve1.evaluate(s)\n            # we only get the single point.\n            point = points.T[0]\n            x, y = point\n            print(\"x: %f, y: %f\" % (x, y))\n        except:\n            print(\"ERROR: Invalid input value: %s\" % s)",
        "type": "code",
        "location": "/tests/unittest_bezier_evaluate.py:1-43"
    },
    "1815": {
        "file_id": 173,
        "content": "Code initializes a bezier curve with specified nodes, handles two test cases - plot and evaluate. In plot case, the curve is plotted using Seaborn and Matplotlib libraries. For the evaluate case, it continuously asks for user input (type 'q' to quit), evaluates the curve at the given point, and prints the x and y coordinates of the evaluated point.",
        "type": "comment"
    },
    "1816": {
        "file_id": 173,
        "content": "    # print(axis)",
        "type": "code",
        "location": "/tests/unittest_bezier_evaluate.py:44-44"
    },
    "1817": {
        "file_id": 173,
        "content": "This line prints the value of variable 'axis' without any context or further processing.",
        "type": "comment"
    },
    "1818": {
        "file_id": 174,
        "content": "/tests/unittest_bilibili_login.py",
        "type": "filepath"
    },
    "1819": {
        "file_id": 174,
        "content": "Checks if the test variable is 1, if true, imports necessary modules and attempts to remove existing credential file. If the test variable is not 1, tries to return a value using two different methods, handles potential errors and prints the result.",
        "type": "summary"
    },
    "1820": {
        "file_id": 174,
        "content": "test = 2\nif test == 1:\n    import os\n    credpath = \"/root/.bilibili_api.json\"\n    if os.path.exists(credpath):\n        os.remove(credpath)\n    from test_commons import *\n    from pyjom.platforms.bilibili.credentials import (\n        getCredentialByDedeUserId,\n        getCredentialViaSMS,\n    )\n    # myvalue = getCredentialViaSMS()\n    # print(myvalue)\n    val = getCredentialByDedeUserId()\n    print(val)\nelse:\n    # you may want to remove database.\n    # how the fuck you can do that?\n    # not possible. \"RETURN OUTSIDE OF FUNCTION\"\n    def myfunction():\n        try:\n            # exec('val= 1234'+';break'*1000)\n            val = eval(\"1234\")\n        except:\n            ...\n        print(val)\n    value = myfunction()\n    print(value)",
        "type": "code",
        "location": "/tests/unittest_bilibili_login.py:1-34"
    },
    "1821": {
        "file_id": 174,
        "content": "Checks if the test variable is 1, if true, imports necessary modules and attempts to remove existing credential file. If the test variable is not 1, tries to return a value using two different methods, handles potential errors and prints the result.",
        "type": "comment"
    },
    "1822": {
        "file_id": 175,
        "content": "/tests/unittest_bilibili_recommendation_server.py",
        "type": "filepath"
    },
    "1823": {
        "file_id": 175,
        "content": "This code imports requests, sets up a base URL for the bilibili recommendation server and waits for it to be up. It defines objectives such as searching registered videos or user videos and creates parameters using dictionaries. After setting specific values, it sends POST requests with JSON format data and prints the objective and response text.",
        "type": "summary"
    },
    "1824": {
        "file_id": 175,
        "content": "import requests\nport = 7341\nbaseurl = \"http://localhost:{}\".format(port)\nfrom lazero.network.checker import waitForServerUp\nmessage = \"bilibili recommendation server\"\nwaitForServerUp(port, message=message)\n# objective = \"searchRegisteredVideos\"\n# objective = \"searchVideos\"\nobjective = \"searchUserVideos\"\n# objective = \"registerUserVideo\"\nif objective == \"searchVideos\":\n    params = {\n        # \"params\": {\"hop\": 1}, # there is no such parameter here.\n        # can we pass shit without params?\n        \"params\": ...,\n        \"query\": \"hello world\",\n        \"iterate\": False,  # not all pages, you dumb fool!\n        \"page_num\": 1,\n    }  # check if this works?\nelif objective == \"searchRegisteredVideos\":\n    # params = dict(query='hello world') # does not remove ellipsis?\n    params = dict(\n        query=\"hello world\", tid=..., dedeuserid=..., videoOrder=..., page_num=2\n    )  # does not remove ellipsis?\n    # print(j)\n    # exit()\nelif objective == \"searchUserVideos\":\n    # it is good.\n    # params = dict(query=\"猫\", method=\"bm25\", videoOrder=\"click\")",
        "type": "code",
        "location": "/tests/unittest_bilibili_recommendation_server.py:1-33"
    },
    "1825": {
        "file_id": 175,
        "content": "The code imports the requests library, sets up a base URL for the bilibili recommendation server, uses the waitForServerUp function to ensure the server is running before executing further commands. It defines different objectives such as searching registered videos, searching videos, and searching user videos. Depending on the objective, it creates a dictionary of parameters (including query, page_num, etc.) to pass to the server API.",
        "type": "comment"
    },
    "1826": {
        "file_id": 175,
        "content": "    params = dict(query=\"猫\", method=\"bm25\")\n    # params = dict(query='猫',method='bm25', dedeuserid=None)\nelif objective == \"registerUserVideo\":\n    params = dict(\n        bvid=\"BV1MN4y1P7mq\", dedeuserid=\"397424026\", is_mine=True, visible=False\n    )\nelse:\n    raise Exception(\"invalid objective: %s\" % objective)\nfrom lazero.utils.json import jsonify\nparams = jsonify(params)\nr = requests.post(baseurl + \"/\" + objective, json=params)\nprint(\"objective: %s\" % objective)\nprint(\"response:\", r.text)\nbreakpoint()",
        "type": "code",
        "location": "/tests/unittest_bilibili_recommendation_server.py:34-50"
    },
    "1827": {
        "file_id": 175,
        "content": "This code is setting parameters for a function depending on the objective. It uses dictionary to store query, method, dedeuserid and other information. If 'registerUserVideo' is the objective, it sets specific values. The code converts params to json format and sends a POST request to the server with the base URL and objective as parameters. The code also prints the objective and response text.",
        "type": "comment"
    },
    "1828": {
        "file_id": 176,
        "content": "/tests/unittest_extract_tags_tfidf.py",
        "type": "filepath"
    },
    "1829": {
        "file_id": 176,
        "content": "This code is processing Chinese text using the Jieba library to tokenize it and filter out stop words. It then extracts the top 5 keywords using NLTK's jieba.analyse module. The output is the extracted tags printed on the console.",
        "type": "summary"
    },
    "1830": {
        "file_id": 176,
        "content": "text = \"Flask的路由,视图和相关配置\"  # just a sample please?\nfrom nltk.corpus import stopwords\nmyStopwords = stopwords.words([\"chinese\", \"english\"])\nimport jieba.analyse as ana\nimport jieba\nwords = jieba.lcut(text)\nwords_filtered = []\nfor word in words:\n    if word.lower() not in myStopwords:\n        words_filtered.append(word)\ntext_splited = \" \".join(words_filtered)\ntags = ana.extract_tags(\n    text_splited,\n    topK=5,\n)\nprint(tags)\n# seems like you can only change the source to make it into somewhat solveable problem.",
        "type": "code",
        "location": "/tests/unittest_extract_tags_tfidf.py:1-24"
    },
    "1831": {
        "file_id": 176,
        "content": "This code is processing Chinese text using the Jieba library to tokenize it and filter out stop words. It then extracts the top 5 keywords using NLTK's jieba.analyse module. The output is the extracted tags printed on the console.",
        "type": "comment"
    },
    "1832": {
        "file_id": 177,
        "content": "/tests/unittest_cirular_import.py",
        "type": "filepath"
    },
    "1833": {
        "file_id": 177,
        "content": "The code imports a module \"unittest_circular_import\" as \"rea\". It assigns the value 1 to variable x. If the script is executed directly, it prints the value of rea's x. This could be used for testing purposes or handling circular imports.",
        "type": "summary"
    },
    "1834": {
        "file_id": 177,
        "content": "import unittest_circular_import as rea\nx = 1\nif __name__ == \"__main__\":\n    print(rea.x)",
        "type": "code",
        "location": "/tests/unittest_cirular_import.py:1-6"
    },
    "1835": {
        "file_id": 177,
        "content": "The code imports a module \"unittest_circular_import\" as \"rea\". It assigns the value 1 to variable x. If the script is executed directly, it prints the value of rea's x. This could be used for testing purposes or handling circular imports.",
        "type": "comment"
    },
    "1836": {
        "file_id": 178,
        "content": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py",
        "type": "filepath"
    },
    "1837": {
        "file_id": 178,
        "content": "This code defines Bezier curve functions and applies them in an exponential network model for animal detection. It uses hyperparameter optimization in the Hyperopt library to represent results, tune input parameters, and find the best loss value.",
        "type": "summary"
    },
    "1838": {
        "file_id": 178,
        "content": "import numpy as np\nimport bezier\n# BEST: {'input_bias': 0.0830047243746045, 'skew': -0.4986098769473948}\n# maybe not so right?\ndef bezierCurve(start=(0, 0), end=(1, 1), skew=0):\n    # skew: (-0.5,0.5) otherwise this shit will look ugly.\n    assert skew >= -0.5\n    assert skew <= 0.5\n    x_start, y_start = start\n    x_end, y_end = end\n    x_diff = x_end - x_start\n    y_diff = y_end - y_start\n    nodes1 = np.asfortranarray(\n        [\n            [x_start, x_diff * (0.5 + skew), x_end],\n            [y_start, y_diff * (0.5 - skew), y_end],\n        ]\n    )\n    curve1 = bezier.Curve(nodes1, degree=2)\n    curve_params = {\"x_start\": x_start, \"x_diff\": x_diff, \"x_end\": x_end}\n    return curve1, curve_params\ndef evaluateBezierCurve(input_value: float, curve, curve_params: dict):\n    x_start = curve_params[\"x_start\"]\n    x_end = curve_params[\"x_end\"]\n    assert x_start <= input_value\n    assert x_end >= input_value\n    x_diff = curve_params[\"x_diff\"]\n    s = (input_value - x_start) / x_diff\n    points = curve.evaluate(s)\n    # we only get the single point.",
        "type": "code",
        "location": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py:1-33"
    },
    "1839": {
        "file_id": 178,
        "content": "This code defines a function `bezierCurve()` that creates a Bezier curve with optional skew parameter and returns the curve object and its parameters. The `evaluateBezierCurve()` function evaluates a given input value on the Bezier curve.",
        "type": "comment"
    },
    "1840": {
        "file_id": 178,
        "content": "    point = points.T[0]\n    x, y = point\n    result = y\n    return result\ndef multiParameterExponentialNetwork(\n    *args,\n    input_bias=0.05,\n    curve_function=bezierCurve,\n    curve_function_kwargs={\"start\": (0, 0), \"end\": (1, 1), \"skew\": 0},\n    evaluate_function=evaluateBezierCurve\n):\n    curve, curve_params = curve_function(**curve_function_kwargs)\n    value = evaluate_function(input_bias, curve, curve_params)\n    for index, input_value in enumerate(args):\n        apply_list = [input_value] * (index + 1)\n        for apply_item in apply_list:\n            value += (1 - value) * evaluate_function(apply_item, curve, curve_params)\n    return value\n# params = (0.2,0.1,0.1)\n##################################################\n# [('cat', 0.23492032289505005), ('cat', 0.14728288352489471), ('cat', 0.13097935914993286)]\n# [('cat', 0.29809582233428955), ('cat', 0.2462661862373352), ('cat', 0.13935738801956177)]\ntest_params = [\n    # [('cat', 0.3532187342643738), ('cat', 0.22708916664123535), (None, 0.11154596507549286)],0.7],",
        "type": "code",
        "location": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py:34-61"
    },
    "1841": {
        "file_id": 178,
        "content": "This code defines a function `multiParameterExponentialNetwork` which takes input parameters and applies an exponential network model using a given curve function, evaluate function, and additional arguments. The result is returned after applying the exponential network model to each input parameter. Testing with different sets of parameters is shown in the last part of the code.",
        "type": "comment"
    },
    "1842": {
        "file_id": 178,
        "content": "    ##################################################\n    [\n        [\n            (\"cat\", 0.15381687879562378),\n            (\"cat\", 0.14100512862205505),\n            (\"cat\", 0.11225848644971848),\n        ],\n        0.7,\n    ],\n    # params = (0.2,0.1,0.1)\n    # source = \"/root/Desktop/works/pyjom/samples/image/samoyed.jpeg\"\n    # [('dog', 0.8835851550102234), ('dog', 0.08754527568817139), ('dog', 0.008648859336972237)]\n    # source = \"/root/Desktop/works/pyjom/samples/image/dog_saturday_night.jpg\"\n    [\n        [\n            (None, 0.33663231134414673),\n            (\"dog\", 0.32254937291145325),\n            (\"dog\", 0.0494903139770031),\n        ],\n        0.7,\n    ],\n]  # select the typical things for evaluation.\n# not animal? wtf?\n# source = \"/root/Desktop/works/pyjom/samples/image/porn_shemale.jpeg\" # definitely not animal\n# [(None, 0.9894463419914246), ('dog', 1.564090962347109e-05), ('dog', 1.3550661606132053e-05)]\n# source = \"/root/Desktop/works/pyjom/samples/image/is_this_duck.bmp\"\n# [(None, 0.9864748120307922), ('dog', 1.2670795513258781e-05), (None, 9.569253961672075e-06)]",
        "type": "code",
        "location": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py:62-88"
    },
    "1843": {
        "file_id": 178,
        "content": "This code represents a list of animal detection results, where each element consists of the detected animal category and its corresponding probability. It also contains an optional \"None\" entry for non-animal detections. The list is used to evaluate typical scenarios with different images and animals, including some anomalies like non-animal images or images with extremely low detection probabilities.",
        "type": "comment"
    },
    "1844": {
        "file_id": 178,
        "content": "# source = \"/root/Desktop/works/pyjom/samples/image/pig_really.bmp\" # it's really a dog, but it is so ugly so i don't want to admit.\n# [(None, 0.35919442772865295), ('dog', 0.16199783980846405), ('dog', 0.07987158000469208)]\n# source = \"/root/Desktop/works/pyjom/samples/image/miku_on_green.png\"\n# besides calculating \"DOG\" or \"CAT\" we are also concerned about \"NONE\"\n# [(None, 0.9998186230659485), (None, 1.7534730432089418e-06), (None, 7.280816021193459e-07)]\n# source = \"/root/Desktop/works/pyjom/samples/image/dog_with_text.jpg\" # no dog\n#  [(None, 0.9998675584793091), ('dog', 2.565316492564307e-07), (None, 1.562129767762599e-07)]\n# source = \"/root/Desktop/works/pyjom/samples/image/dog_with_text2.png\" # has dog\n#  [(None, 0.8876796960830688), ('dog', 0.0498274527490139), ('dog', 0.02175540290772915)]\n# a little, but not focused.\n# input_bias = 0.05\n# skew = -0.5\n# change these two things.\nfrom lazero.utils.logger import sprint\nimport hyperopt\nfrom hyperopt import fmin, tpe, space_eval\ndef evaluate_params(input_bias, skew):",
        "type": "code",
        "location": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py:89-109"
    },
    "1845": {
        "file_id": 178,
        "content": "This code snippet is using hyperparameter optimization to tune the input_bias and skew parameters for a machine learning model. The code provides sample inputs and expected outputs, demonstrating how these hyperparameters affect the results of the model. It then uses the Hyperopt library to perform the optimization.",
        "type": "comment"
    },
    "1846": {
        "file_id": 178,
        "content": "    curve_function_kwargs = {\n        \"start\": (0, 0),\n        \"end\": (1, 1),\n        \"skew\": skew,\n    }  # maximize the output.\n    difference_items = []\n    for subject_id, (test_param, target_output) in enumerate(test_params):\n        differences = []\n        for index, (label, confidence) in enumerate(test_param):\n            scope = test_param[index:]\n            scope_confidences = [elem[1] for elem in scope if elem[0] == label]\n            output = multiParameterExponentialNetwork(\n                *scope_confidences,\n                input_bias=input_bias,\n                curve_function_kwargs=curve_function_kwargs\n            )\n            print(\"test subject_id:\", subject_id)\n            print(\"label:\", label)\n            print(\"output:\", output)\n            print(\"target_output:\", target_output)\n            absolute_difference = abs(target_output - output)\n            sprint(\"absolute difference:\", absolute_difference)\n            differences.append((label, absolute_difference))\n        mLabels = [\"dog\", \"cat\"]",
        "type": "code",
        "location": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py:110-133"
    },
    "1847": {
        "file_id": 178,
        "content": "This code defines a function that takes in a set of test parameters and their corresponding target outputs. It then calculates the output from a neural network with the given parameters, using a specific curve function with skew factor. The differences between the calculated output and the target output are recorded for each parameter combination, and printed along with other information such as subject ID and label.",
        "type": "comment"
    },
    "1848": {
        "file_id": 178,
        "content": "        best_params_dict = {}\n        for label, difference in differences:\n            if label in mLabels:\n                previousDifference = best_params_dict.get(label, 1)\n                if previousDifference > difference:\n                    best_params_dict[label] = difference\n        final_differences = []\n        for mLabel in mLabels:\n            d = best_params_dict.get(mLabel, 1)\n            final_differences.append(d)\n        difference_item = min(final_differences)\n        difference_items.append(difference_item)\n    final_difference = sum(difference_items)\n    sprint(\"FINAL DIFFERENCE:\", final_difference)\n    return final_difference\ndef objective(args):\n    skew, input_bias = args\n    # print(args)\n    print(\"skew:\", skew)\n    sprint(\"input_bias:\", input_bias)\n    # it is just a tuple.\n    # breakpoint()\n    value = evaluate_params(input_bias, skew)\n    return value\nspace = (\n    hyperopt.hp.uniform(\"skew\", -0.5, 0),\n    hyperopt.hp.uniform(\"input_bias\", 0, 0.1),\n)\nbest = fmin(objective, space, algo=tpe.suggest, max_evals=100)",
        "type": "code",
        "location": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py:134-167"
    },
    "1849": {
        "file_id": 178,
        "content": "This code uses hyperparameter optimization to find the best skew and input_bias values for a model. It calculates the final difference by iterating over the labels, comparing previous differences with new ones, and finding the minimum difference in each label. The objective function evaluates the parameters for a given input and returns a value. Hyperopt's tpe algorithm is used to search for the best combination of skew and input_bias within the specified ranges, and max_evals sets the maximum number of evaluations to be performed.",
        "type": "comment"
    },
    "1850": {
        "file_id": 178,
        "content": "# sprint(\"EVAL:\",space_eval(space, best))\nbest_loss = objective((best[\"skew\"], best[\"input_bias\"]))\nsprint(\"BEST LOSS:\", best_loss)\nsprint(\"BEST:\", best)",
        "type": "code",
        "location": "/tests/unittest_bezier_fitting_bias_skew_baidu_resnet_animals_detection_hyperopt.py:168-172"
    },
    "1851": {
        "file_id": 178,
        "content": "These lines evaluate the best hyperparameters found and print the loss value, as well as the entire set of hyperparameters.",
        "type": "comment"
    },
    "1852": {
        "file_id": 179,
        "content": "/tests/unittest_caer_fps_kitty_9.5.py",
        "type": "filepath"
    },
    "1853": {
        "file_id": 179,
        "content": "The code imports necessary modules, finds the correct OpenCV library file, adds its parent directory to the system path, and retrieves the frame rate of a video file using the caer.video module. The FPS value is then printed.",
        "type": "summary"
    },
    "1854": {
        "file_id": 179,
        "content": "src = \"/root/Desktop/works/pyjom/samples/video/kitty_flash.gif\"\nimport pathlib, sys  # great.\nsite_path = pathlib.Path(\"/usr/local/lib/python3.9/site-packages\")\ncv2_libs_dir = (\n    site_path / \"cv2\" / f\"python-{sys.version_info.major}.{sys.version_info.minor}\"\n)\nprint(cv2_libs_dir)\ncv2_libs = sorted(cv2_libs_dir.glob(\"*.so\"))\nif len(cv2_libs) == 1:\n    print(\"INSERTING:\", cv2_libs[0].parent)\n    sys.path.insert(1, str(cv2_libs[0].parent))\nfrom caer.video.frames_and_fps import get_fps_float\nfps = get_fps_float(src)\nprint(\"FPS:\", fps)  # 10? was very inaccurate for me\n# now it is good. 9.5",
        "type": "code",
        "location": "/tests/unittest_caer_fps_kitty_9.5.py:1-19"
    },
    "1855": {
        "file_id": 179,
        "content": "The code imports necessary modules, finds the correct OpenCV library file, adds its parent directory to the system path, and retrieves the frame rate of a video file using the caer.video module. The FPS value is then printed.",
        "type": "comment"
    },
    "1856": {
        "file_id": 180,
        "content": "/tests/unittest_caer_get_gif_width_height.py",
        "type": "filepath"
    },
    "1857": {
        "file_id": 180,
        "content": "This code imports the get_res function from caer.video, sets a video path, and calls the get_res function with the video path to retrieve the width and height of the video, then prints them out.",
        "type": "summary"
    },
    "1858": {
        "file_id": 180,
        "content": "from caer.video.frames_and_fps import get_res\nvideoPath = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\nwidth, height = get_res(videoPath)\nprint(width, height)",
        "type": "code",
        "location": "/tests/unittest_caer_get_gif_width_height.py:1-6"
    },
    "1859": {
        "file_id": 180,
        "content": "This code imports the get_res function from caer.video, sets a video path, and calls the get_res function with the video path to retrieve the width and height of the video, then prints them out.",
        "type": "comment"
    },
    "1860": {
        "file_id": 181,
        "content": "/tests/unittest_check_video_corrput.py",
        "type": "filepath"
    },
    "1861": {
        "file_id": 181,
        "content": "The code tests a video file for corruption by using ffmpeg to input the video, output it to null format, and then checks if any error or failure messages appear in the stderr. If such messages are found, the video is considered corrupted.",
        "type": "summary"
    },
    "1862": {
        "file_id": 181,
        "content": "import ffmpeg\nnot_nice = [\"invalid\", \"failed\", \"error\"]\nvideoPath = \"/root/Desktop/works/pyjom/samples/video/dog_with_large_text.gif\"\n# videoPath = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif\"\n# videoPath = \"/root/Desktop/works/pyjom/samples/video/corrupt_video.gif\"\ncorrupted = False\ntry:\n    stdout, stderr = (\n        ffmpeg.input(videoPath)\n        .output(\"null\", f=\"null\")\n        .run(capture_stdout=True, capture_stderr=True)\n    )\n    stderr_lower = stderr.decode(\"utf-8\").lower()\n    for word in not_nice:\n        if word in stderr_lower:\n            print(\"video is corrupted\")\n            corrupted = True\n            break\nexcept:\n    import traceback\n    traceback.print_exc()\n    corrupted = True\n    print(\"corrupt video\")\nif not corrupted:\n    print(\"video is fine\")",
        "type": "code",
        "location": "/tests/unittest_check_video_corrput.py:1-28"
    },
    "1863": {
        "file_id": 181,
        "content": "The code tests a video file for corruption by using ffmpeg to input the video, output it to null format, and then checks if any error or failure messages appear in the stderr. If such messages are found, the video is considered corrupted.",
        "type": "comment"
    },
    "1864": {
        "file_id": 182,
        "content": "/tests/unittest_extract_cat_cover_from_video.py",
        "type": "filepath"
    },
    "1865": {
        "file_id": 182,
        "content": "This code downloads Bilibili videos, extracts covers for pet videos, and checks frames to display the cover. It uses yt_dlp, image processing libraries, and OpenCV's imshow function. If a clear frame is found, it breaks the loop and waits for a key press before proceeding.",
        "type": "summary"
    },
    "1866": {
        "file_id": 182,
        "content": "videoLink = \"https://www.bilibili.com/video/BV1Cb4y1s7em\"  # this is a dog.\n# videoLink = \"https://www.bilibili.com/video/BV1Lx411B7X6\"  # multipart download\n# from lazero.filesystem.temp import tmpfile\nimport yt_dlp\n# import pyidm\npath = \"/dev/shm/testVideo.mp4\"\nfrom test_commons import *\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nimport cv2\nfrom pyjom.videotoolbox import getVideoFrameSampler\nfrom pyjom.imagetoolbox import imageDogCatCoverCropAdvanced\n# from pyjom.imagetoolbox import (\n#     bezierPaddleHubResnet50ImageDogCatDetector,\n#     # we deprecate this thing to make it somehow better.\n#     getImageTextAreaRatio,\n#     imageFourCornersInpainting,\n#     imageCropoutBlackArea,\n#     imageCropoutBlurArea,\n#     imageDogCatDetectionForCoverExtraction,\n#     imageLoader,\n# )\nfrom pyjom.commons import checkMinMaxDict\nimport os\n# with tmpfile(path=path, replace=True) as TF:\nif os.path.exists(path):\n    os.remove(path)\nx = yt_dlp.YoutubeDL(\n    {\n        \"outtmpl\": path,  # seems only video p1 is downloaded.",
        "type": "code",
        "location": "/tests/unittest_extract_cat_cover_from_video.py:1-42"
    },
    "1867": {
        "file_id": 182,
        "content": "This code is downloading a video from Bilibili using yt_dlp library and saving it to the path \"/dev/shm/testVideo.mp4\". It also imports various libraries for image processing and video analysis. The commented out section suggests an alternative download method, possibly for multipart downloads.",
        "type": "comment"
    },
    "1868": {
        "file_id": 182,
        "content": "    }\n)\ny = x.download([videoLink])\n# shall you use frame sampler instead of iterator? cause this is dumb.\n# breakpoint()\nfrom pyjom.videotoolbox import corruptVideoFilter\nvideo_fine = corruptVideoFilter(path)\nif not video_fine:\n    print(\"VIDEO FILE CORRUPTED\")\n    exit()\nfrom caer.video.frames_and_fps import get_duration\nduration = get_duration(path)\nmSampleSize = int(duration / 2)  # fps = 0.5 or something?\nprocessed_frame = None\ndog_or_cat = \"dog\"\nfor frame in getVideoFrameSampler(path, -1, -1, sample_size=mSampleSize, iterate=True):\n    # animalCropDiagonalRect = imageDogCatDetectionForCoverExtraction(\n    #     frame,\n    #     dog_or_cat=dog_or_cat,\n    #     confidence_threshold=confidence_threshold,\n    #     crop=False,\n    # )  # you must use gpu this time.\n    # if animalCropDiagonalRect is not None:  # of course this is not None.\n    # we need to identify this shit.\n    # if checkMinMaxDict(text_area_ratio, text_area_threshold):\n    processed_frame = imageDogCatCoverCropAdvanced(frame, dog_or_cat=dog_or_cat)",
        "type": "code",
        "location": "/tests/unittest_extract_cat_cover_from_video.py:43-74"
    },
    "1869": {
        "file_id": 182,
        "content": "This code downloads a video file, checks for corruption, calculates the duration, sets the sample size based on duration, iterates through video frames, and applies an image processing algorithm to extract a cover for either dog or cat videos. The code might benefit from using a frame sampler instead of an iterator as the current implementation is considered inefficient.",
        "type": "comment"
    },
    "1870": {
        "file_id": 182,
        "content": "    if processed_frame is not None:\n        # blurValue = imageCropoutBlurArea(processed_frame, value=True)\n        # print(\"BLUR VALUE:\", blurValue)\n        # if not checkMinMaxDict(blurValue, blurValue_threshold):\n        #     # will skip this one since it is not so clear.\n        #     continue\n        break\nif processed_frame is not None:\n    print(\"COVER IMAGE FOUND!\")\n    processed_frame_show = cv2.resize(processed_frame, (int(1920 / 2), int(1080 / 2)))\n    cv2.imshow(\"image\", processed_frame_show)\n    cv2.waitKey(0)\nelse:\n    print(\"COVER NOT FOUND FOR %s\" % videoLink)",
        "type": "code",
        "location": "/tests/unittest_extract_cat_cover_from_video.py:75-88"
    },
    "1871": {
        "file_id": 182,
        "content": "This code checks for a clear frame in a video and if found, displays it; otherwise, it indicates that the cover was not found. If a clear frame is detected (processed_frame), it will break out of the loop. The processed frame is resized and displayed using OpenCV's imshow function, then the program waits for any key press before proceeding.",
        "type": "comment"
    },
    "1872": {
        "file_id": 183,
        "content": "/tests/unittest_clean_lrc.py",
        "type": "filepath"
    },
    "1873": {
        "file_id": 183,
        "content": "The code checks lyrics' adherence to line requirements, processes a list of lyrics, extracts flags, and formats the lyrics into an LRC string.",
        "type": "summary"
    },
    "1874": {
        "file_id": 183,
        "content": "lyric_string = \"\"\"[00:00.000] 作词 : 苏喜多/挡风玻璃\\n[00:01.000] 作曲 : 苏喜多/陈恒冠\\n[00:02.000] 编曲 : 陈恒冠/陈恒家\\n[00:31.154]你戴上帽子遮住眼睛 轻轻地绕着我 总洋溢着暖\\n[00:44.404]我…我只能唱\\n[00:54.902]你像气泡水直接淘气 爱和星星眨眼睛 轻易抓住我\\n[01:07.903]我…我只能唱\\n[01:16.651]有一个岛屿 在北极冰川\\n[01:23.403]那儿没有花朵 也没有失落\\n[01:30.159]在那个岛屿 洒满了繁星\\n[01:36.904]拥有我和你 再没有失落\\n[02:15.903]你邀请流浪期待欢喜 惹我专心好奇 我看见了光\\n[02:29.153]我…我只能唱\\n[02:39.403]难免坏天气闪电暴雨 练就肩膀和勇气 只为你拥抱我\\n[02:54.156]我…我只能唱\\n[03:01.659]有一个岛屿 在北极冰川\\n[03:08.154]那儿没有花朵 也没有失落\\n[03:14.906]在那个岛屿 洒满了繁星\\n[03:21.651]拥有我和你 再没有失落\\n[03:28.656]有一个岛屿 在北极冰川\\n[03:35.152]\n那儿没有花朵 也没有失落\\n[03:41.904]在那个岛屿 洒满了繁星\\n[03:48.661]拥有我和你 再没有失落\\n[03:59.159]有一个岛屿 在北极冰川\\n[04:05.654]那儿没有花朵 也没有失落\\n[04:12.659]在那个岛屿 洒满了繁星\\n[04:19.152]拥有我和你 再没有失落\\n[04:26.405]有一个岛屿\n在北极冰川\\n[04:33.658]那儿没有花朵 也没有失落…\\n[04:40.401]吉他：陈恒家\\n[04:42.654]钢琴：陈恒冠\\n[04:47.407]混音：陈恒家\\n[04:49.907]母带：陈恒家\\n[04:53.907]监制：1991与她\\n\"\"\"\n# assume song duration here!\nsong_duration = 5 * 60\nimport pylrc\n# you'd better inspect the thing. what is really special about the lyric, which can never appear?",
        "type": "code",
        "location": "/tests/unittest_clean_lrc.py:1-10"
    },
    "1875": {
        "file_id": 183,
        "content": "Lyric string contains time-stamped song lyrics and metadata, assumed song duration is set to 5 minutes, and pylrc module is imported.",
        "type": "comment"
    },
    "1876": {
        "file_id": 183,
        "content": "min_lines_of_lyrics = 5\nmin_total_lines_of_lyrics = 10\npotential_forbidden_chars = [\"[\", \"]\", \"【\", \"】\", \"「\", \"」\", \"《\", \"》\", \"/\", \"(\", \")\"]\ncore_forbidden_chars = [\":\", \"：\", \"@\"]\ndef checkLyricText(text, core_only=False):\n    if core_only:\n        forbidden_chars = core_forbidden_chars\n    else:\n        forbidden_chars = core_forbidden_chars + potential_forbidden_chars\n    return not any([char in text for char in forbidden_chars])\n# also get the total time covered by lyric.\n# the time must be long enough, compared to the total time of the song.\nlrc_parsed = pylrc.parse(lyric_string)\nlrc_parsed_list = [line for line in lrc_parsed]\nlrc_parsed_list.sort(key=lambda line: line.time)\nbegin = False\n# end = False\nline_counter = 0\nnew_lines = []\n# lrc_parsed: pylrc.classes.Lyrics\nflags = []\nfor line in lrc_parsed_list:\n    # print(line)\n    text = line.text.strip()\n    startTime = line.time\n    if not begin:\n        flag = checkLyricText(text, core_only=False)\n        if not flag:\n            begin = True\n    else:\n        flag = checkLyricText(text, core_only=True)",
        "type": "code",
        "location": "/tests/unittest_clean_lrc.py:12-46"
    },
    "1877": {
        "file_id": 183,
        "content": "This code checks if a Lyrics object from pylrc meets certain criteria. It defines minimum line requirements for lyrics and forbidden characters. The function checkLyricText() determines whether a line contains any forbidden characters. The code then processes the lrc_parsed list to get the total time covered by lyrics, ensuring it's long enough compared to the song's total time. It creates new_lines with valid lines and flags for each line based on the presence of forbidden characters.",
        "type": "comment"
    },
    "1878": {
        "file_id": 183,
        "content": "        if flag:\n            begin = False\n    flags.append(flag)\n    # breakpoint()\n# select consecutive spans.\nfrom test_commons import *\nfrom pyjom.mathlib import extract_span\nint_flags = [int(flag) for flag in flags]\nmySpans = extract_span(int_flags, target=1)\nprint(mySpans)  # this will work.\n# this span is for the range function. no need to add one to the end.\ntotal_length = 0\nnew_lyric_list = []\nfor mstart, mend in mySpans:\n    length = mend - mstart\n    total_length += length\n    if length >= min_lines_of_lyrics:\n        # process these lines.\n        for index in range(mstart, mend):\n            line_start_time = lrc_parsed_list[index].time\n            line_text = lrc_parsed_list[index].text\n            if line_start_time <= song_duration:\n                line_end_time = song_duration\n                if index + 1 < len(lrc_parsed_list):\n                    line_end_time = lrc_parsed_list[index + 1].time\n                    if line_end_time > song_duration:\n                        line_end_time = song_duration",
        "type": "code",
        "location": "/tests/unittest_clean_lrc.py:47-78"
    },
    "1879": {
        "file_id": 183,
        "content": "Checks if a flag is set, appends it to the flags list. Filters and extracts consecutive spans from the flags list. Calculates total length of spans. Iterates over the spans, retrieves line start time and text from lrc_parsed_list, checks if line end time is within song duration.",
        "type": "comment"
    },
    "1880": {
        "file_id": 183,
        "content": "                new_lyric_list.append((line_text, line_start_time))\n                if index == mend - 1:\n                    # append one more thing.\n                    new_lyric_list.append((\"\", line_end_time))\n            else:\n                continue\n# for elem in new_lyric_list:\n#     print(elem)\n# exit()\nif total_length >= min_total_lines_of_lyrics:\n    print(\"LYRIC ACCEPTED.\")\n    new_lrc = pylrc.classes.Lyrics()\n    for text, myTime in new_lyric_list:\n        timecode_min, timecode_sec = divmod(myTime, 60)\n        timecode = \"[{:d}:{:.3f}]\".format(int(timecode_min), timecode_sec)\n        myLine = pylrc.classes.LyricLine(timecode, text)\n        new_lrc.append(myLine)\n    new_lrc_string = new_lrc.toLRC()\n    print(new_lrc_string)",
        "type": "code",
        "location": "/tests/unittest_clean_lrc.py:79-98"
    },
    "1881": {
        "file_id": 183,
        "content": "The code processes a list of lyrics and checks if it meets the minimum requirements for length. If so, it formats the lyrics into an LRC string and prints it.",
        "type": "comment"
    },
    "1882": {
        "file_id": 184,
        "content": "/tests/unittest_ffmpeg_overlay_boxblur.py",
        "type": "filepath"
    },
    "1883": {
        "file_id": 184,
        "content": "The code uses ffmpeg library to apply Gaussian blur filter and scale video stream, then creates a second layer, overlays both layers, and outputs the processed video stream. It sets output dimensions, uses \"scale\" and \"gblur\" or \"boxblur\" filters, scales video stream with aspect ratio preservation, and outputs file to temporary directory.",
        "type": "summary"
    },
    "1884": {
        "file_id": 184,
        "content": "# ffmpeg对视频实现高斯模糊，给视频上下加模糊背景\n# ffmpeg实现视频高斯模糊拓边效果\nimport ffmpeg\nsource = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif\"\nstream = ffmpeg.input(source)\nvideo_stream = stream.video\n# the damn thing because they are from the same file! fuck!\n# layer_0 = video_stream.filter(\"scale\", w=1080, h=1920).filter(\"boxblur\", 10) # this is default?\n# however, you need to generalize it here.\n# output_width = 1080\n# output_height = 1920\noutput_height = 1080\noutput_width = 1920\nlayer_0 = video_stream.filter(\"scale\", w=output_width, h=output_height).filter(\n    \"gblur\", sigma=9\n)  # this is default?\n# print('layer_0 args', layer_0.get_args())\nlayer_1 = video_stream.filter(\n    \"scale\",\n    w=\"min(floor(iw*{}/ih),{})\".format(output_height, output_width),\n    h=\"min(floor(ih*{}/iw),{})\".format(output_width, output_height),\n)\n# print('layer_1 args', layer_1.get_args())\n## in case you failed to generalize this shit...\noutput_stream = layer_0.overlay(layer_1, x=\"floor((W-w)/2)\", y=\"floor((H-h)/2)\")\n# print('output_stream args', output_stream.get_args())",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_overlay_boxblur.py:1-40"
    },
    "1885": {
        "file_id": 184,
        "content": "The code uses ffmpeg library to apply Gaussian blur filter and scale video stream. It sets output dimensions, applies \"scale\" filter with given width and height, then applies \"gblur\" or \"boxblur\" filter. Then, it creates a second layer by scaling the video stream with aspect ratio preservation and overlays both layers using specific coordinates. Finally, it outputs the processed video stream.",
        "type": "comment"
    },
    "1886": {
        "file_id": 184,
        "content": "from lazero.filesystem import tmpdir\npath = \"/dev/shm/medialang\"\nimport os\nwith tmpdir(path=path) as T:\n    filepath = os.path.join(path, \"output.mp4\")\n    # args = ffmpeg.get_args(output_stream)\n    # print(args)\n    output_args = {\"preset\": \"veryfast\"}  # seems like it won't speed up so much?\n    ffmpeg.output(output_stream, filepath, **output_args).run(overwrite_output=True)\n    print(\"output file location:\", filepath)\n    breakpoint()",
        "type": "code",
        "location": "/tests/unittest_ffmpeg_overlay_boxblur.py:42-54"
    },
    "1887": {
        "file_id": 184,
        "content": "The code sets a temporary directory path, joins it with the file name, creates FFmpeg output arguments with a fast preset, and then runs an FFmpeg command to output the stream to the file in the temporary directory. The output file location is printed.",
        "type": "comment"
    },
    "1888": {
        "file_id": 185,
        "content": "/tests/unittest_cv2_rectangle.py",
        "type": "filepath"
    },
    "1889": {
        "file_id": 185,
        "content": "This code imports necessary libraries, defines a function to create a black image of given dimensions, creates a black image, draws a rectangle on it with white color, displays the image, and waits for any key press before exiting.",
        "type": "summary"
    },
    "1890": {
        "file_id": 185,
        "content": "from test_commons import *\nfrom pyjom.commons import *\nimport cv2\nimport numpy as np\ndef getBlackPicture(width, height):\n    blackPicture = np.zeros((height, width, 3), dtype=\"uint8\")  # this is grayscale.\n    return blackPicture\nblackPicture = getBlackPicture(500, 500)\ncv2.rectangle(blackPicture, (200, 200), (300, 300), (255, 255, 255), 3)\ncv2.imshow(\"image\", blackPicture)\ncv2.waitKey(0)",
        "type": "code",
        "location": "/tests/unittest_cv2_rectangle.py:1-16"
    },
    "1891": {
        "file_id": 185,
        "content": "This code imports necessary libraries, defines a function to create a black image of given dimensions, creates a black image, draws a rectangle on it with white color, displays the image, and waits for any key press before exiting.",
        "type": "comment"
    },
    "1892": {
        "file_id": 186,
        "content": "/tests/unittest_full_text_search_peewee_sqlite.py",
        "type": "filepath"
    },
    "1893": {
        "file_id": 186,
        "content": "The code imports modules and sets up a SQLite database for full-text search. It defines a model class, populates the table with data, adds/updates a video, searches \"python world\" using BM25 algorithm, limits results to 2, and prints each result. Debugging breakpoints are included.",
        "type": "summary"
    },
    "1894": {
        "file_id": 186,
        "content": "from peewee import *\nfrom playhouse.sqlite_ext import SqliteExtDatabase, FTSModel, SearchField, RowIDField\ndb_path = \"test_fulltext_search.db\"\ndb = SqliteExtDatabase(\n    db_path, pragmas={\"journal_mode\": \"wal\", \"cache_size\": -1024 * 64}\n)\nclass BilibiliVideoIndex(FTSModel):\n    rowid = RowIDField()  # this does not support\n    title = SearchField()\n    content = SearchField()\n    class Meta:\n        database = None  # that's good.\n        options = {\"tokenize\": \"porter\"}  # you need manually separate some\ndb.create_tables([BilibiliVideoIndex])\nimport uuid\nrandomContent = lambda: str(uuid.uuid4())\nobject, flag = BilibiliVideoIndex.get_and_update_or_create(\n    rowid=1, title=randomContent(), content=randomContent(), _unique_keys=[\"rowid\"]\n)\nBilibiliVideoIndex.get_and_update_or_create(\n    rowid=2,\n    title=\"hello world\",\n    content=\"learn python the hard way\",\n    _unique_keys=[\"rowid\"],\n)\nBilibiliVideoIndex.get_and_update_or_create(\n    rowid=3,\n    title=\"hello world\",\n    content=\"learn python the hard way\",\n    _unique_keys=[\"rowid\"],",
        "type": "code",
        "location": "/tests/unittest_full_text_search_peewee_sqlite.py:1-42"
    },
    "1895": {
        "file_id": 186,
        "content": "This code imports necessary modules and sets up a SQLite database with full-text search capabilities. It defines a model class, BilibiliVideoIndex, and creates its corresponding table in the database. Using the get_and_update_or_create method, it populates the table with data for three records, ensuring uniqueness based on the rowid field.",
        "type": "comment"
    },
    "1896": {
        "file_id": 186,
        "content": ")\nBilibiliVideoIndex.get_and_update_or_create(\n    rowid=4,\n    title=\"hello world\",\n    content=\"learn python the hard way\",\n    _unique_keys=[\"rowid\"],\n)\nprint(object)\nprint(flag)\nprint(object.rowid, object.title, object.content)\n# don't know what magic is inside. whatever.\n# updated. my lord.\n# now search for it.\nterm = \"python world\"\nresults = BilibiliVideoIndex.search_bm25(term).limit(2)  # just how many?\n# breakpoint()\n# it does have the limit.\n# it is ordered.\nfor result in results:\n    print(\"RESULT\", result)\n    breakpoint()",
        "type": "code",
        "location": "/tests/unittest_full_text_search_peewee_sqlite.py:43-68"
    },
    "1897": {
        "file_id": 186,
        "content": "Code adds a video to BilibiliVideoIndex, updates it, and searches for \"python world\" using BM25 algorithm. Limits search results to 2, then prints each result. Breakpoints inserted for debugging.",
        "type": "comment"
    },
    "1898": {
        "file_id": 187,
        "content": "/tests/unittest_convolution_bilibili_translate_text_detect.py",
        "type": "filepath"
    },
    "1899": {
        "file_id": 187,
        "content": "This code imports libraries, defines image and video processing functions, reads a JSON file, applies these functions to create the final image, processes bounding boxes, creates rectangles, blurs, visualizes, and displays images while waiting for key presses.",
        "type": "summary"
    }
}