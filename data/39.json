{
    "3900": {
        "file_id": 488,
        "content": "    with torch.no_grad():\n        # outputs = ds_engine.module.generate(inputs, synced_gpus=True)\n        while True:\n            try:\n                gen_tokens = ds_engine.module.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"zh\"),synced_gpus=True,do_sample=True).cpu() # whatever. no too heavy lifting.\n                # gen_tokens = ds_engine.module.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"zh\"),synced_gpus=True,do_sample=True,top_k=0,num_beams=8,num_return_sequences=1,no_repeat_ngram_size=2,temperature=1.4).cpu() # whatever.\n                # gen_tokens = ds_engine.module.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"zh\"),synced_gpus=True,do_sample=True,top_k=0,top_p=0.92,num_beams=5,num_return_sequences=5,no_repeat_ngram_size=2,temperature=0.7).cpu() # whatever.\n                break\n            except:\n                import traceback\n                traceback.print_exc()\n                breakpoint() # translate speed is slow as hell. must do some summarization. or you cover them all.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/functional_dl_translator_1b_deepspeed.py:176-187"
    },
    "3901": {
        "file_id": 488,
        "content": "This code uses deepspeed engine to generate translated text using a model. It employs different generate() calls with varying parameters (top_k, top_p, num_beams) in a while loop, likely for experimentation purposes. The loop continues until a successful generation is achieved without any exceptions or until a breakpoint is hit, and it handles exceptions by printing the traceback and breaking out of the loop.",
        "type": "comment"
    },
    "3902": {
        "file_id": 488,
        "content": "                # you may do this for pictures.\n    # text_out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(\"TRANSLATED:\")\n    return tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n# print(get_response(\"你吃饭了没有\"))\n# print(\"PROMPT READY.\")\n# print(\"type exit to exit.\")\n# while True:\n#     targetSentence = input(\"\\nprompt>\")\n#     if \"exit\" not in targetSentence:\n#         result = get_response(targetSentence)\n#         print(result) # this is goddamly working. fuck!\n#     else:\n#         break\n# import time\n# values = []\n# for _ in range(3):\n#     a = time.time()\n#     translate_once()\n#     b = time.time()\n#     value = b-a\n#     # value = timeit.timeit(stmt=\"translate_once()\")\n#     print(\"TIME COST: {}\".format(value))\n#     values.append(value)\n# print(\"TOTAL COST:\",values)\n# print(\"AVERAGE COST:\",sum(values)/len(values))\n# stuck at the end.\n# TOTAL COST: [6.2853310108184814, 4.705244541168213, 4.688654661178589]\n# AVERAGE COST: 5.226410071055095\n# better not to use swap.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/functional_dl_translator_1b_deepspeed.py:188-220"
    },
    "3903": {
        "file_id": 488,
        "content": "This code is a functional implementation of a DL translator, likely for Chinese to English translation. It takes user input in the form of text and returns the translated output. The code includes batch decoding of tokenizer outputs and handles user input within a while loop. It also measures the time cost and average cost per iteration of the function.",
        "type": "comment"
    },
    "3904": {
        "file_id": 489,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py",
        "type": "filepath"
    },
    "3905": {
        "file_id": 489,
        "content": "The code uses video processing libraries to read a source video, apply Chinese translation and color reduction to frames, save the processed frames in a dictionary, write JSON result to file, and finally saves the final video with h.264 codec.",
        "type": "summary"
    },
    "3906": {
        "file_id": 489,
        "content": "from functional_redraw_chinese_text_offline2 import redraw_english_to_chinese2\nimport cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_json = \"japan_day.json\"\noutput_video = \"japan_day_change_color3.mp4\"\nimport os\nif os.path.exists(output_video): os.remove(output_video)\n# OOM for local translation!\n# this will not work. fucking shit. though ocr is speedy.\n# in this we will get no audio.\n# use ffmpeg and time strencher.\n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\nfourcc = cv2.VideoWriter_fourcc(*'H264') # h.264 # this will fail.\n# fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264\nvideo_writer = cv2.VideoWriter(output_video,fourcc,fps,frame_size)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:1-32"
    },
    "3907": {
        "file_id": 489,
        "content": "This code imports the necessary modules and sets up variables for video processing. It removes any existing output file, initializes a VideoCapture object to read the source video, determines the video's FPS, frame size, and total frames count, and creates a VideoWriter object with h.264 codec for the output video file.",
        "type": "comment"
    },
    "3908": {
        "file_id": 489,
        "content": "# frame_index_counter = 0\n# this is determinism.\n# or you could use framedifference? come on...\n# while True:\nimport json\nmjson_result = open(output_json, 'r',encoding='utf8').read()\nmjson_result = json.loads(mjson_result)\nimport copy\n# use some tweening? pytweening?\n# from test_curve_converter import curve_converter\n    # for index, (orig, target) in enumerate(curve_function):\n    #     if value <= orig:\n    #         forig,ftarget = curve_function[index+1]\n    #         if value == orig: return target\n    #         elif value <=forig:\n    #             if value ==forig: return ftarget\n    #             else:\n    #                 loc = (value-orig)/(forig-orig)\n    #                 new_diff = loc*(ftarget-target)\n    #                 new_value = target+new_diff\n    #                 return new_value\n    # return curve_function[-1][1]\n# def remove_much_red(image,curve_function):\n#     target = copy.copy(image[:,:,2])\n#     target = curve_converter(target,curve_function)\n#     image[:,:,2] = target\n#     return image",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:34-62"
    },
    "3909": {
        "file_id": 489,
        "content": "Code imports json and copy libraries, reads a JSON file and converts its contents. It defines a function for curve conversion and a potential function for removing excessive red from an image.",
        "type": "comment"
    },
    "3910": {
        "file_id": 489,
        "content": "def remove_much_red_with_rate(image,reduce_rate = 0.8):\n    target = copy.copy(image[:,:,2])\n    target = target*(1-reduce_rate)\n    image[:,:,2] = target\n    return image\n# curve_function = [[0,0],[40,30],[100,50],[150,100],[255,130]]\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?\n    success, frame = video_cap.read() # let's just use 1, no frame skip.\n    if not success: break\n    # print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file\n    string_frame_index_counter = str(frame_index_counter)  #inpainting is still slow somehow. freaking shit. though i have the freaking shit.\n    # maybe you can improvise.\n    # this is done purely in CPU.\n    processed_frame_data = mjson_result[string_frame_index_counter]# fucking string key.\n    processed_frame = redraw_english_to_chinese2(frame,processed_frame_data) # step 1\n    processed_frame = remove_much_red_with_rate(processed_frame)\n    # mjson_result.update({frame_index_counter:processed_frame_data})",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:64-83"
    },
    "3911": {
        "file_id": 489,
        "content": "The code reads a video frame by frame and applies two transformations: redrawing English to Chinese (step 1) and reducing the intensity of red color with a certain rate. The progress bar indicates the processing progress, and the processed frames are stored in a dictionary using frame index as the key.",
        "type": "comment"
    },
    "3912": {
        "file_id": 489,
        "content": "    video_writer.write(processed_frame) # what frame?\n    # frame_index_counter+=1\n    # cv2.imshow(\"image\",processed_frame) #\n    # # cv2.waitKey(1) # not wait infinitely.\n    # if cv2.waitKey(20) == ord('q'):\n    #     break\n# with open(output_json,\"w+\",encoding=\"utf-8\") as f:\n#     data = json.dumps(mjson_result,indent=4)\n#     f.write(data)\n# cv2.close\nprint(\"VIDEO DONE. SAVED AT:\",output_video)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:84-95"
    },
    "3913": {
        "file_id": 489,
        "content": "This code writes the processed frame to the video, increments the frame index counter, displays the processed frame using OpenCV's imshow function, waits for a 'q' key press to break the loop, and finally writes the JSON result data to the file. The video is then saved at the specified output_video location.",
        "type": "comment"
    },
    "3914": {
        "file_id": 490,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py",
        "type": "filepath"
    },
    "3915": {
        "file_id": 490,
        "content": "The code translates text, applies color correction, and processes frames from a video using ffmpeg and OpenCV for display and waiting for user input.",
        "type": "summary"
    },
    "3916": {
        "file_id": 490,
        "content": "from functional_redraw_chinese_text_offline2 import redraw_english_to_chinese2\nimport cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_json = \"japan_day.json\"\noutput_video = \"japan_day_change_color2.mp4\"\nimport os\nif os.path.exists(output_video): os.remove(output_video)\n# OOM for local translation!\n# this will not work. fucking shit. though ocr is speedy.\n# in this we will get no audio.\n# use ffmpeg and time strencher.\n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n# fourcc = cv2.VideoWriter_fourcc(*'H264') # h.264\n# fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264 \n# this is builtin ffmpeg. not external shits.\n# video_writer = cv2.VideoWriter(output_video,fourcc,fps,frame_size)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:1-33"
    },
    "3917": {
        "file_id": 490,
        "content": "The code is preparing to process a video file frame by frame for translation. It imports necessary libraries, checks if the output video exists and deletes it, obtains video properties, and sets up variables for further processing. The code also comments on possible issues and suggests using ffmpeg for audio and video processing.",
        "type": "comment"
    },
    "3918": {
        "file_id": 490,
        "content": "# frame_index_counter = 0\n# this is determinism.\n# or you could use framedifference? come on...\n# while True:\nimport json\nmjson_result = open(output_json, 'r',encoding='utf8').read()\nmjson_result = json.loads(mjson_result)\nimport copy\n# use some tweening? pytweening?\nfrom test_curve_converter import curve_converter\n    # for index, (orig, target) in enumerate(curve_function):\n    #     if value <= orig:\n    #         forig,ftarget = curve_function[index+1]\n    #         if value == orig: return target\n    #         elif value <=forig:\n    #             if value ==forig: return ftarget\n    #             else:\n    #                 loc = (value-orig)/(forig-orig)\n    #                 new_diff = loc*(ftarget-target)\n    #                 new_value = target+new_diff\n    #                 return new_value\n    # return curve_function[-1][1]\ndef remove_much_red(image,curve_function):\n    target = copy.copy(image[:,:,2])\n    target = curve_converter(target,curve_function)\n    image[:,:,2] = target\n    return image\ndef remove_much_red_with_rate(image,reduce_rate = 0.8):",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:35-65"
    },
    "3919": {
        "file_id": 490,
        "content": "The code defines a function, `remove_much_red`, which takes an image and curve function as parameters. It applies the given curve function to the red channel of the image, effectively reducing the intensity of red colors. The code also includes another function, `remove_much_red_with_rate`, that allows for adjusting the reduction rate of red colors in images. Both functions modify the image by changing the values of its red channel based on a given curve function or reduction rate.",
        "type": "comment"
    },
    "3920": {
        "file_id": 490,
        "content": "    target = copy.copy(image[:,:,2])\n    target = target*(1-reduce_rate)\n    image[:,:,2] = target\n    return image\ncurve_function = [[0,0],[40,30],[100,50],[150,100],[255,130]]\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?\n    success, frame = video_cap.read() # let's just use 1, no frame skip.\n    if not success: break\n    # print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file\n    string_frame_index_counter = str(frame_index_counter)  #inpainting is still slow somehow. freaking shit. though i have the freaking shit.\n    # maybe you can improvise.\n    # this is done purely in CPU.\n    processed_frame_data = mjson_result[string_frame_index_counter]# fucking string key.\n    processed_frame = redraw_english_to_chinese2(frame,processed_frame_data) # step 1\n    processed_frame = remove_much_red(processed_frame,curve_function)\n    # mjson_result.update({frame_index_counter:processed_frame_data})\n    # video_writer.write(processed_frame) # what frame?",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:66-85"
    },
    "3921": {
        "file_id": 490,
        "content": "The code reads frames from a video and applies color correction using a curve function. It also translates text on the frames and processes them. The progress bar shows the current frame being processed, and if a frame can't be read, the loop breaks. Finally, the processed frames are saved to an output file.",
        "type": "comment"
    },
    "3922": {
        "file_id": 490,
        "content": "    # frame_index_counter+=1\n    cv2.imshow(\"image\",processed_frame) #\n    # # cv2.waitKey(1) # not wait infinitely.\n    if cv2.waitKey(20) == ord('q'):\n        break\n# with open(output_json,\"w+\",encoding=\"utf-8\") as f:\n#     data = json.dumps(mjson_result,indent=4)\n#     f.write(data)\n# cv2.close\nprint(\"VIDEO DONE. SAVED AT:\",output_video)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:87-96"
    },
    "3923": {
        "file_id": 490,
        "content": "This code displays a processed frame on the screen, waits for 20 milliseconds for input to break the loop, and saves the final video. It uses OpenCV to display frames and wait for user input to stop the process.",
        "type": "comment"
    },
    "3924": {
        "file_id": 491,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor.py",
        "type": "filepath"
    },
    "3925": {
        "file_id": 491,
        "content": "This code reads frames from a video, translates each frame using the redraw_english_to_chinese function, updates a dictionary with frame data, and saves the processed frames to an output JSON file. The process stops when no more frames can be read or if 'q' is pressed.",
        "type": "summary"
    },
    "3926": {
        "file_id": 491,
        "content": "import cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_json = \"japan_day.json\"\n# output_video = \"japan_day_translated.mp4\"\n# OOM for local translation!\n# in this we will get no audio.\n# use ffmpeg and time strencher.\nfrom functional_redraw_chinese_text_offline import redraw_english_to_chinese\n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\nfourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264\n# video_writer =cv2.VideoWriter(output_video,fourcc,fps,frame_size)\n# frame_index_counter = 0\n# this is determinism.\n# or you could use framedifference? come on...\n# while True:\nimport json\nmjson_result = {}\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor.py:1-34"
    },
    "3927": {
        "file_id": 491,
        "content": "The code is reading a video file, extracting frame-by-frame information including FPS, frame width, height, and the total number of frames. It initializes variables for output JSON result and a potential output video (currently commented out). The code uses progress bar to iterate through each frame, but the actual translation process is missing from the given code snippet. The original task seems to be long and might require a lot of computation resources.",
        "type": "comment"
    },
    "3928": {
        "file_id": 491,
        "content": "    success, frame = video_cap.read() # let's just use 1, no frame skip.\n    if not success: break\n    print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file\n    processed_frame_data= redraw_english_to_chinese(frame) # step 1\n    mjson_result.update({frame_index_counter:processed_frame_data})\n    # video_writer.write(processed_frame) # what frame?\n    # frame_index_counter+=1\n    # if cv2.waitKey(20) == ord('q'):\n        # break\nwith open(output_json,\"w+\",encoding=\"utf-8\") as f:\n    data = json.dumps(mjson_result,indent=4)\n    f.write(data)\nprint(\"VIDEO DONE ANALYSING. SAVED AT:\",output_json)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor.py:35-48"
    },
    "3929": {
        "file_id": 491,
        "content": "This code reads frames from a video, processes one frame at a time by translating it using the redraw_english_to_chinese function, updates a dictionary with frame data, and saves the processed frames to an output JSON file. The process stops when no more frames can be read or if 'q' is pressed.",
        "type": "comment"
    },
    "3930": {
        "file_id": 492,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_iterator_copy.py",
        "type": "filepath"
    },
    "3931": {
        "file_id": 492,
        "content": "This code reads video frames, prints their indices, and writes them to an output file using video_writer. It tracks progress with a progress bar and checks for keypresses to exit. Upon completion, it displays the saved location as VIDEO DONE message.",
        "type": "summary"
    },
    "3932": {
        "file_id": 492,
        "content": "import cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_video = \"japan_day_copy.mp4\"\n# in this we will get no audio.\n# use ffmpeg and time strencher.\n# from functional_redraw_chinese_text_offline import \n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\nfourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264\nvideo_writer =cv2.VideoWriter(output_video,fourcc,fps,frame_size)\n# frame_index_counter = 0\n# while True:\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?\n    success, frame = video_cap.read()\n    if not success: break\n    print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_iterator_copy.py:1-31"
    },
    "3933": {
        "file_id": 492,
        "content": "This code reads a video file, gets its frame properties like FPS and dimensions, creates an output video file with the same format, then iterates through each frame of the input video, printing its index while processing it. It uses a progress bar for tracking frame index in a loop, but there's a potential issue with the usage of the range function (the video might not have that many frames). Finally, it writes each processed frame to the output file.",
        "type": "comment"
    },
    "3934": {
        "file_id": 492,
        "content": "    video_writer.write(frame) # what frame?\n    # frame_index_counter+=1\n    # if cv2.waitKey(20) == ord('q'):\n        # break\nprint(\"VIDEO DONE. SAVED AT:\",output_video)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_iterator_copy.py:32-36"
    },
    "3935": {
        "file_id": 492,
        "content": "Writes frames to video file using video_writer, counts frame index, checks for keypress to exit. VIDEO DONE message with saved location output_video.",
        "type": "comment"
    },
    "3936": {
        "file_id": 493,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/create_output.sh",
        "type": "filepath"
    },
    "3937": {
        "file_id": 493,
        "content": "This code utilizes FFmpeg to merge webm video with subtitle files, trimming and styling as needed. It provides links for similar tasks, and seeks PlayResX, PlayResY, and ssa subtitle coordinates.",
        "type": "summary"
    },
    "3938": {
        "file_id": 493,
        "content": "ffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Scientists Discovered a Bubble Around Our Solar System! [At7ORzmAaT4].webm\"  -vf \"subtitles=zh_translated.srt:force_style='MarginV=60',subtitles=en_.srt:force_style='Fontsize=10,PrimaryColour=&H00FFFF00,Alignment=6,MarginV=228'\" scientists_bubbles.mp4\n# ffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Scientists Discovered a Bubble Around Our Solar System! [At7ORzmAaT4].webm\" -ss 00:00:07 -to 00:01:00  -vf \"subtitles=zh_translated.srt:force_style='MarginV=60',subtitles=en_.srt:force_style='Fontsize=10,PrimaryColour=&H00FFFF00,Alignment=6,MarginV=228'\" scientists_bubbles.mp4\n# https://www.zhihu.com/question/20779091\n# https://www.jianshu.com/p/cfdbfdc6d3a7\n# https://fileformats.fandom.com/wiki/SubStation_Alpha#Style_overrides\n# PlayResX: 384\n# PlayResY: 288\n# 384×288是标准的4：3画面分辨率之一。ssa字幕里的坐标（字幕的位置）即根据这2个数值的范围来定义。\n# ffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Scientists Discovered a Bubble Around Our Solar System! [At7ORzmAaT4].webm\" -ss",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/create_output.sh:1-9"
    },
    "3939": {
        "file_id": 493,
        "content": "The code uses FFmpeg to combine a webm video with two subtitle files, creating an mp4 output. It also trims the video for a specific duration and applies style overrides for subtitles. The provided links are for reference material on similar tasks. The final part of the code seeks information about PlayResX and PlayResY, along with ssa subtitle coordinates.",
        "type": "comment"
    },
    "3940": {
        "file_id": 493,
        "content": " 00:00:07 -to 00:01:00  -vf \"subtitles=zh_translated.srt:force_style='MarginV=0',subtitles=en_.srt\" scientists_bubbles.mp4",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/create_output.sh:9-9"
    },
    "3941": {
        "file_id": 493,
        "content": "Applying subtitles to a video.",
        "type": "comment"
    },
    "3942": {
        "file_id": 494,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/commons.py",
        "type": "filepath"
    },
    "3943": {
        "file_id": 494,
        "content": "This code defines `jsonWalk` and `jsonLocate` functions that recursively traverse JSON objects, handling dictionaries, lists, tuples, and raising exceptions for non-JSON types. It also updates json's dictionary with new \"walk\" and \"locate\" functions.",
        "type": "summary"
    },
    "3944": {
        "file_id": 494,
        "content": "import json\ndef jsonWalk(jsonObj,location=[]):\n    # this is not tuple. better convert it first?\n    # mlocation = copy.deepcopy(location)\n    if type(jsonObj) == dict:\n        for key in jsonObj:\n            content = jsonObj[key]\n            if type(content) not in [dict,list,tuple]: \n                yield location+[key], content\n            else:\n                # you really ok with this?\n                for mkey, mcontent in jsonWalk(content,location+[key]):\n                    yield mkey, mcontent\n    elif type(jsonObj) in [list,tuple]:\n        for key,content in enumerate(jsonObj):\n        # content = jsonObj[key]\n            if type(content) not in [dict,list,tuple]:\n                yield location+[key], content\n            else:\n                for mkey, mcontent in jsonWalk(content,location+[key]):\n                    yield mkey, mcontent\n    else:\n        raise Exception(\"Not a JSON compatible object: {}\".format(type(jsonObj)))\ndef jsonLocate(jsonObj,location=[]):\n    # print(\"object:\",jsonObj)\n    # print(\"location:\",location)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/commons.py:1-29"
    },
    "3945": {
        "file_id": 494,
        "content": "This code defines two functions, `jsonWalk` and `jsonLocate`, which recursively traverse a JSON object and yield the location and value of each item. It handles dictionaries, lists, and tuples while raising an exception for non-JSON compatible types.",
        "type": "comment"
    },
    "3946": {
        "file_id": 494,
        "content": "    if location!=[]:\n        return jsonLocate(jsonObj[location[0]],location[1:])\n    return jsonObj\njson.__dict__.update({\"walk\":jsonWalk,\"locate\":jsonLocate})\ndef list_startswith(a,b):\n    value = 0\n    if len(a) < len(b): return False\n    for i,v in enumerate(b):\n        v0 = a[i]\n        if v == v0:\n            value +=1\n    return value == len(b)\ndef list_endswith(a,b):\n    value = 0\n    if len(a) < len(b): return False\n    c = a[-len(b):]\n    for i,v in enumerate(b):\n        v0 = c[i]\n        if v == v0:\n            value +=1\n    return value == len(b)\n# list.__dict__.update({\"startswith\": list_startswith,\"endswith\": list_endswith})",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/commons.py:30-57"
    },
    "3947": {
        "file_id": 494,
        "content": "The code contains functions for checking if a list starts or ends with another list, but they are not added to the list class. It also updates json's dictionary with \"walk\" and \"locate\" functions.",
        "type": "comment"
    },
    "3948": {
        "file_id": 495,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test2.py",
        "type": "filepath"
    },
    "3949": {
        "file_id": 495,
        "content": "The code imports the os module and defines two commands - one to install yt-dlp using pip3, another to download subtitles from a YouTube video with yt-dlp. It then iterates over each command in the list and runs them using os.system(). This will result in yt-dlp being installed and the subtitles being downloaded for the specified YouTube video.",
        "type": "summary"
    },
    "3950": {
        "file_id": 495,
        "content": "import os\ncommands = [\"pip3 install yt-dlp\",'yt-dlp --write-subs --convert-subtitles srt \"https://m.youtube.com/watch?v=At7ORzmAaT4\"'] # get recommendation this time.\n# we will still get many videoId from curl.\nfor c in commands:\n    os.system(c)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test2.py:1-8"
    },
    "3951": {
        "file_id": 495,
        "content": "The code imports the os module and defines two commands - one to install yt-dlp using pip3, another to download subtitles from a YouTube video with yt-dlp. It then iterates over each command in the list and runs them using os.system(). This will result in yt-dlp being installed and the subtitles being downloaded for the specified YouTube video.",
        "type": "comment"
    },
    "3952": {
        "file_id": 496,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test.py",
        "type": "filepath"
    },
    "3953": {
        "file_id": 496,
        "content": "Code installs yt-dlp and downloads subtitles from a YouTube video, then converts them to SRT format. Optionally, it also enables sponsorblock-mark for highlighting ad breaks in the output.",
        "type": "summary"
    },
    "3954": {
        "file_id": 496,
        "content": "import os\ncommands = [\"pip3 install yt-dlp\",'yt-dlp --write-subs --convert-subtitles srt  \"https://m.youtube.com/watch?v=At7ORzmAaT4\"']\n# commands = [\"pip3 install yt-dlp\",'yt-dlp --write-subs --convert-subtitles srt --sponsorblock-mark poi_highlight \"https://m.youtube.com/watch?v=At7ORzmAaT4\"']\n# this will mark the highlights.\nfor c in commands:\n    os.system(c)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/test.py:1-8"
    },
    "3955": {
        "file_id": 496,
        "content": "Code installs yt-dlp and downloads subtitles from a YouTube video, then converts them to SRT format. Optionally, it also enables sponsorblock-mark for highlighting ad breaks in the output.",
        "type": "comment"
    },
    "3956": {
        "file_id": 497,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/init.sh",
        "type": "filepath"
    },
    "3957": {
        "file_id": 497,
        "content": "This script initializes a Kaggle kernel, checks its status, and sets proxy environment variables to download at maximum speed.",
        "type": "summary"
    },
    "3958": {
        "file_id": 497,
        "content": "# kaggle kernels init # we have it do not fuck up again\n# code/jessysisca/some-yt-stuff \n# kaggle kernels push\nkaggle kernels status jessysisca/test-of-yt-dlp2\n# jessysisca/some-yt-stuff has status \"complete\"\n# root@alpharetta ~/android_connect_scrcpy_patch# \n# kaggle kernels status jessysisca/test-of-yt-dlp\n# jessysisca/test-of-yt-dlp has status \"running\"\n# after it is done, we pull back all shit.\n# skip all proxies.\n# export http_proxy=\"\"\n# export https_proxy=\"\"\n# kaggle kernels output jessysisca/test-of-yt-dlp2 # what is the freaking speed?\n# not too slow.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/init.sh:1-14"
    },
    "3959": {
        "file_id": 497,
        "content": "This script initializes a Kaggle kernel, checks its status, and sets proxy environment variables to download at maximum speed.",
        "type": "comment"
    },
    "3960": {
        "file_id": 498,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py",
        "type": "filepath"
    },
    "3961": {
        "file_id": 498,
        "content": "This code uses BeautifulSoup and JavaScript libraries to extract HTML data, processes it into a JSON object with view count and video length updates.",
        "type": "summary"
    },
    "3962": {
        "file_id": 498,
        "content": "target = \"curl_dump_youtube.html\"\nfrom bs4 import BeautifulSoup\n# this is m.youtube.com/watch?v={videoId}\n# import esprima\nimport js2py\nsoup = open(target,\"r\",encoding=\"utf-8\").read()\nsoup = BeautifulSoup(soup,features=\"lxml\")\nscripts = soup.find_all(\"script\")\njsfunc = lambda x: \"function f9x() { \"+x+ \"  \\n return ytInitialData;}\"\njsfunc2 = lambda x: \"function f9x() { \"+x+ \"  \\n return ytInitialPlayerResponse;}\"\n# breakpoint()\nfrom commons import *\ndata = None\ndata2 = None\nfor script in scripts:\n    content = script.string\n    if content is not None:\n        if \"var ytInitialPlayerResponse = {\" in content:\n            print(\"HAS DATA\") # only one.\n            # script_obj = esprima.parse(content)\n            script_obj = jsfunc2(content)\n            # print(script_obj)\n            obj = js2py.eval_js(script_obj)\n            # print(obj)\n            data2 = obj() # need a json walker, from pyjom.\n            # breakpoint()\n    # print(content)\nfor script in scripts:\n    content = script.string\n    if content is not None:",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:1-40"
    },
    "3963": {
        "file_id": 498,
        "content": "This code retrieves HTML from a specific target file, parses it using BeautifulSoup, and searches for scripts containing \"ytInitialData\" or \"ytInitialPlayerResponse\". It then uses JavaScript conversion libraries to extract the data from these scripts as Python objects. The data is stored in variables 'data' and 'data2', respectively.",
        "type": "comment"
    },
    "3964": {
        "file_id": 498,
        "content": "        if \"var ytInitialData = {\" in content:\n            print(\"HAS DATA\") # only one.\n            # script_obj = esprima.parse(content)\n            script_obj = jsfunc(content)\n            # print(script_obj)\n            obj = js2py.eval_js(script_obj)\n            # print(obj)\n            data = obj() # need a json walker, from pyjom.\n            # breakpoint()\n    # print(content)\n    # print(\"================================\")\n#     # breakpoint()\ndata_dict =  data.to_dict()\ndata2_dict =  data2.to_dict()\n# print(type(data))\n# breakpoint()\ntarget1 = [\"viewCountText\",\"lengthText\",\"publishedTimeText\"]\ntargets = [\"videoId\", \"simpleText\"]\ninits = ['contents', 'twoColumnWatchNextResults', 'secondaryResults', 'secondaryResults', 'results']\n# inits2 = ['contents', 'twoColumnWatchNextResults', 'secondaryResults', 'secondaryResults', 'results']\nends2 = {\"title\":['compactVideoRenderer', 'title', 'simpleText'],\"viewCountText\": ['compactVideoRenderer', 'viewCountText', 'simpleText'],\"publishTime\":['compactVideoRe",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:41-67"
    },
    "3965": {
        "file_id": 498,
        "content": "This code checks if the content contains \"var ytInitialData = {\" and then parses it using jsfunc, converts to Python object with js2py, extracts data, converts it to dictionaries, and defines some target variables.",
        "type": "comment"
    },
    "3966": {
        "file_id": 498,
        "content": "nderer', 'publishedTimeText', 'simpleText'],\"lengthText\":['compactVideoRenderer', 'lengthText', 'simpleText'],\"videoId\":['compactVideoRenderer', 'videoId']}\nvideoDetails = data2_dict[\"videoDetails\"]\nvideoDetails = {k:videoDetails[k] for k in [\"viewCount\",\"author\",\"keywords\",\"channelId\",\"shortDescription\",\"lengthSeconds\",\"videoId\",\"title\"]}\n# \"https://i.ytimg.com/vi_webp/{videoId}/maxresdefault.webp # default cover.\nvideoDicts = {}\nfor key, content in json.walk(data_dict):\n    # print(key)\n    final_key = key[-1]\n    if final_key in targets:\n        if list_startswith(key,inits):\n            for k in ends2.keys():\n                v = ends2[k]\n                if list_endswith(key,v):\n                    valueType = k\n                    value = content\n                    valueIndex = key[len(inits)]\n                    if valueIndex not in videoDicts.keys():\n                        videoDicts[valueIndex] = {}\n                    # print(valueIndex,valueType,value)\n                    videoDicts[valueIndex].update({valueType:value})",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:67-88"
    },
    "3967": {
        "file_id": 498,
        "content": "This code appears to extract specific data from a JSON object, specifically looking for keys that match certain endings and initials. The extracted data is then stored in a dictionary called \"videoDicts\" with the index as the key and the type and value of the data as the values. The purpose seems to be extracting specific information from the given JSON data, potentially for further use or processing.",
        "type": "comment"
    },
    "3968": {
        "file_id": 498,
        "content": "                    break\n        # print(key)  # i want to know the views of these.\n    # breakpoint()\ndef getViewCount(vc): return vc.replace(\",\",\"\").split(\" \")[0]\ndef getLengthSeconds(lt):\n    lt0 = lt.split(\":\")\n    assert len(lt0) <=5 # no more than week please?\n    dicIndex = {0:1,1:60,2:60*60,3:60*60*24,4:60*60*24*7}\n    seconds = 0\n    for i,v in enumerate(reversed(lt0)):\n        vn = int(v)\n        vs = vn*dicIndex[i]\n        seconds += vs\n    return str(seconds)\nfor k in videoDicts.keys():\n    v = videoDicts[k]\n    viewCount = getViewCount(v[\"viewCountText\"])\n    v.update({\"viewCount\":viewCount})\n    lengthSeconds = getLengthSeconds(v[\"lengthText\"])\n    v.update({\"lengthSeconds\":lengthSeconds})\n    print(v)\n    # for k0 in ends2.keys():\n    #     assert k0 in v.keys()\nprint(videoDetails)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/get_ytInitialData.py:89-116"
    },
    "3969": {
        "file_id": 498,
        "content": "This code iterates over the 'videoDicts' dictionary, extracting and updating the view count and video length (in seconds) for each video. The extracted information is stored as values in the dictionary with keys \"viewCount\" and \"lengthSeconds\". Finally, it prints the updated 'videoDicts' dictionary and the 'videoDetails'.",
        "type": "comment"
    },
    "3970": {
        "file_id": 499,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/download_when_complete.py",
        "type": "filepath"
    },
    "3971": {
        "file_id": 499,
        "content": "The code is using the subprocess module to periodically check the status of a Kaggle kernel. If the status is \"running\" or \"complete\", it executes a final command and sets a lock file. It continues checking until the status is one of the valid ones or an unknown status occurs, in which case it breaks the loop.",
        "type": "summary"
    },
    "3972": {
        "file_id": 499,
        "content": "import parse\nimport subprocess\nimport time\nimport os\n# import pathlib\ndownload_lock = \".kaggle_downloaded\"\nif os.path.exists(download_lock):\n    print(\"already fetched content.\")\nwait_duration = 60\nformatx = '{a} has status \"{b}\"'\nvalid_status = [\"running\",\"complete\"]\nfinal_command = \"kaggle kernels output jessysisca/test-of-yt-dlp2\"\ncmd = \"kaggle kernels status jessysisca/test-of-yt-dlp2\"\nwhile True:\n    output = subprocess.check_output(cmd.split(\" \"))\n    output = output.decode('utf-8')\n    output = output.replace('\\n',\"\").strip()\n    result = parse.parse(formatx,output)\n    rb = result['b']\n    print(\"STATUS:\",rb)\n    if rb in valid_status:\n        if rb == \"complete\":\n            print(\"DOWNLOADING OUTPUT\")\n            os.system(final_command)\n            os.system(\"touch {}\".format(download_lock))\n            break\n        else:\n            time.sleep(wait_duration)\n    else:\n        print(\"UNKNOWN STATUS. ERROR.\")\n        break",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/download_when_complete.py:1-40"
    },
    "3973": {
        "file_id": 499,
        "content": "The code is using the subprocess module to periodically check the status of a Kaggle kernel. If the status is \"running\" or \"complete\", it executes a final command and sets a lock file. It continues checking until the status is one of the valid ones or an unknown status occurs, in which case it breaks the loop.",
        "type": "comment"
    },
    "3974": {
        "file_id": 500,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/translate_srt.py",
        "type": "filepath"
    },
    "3975": {
        "file_id": 500,
        "content": "Code reads an SRT file, translates each line of the content using a web translator, wraps the translated lines to meet a certain character limit, and then saves the results in a new SRT file. The process involves parsing the input SRT file using the \"srt\" library, translating text with \"web_translator\", and modifying the line wrapping for better readability.",
        "type": "summary"
    },
    "3976": {
        "file_id": 500,
        "content": "src = \"en_.srt\"\nfinal_srt = \"zh_translated.srt\"\nimport srt\nwrap_limit = 20\nsource_srt = open(src, \"r\",encoding=\"utf-8\").read()\nssrt = srt.parse(source_srt)\nfrom web_translator import translator\nimport math\ndef wrapLine(line):\n    lines = [line[x*wrap_limit:(x+1)*wrap_limit] for x in range(math.ceil(len(line)/wrap_limit))]\n    return \"\\n\".join(lines)\ndef fixline(line):\n    notEndings = [\"。\",\"，\"]\n    for x in notEndings:\n        if line.endswith(x): return line[:-1]\n    return line\nnew_ssrt = []\nfor line in ssrt:\n    # print(line)\n    start = line.start\n    end = line.end # timedelta.\n    content = line.content\n    index = line.index\n    unwrapped_content = content.replace(\"\\n\",\" \")\n    result = translator(unwrapped_content)\n    result = fixline(result)\n    print(result)\n    line.content = result\n    new_ssrt.append(line)\n    # wrapped = wrapLine(result)\n    # print(wrapped)\n    # print(start, end, content, index)\nfinal_content = srt.compose(new_ssrt)\nwith open(final_srt,\"w+\",encoding=\"utf-8\") as f:\n    f.write(final_content)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/translate_srt.py:1-45"
    },
    "3977": {
        "file_id": 500,
        "content": "Code reads an SRT file, translates each line of the content using a web translator, wraps the translated lines to meet a certain character limit, and then saves the results in a new SRT file. The process involves parsing the input SRT file using the \"srt\" library, translating text with \"web_translator\", and modifying the line wrapping for better readability.",
        "type": "comment"
    },
    "3978": {
        "file_id": 501,
        "content": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/web_translator.py",
        "type": "filepath"
    },
    "3979": {
        "file_id": 501,
        "content": "The code defines a translator function that randomly selects from multiple translation services to convert English text to either \"zh\" or \"zh-CHS\". It uses the \"translators\" module and imports random for selecting the translation service and language. The code also allows for different combinations of translation services to be tested by uncommenting specific lines in the mtranslators list. If an error occurs during translation, it prints the exception stack trace using traceback.",
        "type": "summary"
    },
    "3980": {
        "file_id": 501,
        "content": "import translators as ts\n# translator = \n# mtranslators = [ts.sogou] #this is pure shit.\n# mtranslators = [ts.baidu,ts.sogou]\n# mtranslators = [ts.baidu,ts.sogou,ts.iciba]\nmtranslators = [ts.youdao,ts.baidu,ts.alibaba] # no yandex, tencent, sogou.\n# mtranslators = [ts.baidu,ts.iciba]\nimport random\ndef translator(text):\n    randomLang = [\"zh\",\"zh-CHS\"]\n    from_language = \"en\"\n    # lang = random.choice(randomLang)\n    while True:\n        t = random.choice(mtranslators)\n        # print(type(translator))\n        for rl in randomLang:\n            try:\n                result = t(text,from_language=from_language,to_language=rl)\n                # if len(result) < 3:\n                #     print(t)\n                #     breakpoint()\n                return result\n            except:\n                import traceback\n                traceback.print_exc()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_science_subtitle_with_cn_voice/web_translator.py:1-27"
    },
    "3981": {
        "file_id": 501,
        "content": "The code defines a translator function that randomly selects from multiple translation services to convert English text to either \"zh\" or \"zh-CHS\". It uses the \"translators\" module and imports random for selecting the translation service and language. The code also allows for different combinations of translation services to be tested by uncommenting specific lines in the mtranslators list. If an error occurs during translation, it prints the exception stack trace using traceback.",
        "type": "comment"
    },
    "3982": {
        "file_id": 502,
        "content": "/tests/bilibili_practices/bilibili_tarot/get_foreground.py",
        "type": "filepath"
    },
    "3983": {
        "file_id": 502,
        "content": "This code reads two image files, converts them to grayscale, and creates a mask where pixels with absolute difference less than 40 are set to 0 (black) and others are set to 255 (white). The resulting mask is displayed using OpenCV.",
        "type": "summary"
    },
    "3984": {
        "file_id": 502,
        "content": "background = 'tarot_pictures2/BLANK.jpg'\nforeground = 'tarot_pictures2/ACE_OF_SWORDS.jpg'\nimport cv2\nimport numpy as np\npic1 = cv2.imread(background)\npic2 = cv2.imread(foreground)\nh2,w2,c2 = pic2.shape\npic1.resize(h2,w2,c2)\n# print(pic1.shape)\n# print(pic2.shape)\npic1_b = cv2.cvtColor(pic1, cv2.COLOR_BGR2GRAY)\npic2_b = cv2.cvtColor(pic2, cv2.COLOR_BGR2GRAY)\npic3 = np.where(abs(pic1_b-pic2_b)<40, 0,255).astype(np.uint8)\ncv2.imshow(\"mask\",pic3)\ncv2.waitKey(0)\n# print(pic3)\n# print(pic1.dtype)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/get_foreground.py:1-24"
    },
    "3985": {
        "file_id": 502,
        "content": "This code reads two image files, converts them to grayscale, and creates a mask where pixels with absolute difference less than 40 are set to 0 (black) and others are set to 255 (white). The resulting mask is displayed using OpenCV.",
        "type": "comment"
    },
    "3986": {
        "file_id": 503,
        "content": "/tests/bilibili_practices/bilibili_tarot/get_figures.js",
        "type": "filepath"
    },
    "3987": {
        "file_id": 503,
        "content": "This code retrieves all \"figure\" tags from the HTML document, extracts the URLs of the first image in each figure using their \"data-src\" attribute, removes the \"@\" symbol, and replaces \"//\" with \"https://\". Finally, it logs the extracted URLs as a JSON string to the console.",
        "type": "summary"
    },
    "3988": {
        "file_id": 503,
        "content": "var figures = document.getElementsByTagName(\"figure\");\nvar mlinks = []\nfor (var fig of figures) {\n    var link = fig.getElementsByTagName(\"img\")[0].getAttribute(\"data-src\").split(\"@\")[0].replace(\"//\", \"https://\");\n    mlinks.push(link)\n}\nconsole.log(JSON.stringify(mlinks));",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/get_figures.js:1-7"
    },
    "3989": {
        "file_id": 503,
        "content": "This code retrieves all \"figure\" tags from the HTML document, extracts the URLs of the first image in each figure using their \"data-src\" attribute, removes the \"@\" symbol, and replaces \"//\" with \"https://\". Finally, it logs the extracted URLs as a JSON string to the console.",
        "type": "comment"
    },
    "3990": {
        "file_id": 504,
        "content": "/tests/bilibili_practices/bilibili_tarot/generate_typography_with_voice.py",
        "type": "filepath"
    },
    "3991": {
        "file_id": 504,
        "content": "This code sets up a drawing environment and generates typography frames by rendering text onto an image, handling wrapping and tracking position on screen. It also initializes new lists, saves screenshots, and handles different scenarios before exiting.",
        "type": "summary"
    },
    "3992": {
        "file_id": 504,
        "content": "from p5 import *\nimport os\nfrom test_common import demo_text\nos.system(\"rm screenshot*\")\ntarget_dir = \"demo_typography\"\nos.system(\"rm -rf {}\".format(target_dir))\nos.system(\"mkdir {}\".format(target_dir))\ntsize = 100\ncounterx = 0\nxcoord = 20\nycoord = 75\nscrwidth = 1920\nscrheight = 1080\nlineNum = 0\n# what fucking ever.\ns = demo_text\ns0 = [\"\"]\ndef setup():\n    size(scrwidth,scrheight)\n    text_font(create_font('./SimHei.ttf', size=tsize))\ndef draw():\n    global counterx,xcoord,ycoord,s,s0,scrheight,scrwidth,lineNum,target_dir\n    if len(s0) ==1:\n        if len(s0[0]) == 0:\n            background(0)\n    if counterx > len(s)-1:\n        exit()\n    s1 = s[counterx]\n    stemp0 = s0[-1]+s1\n    tw = text_width(stemp0)\n    th = tsize*(lineNum+1) + tsize*0.2*lineNum\n    # th = tsize*(stemp0.count(\"\\n\")+1)\n    # if (ycoord+th> scrheight):\n    #     s0 = s1\n    # else:\n    if (tw + xcoord+ tsize*0.5> scrwidth):\n        stemp0 = s1\n        s0.append(stemp0)\n        lineNum +=1\n        th = tsize*(lineNum+1) + tsize*0.2*lineNum\n        if (ycoord+th> scrheight):",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_typography_with_voice.py:1-47"
    },
    "3993": {
        "file_id": 504,
        "content": "This code sets up a drawing environment with a specified size and font, and then generates typography frames by rendering text onto an image. It handles wrapping text to multiple lines if the width is exceeded and keeps track of the number of lines and position on the screen. The code also clears any existing files named \"screenshot*\" and creates a new directory for storing the resulting images.",
        "type": "comment"
    },
    "3994": {
        "file_id": 504,
        "content": "            # stemp0 = s1\n            s0 = [stemp0]\n            background(0)\n            lineNum = 0\n    else:\n        s0[-1]= stemp0\n        # no_loop()\n        # clear\n    # s0 = stemp0\n        # end all evil.\n    counterx+=1\n    # load_font(\"SimHei.ttf\")\n    print(\"text w/h:\",tw,th)\n    # for l, text9 in enumerate(s0):\n    text9 = s0[-1][-1]\n    l = len(s0)-1\n    text(text9, (xcoord+text_width(s0[-1][:-1]), ycoord+ l*(tsize*1.2)))  # add str() to key\n    save_frame(\"{}/screenshot.png\".format(target_dir))\nrun()\nprint(\"EXITED.\")",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_typography_with_voice.py:48-69"
    },
    "3995": {
        "file_id": 504,
        "content": "The code handles different scenarios by either initializing a new list 's0' or updating the last element in 's0'. It uses variables like 'l', 'xcoord', 'ycoord', 'target_dir', 'counterx', and 'text9' to handle text placement, saving screenshots, and maintaining state. The font \"SimHei.ttf\" is loaded, and the width of each line of text is calculated using the 'text_width' function. Finally, a screenshot is saved and the script exits.",
        "type": "comment"
    },
    "3996": {
        "file_id": 505,
        "content": "/tests/bilibili_practices/bilibili_tarot/generate_typography.py",
        "type": "filepath"
    },
    "3997": {
        "file_id": 505,
        "content": "This code generates typography using Processing library in Python, handling line wrapping and text overflows, with a Chinese SimHei font, adjustable line heights, and separate line storage. It displays the typography on screen and saves screenshots until all elements are processed.",
        "type": "summary"
    },
    "3998": {
        "file_id": 505,
        "content": "from p5 import *\nimport os\nos.system(\"rm screenshot*\")\ntsize = 100\ncounterx = 0\nxcoord = 20\nycoord = 75\nscrwidth = 1920\nscrheight = 1080\nlineNum = 0\n# what fucking ever.\ns = \"[START]\"+\"SOME TEXT\"*500+\"[END]\"\ns0 = [\"\"]\ndef setup():\n    size(scrwidth,scrheight)\n    text_font(create_font('./SimHei.ttf', size=tsize))\ndef draw():\n    global counterx,xcoord,ycoord,s,s0,scrheight,scrwidth,lineNum\n    if len(s0) ==1:\n        if len(s0[0]) == 0:\n            background(0)\n    if counterx > len(s)-1:\n        exit()\n    s1 = s[counterx]\n    stemp0 = s0[-1]+s1\n    tw = text_width(stemp0)\n    th = tsize*(lineNum+1) + tsize*0.2*lineNum\n    # th = tsize*(stemp0.count(\"\\n\")+1)\n    # if (ycoord+th> scrheight):\n    #     s0 = s1\n    # else:\n    if (tw + xcoord+ tsize*0.5> scrwidth):\n        stemp0 = s1\n        s0.append(stemp0)\n        lineNum +=1\n        th = tsize*(lineNum+1) + tsize*0.2*lineNum\n        if (ycoord+th> scrheight):\n            # stemp0 = s1\n            s0 = [stemp0]\n            background(0)\n            lineNum = 0\n    else:\n        s0[-1]= stemp0",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/generate_typography.py:1-48"
    },
    "3999": {
        "file_id": 505,
        "content": "This code generates a typography using Processing (p5.js) library in Python, handling line wrapping and text overflows to fit within the specified screen width and height. It uses a Chinese SimHei font, dynamically adjusts line heights, and stores each line of text separately for easier manipulation.",
        "type": "comment"
    }
}