{
    "3600": {
        "file_id": 436,
        "content": "        max_cartesian = max(motion_vectors_filtered_cartesian_distance)\n        motion_area_ratio_array.append(motion_area_ratio)\n        # print()\n        # print(average_weighted_motion_vector)\n        # print(average_global_weighted_motion_vector)\n        # breakpoint()\n        average_weighted_motion_vector_cartesian=cartesianDistance(average_weighted_motion_vector)\n        average_weighted_motion_vector_cartesian_array.append(average_weighted_motion_vector_cartesian)\n        average_global_weighted_motion_vector_cartesian = cartesianDistance(average_global_weighted_motion_vector)\n        average_global_weighted_motion_vector_cartesian_array.append(\n        average_global_weighted_motion_vector_cartesian\n        )\n        average_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_global_weighted_motion_vectors_filtered_cartesian_distance",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:329-346"
    },
    "3601": {
        "file_id": 436,
        "content": "Calculates the average weighted motion vector and global weighted motion vector in Cartesian distance, then appends them to corresponding arrays. It also computes and appends filtered Cartesian distances of both types of vectors to their respective arrays. No print statements or breakpoints are executed.",
        "type": "comment"
    },
    "3602": {
        "file_id": 436,
        "content": "        )\n        if motion_vectors_dict_averaged != {}:\n            # breakpoint()\n            if visualize:\n                print(\"motion_area_ratio\", motion_area_ratio)\n                print(\"average_weighted_motion_vector_cartesian\", average_weighted_motion_vector_cartesian)\n                print(\n                    \"average_global_weighted_motion_vecto_cartesianr\",\n                    average_global_weighted_motion_vector_cartesian,\n                )\n                print(\n                    \"average_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                print(\n                    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_global_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                motion_mask = np.zeros(\n                    (motion_render_frame[1], motion_render_frame[0], 1)\n                )\n                for index, (x, y, w, h) in enumerate(rectangles):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:347-369"
    },
    "3603": {
        "file_id": 436,
        "content": "The code checks if there are any motion vectors in the dictionary and prints various motion-related information and creates a motion mask with zeros.",
        "type": "comment"
    },
    "3604": {
        "file_id": 436,
        "content": "                    pt1, pt2 = XYWHToDiagonal(x, y, w, h)\n                    # print(pt1, pt2)\n                    current_cartesian = motion_vectors_filtered_cartesian_distance[\n                        index\n                    ]\n                    # print(type(pt1), type(pt1[0]))\n                    relative_motion_cartesian = (current_cartesian - min_cartesian) / (\n                        max_cartesian - min_cartesian\n                    )  # must from 0 to 1 so we can plot this,\n                    # relative_motion_cartesian = 255*((current_cartesian-min_cartesian)/(max_cartesian-min_cartesian))\n                    # relative_motion_cartesian = int(relative_motion_cartesian)\n                    # relative_motion_cartesian = min(255,max(0, relative_motion_cartesian))\n                    # breakpoint()\n                    cv2.rectangle(\n                        motion_mask,\n                        pt1,\n                        pt2,\n                        color=(relative_motion_cartesian,),\n                        thickness=-1,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:370-388"
    },
    "3605": {
        "file_id": 436,
        "content": "This code calculates the relative motion vector cartesian distance and draws a rectangle on an image using OpenCV's `cv2.rectangle` function. The rectangle dimensions are based on the input x, y, w, and h parameters, and its color is determined by the relative motion vector cartesian distance, converted to a range of 0-255 for image intensity values.",
        "type": "comment"
    },
    "3606": {
        "file_id": 436,
        "content": "                    )\n                # should we gaussian blur, threshold this, do convolution and then apply bounding box on it?\n                # # visualize this.\n                if show_picture:\n                    cv2.imshow(\"motion_mask\", motion_mask)\n                    cv2.waitKey(100)\n            # may you create bounding box for this? for tracking motion? or not?\n        # breakpoint()\n    else:\n        break\n# print('max_dst_x', max_dst_x)\n# print('max_dst_y', max_dst_y)\nimport matplotlib.pyplot as plt\n# plt.style.use('dark_background')\na, b = 5, 1\nfigure, axis = plt.subplots(a, b)\ndata = [\n    motion_area_ratio_array,\n    # average_weighted_motion_vector_array,\n    # average_global_weighted_motion_vector_array,\n    average_weighted_motion_vector_cartesian_array,\n    average_global_weighted_motion_vector_cartesian_array,\n    average_weighted_motion_vectors_filtered_cartesian_distance_array,\n    average_global_weighted_motion_vectors_filtered_cartesian_distance_array,\n]\ntitles = [\n    \"motion_area_ratio\",",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:389-419"
    },
    "3607": {
        "file_id": 436,
        "content": "The code is visualizing and analyzing motion data using image processing techniques. It displays a motion mask, creates a bounding box for motion tracking, and plots various motion-related data on subplots. The code also includes options to blur, threshold, apply convolution, and display the results.",
        "type": "comment"
    },
    "3608": {
        "file_id": 436,
        "content": "    # \"average_weighted_motion_vector\",\n    # \"average_global_weighted_motion_vector\",\n    \"average_weighted_motion_vector_cartesian\",\n    \"average_global_weighted_motion_vector_cartesian\",\n    \"average_weighted_motion_vectors_filtered_cartesian_distance\",\n    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n]\n# breakpoint()\nassert len(titles) == len(data)\nassert a*b >= len(titles)\nfor _a in range(a):\n    for _b in range(b):\n        index = _a * b + _b\n        if index > len(data) - 1:\n            break\n        if a == 1:\n            if b == 1:\n                axis[0].plot(data[index])\n                axis[0].set_title(titles[index])\n            else:\n                axis[_b].plot(data[index])\n                axis[_b].set_title(titles[index])\n        elif b == 1:\n            axis[_a].plot(data[index])\n            axis[_a].set_title(titles[index])\n        else:\n            axis[_a, _b].plot(data[index])\n            axis[_a, _b].set_title(titles[index])\nplt.show()",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:420-449"
    },
    "3609": {
        "file_id": 436,
        "content": "This code is plotting multiple sets of data onto a graph, with each set corresponding to an item in two lists of titles and data. The code asserts that the lengths of both lists are equal, and then iterates through each element of the lists using nested for loops. If a single plot is desired, it plots and labels one line of data at a time. If multiple plots are desired, it creates and labels a separate plot for each line of data. Finally, it displays the graph.",
        "type": "comment"
    },
    "3610": {
        "file_id": 437,
        "content": "/tests/motion_vector_estimation/run.sh",
        "type": "filepath"
    },
    "3611": {
        "file_id": 437,
        "content": "This code runs a Docker container using lubo1994/mv-extractor image, mounting the current directory to /home/video_cap within the container and allowing X11 forwarding for graphical user interface support.",
        "type": "summary"
    },
    "3612": {
        "file_id": 437,
        "content": "#!/bin/bash\nxhost +\ndocker run \\\n    -it \\\n    --ipc=host \\\n    --env=\"DISPLAY\" \\\n    -v $(pwd):/home/video_cap \\\n    -v /tmp/.X11-unix:/tmp/.X11-unix:rw \\\n    lubo1994/mv-extractor:latest \\\n    \"$@\"",
        "type": "code",
        "location": "/tests/motion_vector_estimation/run.sh:1-12"
    },
    "3613": {
        "file_id": 437,
        "content": "This code runs a Docker container using lubo1994/mv-extractor image, mounting the current directory to /home/video_cap within the container and allowing X11 forwarding for graphical user interface support.",
        "type": "comment"
    },
    "3614": {
        "file_id": 438,
        "content": "/tests/motion_vector_estimation/test.py",
        "type": "filepath"
    },
    "3615": {
        "file_id": 438,
        "content": "The code processes video frames and estimates motion vectors, then plots the results using matplotlib and handles potential errors. It uses pandas, numpy, and OpenCV for calculations.",
        "type": "summary"
    },
    "3616": {
        "file_id": 438,
        "content": "# it contains subpixel motion vectors. fucking hell\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# change source?\n# gif containers does not have motion vectors.\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n# without mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_without_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_without_mestimate.mp4\"\n# with mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"\nsource = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nfrom mvextractor.videocap import VideoCap",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:1-25"
    },
    "3617": {
        "file_id": 438,
        "content": "This code is setting the source video file path for various test cases involving motion vector estimation. The files include different types of videos such as MP4 and GIF, with and without mestimate data, and nearly duplicate frame detection tests. It also initializes custom CV2 build and imports necessary modules.",
        "type": "comment"
    },
    "3618": {
        "file_id": 438,
        "content": "from caer.video.frames_and_fps import count_frames, get_res\nimport cv2\nframesCount = count_frames(source)\nres = get_res(source)  # (width, height)\nprint(\"RES: %s\" % str(res))\nres_x, res_y = res\nframe_common_divisor = min(res_x, res_y)\nimport math\ndef cartesianDistance(d2vector):\n    try:\n        x, y = d2vector\n        return math.sqrt(x**2 + y**2)\n    except:\n        print('item unpackable.', d2vector)\n        return 0\ndef XYWHToDiagonal(x, y, w, h):\n    return (x, y), (x + w, y + h)\n# 如果整除16那么就在这个范围里面 如果不整除范围就要扩大 扩大到相应的16的倍数\ndef get16Value(res_x):\n    rem_x = res_x % 16\n    val = res_x // 16\n    if rem_x != 0:\n        val += 1\n    return val\nx_16val = get16Value(res_x)\ny_16val = get16Value(res_y)\nmotion_render_frame = (x_16val * 16, y_16val * 16)\ntotal_block_weights = x_16val * y_16val * 2 * 2\ncap = VideoCap()\ncap.open(source)  # wtf is going on here?\n# if there is nothing we will breakup\n# visualize, show_picture = True, True\nvisualize, show_picture = False, False\n# so there can only be one such macroblock\ndef checkMacroBlock(value):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:26-75"
    },
    "3619": {
        "file_id": 438,
        "content": "This code is initializing variables and functions related to video processing. It calculates the resolution of a source, determines if it's divisible by 16, adjusts if necessary, and sets up variables for motion vector estimation and visualization. The VideoCap class is opened but its functionality remains unclear. The checkMacroBlock function checks for one macroblock value.",
        "type": "comment"
    },
    "3620": {
        "file_id": 438,
        "content": "    for mod in [16, 8]:\n        modValue = value % mod\n        if modValue == mod / 2:\n            return mod\n    # if not satisfied, we are shit.\nfrom functools import lru_cache\n@lru_cache(maxsize=4)\ndef getModXModYFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = checkMacroBlock(block_x), checkMacroBlock(block_y)\n    if mod_x is not None and mod_y is not None:\n        return mod_x, mod_y\n    else:\n        print(\"block center coordinates\", blockCenterCoordinates)\n        print(\"WTF IS GOING ON WITH THE BLOCK CENTER\")\n        breakpoint()\n        return 0, 0\ndef getRectangleXYWHFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    mod_x_half, mod_y_half = mod_x / 2, mod_y / 2\n    x, y, w, h = block_x - mod_x_half, block_y - mod_y_half, mod_x, mod_y\n    return tuple([int(elem) for elem in [x, y, w, h]])\ndef getBlockWeightFromBlockCenterCoordinates(blockCenterCoordinates):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:76-107"
    },
    "3621": {
        "file_id": 438,
        "content": "This code defines several functions for handling block center coordinates in a specific context. It checks the modulo value of the coordinates to determine the size and position of the blocks, and uses these values to calculate the rectangle's dimensions and the block weight. The `lru_cache` decorator is used to cache the results of the `getModXModYFromBlockCenterCoordinates` function to improve performance.",
        "type": "comment"
    },
    "3622": {
        "file_id": 438,
        "content": "    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    weights = mod_x * mod_y / 8 / 8\n    return weights\nimport progressbar\nimport numpy as np\n# max_dst_x, max_dst_y = 0,0\ndef averageMotionVectors(motion_vector_list):\n    if len(motion_vector_list) == 0:\n        average_tuple = (0, 0)\n    if len(motion_vector_list) > 1:\n        marray = np.array(motion_vector_list)\n        # print(\"MAKING AVERAGE:\")\n        # print(marray)\n        average = np.average(marray, axis=0)\n        # breakpoint()\n        average_tuple = tuple(average)\n    else:\n        average_tuple = tuple(motion_vector_list[0])\n    return average_tuple\nmotion_area_ratio_array = []\n# average_weighted_motion_vector_array = []\n# average_global_weighted_motion_vector_array = []\naverage_weighted_motion_vector_cartesian_array = []\naverage_global_weighted_motion_vector_cartesian_array = []\naverage_weighted_motion_vectors_filtered_cartesian_distance_array = []\naverage_global_weighted_motion_vectors_filtered_cartesian_distance_array = []",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:108-140"
    },
    "3623": {
        "file_id": 438,
        "content": "Function to calculate the average motion vectors based on a list of motion vectors. If the list is empty, returns (0, 0). If the list has more than one vector, calculates the average and returns it as a tuple. Else, returns the first vector in the list.\n\nInitializes arrays for storing average_weighted_motion_vector_cartesian, average_global_weighted_motion_vector_cartesian, average_weighted_motion_vectors_filtered_cartesian_distance, and average_global_weighted_motion_vectors_filtered_cartesian_distance.",
        "type": "comment"
    },
    "3624": {
        "file_id": 438,
        "content": "for _ in progressbar.progressbar(range(framesCount)):\n    success, frame, motion_vectors, frame_type, timestamp = cap.read()\n    height, width, channels = frame.shape\n    # breakpoint()\n    if success:\n        # what is the content of this motion vector?\n        # print(motion_vectors)\n        # import pandas as pd\n        # df = pd.DataFrame(motion_vectors)\n        # df = pd.DataFrame(motion_vectors,index=['source_index','unk0','unk1','src_x','src_y','dst_x','dst_y','motion_x','motion_y','motion_scale'])\n        # breakpoint()\n        # print()\n        # print(\"_____________________________\")\n        condition = motion_vectors[:, 0] < 0\n        # print(condition)\n        # print(condition.shape)\n        # breakpoint()\n        motion_vectors_simplified = motion_vectors[condition, :][:, [0, 5, 6, 7, 8, 9]]\n        motion_vectors_scale = motion_vectors_simplified[:, [5]]\n        motion_vectors_scale_inversed = 1 / motion_vectors_scale\n        motion_vectors_with_scale = motion_vectors_simplified[:, [3, 4]]\n        motion_vectors_scale_inversed_stacked = np.hstack(",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:142-163"
    },
    "3625": {
        "file_id": 438,
        "content": "The code reads frames and motion vectors from a video stream, processes them, and stores selected information in separate arrays. It uses pandas for data processing and numpy for array manipulation.",
        "type": "comment"
    },
    "3626": {
        "file_id": 438,
        "content": "            [motion_vectors_scale_inversed] * 2\n        )\n        motion_vectors_restored = (\n            motion_vectors_scale_inversed_stacked * motion_vectors_with_scale\n        )  # just element wise?\n        # print('STACKED:', motion_vectors_scale_inversed_stacked.shape)\n        # print(\"WITH SCALE:\", motion_vectors_with_scale.shape)\n        # print(\"RESTORED:\",motion_vectors_restored.shape)\n        # print(motion_vectors_simplified.shape)\n        # print(motion_vectors_scale.shape)\n        # breakpoint()\n        motion_vectors_dest_coords_restored = np.hstack(\n            [motion_vectors_simplified[:, [1, 2]], motion_vectors_restored]\n        )\n        # motion_vectors_simplified = motion_vectors[:,[0,5,6,7,8]]\n        # motion_vectors_simplified_unique = np.unique(motion_vectors_simplified, axis=0)\n        # print(motion_vectors_simplified_unique.shape, motion_vectors.shape)\n        # breakpoint()\n        motion_vectors_dict = {}\n        for mv in motion_vectors_dest_coords_restored:\n            # drop duplicates first!",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:164-184"
    },
    "3627": {
        "file_id": 438,
        "content": "This code segment is responsible for restoring the motion vectors after scaling and stacking. It performs element-wise multiplication of two arrays, one containing scaled motion vectors and the other being the stacked motion vectors. The result is stored in \"motion_vectors_restored\". Then, it horizontally stacks the simplified motion vector coordinates and the restored ones using numpy's hstack function, resulting in \"motion_vectors_dest_coords_restored\". Finally, a dictionary named \"motion_vectors_dict\" is initialized but not fully populated in this snippet.",
        "type": "comment"
    },
    "3628": {
        "file_id": 438,
        "content": "            (\n                dst_x,  # corresponding macro block.\n                dst_y,  # for destination only\n                motion_x,\n                motion_y,\n                # motion_scale,  # don't know what the fuck is wrong with the motion scale\n            ) = mv.tolist()\n            # say we just want source_index <0, aka mv compared to previous frame\n            # try:\n            #     assert motion_x / motion_scale == src_x - dst_x\n            #     assert motion_y / motion_scale == src_y - dst_y\n            # except:\n            #     print(src_x, dst_x, motion_x, motion_scale)\n            #     print(src_y, dst_y, motion_y, motion_scale)\n            #     print(\"*\" * 20)\n            # it will be inaccurate if we abandon this subpixel precision.\n            # if source_index >= 0:\n            #     continue\n            # if dst_x>max_dst_x:\n            #     max_dst_x = dst_x\n            # if dst_y>max_dst_y:\n            #     max_dst_y = dst_y\n            destCoord = (dst_x, dst_y)\n            motion_vector = (motion_x, motion_y)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:185-208"
    },
    "3629": {
        "file_id": 438,
        "content": "This code segment is related to motion vector estimation in video processing. It calculates the destination coordinates and motion vector for a macro block, but there seems to be an issue with the motion scale. The code tries to assert that the motion_x and motion_y are scaled correctly based on the motion_scale, but it is causing some problem.",
        "type": "comment"
    },
    "3630": {
        "file_id": 438,
        "content": "            # print(destCoord)\n            # breakpoint()\n            if motion_vector == (0, 0):\n                # print(\"zero motion vector detected. skipping\")\n                # breakpoint()\n                continue\n            # print('destination coords:',destCoord)\n            # print('motion vector:',motion_vector)\n            motion_vectors_dict.update(\n                {destCoord: motion_vectors_dict.get(destCoord, []) + [motion_vector]}\n            )\n            # you know, different frame sources may lead to different results.\n            # these vectors could overlap. which one you want to keep? the smaller ones or the bigger ones?\n            # if destCoord in destCoords:\n            #     print(\"SKIPPING DUPLICATE DESTCOORD:\", destCoord)\n            #     print(\"PREVIOUS MV\",prevMV)\n            #     print(\"CURRENT MV\", mv)\n            #     continue\n            # else:\n            #     destCoords.add(destCoord)\n            # prevMV = mv\n            # try:\n            #     # src_x, src_y may not apply the same rule.",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:209-232"
    },
    "3631": {
        "file_id": 438,
        "content": "This code checks if a motion vector is zero and skips processing if it is. It then updates a dictionary of motion vectors by adding the new motion vector to the destination coordinate, while considering potential overlaps with other motion vectors.",
        "type": "comment"
    },
    "3632": {
        "file_id": 438,
        "content": "            #     # assert src_x % 16 == 8\n            #     # assert src_y % 16 == 8\n            #     assert checkMacroBlock(dst_x) is not None\n            #     assert checkMacroBlock(dst_y) is not None\n            #     # assert dst_x<=res_x # dst_x can go beyond the res_x\n            #     # assert dst_y<=res_y\n            #     # so all rules applied.\n            # except:\n            #     # print('source',src_x, src_y)\n            #     print(\"res\", res_x, res_y)\n            #     print('destionation',dst_x, dst_y)\n            #     print('motion',motion_x, motion_y)\n            #     print(\"scale\",motion_scale)\n        motion_vectors_dict_averaged = {\n            key: averageMotionVectors(motion_vectors_dict[key])\n            for key in motion_vectors_dict.keys()\n        }\n        # assuming no duplicates?\n        weighted_motion_vectors = []\n        weights = []\n        rectangles = []\n        motion_vectors_filtered = []  # for getting data later?\n        for (\n            blockCenterCoordinates,\n            average_motion_vector,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:233-257"
    },
    "3633": {
        "file_id": 438,
        "content": "Testing macro block placement, asserting non-null checkMacroBlock results for dst_x and dst_y, asserting within res limits (dst_x <= res_x), and handling exceptions with error printing. Averages motion vectors using averageMotionVectors function. Creates weightedMotionVectors list and weights list. Initializing rectangles and motionVectorsFiltered for later use.",
        "type": "comment"
    },
    "3634": {
        "file_id": 438,
        "content": "        ) in motion_vectors_dict_averaged.items():\n            if average_motion_vector == (0, 0):\n                continue\n                # wtf is this? why fucking zero?\n                # print('skipping zero average motion vector')\n                # print(\"destination coords\", key)\n                # print('average motion vector', average_motion_vector)\n            else:\n                m_x, m_y = average_motion_vector\n                motion_vectors_filtered.append(average_motion_vector)\n                rectangle_XYWH = getRectangleXYWHFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                rectangles.append(rectangle_XYWH)\n                blockWeight = getBlockWeightFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                weights.append(blockWeight)\n                weighted_motion_vectors.append(\n                    (\n                        m_x * blockWeight / frame_common_divisor,\n                        m_y * blockWeight / frame_common_divisor,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:258-279"
    },
    "3635": {
        "file_id": 438,
        "content": "This code block is filtering and processing motion vectors from a dictionary. It skips any average motion vector that is (0, 0) and then proceeds to calculate the weighted motion vectors by multiplying the motion vector with block weight and dividing it by a frame common divisor. The resulting coordinates are stored in 'weighted_motion_vectors'.",
        "type": "comment"
    },
    "3636": {
        "file_id": 438,
        "content": "                    )\n                )\n        weighted_motion_vectors = np.array(weighted_motion_vectors)\n        sum_weighted_motion_vector = np.sum(weighted_motion_vectors, axis=0)\n        average_global_weighted_motion_vector = (\n            sum_weighted_motion_vector / total_block_weights\n        )\n        sum_weights = sum(weights)\n        average_weighted_motion_vector = sum_weighted_motion_vector / sum_weights\n        motion_area_ratio = sum_weights / total_block_weights\n        # print(motion_vectors.shape)\n        motion_vectors_filtered_cartesian_distance = [\n            cartesianDistance(vector) for vector in motion_vectors_filtered\n        ] + [\n            0\n        ]  # to avoid errors.\n        motion_vectors_filtered_cartesian_distance = np.array(\n            motion_vectors_filtered_cartesian_distance\n        )\n        cartesianWeights = weights + [0]\n        cartesianWeights = np.array(cartesianWeights)\n        cartesianWeightsSum = np.sum(cartesianWeights)\n        weighted_motion_vectors_filtered_cartesian_distance = (",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:280-304"
    },
    "3637": {
        "file_id": 438,
        "content": "This code calculates the weighted average motion vector and the average weighted motion vector for motion vectors in a block. It also determines the motion area ratio, applies cartesian distance to filtered motion vectors, and stores them with corresponding weights.",
        "type": "comment"
    },
    "3638": {
        "file_id": 438,
        "content": "            motion_vectors_filtered_cartesian_distance * cartesianWeights\n        )\n        sum_weighted_motion_vectors_filtered_cartesian_distance = np.sum(\n            weighted_motion_vectors_filtered_cartesian_distance\n        )\n        # print(\"SUM\", sum_weighted_motion_vectors_filtered_cartesian_distance)\n        # breakpoint()\n        average_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance / cartesianWeightsSum\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance\n            / total_block_weights # this is a number, not array!\n        )\n        min_cartesian = min(motion_vectors_filtered_cartesian_distance)\n        max_cartesian = max(motion_vectors_filtered_cartesian_distance)\n        motion_area_ratio_array.append(motion_area_ratio)\n        # print()\n        # print(average_weighted_motion_vector)\n        # print(average_global_weighted_motion_vector)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:305-329"
    },
    "3639": {
        "file_id": 438,
        "content": "This code calculates the average and global-weighted motion vectors for a set of motion vectors, considering their weights and distances. It also finds the minimum and maximum cartesian distance in the list and appends the motion area ratio to an array.",
        "type": "comment"
    },
    "3640": {
        "file_id": 438,
        "content": "        # breakpoint()\n        average_weighted_motion_vector_cartesian=cartesianDistance(average_weighted_motion_vector)\n        average_weighted_motion_vector_cartesian_array.append(average_weighted_motion_vector_cartesian)\n        average_global_weighted_motion_vector_cartesian = cartesianDistance(average_global_weighted_motion_vector)\n        average_global_weighted_motion_vector_cartesian_array.append(\n        average_global_weighted_motion_vector_cartesian\n        )\n        average_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_global_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        if motion_vectors_dict_averaged != {}:\n            # breakpoint()\n            if visualize:\n                print(\"motion_area_ratio\", motion_area_ratio)\n                print(\"average_weighted_motion_vector_cartesian\", average_weighted_motion_vector_cartesian)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:330-348"
    },
    "3641": {
        "file_id": 438,
        "content": "Calculates the average weighted motion vector cartesian distance, appends it to the array and does the same for global vectors. If motion_vectors_dict_averaged is not empty, prints motion_area_ratio and average_weighted_motion_vector_cartesian if visualize is True.",
        "type": "comment"
    },
    "3642": {
        "file_id": 438,
        "content": "                print(\n                    \"average_global_weighted_motion_vecto_cartesianr\",\n                    average_global_weighted_motion_vector_cartesian,\n                )\n                print(\n                    \"average_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                print(\n                    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_global_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                motion_mask = np.zeros(\n                    (motion_render_frame[1], motion_render_frame[0], 1)\n                )\n                for index, (x, y, w, h) in enumerate(rectangles):\n                    pt1, pt2 = XYWHToDiagonal(x, y, w, h)\n                    # print(pt1, pt2)\n                    current_cartesian = motion_vectors_filtered_cartesian_distance[\n                        index\n                    ]",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:349-369"
    },
    "3643": {
        "file_id": 438,
        "content": "Calculates and prints average motion vector metrics. Creates a zeroed motion mask. Iterates through rectangles to calculate the current cartesian distance.",
        "type": "comment"
    },
    "3644": {
        "file_id": 438,
        "content": "                    # print(type(pt1), type(pt1[0]))\n                    relative_motion_cartesian = (current_cartesian - min_cartesian) / (\n                        max_cartesian - min_cartesian\n                    )  # must from 0 to 1 so we can plot this,\n                    # relative_motion_cartesian = 255*((current_cartesian-min_cartesian)/(max_cartesian-min_cartesian))\n                    # relative_motion_cartesian = int(relative_motion_cartesian)\n                    # relative_motion_cartesian = min(255,max(0, relative_motion_cartesian))\n                    # breakpoint()\n                    cv2.rectangle(\n                        motion_mask,\n                        pt1,\n                        pt2,\n                        color=(relative_motion_cartesian,),\n                        thickness=-1,\n                    )\n                # should we gaussian blur, threshold this, do convolution and then apply bounding box on it?\n                # # visualize this.\n                if show_picture:\n                    cv2.imshow(\"motion_mask\", motion_mask)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:370-388"
    },
    "3645": {
        "file_id": 438,
        "content": "This code calculates the relative motion vectors for a set of points and plots them on an image using OpenCV. It converts the motion vectors to a range of 0-255, representing the pixel intensity values used in the image plotting. The resulting image is then displayed if the \"show_picture\" flag is set.",
        "type": "comment"
    },
    "3646": {
        "file_id": 438,
        "content": "                    cv2.waitKey(100)\n            # may you create bounding box for this? for tracking motion? or not?\n        # breakpoint()\n    else:\n        break\n# print('max_dst_x', max_dst_x)\n# print('max_dst_y', max_dst_y)\nimport matplotlib.pyplot as plt\n# plt.style.use('dark_background')\na, b = 5,1\nfigure, axis = plt.subplots(a, b)\ndata = [\n    motion_area_ratio_array,\n    # average_weighted_motion_vector_array,\n    # average_global_weighted_motion_vector_array,\n    average_weighted_motion_vector_cartesian_array,\n    average_global_weighted_motion_vector_cartesian_array,\n    average_weighted_motion_vectors_filtered_cartesian_distance_array,\n    average_global_weighted_motion_vectors_filtered_cartesian_distance_array,\n]\ntitles = [\n    \"motion_area_ratio\",\n    # \"average_weighted_motion_vector\",\n    # \"average_global_weighted_motion_vector\",\n    \"average_weighted_motion_vector_cartesian\",\n    \"average_global_weighted_motion_vector_cartesian\",\n    \"average_weighted_motion_vectors_filtered_cartesian_distance\",",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:389-419"
    },
    "3647": {
        "file_id": 438,
        "content": "The code imports matplotlib and creates a figure with subplots. It stores various motion vector related arrays in the \"data\" list, presumably for plotting. These arrays are likely different representations of motion vectors at each point. The code then defines titles corresponding to each array's content.",
        "type": "comment"
    },
    "3648": {
        "file_id": 438,
        "content": "    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n]\n# breakpoint()\nassert len(titles) == len(data)\nassert a*b >= len(titles)\nfor _a in range(a):\n    for _b in range(b):\n        index = _a * b + _b\n        if index > len(data) - 1:\n            break\n        if a == 1:\n            if b == 1:\n                axis[0].plot(data[index])\n                axis[0].set_title(titles[index])\n            else:\n                axis[_b].plot(data[index])\n                axis[_b].set_title(titles[index])\n        elif b == 1:\n            axis[_a].plot(data[index])\n            axis[_a].set_title(titles[index])\n        else:\n            axis[_a, _b].plot(data[index])\n            axis[_a, _b].set_title(titles[index])\nplt.show()",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:420-444"
    },
    "3649": {
        "file_id": 438,
        "content": "This code plots the data using matplotlib and sets titles for each plot based on the corresponding title from the provided list. It checks for potential errors like unequal lengths of 'titles' and 'data', and also handles cases when 'a' or 'b' is 1, adjusting the number of axes accordingly.",
        "type": "comment"
    },
    "3650": {
        "file_id": 439,
        "content": "/tests/motion_vector_estimation/test.sh",
        "type": "filepath"
    },
    "3651": {
        "file_id": 439,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "summary"
    },
    "3652": {
        "file_id": 439,
        "content": "bash ./run.sh python3.10 extract_mvs.py vid_h264.mp4 --preview --verbose",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.sh:1-1"
    },
    "3653": {
        "file_id": 439,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "comment"
    },
    "3654": {
        "file_id": 440,
        "content": "/tests/moviepy_loop_video_till_target/loop_till_target.py",
        "type": "filepath"
    },
    "3655": {
        "file_id": 440,
        "content": "This code uses ffmpeg to create a video clip with repeating segments, splitting the input video into original and reversed parts, and concatenates them based on loop strategy. It replaces sections of the input video until reaching the target duration and saves the output at specified location.",
        "type": "summary"
    },
    "3656": {
        "file_id": 440,
        "content": "import os\n# moviepy's shit.\nfrom moviepy.editor import VideoFileClip  # , concatenate_videoclips\n# import moviepy.video.fx.all as vfx\ndef main(\n    f_in: str,\n    target_secs: float,\n    f_out: str = \"\",\n    in_place: bool = True,\n    debug: bool = False,\n    # accuracy_float:int=4\n    # audio:bool=False, # it will cause trouble?\n):\n    # print(\"___\")\n    # print(\"AUDIO?\",audio)\n    # print(\"IN PLACE?\",in_place)\n    # print(\"___\")\n    assert os.path.exists(f_in)\n    assert target_secs > 0\n    # target_secs_str =(\"{\"+f':.{accuracy_float}f'+\"}\").format(target_secs)\n    targetFilePath = f_out\n    if not in_place:\n        assert f_out != \"\"\n    else:\n        targetFilePath = f_in\n    clip = VideoFileClip(f_in)\n    # if not audio:\n    #     clip = clip.without_audio()\n    # newclip = clip.fx(vfx.time_mirror) # error?\n    # newclip = clip\n    import ffmpeg\n    file_input_split = ffmpeg.input(f_in).filter_multi_output(\n        \"split\"\n    )  # this is infinite split.\n    videoDuration = clip.duration\n    import math\n    import tempfile",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:1-47"
    },
    "3657": {
        "file_id": 440,
        "content": "The code imports necessary libraries and defines a function \"main\" that takes input file, target duration, output file (optional), performs in-place editing (optional), and debug mode (optional). It asserts the existence of the input file and positive target duration. Depending on options, it either splits or mirrors the video using ffmpeg before processing.",
        "type": "comment"
    },
    "3658": {
        "file_id": 440,
        "content": "    import shutil\n    fileExtension = f_in.split(\".\")[-1]\n    assert fileExtension != \"\"\n    loopStrategy = [\n        (-1) ** i for i in range(math.ceil(target_secs / videoDuration))\n    ]  # zero division error?\n    if debug:\n        print(\"Loop strategy:\")\n        print(loopStrategy)\n    clips = []\n    file_input_original = file_input_split[0].filter_multi_output(\"split\")\n    file_input_reverse = (\n        file_input_split[1].filter(\"reverse\").filter_multi_output(\"split\")\n    )\n    for index, signal in enumerate(loopStrategy):\n        mindex = index // 2\n        if signal == 1:\n            file_input = file_input_original[mindex]\n            clips.append(file_input)\n        else:\n            file_input_reverse2 = file_input_reverse[mindex]\n            clips.append(file_input_reverse2)\n    # final = concatenate_videoclips(clips)\n    final = ffmpeg.concat(*clips)\n    finalVideoDuration = len(loopStrategy) * videoDuration\n    with tempfile.NamedTemporaryFile(\n        \"w+\",\n        suffix=f\".{fileExtension}\",\n    ) as f:",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:48-82"
    },
    "3659": {
        "file_id": 440,
        "content": "This code is creating a video clip with repeating segments. It splits the input video into two parts, original and reversed. Then, it loops through a list of loop strategies to determine which segment (original or reversed) should be used for each iteration. The final video is created by concatenating these segments together using ffmpeg. The resulting video's duration will be determined by the length of the loop strategy list multiplied by the original video's duration.",
        "type": "comment"
    },
    "3660": {
        "file_id": 440,
        "content": "        tmpFilePath = f.name\n        # warning! what is the audio shit?\n        # print(\"TMP FILE PATH?\",tmpFilePath)\n        # breakpoint()\n        # final.write_videofile(tmpFilePath, fps=clip.fps)\n        # finalVideoDuration = final.duration\n        final.output(tmpFilePath).run(overwrite_output=True)\n        shutil.copy(tmpFilePath, targetFilePath)\n    return finalVideoDuration\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-i\", \"--input\", help=\"input file\", required=True, type=str)\n    parser.add_argument(\"-o\", \"--output\", help=\"output file\", default=\"\", type=str)\n    parser.add_argument(\n        \"-r\",\n        \"--replace\",\n        help=\"replace original input file\",\n        action=\"store_true\",\n        default=False,\n    )\n    # parser.add_argument(\n    #     \"-a\",\n    #     \"--audio\",\n    #     help=\"include audio from input\",\n    #     action=\"store_true\",\n    #     default=False,\n    # )\n    parser.add_argument(\n        \"-t\", \"--target\", help=\"target seconds\", required=True, type=float",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:83-116"
    },
    "3661": {
        "file_id": 440,
        "content": "This code takes an input video file and replaces a specific section of the video with another video until a target duration is reached. The final output is saved at the specified output location.",
        "type": "comment"
    },
    "3662": {
        "file_id": 440,
        "content": "    )\n    args = parser.parse_args()\n    if not args.replace:\n        assert args.output != \"\"\n    main(\n        args.input,\n        args.target,\n        f_out=args.output,\n        in_place=args.replace,\n        # audio=args.audio\n    )",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/loop_till_target.py:117-128"
    },
    "3663": {
        "file_id": 440,
        "content": "The code initializes a parser, parses command line arguments, asserts the absence of replace flag or an output path specified, and then calls the main function with the input, target, output (if applicable), and replace (if applicable) arguments.",
        "type": "comment"
    },
    "3664": {
        "file_id": 441,
        "content": "/tests/moviepy_loop_video_till_target/test.py",
        "type": "filepath"
    },
    "3665": {
        "file_id": 441,
        "content": "This code imports the \"main\" function from the \"loop_till_target\" module and sets the target duration of the video to 20 seconds. It uses a GIF file named \"cute_cat_gif\" as input, applies the main function to it, and saves the resulting video as \"cute_cat_gif_20_secs_plus.gif\". The code also checks if the final duration of the video is greater than or equal to the target duration using an assertion statement.",
        "type": "summary"
    },
    "3666": {
        "file_id": 441,
        "content": "from loop_till_target import main\ntarget_secs = 20\nvideo_in = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif\"\n# no right codec! fuck. GIF not supported?\nvideo_out = f\"/root/Desktop/works/pyjom/samples/video/cute_cat_gif_{target_secs}_secs_plus.gif\"\nfvd = main(video_in, target_secs, f_out=video_out, in_place=False,debug=True)\nassert fvd >= target_secs",
        "type": "code",
        "location": "/tests/moviepy_loop_video_till_target/test.py:1-11"
    },
    "3667": {
        "file_id": 441,
        "content": "This code imports the \"main\" function from the \"loop_till_target\" module and sets the target duration of the video to 20 seconds. It uses a GIF file named \"cute_cat_gif\" as input, applies the main function to it, and saves the resulting video as \"cute_cat_gif_20_secs_plus.gif\". The code also checks if the final duration of the video is greater than or equal to the target duration using an assertion statement.",
        "type": "comment"
    },
    "3668": {
        "file_id": 442,
        "content": "/tests/music_analysis/bpm_tracking/test_audioowl.py",
        "type": "filepath"
    },
    "3669": {
        "file_id": 442,
        "content": "The code uses AudioOwl library to import audio file data, calculates beat times, slices beats, finds closest BPM time and selects startup beat. It then detects the closest beat time to a specified value, appends it to 'selected_beat_times' and prints this list.",
        "type": "summary"
    },
    "3670": {
        "file_id": 442,
        "content": "import matplotlib\nmatplotlib.use(\"TkAgg\")\nimport matplotlib.pyplot as plt # cannot plot shit. must change the thing.\nimport audioowl # do not install with dependencies. check it in setup.py and install latest versions.\nmyMusic = \"tarot_desc_acc_exceprt.wav\"\n# myMusic = \"/root/Desktop/works/bilibili_tarot/tarot_desc_acc.wav\"\nfrom MediaInfo import MediaInfo\ninfo = MediaInfo(filename = myMusic)\ninfo = info.getInfo()\nprint(info)\n# breakpoint()\naudioSampleRate = info[\"audioSamplingRate\"]\naudioSampleRate = int(audioSampleRate)\nwaveform = audioowl.get_waveform(myMusic,sr=audioSampleRate)\ndata = audioowl.analyze_file(myMusic,sr=audioSampleRate) # how fucking long?\n# plt.figure()\n# plt.vlines(data['beat_samples'], -1.0, 1.0)\n# plt.plot(waveform)\n# plt.show()\n# dict_keys(['sample_rate', 'duration', 'beat_samples', 'number_of_beats', 'tempo_float', 'tempo_int', 'zero_crossing', 'noisiness_median', 'noisiness_sum', 'notes', 'dominant_note'])\ndef getClosest(mlist,standard):\n    # mlist is sorted.\n    # assert mlist == list(sorted(mlist))",
        "type": "code",
        "location": "/tests/music_analysis/bpm_tracking/test_audioowl.py:1-30"
    },
    "3671": {
        "file_id": 442,
        "content": "The code imports necessary libraries, reads audio file information and waveform using AudioOwl library, stores the relevant data in a dictionary, and provides a function to find the closest element in a sorted list.",
        "type": "comment"
    },
    "3672": {
        "file_id": 442,
        "content": "    queue_list = []\n    last_elem = None\n    for elem in mlist:\n        mred = abs(elem-standard)\n        queue_list.append(mred)\n        if len(queue_list) > 2:\n            queue_list.pop(0)\n        if len(queue_list) == 2:\n            #compare now.\n            last_mred = queue_list[0]\n            if mred >= last_mred: return last_elem\n        last_elem = elem\n    return last_elem\na,b,c,d = [data[k] for k in [\"beat_samples\",\"duration\",\"sample_rate\",\"tempo_float\"]]\nprint(data)\nbreakpoint()\nsingle_bpm_time = 60/d\nbpm_times = [single_bpm_time*(2**x) for x in range(5)] #usually works.\nmin_beat_time = 2 # minimum beat skip time.\nclosest_beat_time = getClosest(bpm_times,min_beat_time)\n# breakpoint()\nmin_outro_time = 3 # must longer than the song.\n# total_samples = b*c\nbeat_times = [x/c for x in a if x <= c*(b - min_outro_time)] # no final cut.\n# so the beats are evenly sliced.\n# print(beat_times)\n# breakpoint()\nselected_beat_times = [0] # original beat. the startup.\nfor i,x in enumerate(beat_times):\n    lastBeat = selected_beat_times[-1]",
        "type": "code",
        "location": "/tests/music_analysis/bpm_tracking/test_audioowl.py:31-69"
    },
    "3673": {
        "file_id": 442,
        "content": "Calculates beat times for audio, ensures beats are evenly sliced, finds closest bpm time, selects original beat as startup.",
        "type": "comment"
    },
    "3674": {
        "file_id": 442,
        "content": "    if x <= lastBeat:\n        continue\n    ired_beat_times = beat_times[i:] # exactly what we want.\n    selectedBeat = getClosest(ired_beat_times,lastBeat+closest_beat_time)\n    selected_beat_times.append(selectedBeat)\nprint('selected beat times:')\nprint(selected_beat_times)\n# we have to check the thing.",
        "type": "code",
        "location": "/tests/music_analysis/bpm_tracking/test_audioowl.py:70-78"
    },
    "3675": {
        "file_id": 442,
        "content": "This code segment is finding the closest beat time to a specified value from a set of beat times. It continues from the last detected beat and appends the selected beat time to the 'selected_beat_times' list. Finally, it prints out the 'selected_beat_times'.",
        "type": "comment"
    },
    "3676": {
        "file_id": 443,
        "content": "/tests/music_analysis/download_exciting_bgm_with_lyric.py",
        "type": "filepath"
    },
    "3677": {
        "file_id": 443,
        "content": "The code utilizes requests to interact with an API, defines a download path based on file extension, and has functions for login, logout, registration, and downloading BGMs. It searches endpoints for song details, extracts them, downloads and saves the songs as binary files, retrieves lyrics from a local server, writes them to a file, and handles potential issues with duration or service login.",
        "type": "summary"
    },
    "3678": {
        "file_id": 443,
        "content": "get_download_path = lambda extension:\"exciting_bgm.{}\".format(extension) # is the extension right?\nimport requests\nbaseUrl = \"http://localhost:4000\"\n# now what is the port?\n# 4042\nkeywords = \"last friday night\" # american pop music?\nimport time\ndef getJSTimeStamp(): return int(time.time()*1000)\n# {'data': {'code': 200, 'account': {'id': 7935782775, 'userName': '0_fxg_pxw@163.com', 'type': 0, 'status': -10, 'whitelistAuthority': 0, 'createTime': 1657240405751, 'tokenVersion': 0, 'ban': 0, 'baoyueVersion': 0, 'donateVersion': 0, 'vipType': 0, 'anonimousUser': False, 'paidFee': False}, 'profile': None}}\n# breakpoint()\n# phone, password = \"19825089619\",\"dbH361210110\"\n# login_response = requests.get(baseUrl+\"/login/cellphone\",params={\"phone\": phone,\"password\": password})\n# login_response = requests.get(baseUrl+\"/logout\")\n# login_response_json = login_response.json()\n# print(login_response_json)\n# login_response = requests.get(baseUrl+\"/register/anonimous\")\n# login_response_json = login_response.json()\n# # {'code': -460, 'message': '网络太拥挤，请稍候再试！'}",
        "type": "code",
        "location": "/tests/music_analysis/download_exciting_bgm_with_lyric.py:1-23"
    },
    "3679": {
        "file_id": 443,
        "content": "The code defines a download path based on file extension and uses requests to interact with an API at \"http://localhost:4000\". It seems to be related to music analysis and has functions for login, logout, and registration. The API endpoints are used to verify the account and perform operations related to downloading exciting background music (BGMs) with lyrics. The code also uses time.time() function to get the current timestamp in JST format. The purpose of the code is unclear without further context or knowledge of the specific project it's part of.",
        "type": "comment"
    },
    "3680": {
        "file_id": 443,
        "content": "# # what the fuck is this shit?\n# print(login_response_json)\n# login_status = requests.get(baseUrl+\"/login/status\")\n# login_status_json = login_status.json()\n# print(login_status_json)\n# breakpoint()\nsearch_result = requests.get(baseUrl+\"/search\", params={\"keywords\": keywords, \"timestamp\":getJSTimeStamp()})\n# search_result = requests.get(baseUrl+\"/cloudsearch\", params={\"keywords\": keywords, \"timestamp\":getJSTimeStamp()})\nsearch_result_json = search_result.json() # check search_result.json\n# breakpoint()\ncode = search_result_json[\"code\"]\n# print(search_result_json)\n# breakpoint()\n# {'msg': '操作频繁，请稍候再试', 'code': 405, 'message': '操作频繁，请稍候再试'} # too frequent.\nif not code == 200:\n    print(\"ERROR CODE IN SEARCH:\", code)\n    print(search_result_json)\nelse:# no error here.\n    result = search_result_json[\"result\"]\n    songs = result[\"songs\"]\n    mySong = songs[1]\n    mySongName = mySong[\"name\"]\n    mySongId = mySong[\"id\"]\n    if \"ar\" in mySong.keys():\n        mySongArtists = mySong[\"ar\"] # reserved for further use. like find other songs by the artist.",
        "type": "code",
        "location": "/tests/music_analysis/download_exciting_bgm_with_lyric.py:24-55"
    },
    "3681": {
        "file_id": 443,
        "content": "This code makes a GET request to a search endpoint with specified keywords and timestamp. If the response code is not 200, it prints an error message along with the response JSON. Otherwise, it extracts song details from the response and assigns them to variables for further use.",
        "type": "comment"
    },
    "3682": {
        "file_id": 443,
        "content": "    elif \"artists\" in mySong.keys():\n        mySongArtists = mySong[\"artists\"]\n    else: mySongArtists = []\n    # mySong[\"artists\"]\n    print(\"SELECTED SONG:\")\n    print(mySongName, mySongId, mySongArtists)\n    # download that thing.\n    download_result = requests.get(baseUrl + \"/song/url\", params = {\"id\":mySongId}) # 试听歌曲\n    # download_result = requests.get(baseUrl + \"/song/url\", params = {\"id\":mySongId, \"timestamp\":getJSTimeStamp()}) # 试听歌曲\n    download_result_json = download_result.json()\n    print(download_result_json) # no download url!\n    # breakpoint()\n    code = download_result_json[\"code\"]\n    if code == 200: # allow to download now?\n        myDownloads = download_result_json[\"data\"]\n        myDownload = myDownloads[0]\n        myDownloadUrl = myDownload[\"url\"]\n        myDownloadType = myDownload[\"type\"]\n        # now download the thing.\n        result = requests.get(myDownloadUrl) # no need for timestamp?\n        if result.status_code == 200:\n            data = result.content\n            with open(get_download_path(myDownloadType),\"wb\") as f:",
        "type": "code",
        "location": "/tests/music_analysis/download_exciting_bgm_with_lyric.py:56-82"
    },
    "3683": {
        "file_id": 443,
        "content": "This code is checking if the song has associated artists and then prints the selected song's name, ID, and artists. It attempts to download the song's URL based on the provided parameters. If successful, it downloads the song data and saves it as a binary file using the downloaded type and path.",
        "type": "comment"
    },
    "3684": {
        "file_id": 443,
        "content": "                f.write(data)\n            print(\"DOWNLOAD SONG DONE.\") # you should check the duration of this music file.\n            # 2871154\n            lyrics_result = requests.get(\"http://localhost:4000/lyric\",{\"id\":mySongId, \"timestamp\":getJSTimeStamp()})\n            # this is cached.\n            lyrics_result_json = lyrics_result.json()\n            if lyrics_result_json[\"code\"] == 200:\n                lrc = lyrics_result_json[\"lrc\"]\n                if type(lrc) == dict:\n                    version = lrc[\"version\"]\n                    lyric = lrc[\"lyric\"]\n                    if type(lyric) == str:\n                        with open(\n                            \"exciting_bgm.lrc\",\"w\") as f0: f0.write(lyric)\n                        print(\"LYRIC DOWNLOAD DONE.\")\n            # THIS IS FREAKING WRONG... SHALL I LOGIN?\n            # Duration                                 : 30 s 41 ms",
        "type": "code",
        "location": "/tests/music_analysis/download_exciting_bgm_with_lyric.py:83-99"
    },
    "3685": {
        "file_id": 443,
        "content": "This code downloads a music file, then retrieves its lyrics from a local server. It writes the lyrics to a file named \"exciting_bgm.lrc\" and prints messages indicating when the song and lyric downloads are done. The code also includes a comment pointing out an issue, possibly with the duration of the song or logging in to a service.",
        "type": "comment"
    },
    "3686": {
        "file_id": 444,
        "content": "/tests/music_analysis/lyric_change_detector/download_lyric.sh",
        "type": "filepath"
    },
    "3687": {
        "file_id": 444,
        "content": "The code downloads a JSON file containing lyrics from an API endpoint, then extracts the lyrics using a separate script. The goal is to obtain the \"lrc\" part of the lyrics.",
        "type": "summary"
    },
    "3688": {
        "file_id": 444,
        "content": "curl -L -o some_lyrics.json http://localhost:4000/lyric?id=33894312\npython3 extract_lyrics_from_netease_json.py some_lyrics.json\n# just want the \"lrc\" part.",
        "type": "code",
        "location": "/tests/music_analysis/lyric_change_detector/download_lyric.sh:1-4"
    },
    "3689": {
        "file_id": 444,
        "content": "The code downloads a JSON file containing lyrics from an API endpoint, then extracts the lyrics using a separate script. The goal is to obtain the \"lrc\" part of the lyrics.",
        "type": "comment"
    },
    "3690": {
        "file_id": 445,
        "content": "/tests/music_analysis/lyric_change_detector/extract_lyrics_from_netease_json.py",
        "type": "filepath"
    },
    "3691": {
        "file_id": 445,
        "content": "This code reads a JSON file, checks if it ends with \".json\", and extracts the lyric content. It then writes the extracted lyric to another file with the same name but with an additional \".lrc\" extension.",
        "type": "summary"
    },
    "3692": {
        "file_id": 445,
        "content": "import json\nimport sys\njson_file = sys.argv[1]\nassert json_file.endswith(\".json\")\nwith open(json_file,\"r\", encoding=\"utf-8\") as f:\n    json_data = json.loads(f.read())\n    lrc = json_data[\"lrc\"]\n    version = lrc[\"version\"]\n    lyric = lrc[\"lyric\"]\n    with open(json_file+\".lrc\",\"w\") as f0: f0.write(lyric)",
        "type": "code",
        "location": "/tests/music_analysis/lyric_change_detector/extract_lyrics_from_netease_json.py:1-12"
    },
    "3693": {
        "file_id": 445,
        "content": "This code reads a JSON file, checks if it ends with \".json\", and extracts the lyric content. It then writes the extracted lyric to another file with the same name but with an additional \".lrc\" extension.",
        "type": "comment"
    },
    "3694": {
        "file_id": 446,
        "content": "/tests/music_analysis/lyric_change_detector/launch_lyric_api_server.sh",
        "type": "filepath"
    },
    "3695": {
        "file_id": 446,
        "content": "The code changes the directory to the NeteaseCloudMusicApi project and starts a server on port 4000 with Node.js, launching the music API server.",
        "type": "summary"
    },
    "3696": {
        "file_id": 446,
        "content": "cd ../../../externals/NeteaseCloudMusicApi\nPORT=4000 node app.js",
        "type": "code",
        "location": "/tests/music_analysis/lyric_change_detector/launch_lyric_api_server.sh:1-3"
    },
    "3697": {
        "file_id": 446,
        "content": "The code changes the directory to the NeteaseCloudMusicApi project and starts a server on port 4000 with Node.js, launching the music API server.",
        "type": "comment"
    },
    "3698": {
        "file_id": 447,
        "content": "/tests/music_analysis/lyric_change_detector/read_lyrics.py",
        "type": "filepath"
    },
    "3699": {
        "file_id": 447,
        "content": "Reading lyrics from \"some_lyrics.json.lrc\" file using pylrc library, parsing the LRC format and storing time and content for each subtitle in subs variable.",
        "type": "summary"
    }
}