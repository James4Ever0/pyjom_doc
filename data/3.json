{
    "300": {
        "file_id": 15,
        "content": "    endpoint=BEZIER_PADDLE_RESNET50_IMAGE_DOG_CAT_DETECTOR_SERVER_ENDPOINT,\n    serverHelloMessage: str = BEZIER_PADDLE_RESNET50_IMAGE_DOG_CAT_DETECTOR_SERVER_HELLO,\n    connection: redis.Redis = redis_connection,\n    lockName: str = \"bezier_paddlehub_resnet50_image_dog_cat_detector_server\",\n    timeout: float = 10,\n    expire: float = 60,\n):\n    from fastapi import FastAPI, Body\n    import numpy_serializer\n    app = FastAPI()\n    @app.get(\"/\")\n    def serverHello():\n        return serverHelloMessage\n    @app.post(\"/\" + endpoint)\n    def receiveImage(\n        image: bytes = Body(default=None),\n        isBytes: bool = False,\n        encoding: str = \"utf-8\",\n        debug: bool = False,\n        input_bias: float = 0.0830047243746045,\n        skew: float = -0.4986098769473948,\n        dog_label_file_path: str = \"/root/Desktop/works/pyjom/tests/animals_paddlehub_classification_resnet/dogs.txt\",\n        cat_label_file_path: str = \"/root/Desktop/works/pyjom/tests/animals_paddlehub_classification_resnet/cats.txt\",\n        download_timeout: int = 2,",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:713-740"
    },
    "301": {
        "file_id": 15,
        "content": "Endpoint definition for a FastAPI app with two routes: a GET endpoint to return a server hello message and a POST endpoint to receive an image. The app uses numpy_serializer, allows specifying additional parameters like debug mode, input bias, skew, and label file paths for dog and cat classification models.",
        "type": "comment"
    },
    "302": {
        "file_id": 15,
        "content": "    ):\n        detections = []  # nothing good.\n        try:\n            lock = redis_lock.Lock(connection, name=lockName, expire=expire)\n            if lock.acquire(blocking=True, timeout=timeout):\n                # return book\n                # print('image type:',type(image))\n                # print(image)\n                import urllib.parse\n                image = image.removeprefix(b\"image=\")  # fuck man.\n                image = urllib.parse.unquote_to_bytes(image)\n                if debug:\n                    print(\"isBytes:\", isBytes)\n                if not isBytes:\n                    image = image.decode(encoding)  # fuck?\n                    # read image from path, url\n                    if image.startswith(\"http\"):\n                        import requests\n                        img_bytes = requests.get(\n                            image, proxies=None, timeout=download_timeout\n                        ).content\n                        # warning! you deal with gif somehow!\n                        import tempfile",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:741-766"
    },
    "303": {
        "file_id": 15,
        "content": "Code handles image processing with Redis locking mechanism and urllib parsing. It attempts to acquire a lock, then checks if the image data is in bytes or not, decoding it accordingly. If the image URL starts with \"http\", it uses requests module to download the image content before proceeding. The code also mentions a warning about handling GIFs but the specifics are not explained.",
        "type": "comment"
    },
    "304": {
        "file_id": 15,
        "content": "                        with tempfile.NamedTemporaryFile(\"wb\", suffix=\".media\") as f:\n                            filepath = f.name\n                            f.write(img_bytes)\n                            try:\n                                image = cv2.imread(filepath)\n                                if image is None:\n                                    cap = cv2.VideoCapture(filepath)\n                                    success, image = cap.read()\n                                    if not success:\n                                        image = None\n                            except:\n                                import traceback\n                                traceback.print_exc()\n                                print(\"error while reading visual media file from web.\")\n                                print(\"source url:\", image)\n                        # nparr = np.fromstring(img_bytes, np.uint8)\n                        # image = cv2.imdecode(nparr, flags=1)\n                    elif os.path.exists(image):",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:768-786"
    },
    "305": {
        "file_id": 15,
        "content": "This code reads an image or video from a given file path. It creates a temporary file, writes the image bytes to it, and tries to read it as an image using OpenCV. If that fails, it attempts to open it with VideoCapture and read the first frame. If all else fails, it prints an error message.",
        "type": "comment"
    },
    "306": {
        "file_id": 15,
        "content": "                        image = cv2.imread(image)\n                    else:\n                        raise Exception(\n                            \"image cannot be found as url or filepath:\", image\n                        )\n                else:\n                    image = numpy_serializer.from_bytes(image)\n                if debug:\n                    print(\"shape?\", image.shape)\n                    print(\"image?\", image)\n                detections = bezierPaddleHubResnet50ImageDogCatDetectorCore(\n                    image,\n                    input_bias=input_bias,\n                    skew=skew,\n                    # threshold=0.5,\n                    dog_label_file_path=dog_label_file_path,\n                    cat_label_file_path=cat_label_file_path,\n                    debug=debug,\n                )\n                lock.release()\n                # return detections\n        except:\n            import traceback\n            traceback.print_exc()\n        if debug:\n            print(\"DETECTIONS?\")\n            print(detections)",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:787-814"
    },
    "307": {
        "file_id": 15,
        "content": "This code attempts to load an image from a specified URL or filepath. If the image cannot be found, it raises an exception. It then applies image processing and detection using the bezierPaddleHubResnet50ImageDogCatDetectorCore function, and potentially returns the detections. The code also includes optional debugging functionality to print image shape and detections for further inspection.",
        "type": "comment"
    },
    "308": {
        "file_id": 15,
        "content": "        return detections\n    import uvicorn\n    # checking: https://9to5answer.com/python-how-to-use-fastapi-and-uvicorn-run-without-blocking-the-thread\n    def run(host=\"0.0.0.0\", port=server_port):\n        \"\"\"\n        This function to run configured uvicorn server.\n        \"\"\"\n        uvicorn.run(app=app, host=host, port=port)\n    run()\ndef imageCropoutBlackArea(image, cropped_area_threshold=0.1, debug=False, crop=True):\n    image = imageLoader(image)\n    height, width = image.shape[:2]\n    total_area = height * width\n    import ffmpeg\n    # it must be a existing image.\n    from lazero.filesystem.temp import tmpfile\n    import uuid\n    path = \"/dev/shm/cropdetect_ffmpeg_black_border/{}.png\".format(str(uuid.uuid4()))\n    x, y, x1, y1 = 0, 0, width, height\n    with tmpfile(path=path) as TF:\n        mediaPath = path\n        cv2.imwrite(mediaPath, image)\n        stdout, stderr = (\n            ffmpeg.input(mediaPath, loop=1, t=1)\n            .filter(\"cropdetect\")\n            .output(\"null\", f=\"null\")\n            .run(capture_stdout=True, capture_stderr=True)",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:815-850"
    },
    "309": {
        "file_id": 15,
        "content": "This code is using the FastAPI framework along with uvicorn to run a server. It includes a function for cropping images and removing black areas, which utilizes ffmpeg and OpenCV. The function takes an image, adjusts the crop threshold, debug mode flag, and crop flag as parameters. It then loads the image using imageLoader, calculates the total area of the image, generates a temporary file path, creates a media path for the image, writes the image to the media path, runs ffmpeg to detect black areas and crops the image if necessary, and saves the result in the temporary file path. The function returns the detections made on the image.",
        "type": "comment"
    },
    "310": {
        "file_id": 15,
        "content": "        )\n        stdout_decoded = stdout.decode(\"utf-8\")\n        stderr_decoded = stderr.decode(\"utf-8\")\n        # nothing here.\n        # for line in stdout_decoded.split(\"\\n\"):\n        #     print(line)\n        # breakpoint()\n        import parse\n        common_crops = []\n        for line in stderr_decoded.split(\"\\n\"):\n            line = line.replace(\"\\n\", \"\").strip()\n            formatString = \"[{}] x1:{x1:d} x2:{x2:d} y1:{y1:d} y2:{y2:d} w:{w:d} h:{h:d} x:{x:d} y:{y:d} pts:{pts:g} t:{t:g} crop={}:{}:{}:{}\"\n            # print(line)\n            result = parse.parse(formatString, line)\n            if result is not None:\n                # print(result)\n                cropString = \"{}_{}_{}_{}\".format(\n                    *[result[key] for key in [\"w\", \"h\", \"x\", \"y\"]]\n                )\n                # print(cropString)\n                # breakpoint()\n                common_crops.append(cropString)\n            # [Parsed_cropdetect_0 @ 0x56246a16cbc0] x1:360 x2:823 y1:0 y2:657 w:464 h:656 x:360 y:2 pts:3 t:0.120000 crop=464:656:360:2",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:851-878"
    },
    "311": {
        "file_id": 15,
        "content": "The code parses stderr output, extracts crop information, and stores unique crop strings in common_crops list.",
        "type": "comment"
    },
    "312": {
        "file_id": 15,
        "content": "            # this crop usually will never change. but let's count?\n        area = 0\n        # x,x1,y,y1= 0,width, 0, height\n        if len(common_crops) > 0:\n            common_crops_count_tuple_list = [\n                (cropString, common_crops.count(cropString))\n                for cropString in set(common_crops)\n            ]\n            common_crops_count_tuple_list.sort(key=lambda x: -x[1])\n            selected_crop_string = common_crops_count_tuple_list[0][0]\n            result = parse.parse(\"{w:d}_{h:d}_{x:d}_{y:d}\", selected_crop_string)\n            w, h, x, y = [result[key] for key in [\"w\", \"h\", \"x\", \"y\"]]\n            x1, y1 = min(x + w, width), min(y + h, height)\n            if x < x1 and y < y1:\n                # allow to calculate the area.\n                area = (x1 - x) * (y1 - y)\n        cropped_area_ratio = 1 - (area / total_area)  # 0.5652352766414517\n        # use 0.1 as threshold?\n        print(\"CROPPED AREA RATIO:\", cropped_area_ratio)\n        if cropped_area_ratio > cropped_area_threshold:",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:879-900"
    },
    "313": {
        "file_id": 15,
        "content": "This code calculates the area of a common crop and determines if it should be cropped. It first counts the occurrences of each crop string in the common_crops list, then selects the most frequent one and parses its dimensions. The code checks if these dimensions overlap with the image's dimensions, calculates the area of the common crop, and computes the cropped area ratio by dividing this area with the total image area. If the cropped area ratio is greater than a threshold value, it prints the result.",
        "type": "comment"
    },
    "314": {
        "file_id": 15,
        "content": "            print(\"we need to crop this. no further processing needed\")\n            if debug:\n                image_black_cropped = image[y:y1, x:x1]\n                cv2.imshow(\"CROPPED IMAGE\", image_black_cropped)\n                cv2.waitKey(0)\n        else:\n            print(\"image no need to crop black borders. further processing needed\")\n    diagonalRect = [(x, y), (x1, y1)]\n    if crop:\n        return imageCropWithDiagonalRectangle(image, diagonalRect)\n    return diagonalRect\ndef imageCropoutBlurArea(\n    image, thresh=10, max_thresh=120, min_thresh=50, debug=False, crop=True, value=False\n):\n    import numpy\n    import BlurDetection\n    img = imageLoader(image)\n    # import sys\n    # sys.path.append(\"/root/Desktop/works/pyjom/\")\n    # from pyjom.imagetoolbox import imageFourCornersInpainting, getImageTextAreaRatio\n    # img = imageFourCornersInpainting(img)\n    # img = getImageTextAreaRatio(img, inpaint=True, edgeDetection=True)\n    img_fft, val, blurry = BlurDetection.blur_detector(img, thresh=thresh)\n    if debug:",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:901-932"
    },
    "315": {
        "file_id": 15,
        "content": "This function takes an image and checks if there are black borders that need to be cropped. If so, it crops the image using the diagonal rectangle method. It also detects blur areas in the image and performs other operations such as four corners inpainting and getting image text area ratio (if debug is set). The function returns either the cropped image or the diagonal rectangle if crop is not set.",
        "type": "comment"
    },
    "316": {
        "file_id": 15,
        "content": "        print(\"this image {0} blurry\".format([\"isn't\", \"is\"][blurry]))\n    msk, result, blurry = BlurDetection.blur_mask(\n        img, min_thresh=min_thresh, max_thresh=max_thresh\n    )\n    if value:\n        return result\n    inv_msk = 255 - msk\n    def display(title, img, max_size=200000):\n        assert isinstance(img, numpy.ndarray), \"img must be a numpy array\"\n        assert isinstance(title, str), \"title must be a string\"\n        scale = numpy.sqrt(min(1.0, float(max_size) / (img.shape[0] * img.shape[1])))\n        print(\"image is being scaled by a factor of {0}\".format(scale))\n        shape = (int(scale * img.shape[1]), int(scale * img.shape[0]))\n        img = cv2.resize(img, shape)\n        cv2.imshow(title, img)\n    # BlurDetection.scripts.display('img', img)\n    if debug:\n        display(\"img\", img)\n        # display(\"msk\", msk)\n        display(\"inv_msk\", inv_msk)\n    # BlurDetection.scripts.display('msk', msk)\n    contours, hierarchy = cv2.findContours(inv_msk, 1, 2)\n    rectangle_boundingbox = draw_bounding_box_with_contour(contours, img, debug=debug)",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:933-958"
    },
    "317": {
        "file_id": 15,
        "content": "The code performs blur detection and displays the original image, mask, and inverse mask if debug mode is enabled. It uses OpenCV to find contours in the inverse mask and then draws a bounding box around the largest contour.",
        "type": "comment"
    },
    "318": {
        "file_id": 15,
        "content": "    if crop:\n        return imageCropWithDiagonalRectangle(img, rectangle_boundingbox)\n    return rectangle_boundingbox\ndef imageHistogramMatch(image, reference, delta=0.2):\n    from color_transfer import color_transfer\n    target = imageLoader(image)\n    source = imageLoader(reference)\n    transfer = color_transfer(source, target)\n    import numpy as np\n    transfer_02 = (target * (1 - delta) + transfer * delta).astype(np.uint8)\n    return transfer_02\ndef imageDogCatDetectionForCoverExtraction(\n    image,\n    dog_or_cat: Literal[\"dog\", \"cat\"] = \"dog\",\n    area_threshold=0.08,  # min area?\n    confidence_threshold=0.85,  # this is image quality maybe.\n    y_expansion_rate=0.03,  # to make the starting point on y axis less \"headless\"\n    defaultCropWidth=1920,\n    defaultCropHeight=1080,\n    debug=False,\n    debug_show=False,\n    crop=False,\n    mod=0.8,\n):\n    # return detected most significant dog area?\n    model = configYolov5()\n    # dog_or_cat = \"dog\"\n    # Images\n    # img = '/media/root/help/pyjom/samples/image/miku_on_green.png'  # or file, Path, PIL, OpenCV, numpy, list",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:959-996"
    },
    "319": {
        "file_id": 15,
        "content": "The code defines a function for dog and cat detection and cropping for cover extraction. It uses the YOLOv5 model to detect areas with significant dog or cat presence, applies color transfer for better matching, and allows crop parameter for image processing. The function takes in an image and optional parameters such as desired area threshold, confidence threshold, expansion rate, default crop dimensions, debug mode, and crop option. It returns the detected most significant dog area.",
        "type": "comment"
    },
    "320": {
        "file_id": 15,
        "content": "    # img = \"/root/Desktop/works/pyjom/samples/image/dog_with_text.jpg\"\n    # imgPath = \"/root/Desktop/works/pyjom/samples/image/dog_blue_sky.png\"\n    imgPath = image\n    # img = cv2.imread(imgPath)\n    img = imageLoader(imgPath)\n    defaultHeight, defaultWidth = img.shape[:2]\n    total_area = defaultHeight * defaultWidth\n    # Inference\n    results = model(img)\n    # print(results)\n    # # Results\n    # breakpoint()\n    animal_detection_dataframe = results.pandas().xyxy[0]\n    # results.show()\n    # # results.print() # or .show(),\n    area = (animal_detection_dataframe[\"xmax\"] - animal_detection_dataframe[\"xmin\"]) * (\n        animal_detection_dataframe[\"ymax\"] - animal_detection_dataframe[\"ymin\"]\n    )\n    animal_detection_dataframe[\"area_ratio\"] = area / total_area\n    df = animal_detection_dataframe\n    if debug:\n        print(\"DETECTION DATAFRAME\")\n        print(df)\n    new_df = df.loc[\n        (df[\"area_ratio\"] >= area_threshold)\n        & (df[\"confidence\"] >= confidence_threshold)\n        & (df[\"name\"] == dog_or_cat)",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:997-1031"
    },
    "321": {
        "file_id": 15,
        "content": "This code reads an image and applies object detection using a pre-trained model. It extracts the detected objects' bounding boxes and calculates their areas relative to the image size. The resulting DataFrame is filtered based on area ratio, confidence threshold, and the detected object name (either dog or cat). If debugging is enabled, it prints the detection DataFrame.",
        "type": "comment"
    },
    "322": {
        "file_id": 15,
        "content": "    ].sort_values(\n        by=[\"confidence\"]\n    )  # this one is for 0.13\n    # count = new_df.count(axis=0)\n    count = len(new_df)\n    # print(\"COUNT: %d\" % count)\n    # this is just to maintain the ratio.\n    # you shall find the code elsewhere?\n    allowedHeight = min(\n        int(defaultWidth / defaultCropWidth * defaultHeight), defaultHeight\n    )\n    croppedImageCoverResized = None\n    flag = count >= 1\n    # if not crop:\n    #     return flag\n    if flag:\n        selected_col = new_df.iloc[0]  # it is a dict-like object.\n        # print(new_df)\n        if debug:\n            print(\"selected_col\")\n            print(selected_col)\n        # breakpoint()\n        # selected_col_dict = dict(selected_col)\n        # these are floating point shits.\n        # {'xmin': 1149.520263671875, 'ymin': 331.6445007324219, 'xmax': 1752.586181640625, 'ymax': 1082.3826904296875, 'confidence': 0.9185908436775208, 'class': 16, 'name': 'dog', 'area_ratio': 0.13691652620239364}\n        x0, y0, x1, y1 = [\n            int(selected_col[key]) for key in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:1032-1062"
    },
    "323": {
        "file_id": 15,
        "content": "Code snippet is performing image cropping and resizing based on a confidence threshold. It reads data from a DataFrame (new_df) which contains the coordinates of the image, confidence level, and other information. The code ensures that at least one row in new_df exists before proceeding. If no row exists, it returns False. Else, it selects the first row of new_df, extracts the relevant values, performs typecasting to integers for coordinates, and stores them in x0, y0, x1, and y1 respectively. The code also includes a debug print statement which prints the selected_col dictionary if the debug flag is set.",
        "type": "comment"
    },
    "324": {
        "file_id": 15,
        "content": "        ]\n        y0_altered = max(int(y0 - (y1 - y0) * y_expansion_rate), 0)\n        height_current = min((y1 - y0_altered), allowedHeight)  # reasonable?\n        width_current = min(\n            int((height_current / defaultCropHeight) * defaultCropWidth), defaultWidth\n        )  # just for safety. not for mathematical accuracy.\n        # height_current = min(allowedHeight, int((width_current/defaultCropWidth)*defaultCropHeight))\n        # (x1+x0)/2-width_current/2\n        import random\n        randStart, randEnd = max((x1 - width_current), 0), min(\n            x0, defaultWidth - width_current\n        )\n        randRange = randEnd - randStart\n        randModRange = int(randRange * (1 - mod) / 2)\n        randModStart = min(randStart + randModRange, randEnd)\n        randModEnd = max(randModStart, randEnd - randModRange)\n        x0_framework = random.randint(randModStart, randModEnd)\n        framework_XYWH = (x0_framework, y0_altered, width_current, height_current)\n        x_f, y_f, w_f, h_f = framework_XYWH",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:1063-1083"
    },
    "325": {
        "file_id": 15,
        "content": "This code determines the size and position of a cropped area based on specified dimensions and a random modifier. It uses variables such as `y0_altered`, `height_current`, `width_current`, `randStart`, `randEnd`, `randRange`, `randModRange`, `randModStart`, `randModEnd`, and `x0_framework` to calculate the final crop position and size. The result is stored in `framework_XYWH`.",
        "type": "comment"
    },
    "326": {
        "file_id": 15,
        "content": "        diagonalRect = [(x_f, y_f), (x_f + w_f, y_f + h_f)]\n        if not crop:\n            return diagonalRect\n        # croppedImageCover = img[y_f : y_f + h_f, x_f : x_f + w_f, :]\n        croppedImageCover = imageCropWithDiagonalRectangle(img, diagonalRect)\n        # breakpoint()\n        # resize image\n        croppedImageCoverResized = cv2.resize(\n            croppedImageCover, (defaultCropWidth, defaultCropHeight)\n        )\n        if debug_show:\n            cv2.imshow(\"CROPPED IMAGE COVER\", croppedImageCover)\n            cv2.imshow(\"CROPPED IMAGE COVER RESIZED\", croppedImageCoverResized)\n            # print(selected_col_dict)\n            # print(count)\n            # breakpoint()\n            cv2.waitKey(0)\n    else:\n        if debug:\n            print(\"NO COVER FOUND.\")\n    # if not crop:\n    # return [(0, 0), (defaultWidth, defaultHeight)]\n    return croppedImageCoverResized\ndef getImageBestConfidenceWithBezierDogCatDetector(\n    frame, dog_or_cat: Literal[\"dog\", \"cat\"] = \"dog\", debug=False\n):\n    best_confidence = 0",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:1084-1112"
    },
    "327": {
        "file_id": 15,
        "content": "Function to detect and crop best cover with dog or cat detection. If no cover found, returns default image. If debug is enabled, displays original and resized cropped image.",
        "type": "comment"
    },
    "328": {
        "file_id": 15,
        "content": "    detections = bezierPaddleHubResnet50ImageDogCatDetector(\n        frame, use_gpu=False\n    )  # no gpu avaliable\n    mDetections = [x for x in detections if x[\"identity\"] == dog_or_cat]\n    mDetections.sort(key=lambda x: -x[\"confidence\"])  # select the best one.\n    if len(mDetections) > 0:\n        best_confidence = mDetections[0][\"confidence\"]\n        if debug:\n            print(\"BEST CONFIDENCE:\", best_confidence)\n    return best_confidence\ndef filterImageBestConfidenceWithBezierDogCatDetector(\n    frame,\n    dog_or_cat: Literal[\"dog\", \"cat\"] = \"dog\",\n    debug=False,\n    confidence_threshold={\"min\": 0.7},\n):\n    best_confidence = getImageBestConfidenceWithBezierDogCatDetector(\n        frame, dog_or_cat=dog_or_cat, debug=debug\n    )\n    return checkMinMaxDict(best_confidence, confidence_threshold)\ndef imageDogCatCoverCropAdvanced(\n    frame,\n    dog_or_cat=\"dog\",\n    confidence_threshold={\"min\": 0.7},\n    yolov5_confidence_threshold=0.4,\n    text_area_threshold={\"max\": 0.2},\n    gpu=True,\n    corner=True,\n    area_threshold=0.2,",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:1113-1145"
    },
    "329": {
        "file_id": 15,
        "content": "The code snippet demonstrates the use of a detector for identifying dogs and cats in an image. The function `getImageBestConfidenceWithBezierDogCatDetector` detects objects in the frame, selects the best detection based on confidence level, and returns it. The function `filterImageBestConfidenceWithBezierDogCatDetector` filters the detected confidence value with a specified threshold. The `imageDogCatCoverCropAdvanced` function uses this to crop the image focusing on either dog or cat object.",
        "type": "comment"
    },
    "330": {
        "file_id": 15,
        "content": "    debug=False,\n):\n    processed_frame = None\n    frame = imageLoader(frame)\n    height, width = frame.shape[:2]\n    area = height * width\n    # detections = bezierPaddleHubResnet50ImageDogCatDetector(\n    #     frame, use_gpu=False\n    # )  # no gpu avaliable\n    # mDetections = [x for x in detections if x[\"identity\"] == dog_or_cat]\n    # mDetections.sort(key=lambda x: -x[\"confidence\"])  # select the best one.\n    # if len(mDetections) > 0:\n    # best_confidence =\n    # if best_confidence >0: # just stub.\n    #     best_confidence = mDetections[0][\"confidence\"]\n    #     print(\"BEST CONFIDENCE:\", best_confidence)\n    # if checkMinMaxDict(best_confidence, confidence_threshold):\n    if filterImageBestConfidenceWithBezierDogCatDetector(\n        frame,\n        dog_or_cat=dog_or_cat,\n        debug=debug,\n        confidence_threshold=confidence_threshold,\n    ):\n        # target = getImageTextAreaRatio(frame, inpaint=True, gpu=gpu)\n        # target = imageFourCornersInpainting(target)\n        # processed_frame = target",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:1146-1173"
    },
    "331": {
        "file_id": 15,
        "content": "The code defines a function that processes an image frame, detects whether it contains a dog or cat using a BezierPaddleHubResnet50ImageDogCatDetector, and if successful, applies inpainting to the target area. The best confidence score is checked against a threshold before proceeding with inpainting. If no GPU is available, detection is not performed.",
        "type": "comment"
    },
    "332": {
        "file_id": 15,
        "content": "        # break\n        text_area_ratio = getImageTextAreaRatio(\n            frame,\n            gpu=gpu,\n        )\n        # text_area_ratio = getImageTextAreaRatio(frame, gpu=gpu)\n        print(\"TEXT AREA RATIO\", text_area_ratio)\n        # if animalCropDiagonalRect is not None:\n        if checkMinMaxDict(text_area_ratio, text_area_threshold):\n            mFrame = getImageTextAreaRatio(frame, gpu=gpu, inpaint=True)\n            if corner:\n                mFrame = imageFourCornersInpainting(mFrame)\n            mFrame = imageCropoutBlackArea(mFrame)\n            mFrame = imageCropoutBlurArea(mFrame)\n            # cv2.imshow(\"PRE_FINAL_IMAGE\", mFrame)\n            # cv2.waitKey(0)\n            processed_frame = imageDogCatDetectionForCoverExtraction(\n                mFrame,\n                dog_or_cat=dog_or_cat,\n                confidence_threshold=yolov5_confidence_threshold,\n                # area_threshold=0.15,\n                crop=True,\n                debug=True,\n            )\n    if processed_frame is not None:",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:1174-1198"
    },
    "333": {
        "file_id": 15,
        "content": "The code checks if the text area ratio is within the threshold and applies image processing techniques to remove unwanted areas. If a valid frame is obtained, it performs dog or cat detection for covering extraction.",
        "type": "comment"
    },
    "334": {
        "file_id": 15,
        "content": "        p_height, p_width = processed_frame.shape[:2]\n        p_area = p_height * p_width\n        if p_area / area < area_threshold:\n            processed_frame = None\n        elif not filterImageBestConfidenceWithBezierDogCatDetector(\n            frame,\n            dog_or_cat=dog_or_cat,\n            debug=debug,\n            confidence_threshold=confidence_threshold,\n        ):\n            processed_frame = None\n    return processed_frame",
        "type": "code",
        "location": "/pyjom/imagetoolbox.py:1199-1212"
    },
    "335": {
        "file_id": 15,
        "content": "The code calculates the area of the processed frame and checks if it's smaller than a certain threshold. If so, sets processed_frame to None. Then, applies dog or cat detection using Bezier Dog/Cat Detector with specified parameters, setting processed_frame to None if no suitable detection is found.",
        "type": "comment"
    },
    "336": {
        "file_id": 16,
        "content": "/pyjom/languagetoolbox.py",
        "type": "filepath"
    },
    "337": {
        "file_id": 16,
        "content": "This code uses Tesseract OCR, topic modeling, and text preprocessing to extract text from font-specific images, removes unwanted characters, generates topics, applies TF-IDF vectors, paraphrases using ClueAI API, and offers multi-threaded input/output handling.",
        "type": "summary"
    },
    "338": {
        "file_id": 16,
        "content": "########################[FILTERING]#########################\n# DONE: use notofu for rendering then use tesseract for recognition\nimport pygame\nimport functools\n@functools.lru_cache(maxsize=1)\ndef initPygame():\n    os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n    # headless pygame\n    pygame.init()\nimport os\nimport pytesseract\ndef renderSingleLineTextUsingFont(\n    textContent: str,\n    output_name: str,\n    fontPath: str = os.path.join(\n        os.dirname(__file__),\n        \"../tests/render_and_recognize_long_text_to_filter_unwanted_characters/get_and_merge_fonts/GoNotoCurrent.ttf\",\n    ),\n    fontSize: int = 40,\n    margin: int = 20,\n):\n    assert os.path.exists(fontPath)\n    initPygame()\n    black, white = pygame.Color(\"black\"), pygame.Color(\"white\")\n    # pillow can also do that\n    # https://plainenglish.io/blog/generating-text-on-image-with-python-eefe4430fe77\n    # pygame.font.get_fonts()\n    # install your font to system please? but why all lower case font names?\n    # fontName = \"notosans\"\n    # this font is bad.",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:1-41"
    },
    "339": {
        "file_id": 16,
        "content": "Code imports necessary libraries and defines a function `renderSingleLineTextUsingFont` that takes input text, output image name, font path, font size, and margin as parameters. It checks if the specified font exists, initializes pygame in headless mode, sets up colors, and renders the text onto an image with specified font, size, and margin.",
        "type": "comment"
    },
    "340": {
        "file_id": 16,
        "content": "    # font = pygame.font.SysFont(fontName,fontSize)\n    # fontPath = \"/usr/share/fonts/truetype/noto/NotoSans-Regular.ttf\" # shit this fails.\n    # use some kind of super large merged notofont.\n    font = pygame.font.Font(fontPath, fontSize)\n    word_surface = font.render(textContent, False, black)\n    word_width, word_height = word_surface.get_size()\n    SIZE = (word_width + margin * 2, word_height + margin * 2)\n    image = pygame.display.set_mode(SIZE, pygame.RESIZABLE)\n    image.fill(white)\n    image.blit(word_surface, (margin, margin))\n    pygame.display.update()\n    pygame.image.save(image, output_name)\ndef recognizeCharactersFromImageWithTesseract(\n    imagePath: str, langs: list = [\"eng\", \"chi_sim\", \"chi_tra\", \"jpn\"]\n):\n    # pytesseract.get_languages(config=\"\")\n    langCode = \"+\".join(langs)\n    output = pytesseract.image_to_string(imagePath, lang=langCode)\n    return output\nimport tempfile\ndef convertToChineseOrEnglishOrJapaneseCharactersUsingTesseract(char_list: str):\n    with tempfile.NamedTemporaryFile(\"wb\", suffix=\".png\") as f:",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:43-74"
    },
    "341": {
        "file_id": 16,
        "content": "The code initializes a Pygame font, renders text on the surface, gets its size, sets up a display image, fills it with white, blits the rendered text onto the image, updates the display, and saves the final image.\nThe recognizeCharactersFromImageWithTesseract function uses Tesseract OCR to recognize characters in an image file for specified languages and returns the output as a string.\nThe convertToChineseOrEnglishOrJapaneseCharactersUsingTesseract function temporarily stores input text in a PNG file, uses Tesseract to extract Chinese, English, or Japanese characters from the image, and potentially returns the extracted text.",
        "type": "comment"
    },
    "342": {
        "file_id": 16,
        "content": "        imagePath = f.name\n        renderSingleLineTextUsingFont(char_list,imagePath)\n        output = recognizeCharactersFromImageWithTesseract(imagePath)\n        return output\n# bilibili title requirements may also applied to tags, descriptions\nimport re\nimport string as string_builtin\nfrom zhon.hanzi import punctuation as chinese_punctuation\ndef filterNonChineseOrEnglishOrJapaneseCharacters(char_list: str):\n    output = []\n    checkers = {\n        \"chinese\": lambda c: (\n            (c in chinese_punctuation) or (re.match(r\"[\\u4e00-\\u9fa5]\", c) is not None)\n        ),\n        \"english\": lambda c: (\n            (c in \" \" + string_builtin.punctuation)\n            or (re.match(r\"[a-zA-Z0-9]\", c) is not None)\n        ),\n        \"japanese\": lambda c: re.match(r\"[一-龠ぁ-ゔァ-ヴーａ-ｚＡ-Ｚ０-９々〆〤ヶ]\", c) is not None,\n    }\n    for char in char_list:\n        signal = True\n        for key, checker in checkers.items():\n            signal = checker(char)\n            if signal in [False, 0, None]:\n                break\n        if signal:",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:75-107"
    },
    "343": {
        "file_id": 16,
        "content": "This function filters out non-Chinese, English, or Japanese characters from a given list of characters. It iterates through each character and checks if it belongs to any of these three categories using the provided checkers dictionary. If a character does not belong to any of these categories, it is excluded from the output list.",
        "type": "comment"
    },
    "344": {
        "file_id": 16,
        "content": "            output.append(char)\n    return \"\".join(output)\n########################[FILTERING]#########################\n########################[PREPROCESSING & TOPIC MODELING]#########################\nenglishNLP = None\nenglishStopWords = None\nporterStemmer = None\ndef get_topics(model, feature_names, n_top_words):\n    # 首先是遍历模型中存储的话题序号和话题内容\n    topics = []\n    for topic_idx, topic in enumerate(model.components_):\n        # 然后打印话题的序号以及指定数量的最高频的关键词\n        message = \"topic #%d:\" % topic_idx\n        mList = [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]\n        mListStr = \" \".join(mList)\n        message += mListStr\n        mSet = set(mList)  # the set contains word groups like 'river question'\n        cDict = {k: mList.count(k) for k in mSet}\n        mRealList = mListStr.split(\" \")\n        mRealList = [\n            x.strip() for x in mRealList if len(x.strip()) > 1\n        ]  # usually things shorter than 2 letters are no good.\n        mRealSet = set(mRealList)\n        cRealDict = {k: mRealList.count(k) for k in mRealSet}",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:108-136"
    },
    "345": {
        "file_id": 16,
        "content": "This code is implementing a function `get_topics` for retrieving topics and their corresponding words from a topic model. It iterates through the model's components, sorts them by frequency, selects top n_top_words, removes short/redundant keywords, and stores this information in the 'topics' list.",
        "type": "comment"
    },
    "346": {
        "file_id": 16,
        "content": "        topics.append({\"combined\": mList, \"separate\": mRealList})\n    return topics\ndef print_topics(model, feature_names, n_top_words):\n    # 首先是遍历模型中存储的话题序号和话题内容\n    for topic_idx, topic in enumerate(model.components_):\n        # 然后打印话题的序号以及指定数量的最高频的关键词\n        message = \"topic #%d:\" % topic_idx\n        mList = [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]\n        mListStr = \" \".join(mList)\n        message += mListStr\n        mSet = set(mList)  # the set contains word groups like 'river question'\n        cDict = {k: mList.count(k) for k in mSet}\n        mRealList = mListStr.split(\" \")\n        mRealList = [\n            x.strip() for x in mRealList if len(x.strip()) > 1\n        ]  # usually things shorter than 2 letters are no good.\n        mRealSet = set(mRealList)\n        cRealDict = {k: mRealList.count(k) for k in mRealSet}\n        print(\"MESSAGE\", message)\n        print(\"SET\", mSet)\n        print(\"COUNT DICT\", cDict)  # pointless to count here?\n        print(\"RealSET\", mRealSet)\n        print(\"RealCOUNT DICT\", cRealDict)",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:137-162"
    },
    "347": {
        "file_id": 16,
        "content": "This code generates and prints the topics from a given model, along with their indexes. It then displays the top words for each topic and provides two count dictionaries: one for the original list and another for the filtered real list. The original list includes all words sorted by frequency, while the real list only contains words longer than 2 characters to exclude noise or irrelevant terms. The code also prints the sets of these lists and the count dictionaries.",
        "type": "comment"
    },
    "348": {
        "file_id": 16,
        "content": "    print()\ndef englishSentencePreprocessing(\n    text, unwantedPOS=[\"PRON\", \"CCONJ\", \"ADP\", \"PART\", \"PUNCT\", \"AUX\"]\n):\n    global englishNLP, englishStopWords, porterStemmer\n    from nltk.corpus import stopwords\n    from nltk.tokenize import word_tokenize\n    import en_core_web_sm\n    from nltk.stem import PorterStemmer\n    if englishNLP is None:\n        englishNLP = en_core_web_sm.load()\n    doc = englishNLP(text)\n    if englishStopWords is None:\n        set(stopwords.words(\"english\"))\n        englishStopWords = set([elem.lower() for elem in stopwords.words(\"english\")])\n    if porterStemmer is None:\n        porterStemmer = PorterStemmer()\n    lemma_word1 = []\n    # this shit has the lang tag. it might be useful for language detection. really?\n    for token in doc:\n        if token.pos_ in unwantedPOS:\n            continue\n        if token.text.lower() in englishStopWords:\n            continue\n        lemma_word1.append(token.text)\n    Stem_words = []\n    for w in lemma_word1:\n        rootWord = porterStemmer.stem(w)",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:163-194"
    },
    "349": {
        "file_id": 16,
        "content": "This code defines a function called \"englishSentencePreprocessing\" that performs English sentence preprocessing. It utilizes the NLTK and spaCy libraries for natural language processing. The function loads an English language model, tokenizes text into words, filters out unwanted parts of speech (POS) and stop words, and applies stemming to the remaining words. The filtered and stemmed words are stored in \"lemma_word1\" list which is then used further in the code.",
        "type": "comment"
    },
    "350": {
        "file_id": 16,
        "content": "        Stem_words.append(rootWord)\n    return Stem_words\ndef sentenceFlatten(sentence, padding=\" \"):\n    assert len(padding) == 1\n    assert type(padding) == str\n    for x in \"\\n\\r\\t\":\n        sentence = sentence.replace(x, padding)\n    while True:\n        if padding * 2 in sentence:\n            sentence = sentence.replace(padding * 2, padding)\n        else:\n            break\n    sentence = sentence.strip()\n    return sentence\ndef englishTopicModeling(sentences, n_top_words=10, ngram_range=(1, 2), n_components=5):\n    try:\n        dataList = []\n        for sentence in sentences:\n            sentence = sentenceFlatten(sentence)\n            row = englishSentencePreprocessing(sentence)\n            if len(row) > 0:\n                elem = \" \".join(row)\n                dataList.append(elem)\n        data = \"\\n\".join(dataList)\n        from sklearn.feature_extraction.text import TfidfVectorizer\n        # 创建一个CountVectoerizer实例\n        tfidf = TfidfVectorizer(ngram_range=ngram_range)\n        # 打开刚刚保存的txt文档\n        from io import StringIO",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:195-230"
    },
    "351": {
        "file_id": 16,
        "content": "The code defines several functions for natural language processing tasks. \"englishSentencePreprocessing\" stems words, \"sentenceFlatten\" removes newlines and extra spaces in a sentence, and \"englishTopicModeling\" tokenizes sentences using TfidfVectorizer from sklearn library to perform English topic modeling. It takes a list of sentences, sets parameters for n-gram range and the number of topics, and converts the data into TF-IDF vectors.",
        "type": "comment"
    },
    "352": {
        "file_id": 16,
        "content": "        f = StringIO(data)\n        # 使用CountVectorizer拟合数据\n        x_train = tfidf.fit_transform(f)\n        from sklearn.decomposition import LatentDirichletAllocation\n        lda = LatentDirichletAllocation(n_components=n_components)\n        lda.fit(x_train)\n        topics = get_topics(lda, tfidf.get_feature_names(), n_top_words)\n    except:\n        import traceback\n        traceback.print_exc()\n        topics = []\n    return topics\nfrom functools import lru_cache\nfrom lazero.utils.logger import traceError\n# import os\n@lru_cache(maxsize=1)\ndef getChineseStopWords(\n    stopwordFileList=[\n        \"/root/Desktop/works/pyjom/tests/stopwords/chinese_stopwords.txt\",\n        \"/root/Desktop/works/pyjom/tests/stopwords/stopwords-zh/stopwords-zh.json\",\n    ]\n):\n    import json\n    stopwords = []\n    for filename in stopwordFileList:\n        # if os.path.exists(filename) and os.path.isfile(filename):\n        try:\n            with open(filename, \"r\") as f:\n                content = f.read()\n            if filename.endswith(\".json\"):",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:232-269"
    },
    "353": {
        "file_id": 16,
        "content": "This code snippet is importing necessary libraries and defining a function to process text data. It uses CountVectorizer to convert text into numerical features, then applies LatentDirichletAllocation for topic modeling on the transformed data. If there's an exception during processing, it prints the error traceback and returns an empty list. Additionally, it defines another function getChineseStopWords which reads Chinese stopwords from different files and returns them as a list. The function getChineseStopWords is decorated with @lru_cache for performance optimization.",
        "type": "comment"
    },
    "354": {
        "file_id": 16,
        "content": "                try:\n                    mList = json.loads(content)\n                    assert type(mList) == list\n                    stopwords += mList\n                except:\n                    traceError(_breakpoint=True)\n            else:\n                mList = content.split(\"\\n\")\n                mList = [x.replace(\"\\n\", \"\").strip() for x in mList]\n                mList = [x for x in mList if len(x) > 0]\n                stopwords += mList\n        except:\n            traceError(_breakpoint=True)\n    return list(set(stopwords))\ndef chineseSentencePreprocessing(sentence):\n    import jieba\n    import string\n    from zhon.hanzi import punctuation\n    chinese_stopwords = getChineseStopWords()\n    words = jieba.lcut(sentence)\n    rows = []\n    for word in words:\n        word = word.strip()\n        if word in punctuation:\n            continue\n        elif word in string.punctuation:\n            continue\n        elif word in chinese_stopwords:\n            continue\n        rows.append(word)\n    return rows\ndef chineseTopicModeling(sentences, n_top_words=10, ngram_range=(1, 2), n_components=5):",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:270-306"
    },
    "355": {
        "file_id": 16,
        "content": "The code loads stop words from a JSON file or provides them as a list, handles exceptions for reading and parsing errors, and returns the set of unique stop words. The chineseSentencePreprocessing function uses Jieba to tokenize Chinese sentences, filtering out punctuation and stop words, and returns a list of remaining words. The chineseTopicModeling function performs topic modeling on given sentences with specified parameters.",
        "type": "comment"
    },
    "356": {
        "file_id": 16,
        "content": "    try:\n        dataList = []\n        for sentence in sentences:\n            sentence = sentenceFlatten(sentence)\n            row = chineseSentencePreprocessing(sentence)\n            if len(row) > 0:\n                elem = \" \".join(row)\n                dataList.append(elem)\n        data = \"\\n\".join(dataList)\n        from sklearn.feature_extraction.text import TfidfVectorizer\n        # 创建一个CountVectoerizer实例\n        tfidf = TfidfVectorizer(ngram_range=ngram_range)\n        # 打开刚刚保存的txt文档\n        from io import StringIO\n        f = StringIO(data)\n        # 使用CountVectorizer拟合数据\n        x_train = tfidf.fit_transform(f)\n        from sklearn.decomposition import LatentDirichletAllocation\n        lda = LatentDirichletAllocation(n_components=n_components)\n        lda.fit(x_train)\n        topics = get_topics(lda, tfidf.get_feature_names(), n_top_words)\n    except:\n        import traceback\n        traceback.print_exc()\n        topics = []\n    return topics\n########################[PREPROCESSING & TOPIC MODELING]#########################",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:307-343"
    },
    "357": {
        "file_id": 16,
        "content": "This code performs text preprocessing and topic modeling. It flattens sentences, applies Chinese sentence processing, creates a TfidfVectorizer to transform the data, fits it with CountVectorizer, then uses LatentDirichletAllocation for topic modeling. It handles potential exceptions by printing traceback and returns an empty list if error occurs.",
        "type": "comment"
    },
    "358": {
        "file_id": 16,
        "content": "from typing import Literal\n########################[PARAPHRASING]########################\ndef chineseParaphraserAPI(\n    content: str,\n    debug: bool = False,\n    target_id: int = 0,\n    timeout: int = 10,\n    providers: list[str] = [\n        \"http://www.wzwyc.com/api.php?key=\",\n        \"http://ai.guiyigs.com/api.php?key=\",\n    ],  # it is about to close! fuck. \"本站于2023年2月19日关站\" buy code from \"1900373358\"\n):\n    import requests\n    target = providers[target_id]  # all the same?\n    data = {\"info\": content}\n    # target = \"http://www.xiaofamaoai.com/result.php\"\n    # xfm_uid = \"342206661e655450c1c37836d23dc3eb\"\n    # data = {\"contents\":content, \"xfm_uid\":xfm_uid, \"agreement\":\"on\"}\n    # nothing? fuck?\n    r = requests.post(target, data=data, timeout=timeout)\n    output = r.text\n    success = output.strip() != content.strip()\n    if debug:\n        print(output)\n    return output, success\nimport clueai\n@lru_cache(maxsize=1)\ndef getClueAIClient(apiKey: str):\n    if apiKey == \"\":\n        return clueai.Client(\"\", check_api_key=False)",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:346-385"
    },
    "359": {
        "file_id": 16,
        "content": "This function, chineseParaphraserAPI, takes a string input and uses a list of API providers to obtain a paraphrased version of the input. It utilizes the requests library for making HTTP requests. The getClueAIClient function is a cached wrapper for initializing a clueai Client with an optional apiKey parameter.",
        "type": "comment"
    },
    "360": {
        "file_id": 16,
        "content": "    else:\n        return clueai.Client(apiKey)\ndef clueAIParaphraser(\n    title: str,\n    apiKey: str = \"\",\n    generate_config: dict = {\n        \"do_sample\": True,\n        \"top_p\": 0.8,\n        \"max_length\": 128,  # notice! not too long.\n        \"min_length\": 5,\n        \"length_penalty\": 1.0,\n        \"num_beams\": 1,\n    },\n    prompt_template: str = \"\"\"\n生成与下列文字相同意思的句子：\n{}\n答案：\n\"\"\",\n    debug: bool = False,\n):\n    cl = getClueAIClient(apiKey)  # good without API key\n    prompt = prompt_template.format(title)  # shit.\n    # generate a prediction for a prompt\n    # 如果需要自由调整参数自由采样生成，添加额外参数信息设置方式：generate_config=generate_config\n    prediction = cl.generate(\n        model_name=\"clueai-base\", prompt=prompt, generate_config=generate_config\n    )\n    # 需要返回得分的话，指定return_likelihoods=\"GENERATION\"\n    output = prediction.generations[0].text\n    success = title.strip() != output.strip()\n    if debug:\n        # print the predicted text\n        print(\"prediction: {}\".format(output))\n        print(\"paraphrase success?\", success)\n    return output, success",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:386-423"
    },
    "361": {
        "file_id": 16,
        "content": "This code defines a function named `clueAIParaphraser` that returns a paraphrased text using the ClueAI API. It requires an API key, a title to paraphrase, optional generate_config parameters for the AI model, and a debug flag. The function generates a prediction from the input prompt, extracts the generated text, checks if the original title and predicted text are different (success), and optionally prints the prediction and success status if debugging is enabled.",
        "type": "comment"
    },
    "362": {
        "file_id": 16,
        "content": "import paddlehub as hub\n@lru_cache(maxsize=1)\ndef getBaiduLanguageTranslationModel():\n    language_translation_model = hub.Module(name=\"baidu_translate\")\n    return language_translation_model\n@lru_cache(maxsize=1)\ndef getBaiduLanguageRecognitionModel():\n    language_recognition_model = hub.Module(name=\"baidu_language_recognition\")\n    return language_recognition_model\nBAIDU_API_SLEEP_TIME = 1\nBAIDU_TRANSLATOR_LOCK_FILE = (\n    \"/root/Desktop/works/pyjom/tests/karaoke_effects/baidu_translator.lock\"\n)\ndef baidu_lang_detect(\n    content: str, sleep=BAIDU_API_SLEEP_TIME, lock_file=BAIDU_TRANSLATOR_LOCK_FILE\n):  # target language must be chinese.\n    import filelock\n    lock = filelock.FileLock(lock_file)\n    with lock:\n        import time\n        time.sleep(sleep)\n        language_recognition_model = getBaiduLanguageRecognitionModel()\n        langid = language_recognition_model.recognize(content)\n        return langid\ndef baidu_translate(\n    content: str,\n    source: str,\n    target: str,\n    sleep: int = BAIDU_API_SLEEP_TIME,",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:426-466"
    },
    "363": {
        "file_id": 16,
        "content": "This code imports PaddleHub module, defines functions for getting Baidu translation and recognition models using LRU cache, sets API sleep time and lock file path, and includes functions for language detection and translation using Baidu API.",
        "type": "comment"
    },
    "364": {
        "file_id": 16,
        "content": "    lock_file: str = BAIDU_TRANSLATOR_LOCK_FILE,\n):  # target language must be chinese.\n    import filelock\n    lock = filelock.FileLock(lock_file)\n    with lock:\n        import time\n        time.sleep(sleep)\n        language_translation_model = getBaiduLanguageTranslationModel()\n        translated_content = language_translation_model.translate(\n            content, source, target\n        )\n        return translated_content\nfrom typing import Iterable, Union\nimport random\ndef baiduParaphraserByTranslation(\n    content: str,\n    debug: bool = False,\n    paraphrase_depth: Union[\n        int, Iterable\n    ] = 1,  # only 1 intermediate language, default.\n    suggested_middle_languages: list[str] = [\n        \"zh\",\n        \"en\",\n        \"jp\",\n    ],  # english, japanese, chinese\n):\n    if issubclass(type(paraphrase_depth), Iterable):\n        paraphrase_depth = random.choice(paraphrase_depth)\n    target_language_id = baidu_lang_detect(content)\n    all_middle_languages = list(set(suggested_middle_languages + [target_language_id]))",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:467-505"
    },
    "365": {
        "file_id": 16,
        "content": "This function utilizes Baidu's language translation model to paraphrase input content by translating it through a randomly chosen intermediate language from the provided list. The intermediate languages include Chinese, English, and Japanese. It uses a FileLock for synchronization when accessing the Baidu translation model, allowing safe parallel use in multi-threaded environments. The target language is detected using baidu_lang_detect function.",
        "type": "comment"
    },
    "366": {
        "file_id": 16,
        "content": "    assert paraphrase_depth > 0\n    if paraphrase_depth > 1:\n        assert len(all_middle_languages) >= 3\n    current_language_id = target_language_id\n    middle_content = content\n    head_tail_indexs = set([0, paraphrase_depth - 1])\n    intermediate_languages = []\n    for loop_id in range(paraphrase_depth):\n        forbid_langs = set([current_language_id])\n        if loop_id in head_tail_indexs:\n            forbid_langs.add(target_language_id)\n        non_target_middle_languages = [\n            langid for langid in all_middle_languages if langid not in forbid_langs\n        ]\n        if debug:\n            print(f\"INDEX: {loop_id} INTERMEDIATE LANGS: {non_target_middle_languages}\")\n        middle_language_id = random.choice(non_target_middle_languages)\n        middle_content = baidu_translate(\n            middle_content, source=current_language_id, target=middle_language_id\n        )\n        current_language_id = middle_language_id\n        intermediate_languages.append(middle_language_id)\n    output_content = baidu_translate(",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:507-533"
    },
    "367": {
        "file_id": 16,
        "content": "This code is generating a multi-level paraphrase by randomly selecting languages from a list of middle languages, excluding the target and current language. It ensures that the paraphrase_depth is greater than 1 before proceeding to select intermediate languages. The chosen middle language's content is translated using baidu_translate function. The selected language ID and content are added to the respective lists for each loop iteration, resulting in a multi-level paraphrase.",
        "type": "comment"
    },
    "368": {
        "file_id": 16,
        "content": "        middle_content, source=current_language_id, target=target_language_id\n    )\n    success = output_content.strip() != content.strip()\n    if debug:\n        print(\"SOURCE LANGUAGE:\", target_language_id)\n        print(\"USING INTERMEDIATE LANGUAGES:\", intermediate_languages)\n        print(\"PARAPHRASED:\", output_content)\n        print(\"paraphrase success?\", success)\n    return output_content, success\ndef paraphraser(\n    content: str,\n    method: Literal[\"clueai_free\", \"cn_nlp_online\", \"baidu_translator\"] = \"clueai_free\",\n    debug: bool = False,\n    configs: dict = {},\n):  # you could add some translation based methods.\n    implementedMethods = [\"clueai_free\", \"cn_nlp_online\", \"baidu_translator\"]\n    if method not in implementedMethods:\n        raise NotImplementedError(\"method '%s' not implemented\")\n    if content.strip() == \"\":\n        return content, True  # to protect paraphrasers.\n    try:\n        if method == \"clueai_free\":\n            output, success = clueAIParaphraser(content, debug=debug, **configs)",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:534-559"
    },
    "369": {
        "file_id": 16,
        "content": "The code defines a function `paraphraser` which takes in a content string, specifies the method of paraphrasing (clueai_free, cn_nlp_online, baidu_translator) and an optional debug mode. The implemented methods are checked before proceeding to ensure that only valid inputs are accepted. Empty strings are handled with a return statement. Within a try block, the function calls the corresponding paraphrasing method based on the specified input and returns the output along with a boolean value indicating if paraphrase was successful.",
        "type": "comment"
    },
    "370": {
        "file_id": 16,
        "content": "        elif method == \"cn_nlp_online\":\n            output, success = chineseParaphraserAPI(content, debug=debug, **configs)\n        elif method == \"baidu_translator\":\n            output, success = baiduParaphraserByTranslation(\n                content, debug=debug, **configs\n            )\n        # you should not be here.\n        else:\n            raise NotImplementedError(\"method '%s' not implemented\")\n        return output, success\n    except NotImplementedError as e:\n        raise e\n    except:\n        import traceback\n        traceback.print_exc()\n        print(\"Failed to paraphrase content using method '%s'\" % method)\n        print(\"Returning original content and failed signal.\")\n        return content, False\n########################[PARAPHRASING]########################",
        "type": "code",
        "location": "/pyjom/languagetoolbox.py:560-581"
    },
    "371": {
        "file_id": 16,
        "content": "This code checks the method for paraphrasing and executes the corresponding function. If the method is not implemented, it raises a NotImplementedError. If there's any other exception, it prints the traceback and returns the original content with failure signal.",
        "type": "comment"
    },
    "372": {
        "file_id": 17,
        "content": "/pyjom/commons.py",
        "type": "filepath"
    },
    "373": {
        "file_id": 17,
        "content": "The code imports libraries, handles data operations and errors, interacts with Redis caching, supports debug mode, and maps media file extensions. It detects corrupted content, checks server availability, utilizes ffprobe and mediainfo for media details, configures YOLOv5 model, writes to a file, and prints log path.",
        "type": "summary"
    },
    "374": {
        "file_id": 17,
        "content": "import traceback\nfrom pyjom.config import *\nfrom typing import Union\nfrom pyjom.mathlib import checkMinMaxDict\nimport datetime\nimport os\nimport shutil\nimport socket\nimport json\nimport mimetypes\nimport jinja2\nimport copy\nimport uuid\nimport numpy as np\nimport torch\nimport pathlib\nimport site\nimport sys\nimport random\n# from functools import lru_cache\ncommonRedisPort = 9291\nos.system(\"ulimit -n 1048576\")\nfrom lazero.utils.logger import sprint\nfrom functools import lru_cache\nimport time\ndef getJSTimeStamp():\n    return int(time.time() * 1000)\nfrom pymilvus import connections\n@lru_cache(maxsize=1)\ndef connectMilvusDatabase(alias=\"default\", host=\"localhost\", port=\"19530\"):\n    connection = connections.connect(\n        alias=alias, host=host, port=port\n    )  # can we reconnect?\n    print(\"milvus connected\")\n    return connection\n# what is the redis connection?\nimport redis\n@lru_cache(maxsize=1)\ndef getRedisConnection(host=\"localhost\", port=commonRedisPort):\n    connection = redis.Redis(host=host, port=port)\n    return connection\ndef removeRedisValueByKey(",
        "type": "code",
        "location": "/pyjom/commons.py:1-58"
    },
    "375": {
        "file_id": 17,
        "content": "The code imports various libraries and defines several functions. It connects to Milvus and Redis databases, gets the current JSTimeStamp, and provides functions for connecting to these databases and removing a Redis value by key. The redis connection is cached using LRU cache for performance optimization.",
        "type": "comment"
    },
    "376": {
        "file_id": 17,
        "content": "    key: str, debug: bool = False, host=\"localhost\", port=commonRedisPort\n):\n    connection = getRedisConnection(host=host, port=port)\n    returnCode = connection.delete(key)\n    messages = {\n        0: \"key {} not found\".format(key),\n        1: \"delete key {} successfully\".format(key),\n    }\n    if debug:\n        print(messages.get(returnCode, \"unknown return code: {}\".format(returnCode)))\n    return returnCode\ndef removeRedisValueByKeys(\n    keys: list[str], debug: bool = False, host=\"localhost\", port=commonRedisPort\n):\n    for key in keys:\n        removeRedisValueByKey(key, debug=debug, host=host, port=port)\n# @lru_cache(maxsize=1)\n# def getSafeEvalEnvironment():\n#     return sf\ndef safe_eval(\n    code, safenodes=[\"List\", \"Dict\", \"Tuple\", \"Set\", \"Expression\", \"Constant\", \"Load\"]\n):  # strange.\n    from evalidate import safeeval\n    result = safeeval(code, {}, safenodes=safenodes)\n    return result\nimport pickle, dill\ncommonIterableDataTypes = [tuple, list, dict, set]\ncommonNonIterableDataTypes = [int, float, str, bool]",
        "type": "code",
        "location": "/pyjom/commons.py:59-96"
    },
    "377": {
        "file_id": 17,
        "content": "This code includes two functions, one for deleting a single key from Redis and the other for deleting multiple keys. It also has constants for data types and imports necessary libraries for handling data serialization and evaluation. The getSafeEvalEnvironment function is likely used to cache an environment for safe evaluation, although it is not currently utilized. The safe_eval function uses the evalidate library to evaluate input code within a restricted environment. Common iterable and non-iterable data types are defined for potential usage throughout the codebase.",
        "type": "comment"
    },
    "378": {
        "file_id": 17,
        "content": "commonDataTypes = commonNonIterableDataTypes + commonIterableDataTypes\ndef stringifiableCheck(value, debug: bool = False):\n    try:\n        str_value = repr(value)\n        restored_value = safe_eval(value)\n        return restored_value == value\n    except:\n        if debug:\n            traceback.print_exc()\n    return False\ndef setRedisValueByKey(\n    key: str,\n    value,\n    dataType=None,\n    encoding: str = \"utf-8\",\n    host=\"localhost\",\n    port=commonRedisPort,\n    debug: bool = False,\n):\n    def stringifyAndEncode(value):\n        data = repr(value)\n        data = data.encode(encoding)\n        return data\n    connection = getRedisConnection(host=host, port=port)\n    if dataType is None:\n        dataType = type(value)\n        if dataType in commonDataTypes and stringifiableCheck(\n            value, debug=debug\n        ):  # this automation only happens when leaving blank for dataType.\n            data = stringifyAndEncode(value)\n        else:\n            dataType = \"dill\"\n            data = dill.dumps(value)\n    else:",
        "type": "code",
        "location": "/pyjom/commons.py:97-135"
    },
    "379": {
        "file_id": 17,
        "content": "This code defines functions for handling data types and communicating with Redis. It checks if a value is stringifiable, encodes it, and stores it in Redis based on the provided data type. If no data type is given, it automatically determines the type and performs encoding if necessary.",
        "type": "comment"
    },
    "380": {
        "file_id": 17,
        "content": "        if dataType in commonDataTypes:\n            data = stringifyAndEncode(value)\n        elif dataType == \"dill\":\n            data = dill.dumps(value)\n        elif dataType == \"pickle\":\n            data = pickle.dumps(value)\n        else:\n            raise Exception(\"unknown dataType:\", dataType)\n    connection.set(key, data)\n    return dataType\ndef getRedisValueByKey(\n    key: str,\n    dataType=None,\n    encoding: str = \"utf-8\",\n    debug: bool = False,\n    host=\"localhost\",\n    port=commonRedisPort,\n):\n    connection = getRedisConnection(host=host, port=port)\n    value = connection.get(key)\n    if value is not None:\n        if debug:\n            print('data \"{}\" is not None'.format(key))\n        if dataType == None:\n            return dataType\n        elif dataType in commonDataTypes:\n            decoded_value = value.decode(encoding)\n            if dataType in commonNonIterableDataTypes:\n                if dataType == str:\n                    return decoded_value\n                else:\n                    return dataType(decoded_value)",
        "type": "code",
        "location": "/pyjom/commons.py:136-169"
    },
    "381": {
        "file_id": 17,
        "content": "The code handles data storage and retrieval from Redis. It checks the data type, encodes or serializes the value accordingly (using stringifyAndEncode, dill, or pickle), and stores it in Redis using set method. The getRedisValueByKey function retrieves a value by key and decodes it based on the specified data type, if provided. It returns None if the value is not found or the data type is not specified. The code also handles debugging messages and exceptions for unknown data types.",
        "type": "comment"
    },
    "382": {
        "file_id": 17,
        "content": "            else:\n                # safe eval using nsjail?\n                return safe_eval(decoded_value)\n        elif dataType == \"pickle\":\n            return pickle.loads(value)\n        elif dataType == \"dill\":\n            return dill.loads(value)\n        else:\n            raise Exception(\"unknown dataType:\", dataType)\n    if debug:\n        print('data \"{}\" is None'.format(key))\ndef getRedisCachedSet(\n    setName: str,\n    debug: bool = False,\n    host=\"localhost\",\n    port=commonRedisPort,\n    dataType=\"dill\",\n) -> set:\n    # so we know this datatype is set!\n    # but what is our plan? we use dill by default.\n    data = getRedisValueByKey(\n        setName, debug=debug, host=host, port=port, dataType=dataType\n    )\n    if data is None:\n        return set()\n    assert type(data) == set\n    return data\ndef addToRedisCachedSet(\n    item,\n    setName: str,\n    debug: bool = False,\n    host=\"localhost\",\n    port=commonRedisPort,\n    dataType=\"dill\",\n):\n    cachedSet = getRedisCachedSet(\n        setName, debug=debug, host=host, port=port, dataType=dataType",
        "type": "code",
        "location": "/pyjom/commons.py:170-210"
    },
    "383": {
        "file_id": 17,
        "content": "This code defines functions to interact with Redis cached sets. The `getRedisCachedSet` function retrieves a set from Redis, deserializing the data using either pickle or dill depending on the specified data type. If the data is None, it returns an empty set. The `addToRedisCachedSet` function adds an item to a Redis cached set after first retrieving the existing set and updating it with the new item before saving it back to Redis. Both functions support debug mode and have default values for host, port, and data type (dill).",
        "type": "comment"
    },
    "384": {
        "file_id": 17,
        "content": "    )\n    cachedSet.add(item)\n    setRedisValueByKey(setName, cachedSet, dataType=dataType, host=host, port=port)\n    return cachedSet\ndef shuffleAndPopFromList(mlist):\n    import random\n    random.shuffle(mlist)\n    return mlist.pop(0)\ndef getMediaBitrate(mediaPath, audioOnly=False, videoOnly=False):\n    # demo output:\n    # {'programs': [], 'streams': [{'bit_rate': '130770'}]}\n    commandArguments = [\n        \"ffprobe\",\n        \"-i\",\n        mediaPath,\n        \"-v\",\n        \"quiet\",\n    ]\n    if audioOnly:\n        commandArguments += [\n            \"-select_streams\",\n            \"a:0\",\n        ]\n    elif videoOnly:\n        commandArguments += [\n            \"-select_streams\",\n            \"v:0\",\n        ]\n    commandArguments += [\n        \"-show_entries\",\n        \"stream=bit_rate\",\n        \"-hide_banner\",\n        \"-print_format\",\n        \"json\",\n    ]\n    result = subprocess.run(commandArguments, capture_output=True, encoding=\"UTF-8\")\n    stdout = result.stdout\n    stderr = result.stderr\n    try:\n        assert result.returncode == 0",
        "type": "code",
        "location": "/pyjom/commons.py:211-255"
    },
    "385": {
        "file_id": 17,
        "content": "1. Defines functions for caching, shuffling lists, and retrieving media bitrate.\n2. Uses Redis to store sets of data with configurable host and port.\n3. Shuffles a list of items and returns the first item in the new order.\n4. Retrieves the bitrate of a video or audio stream using ffprobe, then prints it in JSON format.",
        "type": "comment"
    },
    "386": {
        "file_id": 17,
        "content": "        stdout_json = json.loads(stdout)\n        return stdout_json\n    except:\n        import traceback\n        traceback.print_exc()\n        print(\"potential error logs:\")\n        print(stderr)\n        print(\"error when getting media bitrate\")\n        return {}\ndef getFileExtensionToMeaningDictFromString(inputString):\n    inputStringList = inputString.split(\"\\n\")\n    fileExtensionToMeaningDict = {}\n    for line in inputStringList:\n        line = line.strip()\n        if len(line) < 5:\n            continue\n        # try:\n        meaning, extensions = line.split(\" - \")  # problem fixed.\n        # except:\n        #     print('line:',[line])\n        #     breakpoint()\n        meaning = meaning.strip()\n        extensions = extensions.split(\" or \")\n        for extension in extensions:\n            extension = extension.strip()\n            if len(extension) > 0:\n                fileExtensionToMeaningDict.update({extension: meaning})\n    return fileExtensionToMeaningDict\n@lru_cache(maxsize=1)\ndef getMediaFileExtensionToMeaningDict():",
        "type": "code",
        "location": "/pyjom/commons.py:256-290"
    },
    "387": {
        "file_id": 17,
        "content": "This code loads a JSON from stdout, handles potential errors by printing them and returns an empty dictionary. It also defines a function to create a file extension to meaning dictionary using input string lines. Lastly, it caches a media file extension to meaning dictionary with the help of @lru_cache decorator.",
        "type": "comment"
    },
    "388": {
        "file_id": 17,
        "content": "    # no input needed.\n    videoExtensions = \"\"\"MP4 or MPEG4 video file - .mp4\n264 video file - .h264\nAVI video file - .avi\nMKV or Matroska Multimedia Container - .mkv\nMPEG video file - .mpeg or .mpg\nMOV or Apple QuickTime video file - .mov\nApple MP4 video file - .m4v\nAdobe flash video - .flv\n3GP video file - .3gp\nWindows Media Video file - .wmv\nDVD Video Object - .vob\"\"\"\n    imageExtensions = \"\"\"JPEG image - .jpeg or .jpg\nPNG image - .png\nGIF image - .gif\nPhotoshop or PSD image - .psd\nAdobe Illustrator image - .ai\nTIFF image - .tif or .tiff\"\"\"\n    documentExtensions = \"\"\"Microsoft Word file - .doc or .docx\nPDF file - .pdf\nText file - .txt\nMicrosoft Excel file - .xls\nMicrosoft Excel Open XML file - .xlsx\nMicrosoft Excel file with macros - .xlsm\nMicrosoft PowerPoint presentation - .ppt\nMicrosoft PowerPoint slide show - .pps\nMicrosoft PowerPoint Open XML presentation - .pptx\"\"\"\n    audioExtensions = \"\"\"MP3 audio file - .mp3\nAAC audio file - .aac\nAC3 audio file - .ac3\nWAV audio file - .wav\nWMA audio file - .wma\nOgg Vorbis audio file - .ogg",
        "type": "code",
        "location": "/pyjom/commons.py:291-323"
    },
    "389": {
        "file_id": 17,
        "content": "The code defines various file extensions for video, image, document, and audio formats. It includes common extension types for each category, allowing the codebase to identify and handle different file types appropriately.",
        "type": "comment"
    },
    "390": {
        "file_id": 17,
        "content": "MIDI audio file - .midi or .mid\nCD audio file - .cda\nAIF audio file - .aif\"\"\"\n    mapping = [\n        (\"video\", videoExtensions),\n        (\"audio\", audioExtensions),\n        (\"image\", imageExtensions),  # gif could be video.\n        (\"document\", documentExtensions),\n    ]\n    mediaFileExtensionToMeaningDict = {\n        key: getFileExtensionToMeaningDictFromString(value) for key, value in mapping\n    }\n    return mediaFileExtensionToMeaningDict\ndef determineMediaTypeByExtension(extension):\n    extension = extension.strip()\n    if not extension.startswith(\".\"):\n        extension = \".\" + extension\n    extension_lower = extension.lower()\n    # this has to be cached.\n    mediaFileExtensionToMeaningDict = getMediaFileExtensionToMeaningDict()\n    for (\n        mediaType,\n        fileExtensionToMeaningDict,\n    ) in mediaFileExtensionToMeaningDict.items():\n        for fileExtension, meaning in fileExtensionToMeaningDict.items():\n            if fileExtension.lower == extension_lower:\n                return mediaType\n    return \"unknown\"",
        "type": "code",
        "location": "/pyjom/commons.py:324-353"
    },
    "391": {
        "file_id": 17,
        "content": "This code defines a function getMediaFileExtensionToMeaningDict() that maps file extensions to their meanings (video, audio, image, document). It also includes a determineMediaTypeByExtension() function which takes an extension as input, checks it against the mapping and returns the corresponding media type. This code suggests that caching is necessary for efficiency.",
        "type": "comment"
    },
    "392": {
        "file_id": 17,
        "content": "def corruptMediaFilter(\n    mediaPath, tag: str = \"media\", bad_words: list[str] = [\"invalid\", \"failed\", \"error\"]\n):\n    if not os.path.exists(mediaPath):\n        print(\"{} file does not exist\".format(tag))\n    import ffmpeg\n    not_nice = [word.lower() for word in bad_words]\n    corrupted = False\n    try:\n        stdout, stderr = (\n            ffmpeg.input(mediaPath)\n            .output(\"null\", f=\"null\")\n            .run(capture_stdout=True, capture_stderr=True)\n        )\n        stderr_lower = stderr.decode(\"utf-8\").lower()\n        for word in not_nice:\n            if word in stderr_lower:\n                print(\"{} is corrupted\".format(tag))\n                corrupted = True\n                break\n    except:\n        import traceback\n        traceback.print_exc()\n        corrupted = True\n        print(\"corrupt {}\".format(tag))\n    if not corrupted:\n        print(\"video is fine\")\n    # return True for fine video.\n    valid = not corrupted\n    sprint(\"{} file path:\".format(tag), mediaPath)\n    return valid\n## bring about 'redis cache' for faster testing.",
        "type": "code",
        "location": "/pyjom/commons.py:356-392"
    },
    "393": {
        "file_id": 17,
        "content": "This function named 'corruptMediaFilter' takes the path of a media file and checks for potentially corrupted content by scanning the ffmpeg output. If any 'bad words' found in stderr, it considers the file corrupted. If no issues found, it declares the video as fine and returns True. It also prints status updates to stdout about file existence, corruption status, and video condition.",
        "type": "comment"
    },
    "394": {
        "file_id": 17,
        "content": "import redis\nfrom redis_lru import RedisLRU\n# from functools import lru_cache\noneDay = 60 * 60 * 24  # one day?\nredisExpire = oneDay * 7  # god damn it!\n# @lru_cache(maxsize=1)\ndef redisLRUCache(\n    ttl=redisExpire,\n    redisAddress=\"127.0.0.1\",\n    redisPort=commonRedisPort,\n    max_size=20,\n    debug=True,\n):\n    client = redis.StrictRedis(host=redisAddress, port=redisPort)\n    cache = RedisLRU(client, max_size=max_size, debug=debug)\n    return cache(ttl=ttl)\n# this is root. this is not site-packages.\ndef frameSizeFilter(frameMeta, frame_size_filter):\n    width, height = frameMeta[\"width\"], frameMeta[\"height\"]\n    flagWidth, (minWidth, maxWidth) = checkMinMaxDict(\n        width, frame_size_filter.get(\"width\", {}), getMinMaxVal=True\n    )  # type: ignore\n    flagHeight, (minHeight, maxHeight) = checkMinMaxDict(\n        height, frame_size_filter.get(\"height\", {}), getMinMaxVal=True\n    )  # type: ignore\n    if not (flagWidth and flagHeight):\n        print(\"Filter out invalid video with shape of {}x{}\".format(width, height))",
        "type": "code",
        "location": "/pyjom/commons.py:393-423"
    },
    "395": {
        "file_id": 17,
        "content": "This code defines a function `redisLRUCache` that utilizes Redis LRU cache for storing data with Time-To-Live (TTL) and optional parameters like TTL, redisAddress, redisPort, max_size, and debug. It also includes a helper function `frameSizeFilter` that checks the dimensions of a frame against specified width and height ranges from a frame_size_filter dictionary. If both dimensions are filtered out, it prints a message indicating an invalid video shape.",
        "type": "comment"
    },
    "396": {
        "file_id": 17,
        "content": "        print(\n            \"Valid Width and Height are {}-{}x{}-{}\".format(\n                minWidth, maxWidth, minHeight, maxHeight\n            )\n        )\n        return False\n    return True\n# site_path = pathlib.Path([x for x in site.getsitepackages() if \"site-packages\" in x][0])\nos.environ[\"USE_NVIDIA_OPENCV\"] = \"yes\"\nif os.environ[\"USE_NVIDIA_OPENCV\"] == \"yes\":\n    site_path = pathlib.Path(\"/usr/local/lib/python3.9/site-packages\")\n    cv2_libs_dir = (\n        site_path / \"cv2\" / f\"python-{sys.version_info.major}.{sys.version_info.minor}\"\n    )\n    print(cv2_libs_dir)\n    cv2_libs = sorted(cv2_libs_dir.glob(\"*.so\"))\n    if len(cv2_libs) == 1:\n        print(\"INSERTING:\", cv2_libs[0].parent)\n        sys.path.insert(1, str(cv2_libs[0].parent))\nmimetypes.init()\ndef waitForServerUp(\n    port, message, timeout=1, messageLength: Union[None, int] = None  # for netease.\n):  # this messageLength is the length of the binary message.\n    import requests\n    while True:\n        try:\n            url = \"http://localhost:{}\".format(port)",
        "type": "code",
        "location": "/pyjom/commons.py:424-457"
    },
    "397": {
        "file_id": 17,
        "content": "This code checks if the OpenCV library is installed correctly and sets the system path accordingly. It also initializes mimetypes and defines a function waitForServerUp that makes HTTP requests to localhost on a specified port, waiting for a response until the timeout is reached. The function accepts optional parameters for message and messageLength (for netease).",
        "type": "comment"
    },
    "398": {
        "file_id": 17,
        "content": "            with requests.get(url, timeout=timeout) as r:\n                if messageLength is not None:\n                    contentLength = len(r.content)\n                    if messageLength <= contentLength:\n                        break\n                else:\n                    if type(message) == str:\n                        text = r.text.strip('\"').strip(\"'\")\n                    else:\n                        text = r.json()\n                    print(\"SERVER AT PORT %d RESPONDS:\" % port, [text])\n                    assert text == message\n                    print(\"SERVER AT PORT %d IS UP\" % port)\n                    break\n        except:\n            import traceback\n            traceback.print_exc()\n            print(\"SERVER AT PORT %d MIGHT NOT BE UP\" % port)\n            print(\"EXPECTED MESSAGE:\", [message])\n            import time\n            time.sleep(1)\nclass D2Point:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\ndef doRectOverlap(l1, r1, l2, r2):\n    # if rectangle has area 0, no overlap",
        "type": "code",
        "location": "/pyjom/commons.py:458-490"
    },
    "399": {
        "file_id": 17,
        "content": "Code fetches a message from server using URL, checks its length against expected length and prints the received response. If there is a mismatch, it raises an error. If the connection fails, it waits for a second before trying again.",
        "type": "comment"
    }
}