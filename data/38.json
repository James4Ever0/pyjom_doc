{
    "3800": {
        "file_id": 476,
        "content": "        } catch (e) {\n            console.log(e)\n            res.json({ message: 'error' })\n        }\n    }\n})\nconst load_model = async() => {\n    _model = await nsfw.load()\n}\n// Keep the model in memory, make sure it's loaded only once\nload_model().then(() => {\n    console.log('server ready')\n    app.listen(8511)\n})\n// curl --request POST localhost:8080/nsfw --header 'Content-Type: multipart/form-data' --data-binary 'image=@/full/path/to/picture.jpg'",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:91-109"
    },
    "3801": {
        "file_id": 476,
        "content": "The code loads an NSFW image detection model, ensures it's only loaded once, and starts a server on port 8511. It accepts POST requests with image data from the client.",
        "type": "comment"
    },
    "3802": {
        "file_id": 477,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js",
        "type": "filepath"
    },
    "3803": {
        "file_id": 477,
        "content": "The function creates a color mask, processes BMP file header info, handles compression types, and supports various color formats. The code converts images to TensorFlow tensor3d arrays, handles file uploads, loads an NSFW model for classification, and runs on port 8511.",
        "type": "summary"
    },
    "3804": {
        "file_id": 477,
        "content": "// import { createRequire } from \"module\";\n// const require = createRequire(import.meta.url);\n// now we are talking\nfunction maskColor(maskRed, maskGreen, maskBlue, maskAlpha) {\n    const maskRedR = (~maskRed + 1) & maskRed;\n    const maskGreenR = (~maskGreen + 1) & maskGreen;\n    const maskBlueR = (~maskBlue + 1) & maskBlue;\n    const maskAlphaR = (~maskAlpha + 1) & maskAlpha;\n    const shiftedMaskRedL = maskRed / maskRedR + 1;\n    const shiftedMaskGreenL = maskGreen / maskGreenR + 1;\n    const shiftedMaskBlueL = maskBlue / maskBlueR + 1;\n    const shiftedMaskAlphaL = maskAlpha / maskAlphaR + 1;\n    return {\n        shiftRed: (x) => (((x & maskRed) / maskRedR) * 0x100) / shiftedMaskRedL,\n        shiftGreen: (x) => (((x & maskGreen) / maskGreenR) * 0x100) / shiftedMaskGreenL,\n        shiftBlue: (x) => (((x & maskBlue) / maskBlueR) * 0x100) / shiftedMaskBlueL,\n        shiftAlpha: maskAlpha !== 0 ?\n            (x) => (((x & maskAlpha) / maskAlphaR) * 0x100) / shiftedMaskAlphaL :\n            () => 255\n    };",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:1-22"
    },
    "3805": {
        "file_id": 477,
        "content": "This function takes four parameters (maskRed, maskGreen, maskBlue, and maskAlpha) to create a color mask. It performs bitwise operations and calculations to shift the color values and returns an object with functions to shift red, green, blue, and alpha components of any given value. If maskAlpha is not zero, it also returns an additional function for shifting alpha values.",
        "type": "comment"
    },
    "3806": {
        "file_id": 477,
        "content": "}\nvar HeaderTypes;\n(function(HeaderTypes) {\n    HeaderTypes[HeaderTypes[\"BITMAP_INFO_HEADER\"] = 40] = \"BITMAP_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V2_INFO_HEADER\"] = 52] = \"BITMAP_V2_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V3_INFO_HEADER\"] = 56] = \"BITMAP_V3_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V4_HEADER\"] = 108] = \"BITMAP_V4_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V5_HEADER\"] = 124] = \"BITMAP_V5_HEADER\";\n})(HeaderTypes || (HeaderTypes = {}));\nclass BmpDecoder {\n    constructor(buffer, { toRGBA } = { toRGBA: false }) {\n        this.buffer = buffer;\n        this.toRGBA = !!toRGBA;\n        this.pos = 0;\n        this.bottomUp = true;\n        this.flag = this.buffer.toString('utf-8', 0, (this.pos += 2));\n        if (this.flag !== 'BM') {\n            throw new Error('Invalid BMP File');\n        }\n        this.locRed = this.toRGBA ? 0 : 3;\n        this.locGreen = this.toRGBA ? 1 : 2;\n        this.locBlue = this.toRGBA ? 2 : 1;\n        this.locAlpha = this.toRGBA ? 3 : 0;\n        this.parseHeader();",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:23-48"
    },
    "3807": {
        "file_id": 477,
        "content": "Class BmpDecoder is created with a buffer and optional toRGBA parameter, which determines the pixel data format. The constructor initializes variables, checks for valid file signature, and sets location indices for RGB(A) values based on toRGBA flag. parseHeader function will be called next.",
        "type": "comment"
    },
    "3808": {
        "file_id": 477,
        "content": "        this.parseRGBA();\n    }\n    parseHeader() {\n        this.fileSize = this.readUInt32LE();\n        this.reserved1 = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.reserved2 = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.offset = this.readUInt32LE();\n        // End of BITMAP_FILE_HEADER\n        this.headerSize = this.readUInt32LE();\n        if (!(this.headerSize in HeaderTypes)) {\n            throw new Error(`Unsupported BMP header size ${this.headerSize}`);\n        }\n        this.width = this.readUInt32LE();\n        this.height = this.readUInt32LE();\n        this.planes = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.bitPP = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.compression = this.readUInt32LE();\n        this.rawSize = this.readUInt32LE();\n        this.hr = this.readUInt32LE();\n        this.vr = this.readUInt32LE();\n        this.colors = this.readUInt32LE();\n        this.importantColors = this.readUInt32LE();",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:49-74"
    },
    "3809": {
        "file_id": 477,
        "content": "The code reads and parses the BMP file header information. It begins by reading and setting values for file size, reserved bytes, and offset. Then it checks the header size to ensure compatibility before proceeding to read and set values for width, height, planes, bits per pixel, compression type, raw data size, and color depth.",
        "type": "comment"
    },
    "3810": {
        "file_id": 477,
        "content": "        // De facto defaults\n        if (this.bitPP === 32) {\n            this.maskAlpha = 0;\n            this.maskRed = 0x00ff0000;\n            this.maskGreen = 0x0000ff00;\n            this.maskBlue = 0x000000ff;\n        } else if (this.bitPP === 16) {\n            this.maskAlpha = 0;\n            this.maskRed = 0x7c00;\n            this.maskGreen = 0x03e0;\n            this.maskBlue = 0x001f;\n        }\n        // End of BITMAP_INFO_HEADER\n        if (this.headerSize > HeaderTypes.BITMAP_INFO_HEADER ||\n            this.compression === 3 /* BI_BIT_FIELDS */ ||\n            this.compression === 6 /* BI_ALPHA_BIT_FIELDS */ ) {\n            this.maskRed = this.readUInt32LE();\n            this.maskGreen = this.readUInt32LE();\n            this.maskBlue = this.readUInt32LE();\n        }\n        // End of BITMAP_V2_INFO_HEADER\n        if (this.headerSize > HeaderTypes.BITMAP_V2_INFO_HEADER ||\n            this.compression === 6 /* BI_ALPHA_BIT_FIELDS */ ) {\n            this.maskAlpha = this.readUInt32LE();\n        }\n        // End of BITMAP_V3_INFO_HEADER",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:75-100"
    },
    "3811": {
        "file_id": 477,
        "content": "The code checks the bitPP value and sets default mask values accordingly. It then verifies if the headerSize exceeds specific limits or if the compression type is BI_BIT_FIELDS or BI_ALPHA_BIT_FIELDS, in which case it reads and assigns mask values. This code handles different header types and compression types to set appropriate mask values for image processing.",
        "type": "comment"
    },
    "3812": {
        "file_id": 477,
        "content": "        if (this.headerSize > HeaderTypes.BITMAP_V3_INFO_HEADER) {\n            this.pos +=\n                HeaderTypes.BITMAP_V4_HEADER - HeaderTypes.BITMAP_V3_INFO_HEADER;\n        }\n        // End of BITMAP_V4_HEADER\n        if (this.headerSize > HeaderTypes.BITMAP_V4_HEADER) {\n            this.pos += HeaderTypes.BITMAP_V5_HEADER - HeaderTypes.BITMAP_V4_HEADER;\n        }\n        // End of BITMAP_V5_HEADER\n        if (this.bitPP <= 8 || this.colors > 0) {\n            const len = this.colors === 0 ? 1 << this.bitPP : this.colors;\n            this.palette = new Array(len);\n            for (let i = 0; i < len; i++) {\n                const blue = this.buffer.readUInt8(this.pos++);\n                const green = this.buffer.readUInt8(this.pos++);\n                const red = this.buffer.readUInt8(this.pos++);\n                const quad = this.buffer.readUInt8(this.pos++);\n                this.palette[i] = {\n                    red,\n                    green,\n                    blue,\n                    quad\n                };",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:101-123"
    },
    "3813": {
        "file_id": 477,
        "content": "This code handles different header types in a file format. It checks the header size and adjusts the position accordingly for BITMAP_V4_HEADER and BITMAP_V5_HEADER. If bitPP is less than or equal to 8 or colors are 0, it creates a palette array by reading RGB values and quad value from the buffer.",
        "type": "comment"
    },
    "3814": {
        "file_id": 477,
        "content": "            }\n        }\n        // End of color table\n        // Can the height ever be negative?\n        if (this.height < 0) {\n            this.height *= -1;\n            this.bottomUp = false;\n        }\n        const coloShift = maskColor(this.maskRed, this.maskGreen, this.maskBlue, this.maskAlpha);\n        this.shiftRed = coloShift.shiftRed;\n        this.shiftGreen = coloShift.shiftGreen;\n        this.shiftBlue = coloShift.shiftBlue;\n        this.shiftAlpha = coloShift.shiftAlpha;\n    }\n    parseRGBA() {\n        this.data = Buffer.alloc(this.width * this.height * 4);\n        switch (this.bitPP) {\n            case 1:\n                this.bit1();\n                break;\n            case 4:\n                this.bit4();\n                break;\n            case 8:\n                this.bit8();\n                break;\n            case 16:\n                this.bit16();\n                break;\n            case 24:\n                this.bit24();\n                break;\n            default:\n                this.bit32();\n        }\n    }",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:124-159"
    },
    "3815": {
        "file_id": 477,
        "content": "The code initializes variables based on the given color table, checks if the height is negative and adjusts accordingly. It then calculates RGBA shift values for subsequent image parsing based on the bit-per-pixel value provided.",
        "type": "comment"
    },
    "3816": {
        "file_id": 477,
        "content": "    bit1() {\n        const xLen = Math.ceil(this.width / 8);\n        const mode = xLen % 4;\n        const padding = mode !== 0 ? 4 - mode : 0;\n        let lastLine;\n        this.scanImage(padding, xLen, (x, line) => {\n            if (line !== lastLine) {\n                lastLine = line;\n            }\n            const b = this.buffer.readUInt8(this.pos++);\n            const location = line * this.width * 4 + x * 8 * 4;\n            for (let i = 0; i < 8; i++) {\n                if (x * 8 + i < this.width) {\n                    const rgb = this.palette[(b >> (7 - i)) & 0x1];\n                    this.data[location + i * this.locAlpha] = 0;\n                    this.data[location + i * 4 + this.locBlue] = rgb.blue;\n                    this.data[location + i * 4 + this.locGreen] = rgb.green;\n                    this.data[location + i * 4 + this.locRed] = rgb.red;\n                } else {\n                    break;\n                }\n            }\n        });\n    }\n    bit4() {\n        if (this.compression === 2 /* BI_RLE4 */ ) {",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:160-185"
    },
    "3817": {
        "file_id": 477,
        "content": "This function reads the image data in 8-bit chunks (bit1) and converts it into RGBA format. The width of the image is divided into segments of 8 bits, and based on the mode (remainder when width is divided by 4), padding is applied. The scanImage method reads the bits in lines and processes each bit using a for loop to extract red, green, and blue values from the palette and assign them to their respective locations in the data array. If the compression type is BI_RLE4 (bit4 function), it indicates that the image uses RLE4 compression.",
        "type": "comment"
    },
    "3818": {
        "file_id": 477,
        "content": "            this.data.fill(0);\n            let lowNibble = false; //for all count of pixel\n            let lines = this.bottomUp ? this.height - 1 : 0;\n            let location = 0;\n            while (location < this.data.length) {\n                const a = this.buffer.readUInt8(this.pos++);\n                const b = this.buffer.readUInt8(this.pos++);\n                //absolute mode\n                if (a === 0) {\n                    if (b === 0) {\n                        //line end\n                        lines += this.bottomUp ? -1 : 1;\n                        location = lines * this.width * 4;\n                        lowNibble = false;\n                        continue;\n                    }\n                    if (b === 1) {\n                        // image end\n                        break;\n                    }\n                    if (b === 2) {\n                        // offset x, y\n                        const x = this.buffer.readUInt8(this.pos++);\n                        const y = this.buffer.readUInt8(this.pos++);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:186-209"
    },
    "3819": {
        "file_id": 477,
        "content": "This code reads an image file's metadata and processes it. It initializes the data array with zeros, handles absolute mode for lines and pixel positions, checks for line end and image end conditions, and reads offset values for x and y coordinates.",
        "type": "comment"
    },
    "3820": {
        "file_id": 477,
        "content": "                        lines += this.bottomUp ? -y : y;\n                        location += y * this.width * 4 + x * 4;\n                    } else {\n                        let c = this.buffer.readUInt8(this.pos++);\n                        for (let i = 0; i < b; i++) {\n                            location = this.setPixelData(location, lowNibble ? c & 0x0f : (c & 0xf0) >> 4);\n                            if (i & 1 && i + 1 < b) {\n                                c = this.buffer.readUInt8(this.pos++);\n                            }\n                            lowNibble = !lowNibble;\n                        }\n                        if ((((b + 1) >> 1) & 1) === 1) {\n                            this.pos++;\n                        }\n                    }\n                } else {\n                    //encoded mode\n                    for (let i = 0; i < a; i++) {\n                        location = this.setPixelData(location, lowNibble ? b & 0x0f : (b & 0xf0) >> 4);\n                        lowNibble = !lowNibble;\n                    }",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:210-230"
    },
    "3821": {
        "file_id": 477,
        "content": "This code handles image data encoding and decoding. It checks the mode (encoded or not) to determine how to process the pixel data. For unencoded mode, it calculates coordinates and updates location by reading bytes from the buffer. In encoded mode, it processes blocks of pixels using low nibble bit manipulation. The code also handles odd-sized blocks by incrementing the position in the buffer.",
        "type": "comment"
    },
    "3822": {
        "file_id": 477,
        "content": "                }\n            }\n        } else {\n            const xLen = Math.ceil(this.width / 2);\n            const mode = xLen % 4;\n            const padding = mode !== 0 ? 4 - mode : 0;\n            this.scanImage(padding, xLen, (x, line) => {\n                const b = this.buffer.readUInt8(this.pos++);\n                const location = line * this.width * 4 + x * 2 * 4;\n                const first4 = b >> 4;\n                let rgb = this.palette[first4];\n                this.data[location] = 0;\n                this.data[location + 1] = rgb.blue;\n                this.data[location + 2] = rgb.green;\n                this.data[location + 3] = rgb.red;\n                if (x * 2 + 1 >= this.width) {\n                    // throw new Error('Something');\n                    return false;\n                }\n                const last4 = b & 0x0f;\n                rgb = this.palette[last4];\n                this.data[location + 4] = 0;\n                this.data[location + 4 + 1] = rgb.blue;\n                this.data[location + 4 + 2] = rgb.green;",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:231-254"
    },
    "3823": {
        "file_id": 477,
        "content": "This code initializes the image scanning process for a specific region, reading and setting pixel colors based on their respective nibbles. The padding is determined by the mode of the width divided by 2, and the image data is updated accordingly.",
        "type": "comment"
    },
    "3824": {
        "file_id": 477,
        "content": "                this.data[location + 4 + 3] = rgb.red;\n            });\n        }\n    }\n    bit8() {\n        if (this.compression === 1 /* BI_RLE8 */ ) {\n            this.data.fill(0);\n            let lines = this.bottomUp ? this.height - 1 : 0;\n            let location = 0;\n            while (location < this.data.length) {\n                const a = this.buffer.readUInt8(this.pos++);\n                const b = this.buffer.readUInt8(this.pos++);\n                //absolute mode\n                if (a === 0) {\n                    if (b === 0) {\n                        //line end\n                        lines += this.bottomUp ? -1 : 1;\n                        location = lines * this.width * 4;\n                        continue;\n                    }\n                    if (b === 1) {\n                        //image end\n                        break;\n                    }\n                    if (b === 2) {\n                        //offset x,y\n                        const x = this.buffer.readUInt8(this.pos++);\n                        const y = this.buffer.readUInt8(this.pos++);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:255-282"
    },
    "3825": {
        "file_id": 477,
        "content": "This code implements a RLE8 compression for image data. It iterates through the compressed data, decoding absolute mode values to populate an array with pixel values (RGB). When it encounters line end or image end markers, it adjusts the location accordingly.",
        "type": "comment"
    },
    "3826": {
        "file_id": 477,
        "content": "                        lines += this.bottomUp ? -y : y;\n                        location += y * this.width * 4 + x * 4;\n                    } else {\n                        for (let i = 0; i < b; i++) {\n                            const c = this.buffer.readUInt8(this.pos++);\n                            location = this.setPixelData(location, c);\n                        }\n                        // @ts-ignore\n                        const shouldIncrement = b & (1 === 1);\n                        if (shouldIncrement) {\n                            this.pos++;\n                        }\n                    }\n                } else {\n                    //encoded mode\n                    for (let i = 0; i < a; i++) {\n                        location = this.setPixelData(location, b);\n                    }\n                }\n            }\n        } else {\n            const mode = this.width % 4;\n            const padding = mode !== 0 ? 4 - mode : 0;\n            this.scanImage(padding, this.width, (x, line) => {\n                const b = this.buffer.readUInt8(this.pos++);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:283-307"
    },
    "3827": {
        "file_id": 477,
        "content": "This code processes image pixel data based on its mode and other conditions. It updates the location and buffer positions accordingly, applies specific functions to set pixel data depending on mode, and increments pos if necessary.",
        "type": "comment"
    },
    "3828": {
        "file_id": 477,
        "content": "                const location = line * this.width * 4 + x * 4;\n                if (b < this.palette.length) {\n                    const rgb = this.palette[b];\n                    this.data[location] = 0;\n                    this.data[location + 1] = rgb.blue;\n                    this.data[location + 2] = rgb.green;\n                    this.data[location + 3] = rgb.red;\n                } else {\n                    this.data[location] = 0;\n                    this.data[location + 1] = 0xff;\n                    this.data[location + 2] = 0xff;\n                    this.data[location + 3] = 0xff;\n                }\n            });\n        }\n    }\n    bit16() {\n        const padding = (this.width % 2) * 2;\n        this.scanImage(padding, this.width, (x, line) => {\n            const loc = line * this.width * 4 + x * 4;\n            const px = this.buffer.readUInt16LE(this.pos);\n            this.pos += 2;\n            this.data[loc + this.locRed] = this.shiftRed(px);\n            this.data[loc + this.locGreen] = this.shiftGreen(px);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:308-331"
    },
    "3829": {
        "file_id": 477,
        "content": "Calculates the pixel location in the image data based on x and y coordinates. If the pixel index is within the palette range, sets RGB values from the palette; otherwise, sets all values to 255. Utilizes bit16 method for processing pixels in groups of two.",
        "type": "comment"
    },
    "3830": {
        "file_id": 477,
        "content": "            this.data[loc + this.locBlue] = this.shiftBlue(px);\n            this.data[loc + this.locAlpha] = this.shiftAlpha(px);\n        });\n    }\n    bit24() {\n        const padding = this.width % 4;\n        this.scanImage(padding, this.width, (x, line) => {\n            const loc = line * this.width * 4 + x * 4;\n            const blue = this.buffer.readUInt8(this.pos++);\n            const green = this.buffer.readUInt8(this.pos++);\n            const red = this.buffer.readUInt8(this.pos++);\n            this.data[loc + this.locRed] = red;\n            this.data[loc + this.locGreen] = green;\n            this.data[loc + this.locBlue] = blue;\n            this.data[loc + this.locAlpha] = 0;\n        });\n    }\n    bit32() {\n        this.scanImage(0, this.width, (x, line) => {\n            const loc = line * this.width * 4 + x * 4;\n            const px = this.readUInt32LE();\n            this.data[loc + this.locRed] = this.shiftRed(px);\n            this.data[loc + this.locGreen] = this.shiftGreen(px);\n            this.data[loc + this.locBlue] = this.shiftBlue(px);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:332-355"
    },
    "3831": {
        "file_id": 477,
        "content": "This code snippet is part of an image processing library that supports various color formats (bit24, bit32). The bit24 function processes pixels in a 24-bit RGB format and sets the alpha channel to 0. The bit32 function reads pixel values in a 32-bit RGBA format and directly assigns the RGB values while setting the alpha channel to an undefined value. These functions iterate through each pixel of the image and store their respective color data in the \"data\" array.",
        "type": "comment"
    },
    "3832": {
        "file_id": 477,
        "content": "            this.data[loc + this.locAlpha] = this.shiftAlpha(px);\n        });\n    }\n    scanImage(padding = 0, width = this.width, processPixel) {\n        for (let y = this.height - 1; y >= 0; y--) {\n            const line = this.bottomUp ? y : this.height - 1 - y;\n            for (let x = 0; x < width; x++) {\n                const result = processPixel.call(this, x, line);\n                if (result === false) {\n                    return;\n                }\n            }\n            this.pos += padding;\n        }\n    }\n    readUInt32LE() {\n        const value = this.buffer.readUInt32LE(this.pos);\n        this.pos += 4;\n        return value;\n    }\n    setPixelData(location, rgbIndex) {\n        const { blue, green, red } = this.palette[rgbIndex];\n        this.data[location + this.locAlpha] = 0;\n        this.data[location + 1 + this.locBlue] = blue;\n        this.data[location + 2 + this.locGreen] = green;\n        this.data[location + 3 + this.locRed] = red;\n        return location + 4;\n    }\n}\nconst express = require('express')",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:356-386"
    },
    "3833": {
        "file_id": 477,
        "content": "This code defines a class with methods for image processing, including scanning an image line by line and setting pixel data. The class uses a buffer to store data, and has properties such as locAlpha, locBlue, locGreen, and locRed for organizing the data in the buffer. It also utilizes the express module from the Node.js framework.",
        "type": "comment"
    },
    "3834": {
        "file_id": 477,
        "content": "const multer = require('multer')\nconst jpeg = require('jpeg-js')\n    // const bmp = require('bmp-js')\n    // const bmp = require('bmp-ts').default;\n    // const bmpBuffer = fs.readFileSync('bit24.bmp');\nconst { PNG } = require('pngjs')\nconst tf = require('@tensorflow/tfjs-node')\nconst nsfw = require('nsfwjs')\nconst app = express()\nconst upload = multer()\nlet _model\n// this even works for gif!\n// it will normalize and resize the image if needed.\n// shall we check for gif?\nconst convert = async(img, type) => {\n    // Decoded image in UInt8 Byte array\n    let image\n    if (type == 'image/jpeg') {\n        image = await jpeg.decode(img, true)\n            // RGBA\n    } //wtf?\n    // order: rgba\n    else if (type == 'image/png') {\n        image = PNG.sync.read(img)\n    } else if (type == 'image/bmp') {\n        // image = await bmp.decode(img, true)\n        image = new BmpDecoder(img, { toRGBA: true });\n    }\n    const numChannels = 3\n    const numPixels = image.width * image.height // will raise an error if image is not acquired.",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:387-423"
    },
    "3835": {
        "file_id": 477,
        "content": "The code imports necessary libraries for image processing and model loading. It defines an asynchronous function \"convert\" to handle different image types (JPEG, PNG, BMP) and convert them into a standard RGBA format. The function reads the image using appropriate libraries based on its MIME type, determines the number of color channels and total pixels in the image.",
        "type": "comment"
    },
    "3836": {
        "file_id": 477,
        "content": "    const values = new Int32Array(numPixels * numChannels)\n        // are you sure about the width?\n    // can you make this faster? shit?\n    // this shit is no numpy. fuck.\n    for (let i = 0; i < numPixels; i++)\n        for (let c = 0; c < numChannels; ++c)\n        // if (type == 'bmp') {\n        //     // ABGR?\n        //     // values[i * numChannels + c] = image.data[i * 4+c]\n        //     values[i * numChannels + c] = image.data[i * 4 + 3 - c]\n        // } else {\n            values[i * numChannels + c] = image.data[i * 4 + c]\n            // }\n    return tf.tensor3d(values, [image.height, image.width, numChannels], 'int32')\n}\napp.get('/', async(req, res) => {\n    res.send('nsfw nodejs server')\n})\napp.post('/nsfw', upload.single('image'), async(req, res) => {\n    if (!req.file) res.status(400).send('Missing image multipart/form-data')\n    else {\n        try {\n            console.log('file uploaded:', req.file)\n            if (req.file.fieldname == 'image') {\n                type = req.file.mimetype // deal with it later.",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:424-452"
    },
    "3837": {
        "file_id": 477,
        "content": "This code defines a function that converts an image into a TensorFlow tensor3d array. It takes the number of pixels and channels as inputs, iterates over each pixel and channel, and assigns values from the image data to the tensor3d array based on the image's format (BMP or other). The function returns the resulting tensor3d array. The app also has two routes: a GET route that returns \"nsfw nodejs server\" and a POST route for handling image uploads, which logs the file information if it is an image.",
        "type": "comment"
    },
    "3838": {
        "file_id": 477,
        "content": "                extension = req.file.originalname.split(\".\").slice(-1)[0].toLowerCase()\n                if (extension == 'gif' || type == 'image/gif') {\n                    let image = req.file.buffer\n                    let predictions = await _model.classifyGif(image, { topk: 3, fps: 1 })\n                        // image.dispose()\n                    predictions.message = 'success'\n                    res.json(predictions)\n                } else {\n                    if (extension == 'bmp') {\n                        type = 'image/bmp'\n                    }\n                    let image = await convert(req.file.buffer, type) // here we have buffer.\n                    let predictions = await _model.classify(image)\n                    predictions.message = 'success'\n                        // image.dispose()\n                    res.json(predictions)\n                }\n            }\n            // we need some file format hints.\n        } catch (e) {\n            console.log(e)\n            res.json({ message: 'error' })",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:453-475"
    },
    "3839": {
        "file_id": 477,
        "content": "This code handles file uploads and classifies images based on their format. It checks if the image is a GIF, in which case it uses a specialized function for classification, otherwise it converts non-GIF images to a specified type and performs classification. The code catches any errors that occur during this process and sends an appropriate response.",
        "type": "comment"
    },
    "3840": {
        "file_id": 477,
        "content": "        }\n    }\n})\nconst load_model = async() => {\n    _model = await nsfw.load()\n}\n// Keep the model in memory, make sure it's loaded only once\nload_model().then(() => {\n    console.log('server ready')\n    app.listen(8511)\n})\n// curl --request POST localhost:8080/nsfw --header 'Content-Type: multipart/form-data' --data-binary 'image=@/full/path/to/picture.jpg'",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:476-491"
    },
    "3841": {
        "file_id": 477,
        "content": "The code loads an NSFW content detection model and keeps it in memory. It ensures the model is loaded only once and starts the server on port 8511. When a POST request with an image is received, the model classifies the content as NSFW or not.",
        "type": "comment"
    },
    "3842": {
        "file_id": 478,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js",
        "type": "filepath"
    },
    "3843": {
        "file_id": 478,
        "content": "This code imports TensorFlow and nsfwjs libraries, processes GIF frames at 1fps, loads a model for classification using predictions, and sets up a file stream to read data in chunks for partial processing.",
        "type": "summary"
    },
    "3844": {
        "file_id": 478,
        "content": "const tf = require('@tensorflow/tfjs-node')\nconst nsfw = require('nsfwjs')\n// predictions [\n//     [\n//       { className: 'Neutral', probability: 0.9845383167266846 },\n//       { className: 'Porn', probability: 0.009829860180616379 },\n//       { className: 'Drawing', probability: 0.003906613681465387 }\n//     ],\n//     [\n//       { className: 'Neutral', probability: 0.9763429760932922 },\n//       { className: 'Porn', probability: 0.014182578772306442 },\n//       { className: 'Drawing', probability: 0.007088858168572187 }\n//     ],\n//     [\n//       { className: 'Neutral', probability: 0.9598317742347717 },\n//       { className: 'Drawing', probability: 0.03286046162247658 },\n//       { className: 'Porn', probability: 0.003989457152783871 }\n//     ]\n//   ]\nfilepath = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n// mechanism: choose three most likely categories per chosen frame, process at 1fps.\n// no other classes?\n// filepath = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js:1-27"
    },
    "3845": {
        "file_id": 478,
        "content": "Code imports TensorFlow and nsfwjs libraries, and defines an array of prediction results for three frames. The filepath is set to \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\". The code chooses the top three categories from each frame, processes them at 1fps, and does not consider other classes.",
        "type": "comment"
    },
    "3846": {
        "file_id": 478,
        "content": "const fs = require('fs');\n// Store file data chunks in this array\nlet chunks = [];\n// We can use this variable to store the final data\nlet fileBuffer;\n// Read file into stream.Readable\nlet fileStream = fs.createReadStream(filepath);\n// An error occurred with the stream\nfileStream.once('error', (err) => {\n    // Be sure to handle this properly!\n    console.error(err);\n});\nlet _model\nconst load_model = async() => {\n    _model = await nsfw.load()\n    console.log('model ready')\n}\n// Keep the model in memory, make sure it's loaded only once\n// File is done being read\nfileStream.once('end', () => {\n    // create the final data Buffer from data chunks;\n    fileBuffer = Buffer.concat(chunks);\n    // do shit here.\n    console.log(\"filebuffer ready\")\n    load_model().then(() => {\n        _model.classifyGif(fileBuffer, { topk: 3, fps: 1 })\n            .then(predictions => console.log('predictions', predictions))\n            .catch(error => console.log('model error', error))\n    })\n    // Of course, you can do anything else you need to here, like emit an event!",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js:29-64"
    },
    "3847": {
        "file_id": 478,
        "content": "The code reads a file into a stream, stores it in chunks, combines the chunks into a final data buffer, and then loads a model to classify the GIF using its predictions. This allows for efficient processing of large files and accurate detection of content.",
        "type": "comment"
    },
    "3848": {
        "file_id": 478,
        "content": "});\n// Data is flushed from fileStream in chunks,\n// this callback will be executed for each chunk\nfileStream.on('data', (chunk) => {\n    chunks.push(chunk); // push data chunk to array\n    // We can perform actions on the partial data we have so far!\n});",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js:65-73"
    },
    "3849": {
        "file_id": 478,
        "content": "This code snippet sets up a file stream that reads data in chunks. The 'data' event triggers for each chunk, and pushes the chunk into an array (chunks). This allows performing actions on partial data as it arrives.",
        "type": "comment"
    },
    "3850": {
        "file_id": 479,
        "content": "/tests/nsfw_violence_drug_detection/launch_nodejs_server.sh",
        "type": "filepath"
    },
    "3851": {
        "file_id": 479,
        "content": "This line of code runs a JavaScript file named \"nsfwjs_test.js\" using the Node.js runtime environment. The purpose could be to execute tests or perform specific operations related to nsfw (not safe for work) detection, specifically for violence and drug-related content.",
        "type": "summary"
    },
    "3852": {
        "file_id": 479,
        "content": "node nsfwjs_test.js",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/launch_nodejs_server.sh:1-1"
    },
    "3853": {
        "file_id": 479,
        "content": "This line of code runs a JavaScript file named \"nsfwjs_test.js\" using the Node.js runtime environment. The purpose could be to execute tests or perform specific operations related to nsfw (not safe for work) detection, specifically for violence and drug-related content.",
        "type": "comment"
    },
    "3854": {
        "file_id": 480,
        "content": "/tests/nsfw_violence_drug_detection/init_nsfwjs.sh",
        "type": "filepath"
    },
    "3855": {
        "file_id": 480,
        "content": "Installing global dependencies for TF.js, nsfwjs, jpeg-js, express, and multer in the codebase.",
        "type": "summary"
    },
    "3856": {
        "file_id": 480,
        "content": "npm i -g @tensorflow/tfjs-node nsfwjs jpeg-js express multer",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/init_nsfwjs.sh:1-1"
    },
    "3857": {
        "file_id": 480,
        "content": "Installing global dependencies for TF.js, nsfwjs, jpeg-js, express, and multer in the codebase.",
        "type": "comment"
    },
    "3858": {
        "file_id": 481,
        "content": "/tests/motion_vector_estimation/test.sh",
        "type": "filepath"
    },
    "3859": {
        "file_id": 481,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "summary"
    },
    "3860": {
        "file_id": 481,
        "content": "bash ./run.sh python3.10 extract_mvs.py vid_h264.mp4 --preview --verbose",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.sh:1-1"
    },
    "3861": {
        "file_id": 481,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "comment"
    },
    "3862": {
        "file_id": 482,
        "content": "/tests/motion_vector_estimation/test.py",
        "type": "filepath"
    },
    "3863": {
        "file_id": 482,
        "content": "The code processes video frames and estimates motion vectors, then plots the results using matplotlib and handles potential errors. It uses pandas, numpy, and OpenCV for calculations.",
        "type": "summary"
    },
    "3864": {
        "file_id": 482,
        "content": "# it contains subpixel motion vectors. fucking hell\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# change source?\n# gif containers does not have motion vectors.\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n# without mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_without_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_without_mestimate.mp4\"\n# with mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"\nsource = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nfrom mvextractor.videocap import VideoCap",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:1-25"
    },
    "3865": {
        "file_id": 482,
        "content": "This code is setting the source video file path for various test cases involving motion vector estimation. The files include different types of videos such as MP4 and GIF, with and without mestimate data, and nearly duplicate frame detection tests. It also initializes custom CV2 build and imports necessary modules.",
        "type": "comment"
    },
    "3866": {
        "file_id": 482,
        "content": "from caer.video.frames_and_fps import count_frames, get_res\nimport cv2\nframesCount = count_frames(source)\nres = get_res(source)  # (width, height)\nprint(\"RES: %s\" % str(res))\nres_x, res_y = res\nframe_common_divisor = min(res_x, res_y)\nimport math\ndef cartesianDistance(d2vector):\n    try:\n        x, y = d2vector\n        return math.sqrt(x**2 + y**2)\n    except:\n        print('item unpackable.', d2vector)\n        return 0\ndef XYWHToDiagonal(x, y, w, h):\n    return (x, y), (x + w, y + h)\n# 如果整除16那么就在这个范围里面 如果不整除范围就要扩大 扩大到相应的16的倍数\ndef get16Value(res_x):\n    rem_x = res_x % 16\n    val = res_x // 16\n    if rem_x != 0:\n        val += 1\n    return val\nx_16val = get16Value(res_x)\ny_16val = get16Value(res_y)\nmotion_render_frame = (x_16val * 16, y_16val * 16)\ntotal_block_weights = x_16val * y_16val * 2 * 2\ncap = VideoCap()\ncap.open(source)  # wtf is going on here?\n# if there is nothing we will breakup\n# visualize, show_picture = True, True\nvisualize, show_picture = False, False\n# so there can only be one such macroblock\ndef checkMacroBlock(value):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:26-75"
    },
    "3867": {
        "file_id": 482,
        "content": "This code is initializing variables and functions related to video processing. It calculates the resolution of a source, determines if it's divisible by 16, adjusts if necessary, and sets up variables for motion vector estimation and visualization. The VideoCap class is opened but its functionality remains unclear. The checkMacroBlock function checks for one macroblock value.",
        "type": "comment"
    },
    "3868": {
        "file_id": 482,
        "content": "    for mod in [16, 8]:\n        modValue = value % mod\n        if modValue == mod / 2:\n            return mod\n    # if not satisfied, we are shit.\nfrom functools import lru_cache\n@lru_cache(maxsize=4)\ndef getModXModYFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = checkMacroBlock(block_x), checkMacroBlock(block_y)\n    if mod_x is not None and mod_y is not None:\n        return mod_x, mod_y\n    else:\n        print(\"block center coordinates\", blockCenterCoordinates)\n        print(\"WTF IS GOING ON WITH THE BLOCK CENTER\")\n        breakpoint()\n        return 0, 0\ndef getRectangleXYWHFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    mod_x_half, mod_y_half = mod_x / 2, mod_y / 2\n    x, y, w, h = block_x - mod_x_half, block_y - mod_y_half, mod_x, mod_y\n    return tuple([int(elem) for elem in [x, y, w, h]])\ndef getBlockWeightFromBlockCenterCoordinates(blockCenterCoordinates):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:76-107"
    },
    "3869": {
        "file_id": 482,
        "content": "This code defines several functions for handling block center coordinates in a specific context. It checks the modulo value of the coordinates to determine the size and position of the blocks, and uses these values to calculate the rectangle's dimensions and the block weight. The `lru_cache` decorator is used to cache the results of the `getModXModYFromBlockCenterCoordinates` function to improve performance.",
        "type": "comment"
    },
    "3870": {
        "file_id": 482,
        "content": "    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    weights = mod_x * mod_y / 8 / 8\n    return weights\nimport progressbar\nimport numpy as np\n# max_dst_x, max_dst_y = 0,0\ndef averageMotionVectors(motion_vector_list):\n    if len(motion_vector_list) == 0:\n        average_tuple = (0, 0)\n    if len(motion_vector_list) > 1:\n        marray = np.array(motion_vector_list)\n        # print(\"MAKING AVERAGE:\")\n        # print(marray)\n        average = np.average(marray, axis=0)\n        # breakpoint()\n        average_tuple = tuple(average)\n    else:\n        average_tuple = tuple(motion_vector_list[0])\n    return average_tuple\nmotion_area_ratio_array = []\n# average_weighted_motion_vector_array = []\n# average_global_weighted_motion_vector_array = []\naverage_weighted_motion_vector_cartesian_array = []\naverage_global_weighted_motion_vector_cartesian_array = []\naverage_weighted_motion_vectors_filtered_cartesian_distance_array = []\naverage_global_weighted_motion_vectors_filtered_cartesian_distance_array = []",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:108-140"
    },
    "3871": {
        "file_id": 482,
        "content": "Function to calculate the average motion vectors based on a list of motion vectors. If the list is empty, returns (0, 0). If the list has more than one vector, calculates the average and returns it as a tuple. Else, returns the first vector in the list.\n\nInitializes arrays for storing average_weighted_motion_vector_cartesian, average_global_weighted_motion_vector_cartesian, average_weighted_motion_vectors_filtered_cartesian_distance, and average_global_weighted_motion_vectors_filtered_cartesian_distance.",
        "type": "comment"
    },
    "3872": {
        "file_id": 482,
        "content": "for _ in progressbar.progressbar(range(framesCount)):\n    success, frame, motion_vectors, frame_type, timestamp = cap.read()\n    height, width, channels = frame.shape\n    # breakpoint()\n    if success:\n        # what is the content of this motion vector?\n        # print(motion_vectors)\n        # import pandas as pd\n        # df = pd.DataFrame(motion_vectors)\n        # df = pd.DataFrame(motion_vectors,index=['source_index','unk0','unk1','src_x','src_y','dst_x','dst_y','motion_x','motion_y','motion_scale'])\n        # breakpoint()\n        # print()\n        # print(\"_____________________________\")\n        condition = motion_vectors[:, 0] < 0\n        # print(condition)\n        # print(condition.shape)\n        # breakpoint()\n        motion_vectors_simplified = motion_vectors[condition, :][:, [0, 5, 6, 7, 8, 9]]\n        motion_vectors_scale = motion_vectors_simplified[:, [5]]\n        motion_vectors_scale_inversed = 1 / motion_vectors_scale\n        motion_vectors_with_scale = motion_vectors_simplified[:, [3, 4]]\n        motion_vectors_scale_inversed_stacked = np.hstack(",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:142-163"
    },
    "3873": {
        "file_id": 482,
        "content": "The code reads frames and motion vectors from a video stream, processes them, and stores selected information in separate arrays. It uses pandas for data processing and numpy for array manipulation.",
        "type": "comment"
    },
    "3874": {
        "file_id": 482,
        "content": "            [motion_vectors_scale_inversed] * 2\n        )\n        motion_vectors_restored = (\n            motion_vectors_scale_inversed_stacked * motion_vectors_with_scale\n        )  # just element wise?\n        # print('STACKED:', motion_vectors_scale_inversed_stacked.shape)\n        # print(\"WITH SCALE:\", motion_vectors_with_scale.shape)\n        # print(\"RESTORED:\",motion_vectors_restored.shape)\n        # print(motion_vectors_simplified.shape)\n        # print(motion_vectors_scale.shape)\n        # breakpoint()\n        motion_vectors_dest_coords_restored = np.hstack(\n            [motion_vectors_simplified[:, [1, 2]], motion_vectors_restored]\n        )\n        # motion_vectors_simplified = motion_vectors[:,[0,5,6,7,8]]\n        # motion_vectors_simplified_unique = np.unique(motion_vectors_simplified, axis=0)\n        # print(motion_vectors_simplified_unique.shape, motion_vectors.shape)\n        # breakpoint()\n        motion_vectors_dict = {}\n        for mv in motion_vectors_dest_coords_restored:\n            # drop duplicates first!",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:164-184"
    },
    "3875": {
        "file_id": 482,
        "content": "This code segment is responsible for restoring the motion vectors after scaling and stacking. It performs element-wise multiplication of two arrays, one containing scaled motion vectors and the other being the stacked motion vectors. The result is stored in \"motion_vectors_restored\". Then, it horizontally stacks the simplified motion vector coordinates and the restored ones using numpy's hstack function, resulting in \"motion_vectors_dest_coords_restored\". Finally, a dictionary named \"motion_vectors_dict\" is initialized but not fully populated in this snippet.",
        "type": "comment"
    },
    "3876": {
        "file_id": 482,
        "content": "            (\n                dst_x,  # corresponding macro block.\n                dst_y,  # for destination only\n                motion_x,\n                motion_y,\n                # motion_scale,  # don't know what the fuck is wrong with the motion scale\n            ) = mv.tolist()\n            # say we just want source_index <0, aka mv compared to previous frame\n            # try:\n            #     assert motion_x / motion_scale == src_x - dst_x\n            #     assert motion_y / motion_scale == src_y - dst_y\n            # except:\n            #     print(src_x, dst_x, motion_x, motion_scale)\n            #     print(src_y, dst_y, motion_y, motion_scale)\n            #     print(\"*\" * 20)\n            # it will be inaccurate if we abandon this subpixel precision.\n            # if source_index >= 0:\n            #     continue\n            # if dst_x>max_dst_x:\n            #     max_dst_x = dst_x\n            # if dst_y>max_dst_y:\n            #     max_dst_y = dst_y\n            destCoord = (dst_x, dst_y)\n            motion_vector = (motion_x, motion_y)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:185-208"
    },
    "3877": {
        "file_id": 482,
        "content": "This code segment is related to motion vector estimation in video processing. It calculates the destination coordinates and motion vector for a macro block, but there seems to be an issue with the motion scale. The code tries to assert that the motion_x and motion_y are scaled correctly based on the motion_scale, but it is causing some problem.",
        "type": "comment"
    },
    "3878": {
        "file_id": 482,
        "content": "            # print(destCoord)\n            # breakpoint()\n            if motion_vector == (0, 0):\n                # print(\"zero motion vector detected. skipping\")\n                # breakpoint()\n                continue\n            # print('destination coords:',destCoord)\n            # print('motion vector:',motion_vector)\n            motion_vectors_dict.update(\n                {destCoord: motion_vectors_dict.get(destCoord, []) + [motion_vector]}\n            )\n            # you know, different frame sources may lead to different results.\n            # these vectors could overlap. which one you want to keep? the smaller ones or the bigger ones?\n            # if destCoord in destCoords:\n            #     print(\"SKIPPING DUPLICATE DESTCOORD:\", destCoord)\n            #     print(\"PREVIOUS MV\",prevMV)\n            #     print(\"CURRENT MV\", mv)\n            #     continue\n            # else:\n            #     destCoords.add(destCoord)\n            # prevMV = mv\n            # try:\n            #     # src_x, src_y may not apply the same rule.",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:209-232"
    },
    "3879": {
        "file_id": 482,
        "content": "This code checks if a motion vector is zero and skips processing if it is. It then updates a dictionary of motion vectors by adding the new motion vector to the destination coordinate, while considering potential overlaps with other motion vectors.",
        "type": "comment"
    },
    "3880": {
        "file_id": 482,
        "content": "            #     # assert src_x % 16 == 8\n            #     # assert src_y % 16 == 8\n            #     assert checkMacroBlock(dst_x) is not None\n            #     assert checkMacroBlock(dst_y) is not None\n            #     # assert dst_x<=res_x # dst_x can go beyond the res_x\n            #     # assert dst_y<=res_y\n            #     # so all rules applied.\n            # except:\n            #     # print('source',src_x, src_y)\n            #     print(\"res\", res_x, res_y)\n            #     print('destionation',dst_x, dst_y)\n            #     print('motion',motion_x, motion_y)\n            #     print(\"scale\",motion_scale)\n        motion_vectors_dict_averaged = {\n            key: averageMotionVectors(motion_vectors_dict[key])\n            for key in motion_vectors_dict.keys()\n        }\n        # assuming no duplicates?\n        weighted_motion_vectors = []\n        weights = []\n        rectangles = []\n        motion_vectors_filtered = []  # for getting data later?\n        for (\n            blockCenterCoordinates,\n            average_motion_vector,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:233-257"
    },
    "3881": {
        "file_id": 482,
        "content": "Testing macro block placement, asserting non-null checkMacroBlock results for dst_x and dst_y, asserting within res limits (dst_x <= res_x), and handling exceptions with error printing. Averages motion vectors using averageMotionVectors function. Creates weightedMotionVectors list and weights list. Initializing rectangles and motionVectorsFiltered for later use.",
        "type": "comment"
    },
    "3882": {
        "file_id": 482,
        "content": "        ) in motion_vectors_dict_averaged.items():\n            if average_motion_vector == (0, 0):\n                continue\n                # wtf is this? why fucking zero?\n                # print('skipping zero average motion vector')\n                # print(\"destination coords\", key)\n                # print('average motion vector', average_motion_vector)\n            else:\n                m_x, m_y = average_motion_vector\n                motion_vectors_filtered.append(average_motion_vector)\n                rectangle_XYWH = getRectangleXYWHFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                rectangles.append(rectangle_XYWH)\n                blockWeight = getBlockWeightFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                weights.append(blockWeight)\n                weighted_motion_vectors.append(\n                    (\n                        m_x * blockWeight / frame_common_divisor,\n                        m_y * blockWeight / frame_common_divisor,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:258-279"
    },
    "3883": {
        "file_id": 482,
        "content": "This code block is filtering and processing motion vectors from a dictionary. It skips any average motion vector that is (0, 0) and then proceeds to calculate the weighted motion vectors by multiplying the motion vector with block weight and dividing it by a frame common divisor. The resulting coordinates are stored in 'weighted_motion_vectors'.",
        "type": "comment"
    },
    "3884": {
        "file_id": 482,
        "content": "                    )\n                )\n        weighted_motion_vectors = np.array(weighted_motion_vectors)\n        sum_weighted_motion_vector = np.sum(weighted_motion_vectors, axis=0)\n        average_global_weighted_motion_vector = (\n            sum_weighted_motion_vector / total_block_weights\n        )\n        sum_weights = sum(weights)\n        average_weighted_motion_vector = sum_weighted_motion_vector / sum_weights\n        motion_area_ratio = sum_weights / total_block_weights\n        # print(motion_vectors.shape)\n        motion_vectors_filtered_cartesian_distance = [\n            cartesianDistance(vector) for vector in motion_vectors_filtered\n        ] + [\n            0\n        ]  # to avoid errors.\n        motion_vectors_filtered_cartesian_distance = np.array(\n            motion_vectors_filtered_cartesian_distance\n        )\n        cartesianWeights = weights + [0]\n        cartesianWeights = np.array(cartesianWeights)\n        cartesianWeightsSum = np.sum(cartesianWeights)\n        weighted_motion_vectors_filtered_cartesian_distance = (",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:280-304"
    },
    "3885": {
        "file_id": 482,
        "content": "This code calculates the weighted average motion vector and the average weighted motion vector for motion vectors in a block. It also determines the motion area ratio, applies cartesian distance to filtered motion vectors, and stores them with corresponding weights.",
        "type": "comment"
    },
    "3886": {
        "file_id": 482,
        "content": "            motion_vectors_filtered_cartesian_distance * cartesianWeights\n        )\n        sum_weighted_motion_vectors_filtered_cartesian_distance = np.sum(\n            weighted_motion_vectors_filtered_cartesian_distance\n        )\n        # print(\"SUM\", sum_weighted_motion_vectors_filtered_cartesian_distance)\n        # breakpoint()\n        average_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance / cartesianWeightsSum\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance\n            / total_block_weights # this is a number, not array!\n        )\n        min_cartesian = min(motion_vectors_filtered_cartesian_distance)\n        max_cartesian = max(motion_vectors_filtered_cartesian_distance)\n        motion_area_ratio_array.append(motion_area_ratio)\n        # print()\n        # print(average_weighted_motion_vector)\n        # print(average_global_weighted_motion_vector)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:305-329"
    },
    "3887": {
        "file_id": 482,
        "content": "This code calculates the average and global-weighted motion vectors for a set of motion vectors, considering their weights and distances. It also finds the minimum and maximum cartesian distance in the list and appends the motion area ratio to an array.",
        "type": "comment"
    },
    "3888": {
        "file_id": 482,
        "content": "        # breakpoint()\n        average_weighted_motion_vector_cartesian=cartesianDistance(average_weighted_motion_vector)\n        average_weighted_motion_vector_cartesian_array.append(average_weighted_motion_vector_cartesian)\n        average_global_weighted_motion_vector_cartesian = cartesianDistance(average_global_weighted_motion_vector)\n        average_global_weighted_motion_vector_cartesian_array.append(\n        average_global_weighted_motion_vector_cartesian\n        )\n        average_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_global_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        if motion_vectors_dict_averaged != {}:\n            # breakpoint()\n            if visualize:\n                print(\"motion_area_ratio\", motion_area_ratio)\n                print(\"average_weighted_motion_vector_cartesian\", average_weighted_motion_vector_cartesian)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:330-348"
    },
    "3889": {
        "file_id": 482,
        "content": "Calculates the average weighted motion vector cartesian distance, appends it to the array and does the same for global vectors. If motion_vectors_dict_averaged is not empty, prints motion_area_ratio and average_weighted_motion_vector_cartesian if visualize is True.",
        "type": "comment"
    },
    "3890": {
        "file_id": 482,
        "content": "                print(\n                    \"average_global_weighted_motion_vecto_cartesianr\",\n                    average_global_weighted_motion_vector_cartesian,\n                )\n                print(\n                    \"average_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                print(\n                    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_global_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                motion_mask = np.zeros(\n                    (motion_render_frame[1], motion_render_frame[0], 1)\n                )\n                for index, (x, y, w, h) in enumerate(rectangles):\n                    pt1, pt2 = XYWHToDiagonal(x, y, w, h)\n                    # print(pt1, pt2)\n                    current_cartesian = motion_vectors_filtered_cartesian_distance[\n                        index\n                    ]",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:349-369"
    },
    "3891": {
        "file_id": 482,
        "content": "Calculates and prints average motion vector metrics. Creates a zeroed motion mask. Iterates through rectangles to calculate the current cartesian distance.",
        "type": "comment"
    },
    "3892": {
        "file_id": 482,
        "content": "                    # print(type(pt1), type(pt1[0]))\n                    relative_motion_cartesian = (current_cartesian - min_cartesian) / (\n                        max_cartesian - min_cartesian\n                    )  # must from 0 to 1 so we can plot this,\n                    # relative_motion_cartesian = 255*((current_cartesian-min_cartesian)/(max_cartesian-min_cartesian))\n                    # relative_motion_cartesian = int(relative_motion_cartesian)\n                    # relative_motion_cartesian = min(255,max(0, relative_motion_cartesian))\n                    # breakpoint()\n                    cv2.rectangle(\n                        motion_mask,\n                        pt1,\n                        pt2,\n                        color=(relative_motion_cartesian,),\n                        thickness=-1,\n                    )\n                # should we gaussian blur, threshold this, do convolution and then apply bounding box on it?\n                # # visualize this.\n                if show_picture:\n                    cv2.imshow(\"motion_mask\", motion_mask)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:370-388"
    },
    "3893": {
        "file_id": 482,
        "content": "This code calculates the relative motion vectors for a set of points and plots them on an image using OpenCV. It converts the motion vectors to a range of 0-255, representing the pixel intensity values used in the image plotting. The resulting image is then displayed if the \"show_picture\" flag is set.",
        "type": "comment"
    },
    "3894": {
        "file_id": 482,
        "content": "                    cv2.waitKey(100)\n            # may you create bounding box for this? for tracking motion? or not?\n        # breakpoint()\n    else:\n        break\n# print('max_dst_x', max_dst_x)\n# print('max_dst_y', max_dst_y)\nimport matplotlib.pyplot as plt\n# plt.style.use('dark_background')\na, b = 5,1\nfigure, axis = plt.subplots(a, b)\ndata = [\n    motion_area_ratio_array,\n    # average_weighted_motion_vector_array,\n    # average_global_weighted_motion_vector_array,\n    average_weighted_motion_vector_cartesian_array,\n    average_global_weighted_motion_vector_cartesian_array,\n    average_weighted_motion_vectors_filtered_cartesian_distance_array,\n    average_global_weighted_motion_vectors_filtered_cartesian_distance_array,\n]\ntitles = [\n    \"motion_area_ratio\",\n    # \"average_weighted_motion_vector\",\n    # \"average_global_weighted_motion_vector\",\n    \"average_weighted_motion_vector_cartesian\",\n    \"average_global_weighted_motion_vector_cartesian\",\n    \"average_weighted_motion_vectors_filtered_cartesian_distance\",",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:389-419"
    },
    "3895": {
        "file_id": 482,
        "content": "The code imports matplotlib and creates a figure with subplots. It stores various motion vector related arrays in the \"data\" list, presumably for plotting. These arrays are likely different representations of motion vectors at each point. The code then defines titles corresponding to each array's content.",
        "type": "comment"
    },
    "3896": {
        "file_id": 482,
        "content": "    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n]\n# breakpoint()\nassert len(titles) == len(data)\nassert a*b >= len(titles)\nfor _a in range(a):\n    for _b in range(b):\n        index = _a * b + _b\n        if index > len(data) - 1:\n            break\n        if a == 1:\n            if b == 1:\n                axis[0].plot(data[index])\n                axis[0].set_title(titles[index])\n            else:\n                axis[_b].plot(data[index])\n                axis[_b].set_title(titles[index])\n        elif b == 1:\n            axis[_a].plot(data[index])\n            axis[_a].set_title(titles[index])\n        else:\n            axis[_a, _b].plot(data[index])\n            axis[_a, _b].set_title(titles[index])\nplt.show()",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:420-444"
    },
    "3897": {
        "file_id": 482,
        "content": "This code plots the data using matplotlib and sets titles for each plot based on the corresponding title from the provided list. It checks for potential errors like unequal lengths of 'titles' and 'data', and also handles cases when 'a' or 'b' is 1, adjusting the number of axes accordingly.",
        "type": "comment"
    },
    "3898": {
        "file_id": 483,
        "content": "/tests/motion_vector_estimation/run.sh",
        "type": "filepath"
    },
    "3899": {
        "file_id": 483,
        "content": "This code runs a Docker container using lubo1994/mv-extractor image, mounting the current directory to /home/video_cap within the container and allowing X11 forwarding for graphical user interface support.",
        "type": "summary"
    }
}