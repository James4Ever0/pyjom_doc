{
    "2200": {
        "file_id": 224,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/unlock_phone_on_given_ip.py",
        "type": "filepath"
    },
    "2201": {
        "file_id": 224,
        "content": "Device address is set to connect to the phone on a specific IP and port for further interactions.",
        "type": "summary"
    },
    "2202": {
        "file_id": 224,
        "content": "# first, check phone status.\ndevice_address = \"192.168.10.3:5555\"",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/unlock_phone_on_given_ip.py:1-2"
    },
    "2203": {
        "file_id": 224,
        "content": "Device address is set to connect to the phone on a specific IP and port for further interactions.",
        "type": "comment"
    },
    "2204": {
        "file_id": 225,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py",
        "type": "filepath"
    },
    "2205": {
        "file_id": 225,
        "content": "This Python script logs keystrokes and mouse events via Cocoa, for educational purposes, requires privilege settings adjustment, and has an event loop with interrupt handling.",
        "type": "summary"
    },
    "2206": {
        "file_id": 225,
        "content": "#!/usr/bin/env python\n\"\"\"\npkl.py\n:author: Andrew Scott\n:date: 9-3-2018\nIf executed successfully this script will log key strokes until the process is killed.\nThis script is for EDUCATIONAL PURPOSES ONLY. \n\"\"\"\n# can be run without root, but must enable the privilege in privacy settings\nimport os, sys\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom AppKit import NSApplication, NSApp\nfrom Foundation import NSObject\nfrom Cocoa import (\n    NSEvent,\n    NSKeyDownMask, # keyboard\n    NSLeftMouseUpMask, # mouse\n    NSLeftMouseDownMask,\n    NSLeftMouseDraggedMask,\n    NSRightMouseDownMask,\n    NSRightMouseDraggedMask,\n    NSRightMouseUpMask,\n    NSMouseMovedMask,\n)\nfrom PyObjCTools import AppHelper\n# NSLeftMouseUpMask, NSLeftMouseDownMask, NSLeftMouseDraggedMask, NSRightMouseDownMask, NSRightMouseDraggedMask, NSRightMouseUpMask, NSMouseMovedMask\nclass AppDelegate(NSObject):\n    \"\"\"\n    The App Delegate creates a mask to detect the key being pressed and adds\n    a global monitor for this mask.",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:1-38"
    },
    "2207": {
        "file_id": 225,
        "content": "This Python script logs key strokes until the process is killed, intended for educational purposes only. It uses AppKit and Foundation modules from Cocoa and PyObjCTools to create an app delegate that detects keyboard and mouse events without root access, but requires enabling privilege in privacy settings.",
        "type": "comment"
    },
    "2208": {
        "file_id": 225,
        "content": "    \"\"\"\n    def applicationDidFinishLaunching_(self, notification):\n        mask_down = NSKeyDownMask\n        mouse_masks = [\n            NSLeftMouseUpMask,\n            NSLeftMouseDownMask,\n            NSLeftMouseDraggedMask,\n            NSRightMouseDownMask,\n            NSRightMouseDraggedMask,\n            NSRightMouseUpMask,\n            NSMouseMovedMask,\n        ]\n        NSEvent.addGlobalMonitorForEventsMatchingMask_handler_(mask_down, key_handler)\n        for mouse_mask in mouse_masks:\n            NSEvent.addGlobalMonitorForEventsMatchingMask_handler_(\n                mouse_mask, mouse_handler\n            )\n# w = Writer()\ndef mouse_handler(event):\n    import time\n    print(\"mouse have actions\", time.time())\ndef key_handler(event):\n    \"\"\"\n    Translates the key press events into readable characters if one exists\n    the key code is also recorded for non-character input.\n    \"\"\"\n    try:\n        capture_char = event.characters()\n        capture_raw = event.keyCode()\n        print(capture_char, capture_raw)\n        # w.write_to_log(capture_char, capture_raw)",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:39-74"
    },
    "2209": {
        "file_id": 225,
        "content": "The code sets up event handlers for various mouse actions and keyboard events. It adds a global monitor to track these events, and when an event occurs, it logs the characters (if any) and keyCode. The code also includes functions for handling the mouse and key events, but they do not appear to perform any specific actions beyond logging.",
        "type": "comment"
    },
    "2210": {
        "file_id": 225,
        "content": "    except KeyboardInterrupt:\n        AppHelper.stopEventLoop()\nif __name__ == \"__main__\":\n    app = NSApplication.sharedApplication()\n    delegate = AppDelegate.alloc().init()\n    NSApp().setDelegate_(delegate)\n    AppHelper.runEventLoop()",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:75-83"
    },
    "2211": {
        "file_id": 225,
        "content": "The code sets up an event loop and handles interrupts, ensuring that the application properly terminates when needed.",
        "type": "comment"
    },
    "2212": {
        "file_id": 226,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier_with_masscan_scapy.py",
        "type": "filepath"
    },
    "2213": {
        "file_id": 226,
        "content": "This code uses Masscan to scan for open ports, connects to the desired port with AdbWrapper, and stores connected addresses in a list. It is part of a script for controlling devices over the network.",
        "type": "summary"
    },
    "2214": {
        "file_id": 226,
        "content": "# strange.\nfrom __future__ import absolute_import, division, print_function\nimport logging\nimport scapy.config\nimport scapy.layers.l2\nimport scapy.route\nimport socket\nimport math\nimport errno\nimport os\nimport getopt\nimport sys\nmyPort = 5555\nmyInterface = \"wlan0\"\n# list avaliable devices.\nfrom adb_wrapper import AdbWrapper\na = AdbWrapper()\ndevices = a.devices()\nprint(devices)\n# exit()\nconnected_addresses = []\nfor key, value in devices.items():\n    address = key\n    connected_addresses.append(address)\n    deviceType = value\n# not working.\nif os.geteuid() != 0:\n        print('You need to be root to run this script', file=sys.stderr)\n        sys.exit(1)\nscanAddress = None\nfor network, netmask, _, interface, address, _ in scapy.config.conf.route.routes:\n    # print(interface, address)\n    if interface == myInterface:\n        myAddress = address.split(\".\")\n        myAddress[3] = \"0/24\"\n        scanAddress = \".\".join(myAddress)\n        print(scanAddress, interface)\n        break\nif scanAddress is not None:\n    # now scan this interface with masscan.",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier_with_masscan_scapy.py:1-42"
    },
    "2215": {
        "file_id": 226,
        "content": "The code imports necessary libraries, initializes variables, and connects with available devices using AdbWrapper. It then checks if the user is root before attempting to scan a specific network interface using masscan.",
        "type": "comment"
    },
    "2216": {
        "file_id": 226,
        "content": "    import masscan\n    mas = masscan.PortScanner()\n    mas.scan(scanAddress, ports=str(myPort), arguments='--max-rate 1000')\n    result = mas.scan_result\n    # usually it only show opens.\n    import json\n    scanResultDict = json.loads(result)['scan']\n    for key, value in scanResultDict.items():\n        address = key\n        for port in value:\n            if port['port'] == myPort and port['status'] =='open':\n                # print(address, myPort)\n                # we need to connect to it!\n                connect_address = \"{}:{}\".format(address,myPort)\n                print(connect_address)\n                if not connect_address in connected_addresses:\n                    print(\"connecting device:\", connect_address)\n                    # command1 = \"adb tcpip 5555\"\n                    # no need to restart?\n                    command2 = \"adb connect {}\".format(connect_address)\n                    # os.system(command1)\n                    os.system(command2)",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier_with_masscan_scapy.py:43-64"
    },
    "2217": {
        "file_id": 226,
        "content": "This code is using the Masscan library to scan for open ports on a specified address. It then checks if the desired port is open, and if so, connects to it by running \"adb connect\" command. The connected addresses are stored in the connected_addresses list. This code is part of a broader script for controlling devices over network.",
        "type": "comment"
    },
    "2218": {
        "file_id": 227,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier.sh",
        "type": "filepath"
    },
    "2219": {
        "file_id": 227,
        "content": "This line establishes a TCP/IP connection on port 5555 for ADB, ensuring the device is reachable over the network.",
        "type": "summary"
    },
    "2220": {
        "file_id": 227,
        "content": "adb tcpip 5555 # will not restart if already in tcpip mode\\",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier.sh:1-1"
    },
    "2221": {
        "file_id": 227,
        "content": "This line establishes a TCP/IP connection on port 5555 for ADB, ensuring the device is reachable over the network.",
        "type": "comment"
    },
    "2222": {
        "file_id": 228,
        "content": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/test.py",
        "type": "filepath"
    },
    "2223": {
        "file_id": 228,
        "content": "This code fetches and tests proxies, sets up a connection gateway, makes a GET request to \"https://deepl.com\" using the valid proxy, prints first 100 bytes and status code, and displays \"deepl response\".",
        "type": "summary"
    },
    "2224": {
        "file_id": 228,
        "content": "# from download_from_multiple_websites_at_once import concurrentGet\nfrom lazero.network.proxy.clash import (\n    getProxyList,\n    testProxyList,\n    getConnectionGateway,\n    setProxyConfig,\n    setProxyWithSelector,\n)\nimport requests\nif __name__ == \"__main__\":\n    # validProxyDelayList = []\n    proxyList = getProxyList(debug=True)\n    # pprint.pprint(result)\n    validProxyDelayList = testProxyList(proxyList, timeout=5000)\n    #     pprint(gateway)\n    #     {'allow-lan': True,\n    #  'authentication': [],\n    #  'bind-address': '*',\n    #  'ipv6': False,\n    #  'log-level': 'info',\n    #  'mixed-port': 0,\n    #  'mode': 'rule',\n    #  'port': 8381,\n    #  'redir-port': 0,\n    #  'socks-port': 0,\n    #  'tproxy-port': 0}\n    gateway = getConnectionGateway()\n    print(\"valid proxies:\", len(validProxyDelayList))\n    validProxyName = validProxyDelayList[0][\"name\"]\n    # if no valid proxy, better do another run.\n    setProxyConfig(mode=\"Global\")\n    # you can switch to 'Rule' if you want the baidu translation\n    setProxyWithSelector(validProxyName, debug=True)",
        "type": "code",
        "location": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/test.py:1-34"
    },
    "2225": {
        "file_id": 228,
        "content": "This code fetches the proxy list from Clash, tests the proxies for validity, sets up a connection gateway, and configures the global proxy using Clash's functions. It prints the number of valid proxies found and sets a specific valid proxy for further use.",
        "type": "comment"
    },
    "2226": {
        "file_id": 228,
        "content": "    # now use the proxy!\n    r = requests.get(\"https://deepl.com\", proxies={\"http\": gateway, \"https\": gateway})\n    print()\n    print(r.content[:100])\n    print(r.status_code)\n    print(\"deepl response\")",
        "type": "code",
        "location": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/test.py:35-40"
    },
    "2227": {
        "file_id": 228,
        "content": "Using the proxy, make a GET request to \"https://deepl.com\", print the first 100 bytes of response content and status code, then display \"deepl response\".",
        "type": "comment"
    },
    "2228": {
        "file_id": 229,
        "content": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/download_from_multiple_websites_at_once.py",
        "type": "filepath"
    },
    "2229": {
        "file_id": 229,
        "content": "This code imports the \"concurrentGet\" function from the \"lzero.network.asyncio\" module, which allows for making concurrent HTTP GET requests asynchronously.",
        "type": "summary"
    },
    "2230": {
        "file_id": 229,
        "content": "from lazero.network.asyncio import concurrentGet",
        "type": "code",
        "location": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/download_from_multiple_websites_at_once.py:1-1"
    },
    "2231": {
        "file_id": 229,
        "content": "This code imports the \"concurrentGet\" function from the \"lzero.network.asyncio\" module, which allows for making concurrent HTTP GET requests asynchronously.",
        "type": "comment"
    },
    "2232": {
        "file_id": 230,
        "content": "/tests/audio_volume_meter/test_volume_meter.py",
        "type": "filepath"
    },
    "2233": {
        "file_id": 230,
        "content": "This code calculates audio parameters, generates vocal slices, and clusters segments using KMeans for labeling. It merges adjacent segments with similar labels and stores the updated labels.",
        "type": "summary"
    },
    "2234": {
        "file_id": 230,
        "content": "# usually yelling is not always funny. but we can do speech to text. taking longer time though... pinpoint the cue time.\n# often some exclamation attempts like repetation or louder sounds.\naudio_src = \"/media/root/help/pyjom/samples/audio/dog_with_text/vocals.wav\"\n# heard of dog woooling.\n# import audioop\nimport pydub\ntimestep = 0.1  # my time setting.\naudiofile = pydub.AudioSegment.from_wav(audio_src)\nframe_rate = audiofile.frame_rate\nseconds = audiofile.duration_seconds\nprint(frame_rate)  # 44100.\nprint(seconds)  # sample length\nimport math\nimport numpy as np\nfrom talib import stream\n# frame_rate2 = frame_rate *timestep\nmilistep = 1000 * timestep\nma_step = 10  # one second of buffer size. or more. timeperiod=ma_step\nstd_arr, maxval_arr, abs_nonzero_arr = [], [], []\ndef getPaddingMovingAverage(myarray, timeperiod=10):\n    lt = math.ceil(timeperiod / 2)\n    rt = timeperiod - lt\n    len_myarray = len(myarray)\n    max_index = len_myarray - 1\n    result_array = []\n    for i in range(len_myarray):\n        start_index = i - lt",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:1-37"
    },
    "2235": {
        "file_id": 230,
        "content": "Code imports PyDub, sets timestep and frame rate variables from audio file duration and frame rate. Imports math, numpy and talib.stream. Defines function getPaddingMovingAverage to calculate moving average with padding, taking an array and time period as parameters. Initializes std_arr, maxval_arr and abs_nonzero_arr lists for further calculations.",
        "type": "comment"
    },
    "2236": {
        "file_id": 230,
        "content": "        start_index = max(0, start_index)\n        end_index = i + rt\n        end_index = min(end_index, max_index)\n        array_slice = myarray[start_index:end_index]\n        arr_slice_length = end_index - start_index\n        val = sum(array_slice) / arr_slice_length\n        # val = np.median(array_slice)\n        result_array.append(val)\n    return result_array\nmsteps = math.ceil(seconds / timestep)\nfor i in range(msteps):\n    # print(frame_rate2)\n    # probably in miliseconds.\n    segment = audiofile[i * milistep : (i + 1) * milistep]\n    data = segment.get_array_of_samples()\n    # containes two channels. 4410*2\n    darray = np.array(data)\n    print(darray.shape)\n    std = np.std(darray)\n    abs_darray = abs(darray)\n    maxval = np.max(abs_darray)\n    abs_nonzero = np.average(abs_darray)\n    print(\"STD:{} MAX:{} AVG:{}\".format(std, maxval, abs_nonzero))\n    std_arr.append(std)\n    # ma_std = stream.SMA(np.array(std_arr[-ma_step:]).astype(np.float64))\n    maxval_arr.append(maxval)\n    # ma_maxval = stream.SMA(np.array(maxval_arr[-ma_step:]).astype(np.float64))",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:38-67"
    },
    "2237": {
        "file_id": 230,
        "content": "This code calculates the standard deviation, maximum value, and average of absolute values for a given audio segment. It appends the calculated values to respective lists and potentially calculates moving averages. The code utilizes numpy functions for array processing and the SMA function from the stream module (possibly) for calculating moving averages.",
        "type": "comment"
    },
    "2238": {
        "file_id": 230,
        "content": "    abs_nonzero_arr.append(abs_nonzero)\n    # ma_abs_nonzero = stream.SMA(np.array(abs_nonzero_arr[-ma_step:]).astype(np.float64))\n    # breakpoint()\n    # print(\"MA_STD:{} MA_MAX:{} MA_AVG:{}\".format(ma_std,ma_maxval,ma_abs_nonzero))\n    # print(data)\n    # breakpoint()\n    # maxAudioValue =audioop.max(data,2)\n    # print(\"STEP:\",i,\"VOLUME:\",maxAudioValue)\nstd_arr0 = getPaddingMovingAverage(std_arr, timeperiod=20)\nmaxval_arr0 = getPaddingMovingAverage(maxval_arr, timeperiod=20)\nabs_nonzero_arr0 = getPaddingMovingAverage(abs_nonzero_arr, timeperiod=20)\nma_std_arr = getPaddingMovingAverage(std_arr, timeperiod=60)\nma_maxval_arr = getPaddingMovingAverage(maxval_arr, timeperiod=60)\nma_abs_nonzero_arr = getPaddingMovingAverage(abs_nonzero_arr, timeperiod=60)\n# just use one freaking example as my conclusion.\nstatus = \"end\"\nvocal_slices = []\nvocal_slice = []\nfinal_index = msteps - 1\n# could you use clustering.\n# like time versus duration.\navg_std = []\nfor i in range(msteps):\n    a, b, c = std_arr0[i], maxval_arr0[i], abs_nonzero_arr0[i]",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:68-92"
    },
    "2239": {
        "file_id": 230,
        "content": "This code calculates the moving average for various audio parameters (std_arr, maxval_arr, and abs_nonzero_arr) over different time periods. It then generates a vocal slice based on these moving averages for each step in the range of msteps. The final index is set to be one less than the total number of steps, and an average list is created.",
        "type": "comment"
    },
    "2240": {
        "file_id": 230,
        "content": "    a0, b0, c0 = ma_std_arr[i], ma_maxval_arr[i], ma_abs_nonzero_arr[i]\n    if status == \"end\":\n        # startpoint = a0 < a\n        startpoint = a0 < a or b0 < b or c0 < c\n        if startpoint:\n            vocal_slice.append(i)\n            avg_std.append(a)\n            status = \"start\"\n    else:\n        avg_std.append(a)\n        # endpoint = a0 > a\n        endpoint = a0 > a and b0 > b and c0 > c\n        if endpoint:\n            vocal_slice.append(i)\n            # vocal_slice[1] = i\n            status = \"end\"\n            vocal_slices.append([vocal_slice, np.average(avg_std)])\n            vocal_slice = []\n            avg_std = []\nif len(vocal_slice) == 1:\n    vocal_slice.append(final_index)\n    vocal_slices.append([vocal_slice, np.average(avg_std)])\ntime_rate = timestep\ntimed_vocal_slices = [\n    [[x[0][0] * time_rate, x[0][1] * time_rate], x[1]] for x in vocal_slices\n]\nd2_data = []\nd1_data = []\nfor slice_vocal in timed_vocal_slices:\n    print(slice_vocal)  # it could be two dimentional. both for length and volume?",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:93-123"
    },
    "2241": {
        "file_id": 230,
        "content": "The code is iterating through an array of data and dividing it into segments based on threshold values for average, maximum, and absolute non-zero values. These segments are classified as either \"start\" or \"end\", and the indices of the start and end points are stored in separate lists. If a segment only has one point, it is added to the list of vocal slices along with the average of the threshold values. The code then calculates the time rate and creates two-dimensional lists of timed vocal slices (segment start and end times), and data for d1 and d2. Finally, the code prints the timed vocal slices, which could be in a two-dimensional format representing length and volume.",
        "type": "comment"
    },
    "2242": {
        "file_id": 230,
        "content": "    # to find best shit you need grouping.\n    a, b = slice_vocal[0]\n    length = b - a\n    d2_data.append([length, slice_vocal[1]])\n    d1_data.append([slice_vocal[1]])\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2)\nkm = kmeans.fit(d1_data)\nlabels = km.labels_\nlabel_indexs = {i: labels[i] for i in range(len(labels))}\n# print(label_index)\nnew_labels = []\nmergeTimeGap = 0.5\nlb_new = 0\nlast_elem = None\nfor index, data in enumerate(timed_vocal_slices):\n    # data = timed_vocal_slices\n    [start, end], std = data\n    label = label_indexs[index]\n    if last_elem == None:\n        last_elem = [[start, end], label]\n    else:\n        [[last_start, last_end], last_label] = last_elem\n        if start - last_end < mergeTimeGap and last_label == label:\n            pass\n            # last_elem = [[start,end],label]\n        else:\n            lb_new += 1\n        last_elem = [[start, end], label]\n    new_labels.append(lb_new)\n    print(\"DATA:\", data, \"LABEL:\", label, \"NEW_LABEL:\", lb_new)",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:124-157"
    },
    "2243": {
        "file_id": 230,
        "content": "This code is grouping vocal segments based on their start and end timestamps. It uses KMeans clustering from sklearn to assign labels to each segment, then merges adjacent segments with the same label if they are less than a certain time gap apart. The new_labels list stores the updated labels for each segment.",
        "type": "comment"
    },
    "2244": {
        "file_id": 231,
        "content": "/tests/nsfw_violence_drug_detection/README.md",
        "type": "filepath"
    },
    "2245": {
        "file_id": 231,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "summary"
    },
    "2246": {
        "file_id": 231,
        "content": "it is related to video content censorship, but really close to video automatic editing.\nwe have violence video dataset, we also have some 'fun video' dataset called blooper dataset",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/README.md:1-3"
    },
    "2247": {
        "file_id": 231,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "comment"
    },
    "2248": {
        "file_id": 232,
        "content": "/tests/nsfw_violence_drug_detection/post_jpg_to_nsfwjs.sh",
        "type": "filepath"
    },
    "2249": {
        "file_id": 232,
        "content": "This code is making multiple POST requests to http://localhost:8511/nsfw, using different image formats and file paths. The purpose appears to be testing the API's response for NSFW content detection with various images. The last comment suggests that BMP format might have an issue, but consistency is maintained with the original model. A real adult content image is being tested next.",
        "type": "summary"
    },
    "2250": {
        "file_id": 232,
        "content": "curl http://localhost:8511/\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_saturday_night.jpg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_saturday_night.bmp' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.png' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.jpg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.bmp' http://localhost:8511/nsfw\necho\necho\n# but the bmp looks right. is that the format issue?\n# we have consistency with the original model. how about a real porno?",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/post_jpg_to_nsfwjs.sh:1-23"
    },
    "2251": {
        "file_id": 232,
        "content": "This code is making multiple POST requests to http://localhost:8511/nsfw, using different image formats and file paths. The purpose appears to be testing the API's response for NSFW content detection with various images. The last comment suggests that BMP format might have an issue, but consistency is maintained with the original model. A real adult content image is being tested next.",
        "type": "comment"
    },
    "2252": {
        "file_id": 233,
        "content": "/tests/nsfw_violence_drug_detection/porndetect_test.sh",
        "type": "filepath"
    },
    "2253": {
        "file_id": 233,
        "content": "This code is making multiple HTTP POST requests with different image files to a local server on port 8511, specifically targeting the \"/nsfw\" endpoint. The images being tested are JPEG and BMP formats, and the script is checking for errors or issues related to the BMP decoder in the response.",
        "type": "summary"
    },
    "2254": {
        "file_id": 233,
        "content": "curl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/porn_shemale.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/porn_shemale.bmp' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick.bmp' http://localhost:8511/nsfw # something is wrong with bmp decoder.\necho\necho\necho '__________________________________________'\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick2.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick3.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick4.jpeg' http://localhost:8511/nsfw\necho\necho",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/porndetect_test.sh:1-22"
    },
    "2255": {
        "file_id": 233,
        "content": "This code is making multiple HTTP POST requests with different image files to a local server on port 8511, specifically targeting the \"/nsfw\" endpoint. The images being tested are JPEG and BMP formats, and the script is checking for errors or issues related to the BMP decoder in the response.",
        "type": "comment"
    },
    "2256": {
        "file_id": 234,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs",
        "type": "filepath"
    },
    "2257": {
        "file_id": 234,
        "content": "The code imports libraries, sets up an Express app and Multer for file uploads, converts images to RGBA format, initializes a model, calculates pixel counts using TensorFlow, handles requests, checks missing files, logs uploaded files, returns server status, loads NSFW image detection model, serves predictions on port 8511.",
        "type": "summary"
    },
    "2258": {
        "file_id": 234,
        "content": "import { createRequire } from \"module\";\nconst require = createRequire(import.meta.url);\nconst express = require('express')\nconst multer = require('multer')\nconst jpeg = require('jpeg-js')\n    // const bmp = require('bmp-js')\nconst bmp = require('bmp-ts');\n// const bmpBuffer = fs.readFileSync('bit24.bmp');\nconst { PNG } = require('pngjs')\nconst tf = require('@tensorflow/tfjs-node')\nconst nsfw = require('nsfwjs')\nconst app = express()\nconst upload = multer()\nlet _model\n// this even works for gif!\n// it will normalize and resize the image if needed.\n// shall we check for gif?\nconst convert = async(img, type) => {\n    // Decoded image in UInt8 Byte array\n    let image\n    if (type == 'image/jpeg') {\n        image = await jpeg.decode(img, true)\n            // RGBA\n    } //wtf?\n    // order: rgba\n    else if (type == 'image/png') {\n        image = PNG.sync.read(img)\n    } else if (type == 'image/bmp') {\n        // image = await bmp.decode(img, true)\n        image = bmp.decode(img, { toRGBA: true });\n    }\n    const numChannels = 3",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:1-40"
    },
    "2259": {
        "file_id": 234,
        "content": "The code imports necessary libraries, sets up an express application and multer middleware for handling file uploads. It also defines a function to convert images of different types (JPEG, PNG, BMP) into the same RGBA format for further processing using TensorFlow.js. The code also initializes a model and mentions that it works for GIFs as well.",
        "type": "comment"
    },
    "2260": {
        "file_id": 234,
        "content": "    const numPixels = image.width * image.height // will raise an error if image is not acquired.\n    const values = new Int32Array(numPixels * numChannels)\n        // are you sure about the width?\n    // can you make this faster? shit?\n    // this shit is no numpy. fuck.\n    for (let i = 0; i < numPixels; i++)\n        for (let c = 0; c < numChannels; ++c)\n        // if (type == 'bmp') {\n        //     // ABGR?\n        //     // values[i * numChannels + c] = image.data[i * 4+c]\n        //     values[i * numChannels + c] = image.data[i * 4 + 3 - c]\n        // } else {\n            values[i * numChannels + c] = image.data[i * 4 + c]\n            // }\n    return tf.tensor3d(values, [image.height, image.width, numChannels], 'int32')\n}\napp.get('/', async(req, res) => {\n    res.send('nsfw nodejs server')\n})\napp.post('/nsfw', upload.single('image'), async(req, res) => {\n    if (!req.file) res.status(400).send('Missing image multipart/form-data')\n    else {\n        try {\n            console.log('file uploaded:', req.file)",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:41-68"
    },
    "2261": {
        "file_id": 234,
        "content": "The code snippet is calculating the number of pixels in an image and storing its values into a TensorFlow tensor. It's then using the NodeJS framework to handle requests for images, checking if a file is missing, logging uploaded files, and returning a response with the server status. The code uses different data access methods based on the image format (BMP or others). However, there are concerns about potential width calculation errors, improving performance, and frustration with working outside of the Python ecosystem.",
        "type": "comment"
    },
    "2262": {
        "file_id": 234,
        "content": "            if (req.file.fieldname == 'image') {\n                type = req.file.mimetype // deal with it later.\n                extension = req.file.originalname.split(\".\").slice(-1)[0].toLowerCase()\n                if (extension == 'gif' || type == 'image/gif') {\n                    let image = req.file.buffer\n                    let predictions = await _model.classifyGif(image, { topk: 3, fps: 1 })\n                        // image.dispose()\n                    predictions.message = 'success'\n                    res.json(predictions)\n                } else {\n                    if (extension == 'bmp') {\n                        type = 'image/bmp'\n                    }\n                    let image = await convert(req.file.buffer, type) // here we have buffer.\n                    let predictions = await _model.classify(image)\n                    predictions.message = 'success'\n                        // image.dispose()\n                    res.json(predictions)\n                }\n            }\n            // we need some file format hints.",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:69-89"
    },
    "2263": {
        "file_id": 234,
        "content": "Checks if the file field is 'image' and deals with GIF files separately by classifying them directly. For other formats, converts the buffer to the appropriate type before classification. Responds with predictions and success message.",
        "type": "comment"
    },
    "2264": {
        "file_id": 234,
        "content": "        } catch (e) {\n            console.log(e)\n            res.json({ message: 'error' })\n        }\n    }\n})\nconst load_model = async() => {\n    _model = await nsfw.load()\n}\n// Keep the model in memory, make sure it's loaded only once\nload_model().then(() => {\n    console.log('server ready')\n    app.listen(8511)\n})\n// curl --request POST localhost:8080/nsfw --header 'Content-Type: multipart/form-data' --data-binary 'image=@/full/path/to/picture.jpg'",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:91-109"
    },
    "2265": {
        "file_id": 234,
        "content": "The code loads an NSFW image detection model, ensures it's only loaded once, and starts a server on port 8511. It accepts POST requests with image data from the client.",
        "type": "comment"
    },
    "2266": {
        "file_id": 235,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js",
        "type": "filepath"
    },
    "2267": {
        "file_id": 235,
        "content": "The function creates a color mask, processes BMP file header info, handles compression types, and supports various color formats. The code converts images to TensorFlow tensor3d arrays, handles file uploads, loads an NSFW model for classification, and runs on port 8511.",
        "type": "summary"
    },
    "2268": {
        "file_id": 235,
        "content": "// import { createRequire } from \"module\";\n// const require = createRequire(import.meta.url);\n// now we are talking\nfunction maskColor(maskRed, maskGreen, maskBlue, maskAlpha) {\n    const maskRedR = (~maskRed + 1) & maskRed;\n    const maskGreenR = (~maskGreen + 1) & maskGreen;\n    const maskBlueR = (~maskBlue + 1) & maskBlue;\n    const maskAlphaR = (~maskAlpha + 1) & maskAlpha;\n    const shiftedMaskRedL = maskRed / maskRedR + 1;\n    const shiftedMaskGreenL = maskGreen / maskGreenR + 1;\n    const shiftedMaskBlueL = maskBlue / maskBlueR + 1;\n    const shiftedMaskAlphaL = maskAlpha / maskAlphaR + 1;\n    return {\n        shiftRed: (x) => (((x & maskRed) / maskRedR) * 0x100) / shiftedMaskRedL,\n        shiftGreen: (x) => (((x & maskGreen) / maskGreenR) * 0x100) / shiftedMaskGreenL,\n        shiftBlue: (x) => (((x & maskBlue) / maskBlueR) * 0x100) / shiftedMaskBlueL,\n        shiftAlpha: maskAlpha !== 0 ?\n            (x) => (((x & maskAlpha) / maskAlphaR) * 0x100) / shiftedMaskAlphaL :\n            () => 255\n    };",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:1-22"
    },
    "2269": {
        "file_id": 235,
        "content": "This function takes four parameters (maskRed, maskGreen, maskBlue, and maskAlpha) to create a color mask. It performs bitwise operations and calculations to shift the color values and returns an object with functions to shift red, green, blue, and alpha components of any given value. If maskAlpha is not zero, it also returns an additional function for shifting alpha values.",
        "type": "comment"
    },
    "2270": {
        "file_id": 235,
        "content": "}\nvar HeaderTypes;\n(function(HeaderTypes) {\n    HeaderTypes[HeaderTypes[\"BITMAP_INFO_HEADER\"] = 40] = \"BITMAP_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V2_INFO_HEADER\"] = 52] = \"BITMAP_V2_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V3_INFO_HEADER\"] = 56] = \"BITMAP_V3_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V4_HEADER\"] = 108] = \"BITMAP_V4_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V5_HEADER\"] = 124] = \"BITMAP_V5_HEADER\";\n})(HeaderTypes || (HeaderTypes = {}));\nclass BmpDecoder {\n    constructor(buffer, { toRGBA } = { toRGBA: false }) {\n        this.buffer = buffer;\n        this.toRGBA = !!toRGBA;\n        this.pos = 0;\n        this.bottomUp = true;\n        this.flag = this.buffer.toString('utf-8', 0, (this.pos += 2));\n        if (this.flag !== 'BM') {\n            throw new Error('Invalid BMP File');\n        }\n        this.locRed = this.toRGBA ? 0 : 3;\n        this.locGreen = this.toRGBA ? 1 : 2;\n        this.locBlue = this.toRGBA ? 2 : 1;\n        this.locAlpha = this.toRGBA ? 3 : 0;\n        this.parseHeader();",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:23-48"
    },
    "2271": {
        "file_id": 235,
        "content": "Class BmpDecoder is created with a buffer and optional toRGBA parameter, which determines the pixel data format. The constructor initializes variables, checks for valid file signature, and sets location indices for RGB(A) values based on toRGBA flag. parseHeader function will be called next.",
        "type": "comment"
    },
    "2272": {
        "file_id": 235,
        "content": "        this.parseRGBA();\n    }\n    parseHeader() {\n        this.fileSize = this.readUInt32LE();\n        this.reserved1 = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.reserved2 = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.offset = this.readUInt32LE();\n        // End of BITMAP_FILE_HEADER\n        this.headerSize = this.readUInt32LE();\n        if (!(this.headerSize in HeaderTypes)) {\n            throw new Error(`Unsupported BMP header size ${this.headerSize}`);\n        }\n        this.width = this.readUInt32LE();\n        this.height = this.readUInt32LE();\n        this.planes = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.bitPP = this.buffer.readUInt16LE(this.pos);\n        this.pos += 2;\n        this.compression = this.readUInt32LE();\n        this.rawSize = this.readUInt32LE();\n        this.hr = this.readUInt32LE();\n        this.vr = this.readUInt32LE();\n        this.colors = this.readUInt32LE();\n        this.importantColors = this.readUInt32LE();",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:49-74"
    },
    "2273": {
        "file_id": 235,
        "content": "The code reads and parses the BMP file header information. It begins by reading and setting values for file size, reserved bytes, and offset. Then it checks the header size to ensure compatibility before proceeding to read and set values for width, height, planes, bits per pixel, compression type, raw data size, and color depth.",
        "type": "comment"
    },
    "2274": {
        "file_id": 235,
        "content": "        // De facto defaults\n        if (this.bitPP === 32) {\n            this.maskAlpha = 0;\n            this.maskRed = 0x00ff0000;\n            this.maskGreen = 0x0000ff00;\n            this.maskBlue = 0x000000ff;\n        } else if (this.bitPP === 16) {\n            this.maskAlpha = 0;\n            this.maskRed = 0x7c00;\n            this.maskGreen = 0x03e0;\n            this.maskBlue = 0x001f;\n        }\n        // End of BITMAP_INFO_HEADER\n        if (this.headerSize > HeaderTypes.BITMAP_INFO_HEADER ||\n            this.compression === 3 /* BI_BIT_FIELDS */ ||\n            this.compression === 6 /* BI_ALPHA_BIT_FIELDS */ ) {\n            this.maskRed = this.readUInt32LE();\n            this.maskGreen = this.readUInt32LE();\n            this.maskBlue = this.readUInt32LE();\n        }\n        // End of BITMAP_V2_INFO_HEADER\n        if (this.headerSize > HeaderTypes.BITMAP_V2_INFO_HEADER ||\n            this.compression === 6 /* BI_ALPHA_BIT_FIELDS */ ) {\n            this.maskAlpha = this.readUInt32LE();\n        }\n        // End of BITMAP_V3_INFO_HEADER",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:75-100"
    },
    "2275": {
        "file_id": 235,
        "content": "The code checks the bitPP value and sets default mask values accordingly. It then verifies if the headerSize exceeds specific limits or if the compression type is BI_BIT_FIELDS or BI_ALPHA_BIT_FIELDS, in which case it reads and assigns mask values. This code handles different header types and compression types to set appropriate mask values for image processing.",
        "type": "comment"
    },
    "2276": {
        "file_id": 235,
        "content": "        if (this.headerSize > HeaderTypes.BITMAP_V3_INFO_HEADER) {\n            this.pos +=\n                HeaderTypes.BITMAP_V4_HEADER - HeaderTypes.BITMAP_V3_INFO_HEADER;\n        }\n        // End of BITMAP_V4_HEADER\n        if (this.headerSize > HeaderTypes.BITMAP_V4_HEADER) {\n            this.pos += HeaderTypes.BITMAP_V5_HEADER - HeaderTypes.BITMAP_V4_HEADER;\n        }\n        // End of BITMAP_V5_HEADER\n        if (this.bitPP <= 8 || this.colors > 0) {\n            const len = this.colors === 0 ? 1 << this.bitPP : this.colors;\n            this.palette = new Array(len);\n            for (let i = 0; i < len; i++) {\n                const blue = this.buffer.readUInt8(this.pos++);\n                const green = this.buffer.readUInt8(this.pos++);\n                const red = this.buffer.readUInt8(this.pos++);\n                const quad = this.buffer.readUInt8(this.pos++);\n                this.palette[i] = {\n                    red,\n                    green,\n                    blue,\n                    quad\n                };",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:101-123"
    },
    "2277": {
        "file_id": 235,
        "content": "This code handles different header types in a file format. It checks the header size and adjusts the position accordingly for BITMAP_V4_HEADER and BITMAP_V5_HEADER. If bitPP is less than or equal to 8 or colors are 0, it creates a palette array by reading RGB values and quad value from the buffer.",
        "type": "comment"
    },
    "2278": {
        "file_id": 235,
        "content": "            }\n        }\n        // End of color table\n        // Can the height ever be negative?\n        if (this.height < 0) {\n            this.height *= -1;\n            this.bottomUp = false;\n        }\n        const coloShift = maskColor(this.maskRed, this.maskGreen, this.maskBlue, this.maskAlpha);\n        this.shiftRed = coloShift.shiftRed;\n        this.shiftGreen = coloShift.shiftGreen;\n        this.shiftBlue = coloShift.shiftBlue;\n        this.shiftAlpha = coloShift.shiftAlpha;\n    }\n    parseRGBA() {\n        this.data = Buffer.alloc(this.width * this.height * 4);\n        switch (this.bitPP) {\n            case 1:\n                this.bit1();\n                break;\n            case 4:\n                this.bit4();\n                break;\n            case 8:\n                this.bit8();\n                break;\n            case 16:\n                this.bit16();\n                break;\n            case 24:\n                this.bit24();\n                break;\n            default:\n                this.bit32();\n        }\n    }",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:124-159"
    },
    "2279": {
        "file_id": 235,
        "content": "The code initializes variables based on the given color table, checks if the height is negative and adjusts accordingly. It then calculates RGBA shift values for subsequent image parsing based on the bit-per-pixel value provided.",
        "type": "comment"
    },
    "2280": {
        "file_id": 235,
        "content": "    bit1() {\n        const xLen = Math.ceil(this.width / 8);\n        const mode = xLen % 4;\n        const padding = mode !== 0 ? 4 - mode : 0;\n        let lastLine;\n        this.scanImage(padding, xLen, (x, line) => {\n            if (line !== lastLine) {\n                lastLine = line;\n            }\n            const b = this.buffer.readUInt8(this.pos++);\n            const location = line * this.width * 4 + x * 8 * 4;\n            for (let i = 0; i < 8; i++) {\n                if (x * 8 + i < this.width) {\n                    const rgb = this.palette[(b >> (7 - i)) & 0x1];\n                    this.data[location + i * this.locAlpha] = 0;\n                    this.data[location + i * 4 + this.locBlue] = rgb.blue;\n                    this.data[location + i * 4 + this.locGreen] = rgb.green;\n                    this.data[location + i * 4 + this.locRed] = rgb.red;\n                } else {\n                    break;\n                }\n            }\n        });\n    }\n    bit4() {\n        if (this.compression === 2 /* BI_RLE4 */ ) {",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:160-185"
    },
    "2281": {
        "file_id": 235,
        "content": "This function reads the image data in 8-bit chunks (bit1) and converts it into RGBA format. The width of the image is divided into segments of 8 bits, and based on the mode (remainder when width is divided by 4), padding is applied. The scanImage method reads the bits in lines and processes each bit using a for loop to extract red, green, and blue values from the palette and assign them to their respective locations in the data array. If the compression type is BI_RLE4 (bit4 function), it indicates that the image uses RLE4 compression.",
        "type": "comment"
    },
    "2282": {
        "file_id": 235,
        "content": "            this.data.fill(0);\n            let lowNibble = false; //for all count of pixel\n            let lines = this.bottomUp ? this.height - 1 : 0;\n            let location = 0;\n            while (location < this.data.length) {\n                const a = this.buffer.readUInt8(this.pos++);\n                const b = this.buffer.readUInt8(this.pos++);\n                //absolute mode\n                if (a === 0) {\n                    if (b === 0) {\n                        //line end\n                        lines += this.bottomUp ? -1 : 1;\n                        location = lines * this.width * 4;\n                        lowNibble = false;\n                        continue;\n                    }\n                    if (b === 1) {\n                        // image end\n                        break;\n                    }\n                    if (b === 2) {\n                        // offset x, y\n                        const x = this.buffer.readUInt8(this.pos++);\n                        const y = this.buffer.readUInt8(this.pos++);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:186-209"
    },
    "2283": {
        "file_id": 235,
        "content": "This code reads an image file's metadata and processes it. It initializes the data array with zeros, handles absolute mode for lines and pixel positions, checks for line end and image end conditions, and reads offset values for x and y coordinates.",
        "type": "comment"
    },
    "2284": {
        "file_id": 235,
        "content": "                        lines += this.bottomUp ? -y : y;\n                        location += y * this.width * 4 + x * 4;\n                    } else {\n                        let c = this.buffer.readUInt8(this.pos++);\n                        for (let i = 0; i < b; i++) {\n                            location = this.setPixelData(location, lowNibble ? c & 0x0f : (c & 0xf0) >> 4);\n                            if (i & 1 && i + 1 < b) {\n                                c = this.buffer.readUInt8(this.pos++);\n                            }\n                            lowNibble = !lowNibble;\n                        }\n                        if ((((b + 1) >> 1) & 1) === 1) {\n                            this.pos++;\n                        }\n                    }\n                } else {\n                    //encoded mode\n                    for (let i = 0; i < a; i++) {\n                        location = this.setPixelData(location, lowNibble ? b & 0x0f : (b & 0xf0) >> 4);\n                        lowNibble = !lowNibble;\n                    }",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:210-230"
    },
    "2285": {
        "file_id": 235,
        "content": "This code handles image data encoding and decoding. It checks the mode (encoded or not) to determine how to process the pixel data. For unencoded mode, it calculates coordinates and updates location by reading bytes from the buffer. In encoded mode, it processes blocks of pixels using low nibble bit manipulation. The code also handles odd-sized blocks by incrementing the position in the buffer.",
        "type": "comment"
    },
    "2286": {
        "file_id": 235,
        "content": "                }\n            }\n        } else {\n            const xLen = Math.ceil(this.width / 2);\n            const mode = xLen % 4;\n            const padding = mode !== 0 ? 4 - mode : 0;\n            this.scanImage(padding, xLen, (x, line) => {\n                const b = this.buffer.readUInt8(this.pos++);\n                const location = line * this.width * 4 + x * 2 * 4;\n                const first4 = b >> 4;\n                let rgb = this.palette[first4];\n                this.data[location] = 0;\n                this.data[location + 1] = rgb.blue;\n                this.data[location + 2] = rgb.green;\n                this.data[location + 3] = rgb.red;\n                if (x * 2 + 1 >= this.width) {\n                    // throw new Error('Something');\n                    return false;\n                }\n                const last4 = b & 0x0f;\n                rgb = this.palette[last4];\n                this.data[location + 4] = 0;\n                this.data[location + 4 + 1] = rgb.blue;\n                this.data[location + 4 + 2] = rgb.green;",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:231-254"
    },
    "2287": {
        "file_id": 235,
        "content": "This code initializes the image scanning process for a specific region, reading and setting pixel colors based on their respective nibbles. The padding is determined by the mode of the width divided by 2, and the image data is updated accordingly.",
        "type": "comment"
    },
    "2288": {
        "file_id": 235,
        "content": "                this.data[location + 4 + 3] = rgb.red;\n            });\n        }\n    }\n    bit8() {\n        if (this.compression === 1 /* BI_RLE8 */ ) {\n            this.data.fill(0);\n            let lines = this.bottomUp ? this.height - 1 : 0;\n            let location = 0;\n            while (location < this.data.length) {\n                const a = this.buffer.readUInt8(this.pos++);\n                const b = this.buffer.readUInt8(this.pos++);\n                //absolute mode\n                if (a === 0) {\n                    if (b === 0) {\n                        //line end\n                        lines += this.bottomUp ? -1 : 1;\n                        location = lines * this.width * 4;\n                        continue;\n                    }\n                    if (b === 1) {\n                        //image end\n                        break;\n                    }\n                    if (b === 2) {\n                        //offset x,y\n                        const x = this.buffer.readUInt8(this.pos++);\n                        const y = this.buffer.readUInt8(this.pos++);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:255-282"
    },
    "2289": {
        "file_id": 235,
        "content": "This code implements a RLE8 compression for image data. It iterates through the compressed data, decoding absolute mode values to populate an array with pixel values (RGB). When it encounters line end or image end markers, it adjusts the location accordingly.",
        "type": "comment"
    },
    "2290": {
        "file_id": 235,
        "content": "                        lines += this.bottomUp ? -y : y;\n                        location += y * this.width * 4 + x * 4;\n                    } else {\n                        for (let i = 0; i < b; i++) {\n                            const c = this.buffer.readUInt8(this.pos++);\n                            location = this.setPixelData(location, c);\n                        }\n                        // @ts-ignore\n                        const shouldIncrement = b & (1 === 1);\n                        if (shouldIncrement) {\n                            this.pos++;\n                        }\n                    }\n                } else {\n                    //encoded mode\n                    for (let i = 0; i < a; i++) {\n                        location = this.setPixelData(location, b);\n                    }\n                }\n            }\n        } else {\n            const mode = this.width % 4;\n            const padding = mode !== 0 ? 4 - mode : 0;\n            this.scanImage(padding, this.width, (x, line) => {\n                const b = this.buffer.readUInt8(this.pos++);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:283-307"
    },
    "2291": {
        "file_id": 235,
        "content": "This code processes image pixel data based on its mode and other conditions. It updates the location and buffer positions accordingly, applies specific functions to set pixel data depending on mode, and increments pos if necessary.",
        "type": "comment"
    },
    "2292": {
        "file_id": 235,
        "content": "                const location = line * this.width * 4 + x * 4;\n                if (b < this.palette.length) {\n                    const rgb = this.palette[b];\n                    this.data[location] = 0;\n                    this.data[location + 1] = rgb.blue;\n                    this.data[location + 2] = rgb.green;\n                    this.data[location + 3] = rgb.red;\n                } else {\n                    this.data[location] = 0;\n                    this.data[location + 1] = 0xff;\n                    this.data[location + 2] = 0xff;\n                    this.data[location + 3] = 0xff;\n                }\n            });\n        }\n    }\n    bit16() {\n        const padding = (this.width % 2) * 2;\n        this.scanImage(padding, this.width, (x, line) => {\n            const loc = line * this.width * 4 + x * 4;\n            const px = this.buffer.readUInt16LE(this.pos);\n            this.pos += 2;\n            this.data[loc + this.locRed] = this.shiftRed(px);\n            this.data[loc + this.locGreen] = this.shiftGreen(px);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:308-331"
    },
    "2293": {
        "file_id": 235,
        "content": "Calculates the pixel location in the image data based on x and y coordinates. If the pixel index is within the palette range, sets RGB values from the palette; otherwise, sets all values to 255. Utilizes bit16 method for processing pixels in groups of two.",
        "type": "comment"
    },
    "2294": {
        "file_id": 235,
        "content": "            this.data[loc + this.locBlue] = this.shiftBlue(px);\n            this.data[loc + this.locAlpha] = this.shiftAlpha(px);\n        });\n    }\n    bit24() {\n        const padding = this.width % 4;\n        this.scanImage(padding, this.width, (x, line) => {\n            const loc = line * this.width * 4 + x * 4;\n            const blue = this.buffer.readUInt8(this.pos++);\n            const green = this.buffer.readUInt8(this.pos++);\n            const red = this.buffer.readUInt8(this.pos++);\n            this.data[loc + this.locRed] = red;\n            this.data[loc + this.locGreen] = green;\n            this.data[loc + this.locBlue] = blue;\n            this.data[loc + this.locAlpha] = 0;\n        });\n    }\n    bit32() {\n        this.scanImage(0, this.width, (x, line) => {\n            const loc = line * this.width * 4 + x * 4;\n            const px = this.readUInt32LE();\n            this.data[loc + this.locRed] = this.shiftRed(px);\n            this.data[loc + this.locGreen] = this.shiftGreen(px);\n            this.data[loc + this.locBlue] = this.shiftBlue(px);",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:332-355"
    },
    "2295": {
        "file_id": 235,
        "content": "This code snippet is part of an image processing library that supports various color formats (bit24, bit32). The bit24 function processes pixels in a 24-bit RGB format and sets the alpha channel to 0. The bit32 function reads pixel values in a 32-bit RGBA format and directly assigns the RGB values while setting the alpha channel to an undefined value. These functions iterate through each pixel of the image and store their respective color data in the \"data\" array.",
        "type": "comment"
    },
    "2296": {
        "file_id": 235,
        "content": "            this.data[loc + this.locAlpha] = this.shiftAlpha(px);\n        });\n    }\n    scanImage(padding = 0, width = this.width, processPixel) {\n        for (let y = this.height - 1; y >= 0; y--) {\n            const line = this.bottomUp ? y : this.height - 1 - y;\n            for (let x = 0; x < width; x++) {\n                const result = processPixel.call(this, x, line);\n                if (result === false) {\n                    return;\n                }\n            }\n            this.pos += padding;\n        }\n    }\n    readUInt32LE() {\n        const value = this.buffer.readUInt32LE(this.pos);\n        this.pos += 4;\n        return value;\n    }\n    setPixelData(location, rgbIndex) {\n        const { blue, green, red } = this.palette[rgbIndex];\n        this.data[location + this.locAlpha] = 0;\n        this.data[location + 1 + this.locBlue] = blue;\n        this.data[location + 2 + this.locGreen] = green;\n        this.data[location + 3 + this.locRed] = red;\n        return location + 4;\n    }\n}\nconst express = require('express')",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:356-386"
    },
    "2297": {
        "file_id": 235,
        "content": "This code defines a class with methods for image processing, including scanning an image line by line and setting pixel data. The class uses a buffer to store data, and has properties such as locAlpha, locBlue, locGreen, and locRed for organizing the data in the buffer. It also utilizes the express module from the Node.js framework.",
        "type": "comment"
    },
    "2298": {
        "file_id": 235,
        "content": "const multer = require('multer')\nconst jpeg = require('jpeg-js')\n    // const bmp = require('bmp-js')\n    // const bmp = require('bmp-ts').default;\n    // const bmpBuffer = fs.readFileSync('bit24.bmp');\nconst { PNG } = require('pngjs')\nconst tf = require('@tensorflow/tfjs-node')\nconst nsfw = require('nsfwjs')\nconst app = express()\nconst upload = multer()\nlet _model\n// this even works for gif!\n// it will normalize and resize the image if needed.\n// shall we check for gif?\nconst convert = async(img, type) => {\n    // Decoded image in UInt8 Byte array\n    let image\n    if (type == 'image/jpeg') {\n        image = await jpeg.decode(img, true)\n            // RGBA\n    } //wtf?\n    // order: rgba\n    else if (type == 'image/png') {\n        image = PNG.sync.read(img)\n    } else if (type == 'image/bmp') {\n        // image = await bmp.decode(img, true)\n        image = new BmpDecoder(img, { toRGBA: true });\n    }\n    const numChannels = 3\n    const numPixels = image.width * image.height // will raise an error if image is not acquired.",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:387-423"
    },
    "2299": {
        "file_id": 235,
        "content": "The code imports necessary libraries for image processing and model loading. It defines an asynchronous function \"convert\" to handle different image types (JPEG, PNG, BMP) and convert them into a standard RGBA format. The function reads the image using appropriate libraries based on its MIME type, determines the number of color channels and total pixels in the image.",
        "type": "comment"
    }
}