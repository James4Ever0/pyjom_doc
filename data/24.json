{
    "2400": {
        "file_id": 253,
        "content": "# - which params should remain on gpus - the larger the value the smaller the offload size\n#\n# For indepth info on Deepspeed config see\n# https://huggingface.co/docs/transformers/main/main_classes/deepspeed\n# keeping the same format as json for consistency, except it uses lower case for true/false\n# fmt: off\nds_config = {\n    \"fp16\": {\n        \"enabled\": True # to half the model precision.\n    },\n    \"zero_optimization\": {\n        \"stage\": 3,\n        \"offload_param\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": True\n        },\n        \"overlap_comm\": True,\n        \"contiguous_gradients\": True,\n        \"reduce_bucket_size\": model_hidden_size * model_hidden_size,\n        \"stage3_prefetch_bucket_size\": 0.9 * model_hidden_size * model_hidden_size,\n        \"stage3_param_persistence_threshold\": 10 * model_hidden_size\n    },\n    \"steps_per_print\": 2000,\n    \"train_batch_size\": train_batch_size,\n    \"train_micro_batch_size_per_gpu\": 1,\n    \"wall_clock_breakdown\": False\n}\n# fmt: on\n# next line instructs transformers to partition the model directly over multiple gpus using",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/functional_dl_translator_1b_deepspeed.py:93-123"
    },
    "2401": {
        "file_id": 253,
        "content": "This code snippet is initializing a Deepspeed configuration for model training with specific settings. The configuration includes enabling FP16 (half precision) for the model, setting zero optimization stage to 3, and configuring offload parameters such as device and pin memory. Additionally, it specifies steps per print, train batch size, train micro-batch size per GPU, and whether to display wall clock breakdown. This configuration aims to optimize model training on multiple GPUs efficiently.",
        "type": "comment"
    },
    "2402": {
        "file_id": 253,
        "content": "# deepspeed.zero.Init when model's `from_pretrained` method is called.\n#\n# **it has to be run before loading the model AutoModelForSeq2SeqLM.from_pretrained(model_name)**\n#\n# otherwise the model will first be loaded normally and only partitioned at forward time which is\n# less efficient and when there is little CPU RAM may fail\ndschf = HfDeepSpeedConfig(ds_config)  # keep this object alive\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"\n# now a model can be loaded.\n# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\nmodel = M2M100ForConditionalGeneration.from_pretrained(modelpath)\n# this will not fuck shit up.\n# initialise Deepspeed ZeRO and store only the engine object\nds_engine = deepspeed.initialize(model=model, config_params=ds_config)[0]\nds_engine.module.eval()  # inference\n# Deepspeed ZeRO can process unrelated inputs on each GPU. So for 2 gpus you process 2 inputs at once.\n# If you use more GPUs adjust for more.\n# And of course if you have just one input to process you then need to pass the same string to both gpus",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/functional_dl_translator_1b_deepspeed.py:124-146"
    },
    "2403": {
        "file_id": 253,
        "content": "The code initializes Deepspeed ZeRO before loading the model and sets the engine object for parallel processing. This ensures efficient usage of resources by partitioning the model at initialization rather than during forward pass, and allows handling multiple inputs on each GPU if available.",
        "type": "comment"
    },
    "2404": {
        "file_id": 253,
        "content": "# # If you use only one GPU, then you will have only rank 0.\n# rank = torch.distributed.get_rank()\n# if rank == 0:\n#     text_in = \"Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy\"\n# elif rank == 1:\n#     text_in = \"Is this review positive or negative? Review: this is the worst restaurant ever\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# sentence = \"你吃饭了没有\" # You have eaten. from m2m100 418M\ntokenizer = M2M100Tokenizer.from_pretrained(modelpath,src_lang=\"en\",tgt_lang=\"zh\")\n# source = tokenizer.get_lang_id(\"zh\")\n# tokenizer.src_lang = source\nmdevice = torch.device(\"cuda\")\n# tokenizer.to(mdevice)\n# inputs = tokenizer.encode(text_in, return_tensors=\"pt\").to(device=local_rank)\ndef get_response(sentence):\n    text_to_translate =sentence\n    model_inputs = tokenizer(text_to_translate, return_tensors=\"pt\")\n    # inputs = model.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n    model_inputs = {k:model_inputs[k].to(mdevice) for k in model_inputs.keys()}",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/functional_dl_translator_1b_deepspeed.py:147-174"
    },
    "2405": {
        "file_id": 253,
        "content": "This code is setting up the environment for a machine translation task using the M2M100 model. It assigns GPU ranks to different tasks, initializes the tokenizer, and defines a function called \"get_response\" that takes a sentence as input, tokenizes it, prepares inputs for the model, and performs translation. The code is specifically tailored for a CUDA device, meaning it will utilize GPUs for processing.",
        "type": "comment"
    },
    "2406": {
        "file_id": 253,
        "content": "    with torch.no_grad():\n        # outputs = ds_engine.module.generate(inputs, synced_gpus=True)\n        while True:\n            try:\n                gen_tokens = ds_engine.module.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"zh\"),synced_gpus=True,do_sample=True).cpu() # whatever. no too heavy lifting.\n                # gen_tokens = ds_engine.module.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"zh\"),synced_gpus=True,do_sample=True,top_k=0,num_beams=8,num_return_sequences=1,no_repeat_ngram_size=2,temperature=1.4).cpu() # whatever.\n                # gen_tokens = ds_engine.module.generate(**model_inputs, forced_bos_token_id=tokenizer.get_lang_id(\"zh\"),synced_gpus=True,do_sample=True,top_k=0,top_p=0.92,num_beams=5,num_return_sequences=5,no_repeat_ngram_size=2,temperature=0.7).cpu() # whatever.\n                break\n            except:\n                import traceback\n                traceback.print_exc()\n                breakpoint() # translate speed is slow as hell. must do some summarization. or you cover them all.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/functional_dl_translator_1b_deepspeed.py:176-187"
    },
    "2407": {
        "file_id": 253,
        "content": "This code uses deepspeed engine to generate translated text using a model. It employs different generate() calls with varying parameters (top_k, top_p, num_beams) in a while loop, likely for experimentation purposes. The loop continues until a successful generation is achieved without any exceptions or until a breakpoint is hit, and it handles exceptions by printing the traceback and breaking out of the loop.",
        "type": "comment"
    },
    "2408": {
        "file_id": 253,
        "content": "                # you may do this for pictures.\n    # text_out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(\"TRANSLATED:\")\n    return tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n# print(get_response(\"你吃饭了没有\"))\n# print(\"PROMPT READY.\")\n# print(\"type exit to exit.\")\n# while True:\n#     targetSentence = input(\"\\nprompt>\")\n#     if \"exit\" not in targetSentence:\n#         result = get_response(targetSentence)\n#         print(result) # this is goddamly working. fuck!\n#     else:\n#         break\n# import time\n# values = []\n# for _ in range(3):\n#     a = time.time()\n#     translate_once()\n#     b = time.time()\n#     value = b-a\n#     # value = timeit.timeit(stmt=\"translate_once()\")\n#     print(\"TIME COST: {}\".format(value))\n#     values.append(value)\n# print(\"TOTAL COST:\",values)\n# print(\"AVERAGE COST:\",sum(values)/len(values))\n# stuck at the end.\n# TOTAL COST: [6.2853310108184814, 4.705244541168213, 4.688654661178589]\n# AVERAGE COST: 5.226410071055095\n# better not to use swap.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/functional_dl_translator_1b_deepspeed.py:188-220"
    },
    "2409": {
        "file_id": 253,
        "content": "This code is a functional implementation of a DL translator, likely for Chinese to English translation. It takes user input in the form of text and returns the translated output. The code includes batch decoding of tokenizer outputs and handles user input within a while loop. It also measures the time cost and average cost per iteration of the function.",
        "type": "comment"
    },
    "2410": {
        "file_id": 254,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py",
        "type": "filepath"
    },
    "2411": {
        "file_id": 254,
        "content": "The code uses video processing libraries to read a source video, apply Chinese translation and color reduction to frames, save the processed frames in a dictionary, write JSON result to file, and finally saves the final video with h.264 codec.",
        "type": "summary"
    },
    "2412": {
        "file_id": 254,
        "content": "from functional_redraw_chinese_text_offline2 import redraw_english_to_chinese2\nimport cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_json = \"japan_day.json\"\noutput_video = \"japan_day_change_color3.mp4\"\nimport os\nif os.path.exists(output_video): os.remove(output_video)\n# OOM for local translation!\n# this will not work. fucking shit. though ocr is speedy.\n# in this we will get no audio.\n# use ffmpeg and time strencher.\n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\nfourcc = cv2.VideoWriter_fourcc(*'H264') # h.264 # this will fail.\n# fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264\nvideo_writer = cv2.VideoWriter(output_video,fourcc,fps,frame_size)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:1-32"
    },
    "2413": {
        "file_id": 254,
        "content": "This code imports the necessary modules and sets up variables for video processing. It removes any existing output file, initializes a VideoCapture object to read the source video, determines the video's FPS, frame size, and total frames count, and creates a VideoWriter object with h.264 codec for the output video file.",
        "type": "comment"
    },
    "2414": {
        "file_id": 254,
        "content": "# frame_index_counter = 0\n# this is determinism.\n# or you could use framedifference? come on...\n# while True:\nimport json\nmjson_result = open(output_json, 'r',encoding='utf8').read()\nmjson_result = json.loads(mjson_result)\nimport copy\n# use some tweening? pytweening?\n# from test_curve_converter import curve_converter\n    # for index, (orig, target) in enumerate(curve_function):\n    #     if value <= orig:\n    #         forig,ftarget = curve_function[index+1]\n    #         if value == orig: return target\n    #         elif value <=forig:\n    #             if value ==forig: return ftarget\n    #             else:\n    #                 loc = (value-orig)/(forig-orig)\n    #                 new_diff = loc*(ftarget-target)\n    #                 new_value = target+new_diff\n    #                 return new_value\n    # return curve_function[-1][1]\n# def remove_much_red(image,curve_function):\n#     target = copy.copy(image[:,:,2])\n#     target = curve_converter(target,curve_function)\n#     image[:,:,2] = target\n#     return image",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:34-62"
    },
    "2415": {
        "file_id": 254,
        "content": "Code imports json and copy libraries, reads a JSON file and converts its contents. It defines a function for curve conversion and a potential function for removing excessive red from an image.",
        "type": "comment"
    },
    "2416": {
        "file_id": 254,
        "content": "def remove_much_red_with_rate(image,reduce_rate = 0.8):\n    target = copy.copy(image[:,:,2])\n    target = target*(1-reduce_rate)\n    image[:,:,2] = target\n    return image\n# curve_function = [[0,0],[40,30],[100,50],[150,100],[255,130]]\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?\n    success, frame = video_cap.read() # let's just use 1, no frame skip.\n    if not success: break\n    # print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file\n    string_frame_index_counter = str(frame_index_counter)  #inpainting is still slow somehow. freaking shit. though i have the freaking shit.\n    # maybe you can improvise.\n    # this is done purely in CPU.\n    processed_frame_data = mjson_result[string_frame_index_counter]# fucking string key.\n    processed_frame = redraw_english_to_chinese2(frame,processed_frame_data) # step 1\n    processed_frame = remove_much_red_with_rate(processed_frame)\n    # mjson_result.update({frame_index_counter:processed_frame_data})",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:64-83"
    },
    "2417": {
        "file_id": 254,
        "content": "The code reads a video frame by frame and applies two transformations: redrawing English to Chinese (step 1) and reducing the intensity of red color with a certain rate. The progress bar indicates the processing progress, and the processed frames are stored in a dictionary using frame index as the key.",
        "type": "comment"
    },
    "2418": {
        "file_id": 254,
        "content": "    video_writer.write(processed_frame) # what frame?\n    # frame_index_counter+=1\n    # cv2.imshow(\"image\",processed_frame) #\n    # # cv2.waitKey(1) # not wait infinitely.\n    # if cv2.waitKey(20) == ord('q'):\n    #     break\n# with open(output_json,\"w+\",encoding=\"utf-8\") as f:\n#     data = json.dumps(mjson_result,indent=4)\n#     f.write(data)\n# cv2.close\nprint(\"VIDEO DONE. SAVED AT:\",output_video)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor3.py:84-95"
    },
    "2419": {
        "file_id": 254,
        "content": "This code writes the processed frame to the video, increments the frame index counter, displays the processed frame using OpenCV's imshow function, waits for a 'q' key press to break the loop, and finally writes the JSON result data to the file. The video is then saved at the specified output_video location.",
        "type": "comment"
    },
    "2420": {
        "file_id": 255,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py",
        "type": "filepath"
    },
    "2421": {
        "file_id": 255,
        "content": "The code translates text, applies color correction, and processes frames from a video using ffmpeg and OpenCV for display and waiting for user input.",
        "type": "summary"
    },
    "2422": {
        "file_id": 255,
        "content": "from functional_redraw_chinese_text_offline2 import redraw_english_to_chinese2\nimport cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_json = \"japan_day.json\"\noutput_video = \"japan_day_change_color2.mp4\"\nimport os\nif os.path.exists(output_video): os.remove(output_video)\n# OOM for local translation!\n# this will not work. fucking shit. though ocr is speedy.\n# in this we will get no audio.\n# use ffmpeg and time strencher.\n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n# fourcc = cv2.VideoWriter_fourcc(*'H264') # h.264\n# fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264 \n# this is builtin ffmpeg. not external shits.\n# video_writer = cv2.VideoWriter(output_video,fourcc,fps,frame_size)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:1-33"
    },
    "2423": {
        "file_id": 255,
        "content": "The code is preparing to process a video file frame by frame for translation. It imports necessary libraries, checks if the output video exists and deletes it, obtains video properties, and sets up variables for further processing. The code also comments on possible issues and suggests using ffmpeg for audio and video processing.",
        "type": "comment"
    },
    "2424": {
        "file_id": 255,
        "content": "# frame_index_counter = 0\n# this is determinism.\n# or you could use framedifference? come on...\n# while True:\nimport json\nmjson_result = open(output_json, 'r',encoding='utf8').read()\nmjson_result = json.loads(mjson_result)\nimport copy\n# use some tweening? pytweening?\nfrom test_curve_converter import curve_converter\n    # for index, (orig, target) in enumerate(curve_function):\n    #     if value <= orig:\n    #         forig,ftarget = curve_function[index+1]\n    #         if value == orig: return target\n    #         elif value <=forig:\n    #             if value ==forig: return ftarget\n    #             else:\n    #                 loc = (value-orig)/(forig-orig)\n    #                 new_diff = loc*(ftarget-target)\n    #                 new_value = target+new_diff\n    #                 return new_value\n    # return curve_function[-1][1]\ndef remove_much_red(image,curve_function):\n    target = copy.copy(image[:,:,2])\n    target = curve_converter(target,curve_function)\n    image[:,:,2] = target\n    return image\ndef remove_much_red_with_rate(image,reduce_rate = 0.8):",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:35-65"
    },
    "2425": {
        "file_id": 255,
        "content": "The code defines a function, `remove_much_red`, which takes an image and curve function as parameters. It applies the given curve function to the red channel of the image, effectively reducing the intensity of red colors. The code also includes another function, `remove_much_red_with_rate`, that allows for adjusting the reduction rate of red colors in images. Both functions modify the image by changing the values of its red channel based on a given curve function or reduction rate.",
        "type": "comment"
    },
    "2426": {
        "file_id": 255,
        "content": "    target = copy.copy(image[:,:,2])\n    target = target*(1-reduce_rate)\n    image[:,:,2] = target\n    return image\ncurve_function = [[0,0],[40,30],[100,50],[150,100],[255,130]]\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?\n    success, frame = video_cap.read() # let's just use 1, no frame skip.\n    if not success: break\n    # print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file\n    string_frame_index_counter = str(frame_index_counter)  #inpainting is still slow somehow. freaking shit. though i have the freaking shit.\n    # maybe you can improvise.\n    # this is done purely in CPU.\n    processed_frame_data = mjson_result[string_frame_index_counter]# fucking string key.\n    processed_frame = redraw_english_to_chinese2(frame,processed_frame_data) # step 1\n    processed_frame = remove_much_red(processed_frame,curve_function)\n    # mjson_result.update({frame_index_counter:processed_frame_data})\n    # video_writer.write(processed_frame) # what frame?",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:66-85"
    },
    "2427": {
        "file_id": 255,
        "content": "The code reads frames from a video and applies color correction using a curve function. It also translates text on the frames and processes them. The progress bar shows the current frame being processed, and if a frame can't be read, the loop breaks. Finally, the processed frames are saved to an output file.",
        "type": "comment"
    },
    "2428": {
        "file_id": 255,
        "content": "    # frame_index_counter+=1\n    cv2.imshow(\"image\",processed_frame) #\n    # # cv2.waitKey(1) # not wait infinitely.\n    if cv2.waitKey(20) == ord('q'):\n        break\n# with open(output_json,\"w+\",encoding=\"utf-8\") as f:\n#     data = json.dumps(mjson_result,indent=4)\n#     f.write(data)\n# cv2.close\nprint(\"VIDEO DONE. SAVED AT:\",output_video)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor2.py:87-96"
    },
    "2429": {
        "file_id": 255,
        "content": "This code displays a processed frame on the screen, waits for 20 milliseconds for input to break the loop, and saves the final video. It uses OpenCV to display frames and wait for user input to stop the process.",
        "type": "comment"
    },
    "2430": {
        "file_id": 256,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor.py",
        "type": "filepath"
    },
    "2431": {
        "file_id": 256,
        "content": "This code reads frames from a video, translates each frame using the redraw_english_to_chinese function, updates a dictionary with frame data, and saves the processed frames to an output JSON file. The process stops when no more frames can be read or if 'q' is pressed.",
        "type": "summary"
    },
    "2432": {
        "file_id": 256,
        "content": "import cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_json = \"japan_day.json\"\n# output_video = \"japan_day_translated.mp4\"\n# OOM for local translation!\n# in this we will get no audio.\n# use ffmpeg and time strencher.\nfrom functional_redraw_chinese_text_offline import redraw_english_to_chinese\n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\nfourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264\n# video_writer =cv2.VideoWriter(output_video,fourcc,fps,frame_size)\n# frame_index_counter = 0\n# this is determinism.\n# or you could use framedifference? come on...\n# while True:\nimport json\nmjson_result = {}\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor.py:1-34"
    },
    "2433": {
        "file_id": 256,
        "content": "The code is reading a video file, extracting frame-by-frame information including FPS, frame width, height, and the total number of frames. It initializes variables for output JSON result and a potential output video (currently commented out). The code uses progress bar to iterate through each frame, but the actual translation process is missing from the given code snippet. The original task seems to be long and might require a lot of computation resources.",
        "type": "comment"
    },
    "2434": {
        "file_id": 256,
        "content": "    success, frame = video_cap.read() # let's just use 1, no frame skip.\n    if not success: break\n    print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file\n    processed_frame_data= redraw_english_to_chinese(frame) # step 1\n    mjson_result.update({frame_index_counter:processed_frame_data})\n    # video_writer.write(processed_frame) # what frame?\n    # frame_index_counter+=1\n    # if cv2.waitKey(20) == ord('q'):\n        # break\nwith open(output_json,\"w+\",encoding=\"utf-8\") as f:\n    data = json.dumps(mjson_result,indent=4)\n    f.write(data)\nprint(\"VIDEO DONE ANALYSING. SAVED AT:\",output_json)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_translate_processor.py:35-48"
    },
    "2435": {
        "file_id": 256,
        "content": "This code reads frames from a video, processes one frame at a time by translating it using the redraw_english_to_chinese function, updates a dictionary with frame data, and saves the processed frames to an output JSON file. The process stops when no more frames can be read or if 'q' is pressed.",
        "type": "comment"
    },
    "2436": {
        "file_id": 257,
        "content": "/tests/bilibili_practices/bilibili_video_translate/frame_iterator_copy.py",
        "type": "filepath"
    },
    "2437": {
        "file_id": 257,
        "content": "This code reads video frames, prints their indices, and writes them to an output file using video_writer. It tracks progress with a progress bar and checks for keypresses to exit. Upon completion, it displays the saved location as VIDEO DONE message.",
        "type": "summary"
    },
    "2438": {
        "file_id": 257,
        "content": "import cv2\nimport progressbar as pb\nsource_video = \"japan_day.webm\"\noutput_video = \"japan_day_copy.mp4\"\n# in this we will get no audio.\n# use ffmpeg and time strencher.\n# from functional_redraw_chinese_text_offline import \n# this is ideal for frame by frame processing.\n# oh shit!\n# the task is very long to run, i believe.\nvideo_cap = cv2.VideoCapture(source_video)\nfps = video_cap.get(cv2.CAP_PROP_FPS) # 60.\nframe_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nframe_size = (frame_width, frame_height)\nframe_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\nfourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D') # h.264\nvideo_writer =cv2.VideoWriter(output_video,fourcc,fps,frame_size)\n# frame_index_counter = 0\n# while True:\nfor frame_index_counter in pb.progressbar(range(frame_count)): # are you sure?\n    success, frame = video_cap.read()\n    if not success: break\n    print(\"processing frame\",frame_index_counter)\n    # write the frame to the output file",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_iterator_copy.py:1-31"
    },
    "2439": {
        "file_id": 257,
        "content": "This code reads a video file, gets its frame properties like FPS and dimensions, creates an output video file with the same format, then iterates through each frame of the input video, printing its index while processing it. It uses a progress bar for tracking frame index in a loop, but there's a potential issue with the usage of the range function (the video might not have that many frames). Finally, it writes each processed frame to the output file.",
        "type": "comment"
    },
    "2440": {
        "file_id": 257,
        "content": "    video_writer.write(frame) # what frame?\n    # frame_index_counter+=1\n    # if cv2.waitKey(20) == ord('q'):\n        # break\nprint(\"VIDEO DONE. SAVED AT:\",output_video)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_video_translate/frame_iterator_copy.py:32-36"
    },
    "2441": {
        "file_id": 257,
        "content": "Writes frames to video file using video_writer, counts frame index, checks for keypress to exit. VIDEO DONE message with saved location output_video.",
        "type": "comment"
    },
    "2442": {
        "file_id": 258,
        "content": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py",
        "type": "filepath"
    },
    "2443": {
        "file_id": 258,
        "content": "This code converts text to speech audio using PaddleSpeech, merges and normalizes audio segments, generates voice and video files, and exports final videos with background music.",
        "type": "summary"
    },
    "2444": {
        "file_id": 258,
        "content": "import os\nfrom test_common import *\ndef split_sentences(sent):\n    spliters = \"\\n，。、\"\n    cursent = \"\"\n    results = []\n    for elem in sent:\n        cursent += elem\n        if elem in spliters:\n            results.append(cursent)\n            cursent = \"\"\n    if len(cursent) > 0:\n        results.append(cursent)\n    return results\ndef get_speech(sent,output):\n    assert output.endswith(\".wav\")\n    with open(\"temp.txt\", \"w+\",encoding=\"utf-8\") as f:\n        f.write(sent)\n    os.system(\"cat temp.txt | paddlespeech tts --output {}\".format(output))\nfrom pydub import AudioSegment\nfrom functional_gen_typo_video_seq import gen_video\ndef merge_audio(asegs):\n    audio_3 = AudioSegment.empty() #shit\n    for seg in asegs:\n        try:\n            audio_3 = audio_3.append(seg,crossfade=100) # also shit.\n        except:\n            audio_3 = audio_3.append(seg,crossfade=0) # also shit.\n    return audio_3\n    # audio_3.export(\"audio_3.wav\", format=\"wav\")\nif __name__ == \"__main__\":\n    sents = split_sentences(demo_text)\n    # breakpoint()",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py:1-38"
    },
    "2445": {
        "file_id": 258,
        "content": "This code performs text-to-speech (TTS) conversion and merges audio segments. It first splits a given sentence into individual sentences, then uses PaddleSpeech to convert the text to speech audio, which is saved with .wav extension. The resulting audio segments are merged using PyDub's AudioSegment module, allowing for seamless crossfades between audio chunks.",
        "type": "comment"
    },
    "2446": {
        "file_id": 258,
        "content": "    voice_dir = \"voice\"\n    video_dir = \"video\"\n    os.system(\"rm -rf {}\".format(voice_dir))\n    os.system(\"rm -rf {}\".format(video_dir))\n    os.mkdir(\"{}\".format(voice_dir))\n    os.mkdir(\"{}\".format(video_dir))\n    index = 0\n    voice_clips = []\n    video_names = []\n    for i,sent in enumerate(sents):\n        print(\"READING:\",sent)\n        aname = \"{}/{}.wav\".format(voice_dir,i)\n        get_speech(sent,aname)\n        seg = AudioSegment.from_wav(aname)\n        duration = seg.duration_seconds\n        voice_clips.append(seg)\n        # get the duration you fuck.\n        # breakpoint()\n        lsent = len(sent)\n        current_indexs = list(range(index,index+lsent))\n        index += lsent\n        # you can generate video for it.\n        vname = \"{}/{}.mp4\".format(video_dir,i)\n        gen_video(vname,current_indexs,duration)\n        video_names.append(vname)\n    # and finally?\n    final_video = \"{}/final_video.mp4\".format(video_dir)\n    final_audio = \"{}/final_audio.wav\".format(voice_dir)\n    audio_merged = merge_audio(voice_clips)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py:39-68"
    },
    "2447": {
        "file_id": 258,
        "content": "This code clears the \"voice\" and \"video\" directories, creates new ones, reads each sentence from the input, converts it to audio, generates a video for each sentence, appends the corresponding audio clip and video name to their respective lists, and then merges all audio clips. The final video and audio files are named accordingly.",
        "type": "comment"
    },
    "2448": {
        "file_id": 258,
        "content": "    bgm_path = \"/root/Desktop/works/bilibili_tarot/some_bgm.mp3\"\n    bgm = AudioSegment.from_mp3(bgm_path)\n    # duration2 = audio_merged.duration_seconds\n    # bgm = bgm[:duration2*1000] # really?\n    # breakpoint()\n    # audio_merged = audio_merged.overlay(audio_merged,bgm,loop=True)  #wtf?\n    audio_merged = audio_merged.overlay(bgm,loop=True)\n    # audio_merged = audio_merged.normalize()\n    # is it needed?\n    # shit.\n    audio_merged.export(final_audio, format=\"wav\")\n    final_video2 = \"{}/final_video2.mp4\".format(video_dir)\n    with open(\"mylist.txt\",\"w+\") as f:\n        for n in video_names:\n            f.write(\"file \"+n+\"\\n\")\n    os.system(\"ffmpeg -f concat -safe 0 -i mylist.txt -c copy {}\".format(final_video))\n    os.system(\"ffmpeg -i {} -i {} -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 {}\".format(final_video,final_audio,final_video2))",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/voice_with_pictures.py:69-87"
    },
    "2449": {
        "file_id": 258,
        "content": "The code imports audio files, merges them, normalizes the volume, and exports the final audio as a wav file. It then creates a mylist.txt file containing the video names, and uses ffmpeg to concatenate videos with the background music and export the final video2 in mp4 format.",
        "type": "comment"
    },
    "2450": {
        "file_id": 259,
        "content": "/tests/bilibili_practices/bilibili_tarot/test_common.py",
        "type": "filepath"
    },
    "2451": {
        "file_id": 259,
        "content": "The code sets the http and https proxies to empty strings, preventing any proxy usage, and assigns a demo text for use in testing.",
        "type": "summary"
    },
    "2452": {
        "file_id": 259,
        "content": "import os\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"\ndemo_text = \"事情的开始，行动的改变，熟练的技术及技巧，贯彻我的意志，运用自然的力量来达到野心。\"",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/test_common.py:1-6"
    },
    "2453": {
        "file_id": 259,
        "content": "The code sets the http and https proxies to empty strings, preventing any proxy usage, and assigns a demo text for use in testing.",
        "type": "comment"
    },
    "2454": {
        "file_id": 260,
        "content": "/tests/bilibili_practices/bilibili_tarot/test_command.sh",
        "type": "filepath"
    },
    "2455": {
        "file_id": 260,
        "content": "This code is using the melt command to combine multiple screenshots into a single video file with transitions. It uses the \"composite\" and \"mix\" transitions, applies distortion effects, and outputs the final result at 60 FPS. The output is saved as a consumer XML file.",
        "type": "summary"
    },
    "2456": {
        "file_id": 260,
        "content": "melt -track \"color:#000000\" out=0 -track /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0000.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -track -blank :0.570312 /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0001.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -track -blank :1.140625 /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0002.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -track -blank :1.710938 /root/Desktop/works/bilibili_tarot/demo_typography/screenshot0003.png in=\":0.000000\" out=\":0.570312\" output_fps=\"60\" -transition composite distort=0 a_track=0 b_track=1 -transition mix a_track=0 b_track=1 -transition composite distort=0 a_track=0 b_track=2 -transition mix a_track=0 b_track=2 -transition composite distort=0 a_track=0 b_track=3 -transition mix a_track=0 b_track=3 -transition composite distort=0 a_track=0 b_track=4 -transition mix a_track=0 b_track=4 -consumer xml",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/test_command.sh:1-1"
    },
    "2457": {
        "file_id": 260,
        "content": "This code is using the melt command to combine multiple screenshots into a single video file with transitions. It uses the \"composite\" and \"mix\" transitions, applies distortion effects, and outputs the final result at 60 FPS. The output is saved as a consumer XML file.",
        "type": "comment"
    },
    "2458": {
        "file_id": 261,
        "content": "/tests/bilibili_practices/bilibili_tarot/temp.txt",
        "type": "filepath"
    },
    "2459": {
        "file_id": 261,
        "content": "This code appears to be a message encouraging users to follow and continue, possibly in the context of social media or a platform like Bilibili. It could be used as a prompt for engagement or interaction.",
        "type": "summary"
    },
    "2460": {
        "file_id": 261,
        "content": "点个关注再走吧～",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/temp.txt:1-1"
    },
    "2461": {
        "file_id": 261,
        "content": "This code appears to be a message encouraging users to follow and continue, possibly in the context of social media or a platform like Bilibili. It could be used as a prompt for engagement or interaction.",
        "type": "comment"
    },
    "2462": {
        "file_id": 262,
        "content": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py",
        "type": "filepath"
    },
    "2463": {
        "file_id": 262,
        "content": "This code provides Tarot card interpretations for Rider-Waite deck, focusing on career, relationships, and personal growth. The Tower (XVI) represents change and urging embracing it for a better future.",
        "type": "summary"
    },
    "2464": {
        "file_id": 262,
        "content": "mdict = {0: \"\"\"【0】愚者（The Fool，0)\n正位释义：\n事情的开始，行动的改变，熟练的技术及技巧，贯彻我的意志，运用自然的力量来达到野心。\n逆位释义：\n意志力薄弱，起头难，走入错误的方向，知识不足，被骗和失败。\"\"\", 1: \"\"\"【1】魔术师（The Magician，I)\n牌面为罗马神话的诸神传信使墨丘利，有着自信的笑容和炯炯有神的眼睛。 牌的桌面摆了宇宙四要素∶权杖（火）、剑（风）、星币（土）、圣杯（水）魔术师头顶上有个无限的符号，腰带为一头尾相接的蛇，是精神永恒的象征。\n魔术师右手拿着权杖指向天空，左手指着地面，代表权力的交流和精神的赠与。魔术师脚底下为玫瑰和百合，表示人类的动机，反映神的意志，指挥天地。 玫瑰代表生，百合代表死亡。 魔术师为第一张牌，也暗示着你本身也是个魔术师，自己能操纵宇宙的力量。白色长袍代表纯洁的内心，深红色斗篷代表魔术师的活动意义深远。\"\"\", 2: \"\"\"【2】女祭司（The High Priestess，II)\n开发出内在的神秘潜力，前途将有所变化的预言，深刻地思考，敏锐的洞察力，准确的直觉。\n过于洁癖，无知，贪心，目光短浅，自尊心过高，偏差的判断，有勇无谋，自命不凡。\"\"\", 3: \"\"\"【3】女皇（The Empress，III)\n幸福，成功，收获，无忧无虑，圆满的家庭生活，良好的环境，美貌，艺术，与大自然接触，愉快的旅行，休闲。\n倒转解释：\n不活泼，缺乏上进心，散漫的生活习惯，无法解决的事情，不能看到成果，担于享乐，环境险恶，与家人发生纠纷。\"\"\", 4: \"\"\"【4】皇帝（The Emperor，IV)\n光荣，权力，胜利，握有领导权，坚强的意志，达成目标，父亲的责任，精神上的孤单。\n幼稚，无力，独裁，撒娇任性，平凡，没有自信，行动力不足，意志薄弱，被支配。\"\"\", 5: \"\"\"【5】教皇（The Hierophant，or the Pope，V)\n援助，同情，宽宏大量，可信任的人给予的劝告，良好的商量对象，得到精神上的满足，遵守规则，志愿者。信心十足，能正确理解事物本质，工作上外来压力过多，使你有被束缚的感觉。寻找新的工作方法，尽管会面对很大的阻力，但结果会证明这样做是值得的。爱情上屈从于他人的压力，只会按照对方的要求来盲目改变自己，自以为这是必要的付出，其实不过是被迫的选择。伴侣也不会对你保持忠诚，并很难满足双方真实的需要。\n错",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:1-31"
    },
    "2465": {
        "file_id": 262,
        "content": "```python\n# tarot descriptions, each key-value pair represents a tarot card with its meaning and interpretations\nmdict = {\n    0: \"Tarot 0: The Fool - start of something, change, mastery, will, natural power\",\n    1: \"Tarot 1: The Magician - magic, confidence, universal connection, command\",\n    2: \"Tarot 2: The High Priestess - intuition, inner potential, insight, misguided pride\",\n    3: \"Tarot 3: The Empress - harmony, success, fulfillment, family, environment, beauty\",\n    4: \"Tarot 4: The Emperor - authority, strength, victory, fatherhood, isolation\",\n    5: \"Tarot 5: The Hierophant - guidance, compassion, spiritual growth, rule-following, sacrifice\"\n}\n```",
        "type": "comment"
    },
    "2466": {
        "file_id": 262,
        "content": "误的讯息，恶意的规劝，上当，援助被中断，愿望无法达成，被人利用，被放弃。事业上多了些灵活的态度，不再刻板遵循旧有的方式，勇于创新形成自己独特的理念，为自己的真实想法而活、而工作。感情上开始正视自己对感情的真实感受与做法，尽管依旧会听取对方的意见，但以不会全盘接受。当你感到无法接受对方的意见时，会及时与其沟通，找出改善关系的做法。\"\"\", 6: \"\"\"【6】恋人（The Lovers，VI)\n撮合，爱情，流行，兴趣，充满希望的未来，魅力，增加朋友。感情和肉体对爱的渴望，它暗示恋情将向彼此关系更亲密的方向发展。事业上将面临重大的抉择，它将关系到你的未来前途。\n禁不起诱惑，纵欲过度，反覆无常，友情变淡，厌倦，争吵，华丽的打扮，优柔寡断。感情上表现幼稚，对成长虽有期待与希望，却希望永远躲避危险，逃避责任。事业上总保持着很高的戒心，让人感到很不舒服，不愿同你合作。\"\"\", 7: \"\"\"【7】战车（The Chariot，VII)\n努力而获得成功，胜利，克服障碍，行动力，自立，尝试，自我主张，年轻男子，交通工具，旅行运大吉。事业上显示出才能，办事卓有成效。自信而富理智的你将让客户更有信心，愿意与你共同合作。在感情上正在努力控制自己的情绪，而且控制得很好，这让你的感情发展得更顺利。\n争论失败，发生纠纷，阻滞，违返规则，诉诸暴力，顽固的男子，突然的失败，不良少年，挫折和自私自利。放弃以往在事业上所坚持的，结局将会更加完美。感情上失去方向，你已经没有以往的冷静，这让对方在心中产生了不信任感，也许你要反省一下自己的所作所为了。\"\"\", 8: \"\"\"【8】力量（Strength，VIII）\n大胆的行动，有勇气的决断，新发展，大转机，异动，以意志力战胜困难，健壮的女人。在事业上你不断突破自我，上司和客户都对你有充分的信心，成就接踵而来。在爱情上，你将发展一段真正亲密的感情，你们全心投入，相互倾诉，丝毫没有距离感。\n胆小，输给强者，经不起诱惑，屈服在权威与常识之下，没有实践便告放弃，虚荣，懦弱，没有耐性。内心的恐惧使你畏首畏尾，进而遭遇事业的瓶颈，感到失去了自信。在爱情上患得患失，失去清醒的判断。\"\"\", 9: \"\"\"【9】隐者（The Hermit，IX)\n隐藏的事实，个别的行动，倾听他人的意见，享受孤独，自己的丢化，有益的警戒，年长者，避开危险，祖父，乡间生活。你在事业黄金时期引退，旁人都不了解这不过是你在为下一次黄金时期的到来进行休息。感情方面你将深刻思考自己在这段感情中的角色和地位，并探索彼此之间的关系。",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:31-45"
    },
    "2467": {
        "file_id": 262,
        "content": "Code represents tarot card descriptions for the Rider-Waite tarot deck, with each numbered section corresponding to a specific tarot card. The descriptions provide insights into areas of life such as career, relationships, and personal growth based on the card's symbolism and interpretation.",
        "type": "comment"
    },
    "2468": {
        "file_id": 262,
        "content": "无视警，憎恨孤独，自卑，担心，幼稚思想，过于慎重导致失败，偏差，不宜旅行。在事业中过多的投入已经让你不愿面对其它事情，因而事业有了突破性的进展。在感情方面，用工作繁忙来逃避这段感情的发展，对伴侣态度冷淡，因为害怕感情的发展而在关键时刻退缩，使对方心寒。\"\"\", 10: \"\"\"【10】命运之轮（The Wheel of Fortune，X)\n关键性的事件，有新的机会，因的潮流，环境的变化，幸运的开端，状况好转，问题解决，幸运之神降临。命运之轮正转到了你人生最低迷的时刻，也许你有些无法接受，但是若能以平常心来看待，这无疑是你成长的最好时机，需要认真面对。感情方面所受到的挫折近乎让你崩溃，然而你还在不断努力。\n虽然你面前是无数的荆棘，但坚持过去将是平坦的大道。你会发现以前所付出的无谓努力，而今反而成了你前进的动力，先前的付出终于有了回报。命运之轮是由命运女神转动的，所以你俩之前的风风雨雨都将过去，关系将进入稳定的发展阶段。\n边疆的不行，挫折，计划泡汤，障碍，无法修正方向，往坏处发展，恶性循环，中断。\"\"\", 11: \"\"\"【11】正义（Justice，XI）\n公正、中立、诚实、心胸坦荡、表里如一、身兼二职、追求合理化、协调者、与法律有关、光明正大的交往、感情和睦。事业上你不会有其它太多的感觉，只是按照以前的计划认真地执行。你对感情生活相当满意，对于你的选择对方都是接受的态度。\n失衡、偏见、纷扰、诉讼、独断专行、问心有愧、无法两全、表里不一、男女性格不合、情感波折、无视社会道德的恋情。长时间的压抑使你在事业最关键的时刻倒下了，需要认真修整一番才能再次前进。感情上你一直忍让着，然而这次你却爆发了，开始指责对方的不是，你们的感情将会有很大的波折。\"\"\", 12: \"\"\"【12】倒吊人（The Hanged Man，XII)\n接受考验、行动受限、牺牲、不畏艰辛、不受利诱、有失必有得、吸取经验教训、浴火重生、广泛学习、奉献的爱。当牌面正立时，你的事业会有短暂的停顿，但你很清楚其中的原因，再次确认自己的目标，做好出发的准备。感情上同样需要反省的时间，你对爱情的牺牲对会给对方很大的触动，也会成为你们关系发展的催化剂。\n无谓的牺牲、骨折、厄运、不够努力、处于劣势、任性、利己主义者、缺乏耐心、受惩罚、逃避爱情、没有结果的恋情。当牌面倒立时，事业上缺乏远见，迷失了努力的目标。感情上你没有了为对方付出的念头，而对方对你的态度依旧，这使你更想逃避。你已经忽略了内心深处正确的判断力，这让你开始遇到很多失败。\"\"\", 13: \"\"\"【13】 死神（Death，XIII)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:47-61"
    },
    "2469": {
        "file_id": 262,
        "content": "Code snippet for Tarot card descriptions.",
        "type": "comment"
    },
    "2470": {
        "file_id": 262,
        "content": "失败、接近毁灭、生病、失业、维持停滞状态、持续的损害、交易停止、枯燥的生活、别离、重新开始、双方有很深的鸿沟、恋情终止。事业上你将放弃一些得到的利益，并获得全新的发展机会。在感情上，你将会发生深刻的变化，将开始新的阶段，接受事实你们会有更加美好的旅程。\n抱有一线希望、起死回生、回心转意、摆脱低迷状态、挽回名誉、身体康复、突然改变计划、逃避现实、斩断情丝、与旧情人相逢。事业上你在试图“两全其美”，希望能够发生奇迹。在感情上，对方已经接受了改变，而你却在逃避现实，你俩的距离正在越来越大。\"\"\", 14: \"\"\"【14】节制（Temperance，XIV)\n单纯、调整、平顺、互惠互利、好感转为爱意、纯爱、深爱。你在事业上小心翼翼，因为处事理智让你的同事感到十分放心。当下你们的感情简简单单，一切都是这么的单纯、平静，正是因为彼此的沟通才让这段感情之路如此通畅。\n消耗、下降、疲劳、损失、不安、不融洽、爱情的配合度不佳。在事业上，你陷入了朝令夕改的怪圈，不妨效仿一下愚人勇往直前，或许能够取得更大的成功。感情上彼此虽然还在不断尝试着沟通，但每次之后总是感觉没有收获，正因为如此你们之间的距离才会越拉越大。\"\"\", 15: \"\"\"【15】恶魔（The Devil ，XV)\n被束缚、堕落、生病、恶意、屈服、欲望的俘虏、不可抗拒的诱惑、颓废的生活、举债度日、不可告人的秘密、私密恋情。你将在事业中得到相当大的名声与财富，你心中的事业就是一切，财富就是你的目标。感情上你们开始被彼此束缚，却不希望改善这种关系，情愿忍受彼此的牵连和不满。\n逃离拘束、解除困扰、治愈病痛、告别过去、暂停、别离、拒绝诱惑、舍弃私欲、别离时刻、爱恨交加的恋情。事业上理性开始支配欲望，找到真正值得努力的目标。感情上开始尝试与对方进行沟通，这让你俩的感情更加牢固。\"\"\", 16: \"\"\"【16】塔（The Tower，XVI)\n破产、逆境、被开除、急病、致命的打击、巨大的变动、受牵连、信念崩溃、玩火自焚、纷扰不断、突然分离，破灭的爱。事业上的困难显而易见，回避不是办法，要勇于挑战，尽管它貌似强大。在感情方面，突然的改变让你陷入深深的痛苦中，接受改变可以让你或你们双方在未来的人生旅途中走得更好。\n困境、内讧、紧迫的状态、状况不佳、趋于稳定、骄傲自大将付出代价、背水一战、分离的预感、爱情危机。事业上开始有稳定的迹象，你不要盲目抵抗改变的发生",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:63-77"
    },
    "2471": {
        "file_id": 262,
        "content": "这段代码是从pyjom/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py文件中截取的，用于描述塔（The Tower，XVI）这张毒诺牌的含义。在事业和感情方面都提到了突然的改变、困难、痛苦等内容，强调接受改变才能在未来的人生旅途中走得更好。",
        "type": "comment"
    },
    "2472": {
        "file_id": 262,
        "content": "，这只会导致更大的改变，无论你如何抵抗，改变终究会发生。在感情上双方的情绪终于平静下来，虽然沟通上还有些困难，但不会有太大的变化了，也许你做些让步，会让你们的感情更融洽。\"\"\", 17: \"\"\"【17】星星（The Star，XVII)\n前途光明、充满希望、想象力、创造力、幻想、满足愿望、水准提高、理想的对象、美好的恋情。代表当你在事业上得到希望的能量时，前途会无比光明。在感情方面，你对自己很有信心，对两人的关系也抱有乐观的态度，相信自己能把握主动权，并努力追求对方，你们很可能就是命中注定的那一对。\n挫折、失望、好高骛远、异想天开、仓皇失措、事与愿违、工作不顺心、情况悲观、秘密恋情、缺少爱的生活。在事业上，你不要全部依靠别人的给予，因为你还有希望在心中燃烧，只有靠自己才有真正的发展动力。感情方面你俩无法彼此信任，感觉无法把自己托付给对方，也许你们退一步，都冷静一下就能找出解决问题的途径，因为答案就在你们的心中。\"\"\", 18: \"\"\"【18】月亮（The Moon，XVIII)\n不安、迷惑、动摇、谎言、欺骗、鬼迷心窍、动荡的爱、三角关系。在事业上，你可能有些不满足，希望能够把自己内在的力量全使出来，于是你开始想要晚上的时间。感情方面，你很敏感害怕被伤害，尽管有伴侣的承诺，你仍然犹豫不决，甚至有逃避的想法。\n逃脱骗局、解除误会、状况好转、预知危险、等待、正视爱情的裂缝。在事业上，你因为外界的压力开始退缩了，并对自己的既定目标产生了怀疑。在感情上，你们之间的问题开始浮现，虽然有些痛，但是只要共同面对存在的困难，问题就解决一半了。\"\"\", 19: \"\"\"【19】太阳（The Sun，XIX)\n活跃、丰富的生命力、充满生机、精力充沛、工作顺利、贵人相助、幸福的婚姻、健康的交际。事业上会有贵人相助，将会有更好的发展机遇。在感情方面，你们已经走出坎坷的感情之路，前面将是洒满歌声和欢乐的坦途，你们将开始规划未来的生活。\n消沉、体力不佳、缺乏连续性、意气消沉、生活不安、人际关系不好、感情波动、离婚。事业上竞争心太急切了，把对手都吓跑了，然而也让合作伙伴感到害怕，或许你该放松些。感情上两人间出现一些小变化，开始在乎对方的态度和自己的付出，这些怀疑也许都是没必要的。\"\"\", 20: \"\"\"【20】审判（Judgement，XX)\n复活的喜悦、康复、坦白、好消息、好运气、初露锋芒、复苏的爱、重逢、爱的奇迹。当牌面正立时，事业上你超越了自我，在过去努力的基础上取得了成功。感情上双方都在认真学习和成长，虽然表面上的变化并不大，但内在的改变已经很大了。",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:77-91"
    },
    "2473": {
        "file_id": 262,
        "content": "This Python code contains descriptions for the 17, 18, 19, and 20 tarot cards. It provides brief interpretations of each card's meaning in terms of future prospects, career, relationships, and personal growth.",
        "type": "comment"
    },
    "2474": {
        "file_id": 262,
        "content": "一蹶不振、幻灭、隐瞒、坏消息、无法决定、缺少目标、没有进展、消除、恋恋不舍。在事业上缺乏清晰的判断，试图用物质填充精神的空虚。在感情上，不断地回忆着过去的美好时光，不愿意去正视眼前的问题，你们的关系已经是貌合神离了。\"\"\", 21: \"\"\"【21】世界（The World，XXI)\n完成、成功、完美无缺、连续不断、精神亢奋、拥有毕生奋斗的目标、完成使命、幸运降临、快乐的结束、模范情侣。在事业上因为努力工作，所以回报丰厚。感情上，你们在彼此的承诺中持续着美好的关系。\n未完成、失败、准备不足、盲目接受、一时不顺利、半途而废、精神颓废、饱和状态、合谋、态度不够融洽、感情受挫。在事业的路上有巨大的障碍，你精神不振，丧失了挑战的动力。感情上，你们不再重视承诺，只是盲目接受对方。彼此最好能沟通一下，不要让痛苦继续纠缠着你们。\"\"\"}\nsmdict = {0: \"【权杖】（The Leangle)代表元素火，象征激情、能量和创造。\", 1: \"【星币】（The Garren)代表元素土，象征金钱、物质和享受。\",\n          2: \"【圣杯】（The Chalice)代表元素水，象征情感、关系、爱和灵感。\", 3: \"【宝剑】（The Blade)代表元素风，象征思想、智慧、交流和冲突。\"}\nsmdict2 = {1:\"COINS\",2:\"CUP\",3:\"SWORDS\",0:\"WANDS\"}\n#mdict 21, smdict 3\n# class py_solution:\ndef int_to_Roman(num):\n    lookup = [\n        (1000, 'M'),\n        (900, 'CM'),\n        (500, 'D'),\n        (400, 'CD'),\n        (100, 'C'),\n        (90, 'XC'),\n        (50, 'L'),\n        (40, 'XL'),\n        (10, 'X'),\n        (9, 'IX'),\n        (5, 'V'),\n        (4, 'IV'),\n        (1, 'I'),\n    ]\n    res = ''\n    for (n, roman) in lookup:\n        (d, num) = divmod(num, n)\n        res += roman * d",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:93-125"
    },
    "2475": {
        "file_id": 262,
        "content": "This code is mapping the Tarot card descriptions and their corresponding numbers to different elements and card suits. It also includes a function int_to_Roman that converts an integer to its Roman numeral representation using lookup values for each Roman numeral value.",
        "type": "comment"
    },
    "2476": {
        "file_id": 262,
        "content": "    return res",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_descriptions.py:126-126"
    },
    "2477": {
        "file_id": 262,
        "content": "This code is returning the result (res) after some operation or function execution. It indicates that the previous code block was performing a calculation, query, or transformation, and now it's ready to deliver the outcome.",
        "type": "comment"
    },
    "2478": {
        "file_id": 263,
        "content": "/tests/bilibili_practices/bilibili_tarot/tarot_correspondences.py",
        "type": "filepath"
    },
    "2479": {
        "file_id": 263,
        "content": "This code loads tarot card images, maps them to numbers, checks for matches in directories, and prints the major/minor tarot cards along with their corresponding values.",
        "type": "summary"
    },
    "2480": {
        "file_id": 263,
        "content": "dirs =[\"tarot_pictures\",\"tarot_pictures2\"] \nimport os\nfrom tarot_descriptions import *\nmtarget_0 = {k:None for k in mdict.keys()}\nmtarget_1 = {k:None for k in smdict.keys()}\nfn = []\nfor d in dirs:\n    fnames = os.listdir(d)\n    fnames = [os.path.join(d,f) for f in fnames]\n    fn+= fnames\npopdict = []\nfor k in mtarget_0.keys():\n    if k == 0:\n        kv = \"0\"\n    else:\n        kv = int_to_Roman(k)\n    for f in fn:\n        fb = os.path.basename(f)\n        f0 = fb.split(\".\")[0].split(\"_\")[0]\n        if f0.upper() == kv:\n            mtarget_0[k] = f\n            break\n    if mtarget_0[k] is None:\n        popdict.append(k)\nfor k in popdict:\n    mtarget_0.pop(k)\npopdict = []\nfor k in mtarget_1.keys():\n    kv =  smdict2[k]\n    for f in fn:\n        fb = os.path.basename(f)\n        f0 = fb.split(\".\")[0].split(\"_\")[-1]\n        if kv.upper() in f0.upper():\n            mtarget_1[k] = f\n            break\n    if mtarget_1[k] is None:\n        popdict.append(k)\nfor k in popdict:\n    mtarget_1.pop(k)\n# print()\n# ########printing.\n# pretty good.",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_correspondences.py:1-48"
    },
    "2481": {
        "file_id": 263,
        "content": "This code is loading tarot card images and mapping them to their respective numbers. It first defines the directories containing the image files, then iterates over each directory, lists the files, and checks if the file name matches the corresponding tarot card number in Roman or Arabic numeral form. If a match is found, it assigns that image file to the respective dictionary (mtarget_0 for Arabic numbers, mtarget_1 for tarot card names). Finally, it removes any missing mappings from the dictionaries.",
        "type": "comment"
    },
    "2482": {
        "file_id": 263,
        "content": "# if __name__ == \"__main__\":\n#     for k in mtarget_0.keys():\n#         print(\"MAJOR\",k,mtarget_0[k])\n#     for k in mtarget_1.keys():\n#         print(\"MINOR\",k,mtarget_1[k])",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/tarot_correspondences.py:49-53"
    },
    "2483": {
        "file_id": 263,
        "content": "Code checks keys in mtarget_0 and mtarget_1 dictionaries, printing \"MAJOR\" followed by key and its value for mtarget_0, and \"MINOR\" followed by key and its value for mtarget_1.",
        "type": "comment"
    },
    "2484": {
        "file_id": 264,
        "content": "/tests/bilibili_practices/bilibili_tarot/scriptable_generate_typography_with_voice_underline_subtitle.py",
        "type": "filepath"
    },
    "2485": {
        "file_id": 264,
        "content": "This code imports necessary modules and sets up the environment for typography generation using voice underscore subtitle. It reads a demo text, creates a directory to save generated images, sets font and size, and draws each character on the screen with optional rotation and filling options.",
        "type": "summary"
    },
    "2486": {
        "file_id": 264,
        "content": "from p5 import *\nimport os\n# from test_common import demo_text\ndemo_text = open(\"demo_text.log\",\"r\",encoding=\"utf-8\").read()\nos.system(\"rm screenshot*\")\ntarget_dir = \"demo_typography\"\nos.system(\"rm -rf {}\".format(target_dir))\nos.system(\"mkdir {}\".format(target_dir))\ntsize = 100\ncounterx = 0\nscrwidth = 1920\nxcoord = int(scrwidth/2) # how to get this shit?\nscrheight = 1080\nycoord = scrheight - tsize - 75\nlineNum = 0\n# what fucking ever.\ns = demo_text\ns0 = [\"\"]\ndef setup():\n    size(scrwidth,scrheight)\n    # text_font(create_font('./fonts/Fonts/博洋行书3500.ttf', size=tsize))\n    # text_font(create_font('./fonts/Fonts/书体坊兰亭体I.ttf', size=tsize))\n    text_font(create_font('./SimHei.ttf', size=tsize))\nimport random\ndef draw():\n    global counterx,xcoord,ycoord,s,s0,scrheight,scrwidth,lineNum,target_dir\n    #force override.\n    background(0)\n    if counterx > len(s)-1:\n        exit()\n    s1 = s[:counterx]\n    counterx+=1\n    mtext_width = text_width(s1)\n    try:\n        text9 = s1\n        # else:\n        #     text9 = \" \"\n        # l = len(s0)-1",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/scriptable_generate_typography_with_voice_underline_subtitle.py:1-46"
    },
    "2487": {
        "file_id": 264,
        "content": "This code is importing necessary modules and setting up the environment for generating typography with voice underscore subtitle. It reads a demo text, creates a directory to save the generated images, sets up font and size, and begins drawing each character from the text on the screen.",
        "type": "comment"
    },
    "2488": {
        "file_id": 264,
        "content": "        # rotate = random.randint(-15,15)\n        # rotate = random.choice([random.randint(-20,-10),random.randint(10,20)])\n        rotate = 0\n        # r1 = random.randint(220,255)\n        # r2 = random.randint(220,255)\n        # r3 = random.randint(220,255)\n        # r4 = random.randint(220,255)\n        r1 = r2 = r3 = r4 = 255\n        fill(red=r1, green=r2, blue=r3, alpha=r4)\n        text(text9, (xcoord-int(mtext_width/2), ycoord,),rotate = rotate)  # add str() to key\n    except:\n        import traceback\n        traceback.print_exc()\n        print(\"SHIT HAPPENED\")\n        pass\n    save_frame(\"{}/screenshot.png\".format(target_dir))\nrun()\nprint(\"EXITED.\")",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/scriptable_generate_typography_with_voice_underline_subtitle.py:47-65"
    },
    "2489": {
        "file_id": 264,
        "content": "This code sets the rotate value to 0 and RGB values to 255 for filling text. It then displays the text at specified coordinates with optional rotation. If an exception occurs, it prints the traceback and a message before saving a screenshot. The program exits and prints \"EXITED.\"",
        "type": "comment"
    },
    "2490": {
        "file_id": 265,
        "content": "/tests/bilibili_practices/bilibili_tarot/scriptable_generate_typography_with_voice.py",
        "type": "filepath"
    },
    "2491": {
        "file_id": 265,
        "content": "The code manages text display, handles line wrapping and background color updates, reads a file for processing, generates typography text with voice, applies random rotation and colors, saves screenshot or displays error message, then exits.",
        "type": "summary"
    },
    "2492": {
        "file_id": 265,
        "content": "from p5 import *\nimport os\n# from test_common import demo_text\ndemo_text = open(\"demo_text.log\",\"r\",encoding=\"utf-8\").read()\nos.system(\"rm screenshot*\")\ntarget_dir = \"demo_typography\"\nos.system(\"rm -rf {}\".format(target_dir))\nos.system(\"mkdir {}\".format(target_dir))\ntsize = 70\ncounterx = 0\nxcoord = 20\nycoord = 75\nscrwidth = 1920\nscrheight = 1080\nlineNum = 0\n# what fucking ever.\ns = demo_text\ns0 = [\"\"]\ndef setup():\n    size(scrwidth,scrheight)\n    # text_font(create_font('./fonts/Fonts/博洋行书3500.ttf', size=tsize))\n    text_font(create_font('./fonts/Fonts/书体坊兰亭体I.ttf', size=tsize))\n    # text_font(create_font('./SimHei.ttf', size=tsize))\nimport random\ndef draw():\n    global counterx,xcoord,ycoord,s,s0,scrheight,scrwidth,lineNum,target_dir\n    if len(s0) ==1:\n        if len(s0[0]) == 0:\n            background(0)\n    if counterx > len(s)-1:\n        exit()\n    s1 = s[counterx]\n    returnFlag = False\n    if s1 == \"\\n\":\n        # this is return!\n        returnFlag = True\n        lineNum +=1\n        stemp0 = \"\" # this is nothing.\n        tw = text_width(stemp0)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/scriptable_generate_typography_with_voice.py:1-47"
    },
    "2493": {
        "file_id": 265,
        "content": "The code reads a text file, clears the target directory, sets up the screen size and font, and starts drawing characters onto the screen. It checks for line breaks and keeps track of the current position and text content. If there is no more text to process, it exits.",
        "type": "comment"
    },
    "2494": {
        "file_id": 265,
        "content": "        th = tsize*(lineNum+1) + tsize*0.2*(lineNum)\n        if (ycoord+th> scrheight):\n            # stemp0 = s1\n            s0 = [stemp0]\n            clear()\n            background(0)\n            lineNum = 0\n        else:\n            s0.append(stemp0)\n    else:\n        stemp0 = s0[-1]+s1\n        tw = text_width(stemp0)\n        th = tsize*(lineNum+1) + tsize*0.2*lineNum\n        if (tw + xcoord+ tsize*0.5> scrwidth):\n            stemp0 = s1\n            s0.append(stemp0)\n            lineNum +=1\n            th = tsize*(lineNum+1) + tsize*0.2*lineNum\n            if (ycoord+th> scrheight):\n                # stemp0 = s1\n                s0 = [stemp0]\n                background(0)\n                lineNum = 0\n        else:\n            s0[-1]= stemp0\n        # no_loop()\n        # clear\n    # s0 = stemp0\n        # end all evil.\n    counterx+=1\n    # load_font(\"SimHei.ttf\")\n    # print(\"text w/h:\",tw,th)\n    # for l, text9 in enumerate(s0):\n    if len(s0) == 1 and len(s0[0])<=1: # whatever.\n        # breakpoint()\n        clear()\n        background(0)",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/scriptable_generate_typography_with_voice.py:48-85"
    },
    "2495": {
        "file_id": 265,
        "content": "This code is handling text wrapping and line breaking for a text display system. It checks the text width and height, splitting lines when necessary and adjusting the number of lines based on available space. The code also clears the screen and updates the background color when needed to ensure proper visuals.",
        "type": "comment"
    },
    "2496": {
        "file_id": 265,
        "content": "    # if not returnFlag:\n    # print(s0)\n    try:\n        text9 = s0[-1][-1]\n        # else:\n        #     text9 = \" \"\n        l = len(s0)-1\n        # rotate = random.randint(-15,15)\n        rotate = random.choice([random.randint(-20,-10),random.randint(10,20)])\n        r1 = random.randint(200,255)\n        r2 = random.randint(200,255)\n        r3 = random.randint(200,255)\n        r4 = random.randint(200,255)\n        fill(red=r1, green=r2, blue=r3, alpha=r4)\n        text(text9, (xcoord+text_width(s0[-1][:-1]), ycoord+ l*(tsize*1.2),),rotate = rotate)  # add str() to key\n    except:\n        import traceback\n        traceback.print_exc()\n        print(\"SHIT HAPPENED\")\n        pass\n    save_frame(\"{}/screenshot.png\".format(target_dir))\nrun()\nprint(\"EXITED.\")",
        "type": "code",
        "location": "/tests/bilibili_practices/bilibili_tarot/scriptable_generate_typography_with_voice.py:86-109"
    },
    "2497": {
        "file_id": 265,
        "content": "This code generates a typography text with voice and applies random rotation, colors, and adjusts position based on the length of the text. It saves a screenshot if no exception occurs, otherwise prints \"SHIT HAPPENED\" and continues. Finally, it exits and prints \"EXITED.\"",
        "type": "comment"
    },
    "2498": {
        "file_id": 266,
        "content": "/tests/bilibili_practices/bilibili_tarot/pooling.py",
        "type": "filepath"
    },
    "2499": {
        "file_id": 266,
        "content": "This code creates a \"final_output\" directory and moves files from specified directories (\"major\", \"minor\", \"typo_0\", and \"typo_1\") to it, appending their filenames with the directory name. It also moves two specific video files to the same directory.",
        "type": "summary"
    }
}