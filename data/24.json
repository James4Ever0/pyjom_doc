{
    "2400": {
        "file_id": 257,
        "content": "/tests/anime_highlight_cuts/theme_collector/keyboard_listener.py",
        "type": "filepath"
    },
    "2401": {
        "file_id": 257,
        "content": "This code uses the pynput library to listen for keyboard events. It defines two functions, `on_press` and `on_release`, to handle key presses and releases respectively. The listener object is created with these functions assigned as event handlers, and then the program enters a loop where it continuously listens for keystrokes until the listener is stopped or terminated.",
        "type": "summary"
    },
    "2402": {
        "file_id": 257,
        "content": "from pynput.keyboard import Listener\ndef on_press(key):\n    try:\n        print(\"alphanumeric key {0} pressed\".format(key.char))\n    except AttributeError:\n        print(\"special key {0} pressed\".format(key))\ndef on_release(key):\n    print(\"{0} released\".format(key))\nlistener = Listener(on_press=on_press, on_release=on_release)\n# listener.start()\nwith listener:\n    listener.join()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/keyboard_listener.py:1-18"
    },
    "2403": {
        "file_id": 257,
        "content": "This code uses the pynput library to listen for keyboard events. It defines two functions, `on_press` and `on_release`, to handle key presses and releases respectively. The listener object is created with these functions assigned as event handlers, and then the program enters a loop where it continuously listens for keystrokes until the listener is stopped or terminated.",
        "type": "comment"
    },
    "2404": {
        "file_id": 258,
        "content": "/tests/anime_highlight_cuts/theme_collector/create_rounded_rectangle.py",
        "type": "filepath"
    },
    "2405": {
        "file_id": 258,
        "content": "The code defines a function called \"rectangle\" that creates an 800x400 black image, draws a regular rectangle and a rounded rectangle on it using PIL, converts the image to numpy array, prints its shape, data type, and maximum value, displays the image using OpenCV, and then waits for a key press.",
        "type": "summary"
    },
    "2406": {
        "file_id": 258,
        "content": "from PIL import Image, ImageDraw\nimport cv2\nimport numpy as np\ndef rectangle():\n    image = Image.new(\"RGB\", (800, 400), \"black\")  # width, height?\n    draw = ImageDraw.Draw(image)\n    # Draw a regular rectangle\n    draw.rectangle((200, 100, 300, 200), fill=\"white\")\n    # Draw a rounded rectangle\n    draw.rounded_rectangle((50, 50, 150, 150), fill=\"white\", radius=20)\n    npArray = np.array(image)  # /255\n    # uint8? then float64? great.\n    print(npArray)\n    print(npArray.shape, npArray.dtype, npArray.max())  # 255?\n    cv2.imshow(\"mask\", npArray)\n    # maybe we just want \"1\" instead of \"255\"\n    # divide by 255 then.\n    cv2.waitKey(0)\nrectangle()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_rounded_rectangle.py:1-23"
    },
    "2407": {
        "file_id": 258,
        "content": "The code defines a function called \"rectangle\" that creates an 800x400 black image, draws a regular rectangle and a rounded rectangle on it using PIL, converts the image to numpy array, prints its shape, data type, and maximum value, displays the image using OpenCV, and then waits for a key press.",
        "type": "comment"
    },
    "2408": {
        "file_id": 259,
        "content": "/tests/anime_highlight_cuts/theme_collector/create_dataset.py",
        "type": "filepath"
    },
    "2409": {
        "file_id": 259,
        "content": "This code creates a new directory, reads video frames, extracts data points, labels them, and saves images as JPEGs in YAML format. The process ends with \"dataset created.\" message after the loop.",
        "type": "summary"
    },
    "2410": {
        "file_id": 259,
        "content": "import yaml\n# why you are taking so much RAM?\n## suggest that you label some (many) still image and mark out the picture-in-picture parts from it? about 2000 images?\n## man just make sure these pictures are not \"pip\" so we can put borders and arrange them randomly to create our super dataset. use MSCOCO/coco128?\ntrain_path = \"images/train\"\ntest_path = \"images/test\"\ntrain_label_path = \"labels/train\"\ntest_label_path = \"labels/test\"\nbasepath = \"pip_dataset\"\ndata = {\n    \"path\": f\"../{basepath}\",  # dataset root dir\n    \"train\": train_path,  # train images (relative to 'path')\n    \"val\": train_path,  # val images (relative to 'path')\n    \"test\": test_path,\n    \"names\": {0: \"active_frame\"},\n}\nimport os\nos.system(f\"rm -rf {basepath}\")\nindex = 1\nos.makedirs(os.path.join(basepath, train_path), exist_ok=True)\nos.makedirs(os.path.join(basepath, test_path), exist_ok=True)\nos.makedirs(os.path.join(basepath, train_label_path), exist_ok=True)\nos.makedirs(os.path.join(basepath, test_label_path), exist_ok=True)\nwith open(\"pip_dataset/pip_dataset.yaml\", \"w+\") as f:",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_dataset.py:1-39"
    },
    "2411": {
        "file_id": 259,
        "content": "This code creates a new dataset by copying and renaming files from existing \"train\" and \"test\" directories into a new directory named \"pip_dataset\". It also creates label files for the copied images in the same manner. The resulting dataset is stored in a YAML file named \"pip_dataset/pip_dataset.yaml\".",
        "type": "comment"
    },
    "2412": {
        "file_id": 259,
        "content": "    f.write(yaml.dump(data, default_flow_style=False))\nimport cv2\nimport pandas\ncsvNames = [fpath for fpath in os.listdir(\".\") if fpath.endswith(\".csv\")]\nimport progressbar\nremainder = 7 # changed? heck?\nfor csvName in csvNames:\n    dataframe = pandas.read_csv(csvName)\n    videoFileName = f'{csvName.split(\".\")[0]}.mp4'\n    #\n    frameIndex = 0\n    cap = cv2.VideoCapture(videoFileName)\n    myIterator = progressbar.progressbar(dataframe.iterrows())\n    frame_height, frame_width = cap.get(cv2.CAP_PROP_FRAME_HEIGHT), cap.get(\n        cv2.CAP_PROP_FRAME_WIDTH\n    )\n    while True:\n        succ, image = cap.read()\n        nextRow = next(myIterator, None)\n        if nextRow is None:\n            break\n        if succ:\n            frameIndex += 1\n            if frameIndex % remainder != 0:\n                continue\n            _, _, min_x, min_y, w, h = nextRow[1].tolist()\n            if (min_x, min_y, w, h) == (0, 0, 0, 0) or w == 0 or h == 0:\n                continue\n            index += 1\n            imageName = f'{f\"{index}\".zfill(12)}.png'",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_dataset.py:40-73"
    },
    "2413": {
        "file_id": 259,
        "content": "Reading CSV files, extracting relevant data and frame index, creating image names based on the index, writing dataset to YAML format.",
        "type": "comment"
    },
    "2414": {
        "file_id": 259,
        "content": "            labelName = f'{f\"{index}\".zfill(12)}.txt'\n            dataPoints = [\n                (min_x + w / 2) / frame_width,\n                (min_y + h / 2) / frame_height,\n                w / frame_width,\n                h / frame_height,\n            ]\n            with open(os.path.join(basepath, train_label_path, labelName), \"w+\") as f:\n                content = \" \".join(([\"0\"] + [f\"{number:.3f}\" for number in dataPoints]))\n                f.write(content)\n            cv2.imwrite(os.path.join(basepath, train_path, imageName), image)\n            del image\n        else:\n            break\n    cap.release()\n    del cap\n    del dataframe\ntestVideo = \"output.mp4\"\nw, h = 1152, 648\nmin_x, min_y = 384, 216\nprint(\"creating 4min pip dataset\")\ncap = cv2.VideoCapture(testVideo)\nframe_height, frame_width = cap.get(cv2.CAP_PROP_FRAME_HEIGHT), cap.get(\n    cv2.CAP_PROP_FRAME_WIDTH\n)\ndataPoints = [\n    (min_x + w / 2) / frame_width,\n    (min_y + h / 2) / frame_height,\n    w / frame_width,\n    h / frame_height,\n]\nframeCounter = 0",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_dataset.py:74-110"
    },
    "2415": {
        "file_id": 259,
        "content": "The code reads an input video file, extracts and saves data points for each frame, and stores the labeled data in a text file. It also writes each frame to an image file.",
        "type": "comment"
    },
    "2416": {
        "file_id": 259,
        "content": "while True:\n    succ, image = cap.read()\n    if succ:\n        frameCounter += 1\n        if frameCounter % remainder != 0:\n            continue\n        index += 1\n        imageName = f'{f\"{index}\".zfill(12)}.png'\n        labelName = f'{f\"{index}\".zfill(12)}.txt'\n        with open(os.path.join(basepath, train_label_path, labelName), \"w+\") as f:\n            content = \" \".join(([\"0\"] + [f\"{number:.3f}\" for number in dataPoints]))\n            f.write(content)\n        cv2.imwrite(os.path.join(basepath, train_path, imageName), image)\n        del image\n    else:\n        break\ncap.release()\ndel cap\nprint(\"creating reference dataset\")\ntestVideo = \"output_1.mp4\"\ncap = cv2.VideoCapture(testVideo)\nframe_height, frame_width = cap.get(cv2.CAP_PROP_FRAME_HEIGHT), cap.get(\n    cv2.CAP_PROP_FRAME_WIDTH\n)\ndataPoints = [0.5, 0.5, 1, 1]\nframeCounter = 0\nwhile True:\n    succ, image = cap.read()\n    if succ:\n        frameCounter += 1\n        if frameCounter % remainder != 0:\n            continue\n        index += 1\n        imageName = f'{f\"{index}\".zfill(12)}.png'",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_dataset.py:111-152"
    },
    "2417": {
        "file_id": 259,
        "content": "Code snippet reads frames from a video, creates label files for each frame containing data points, and saves corresponding images. The loop iterates until the end of the video is reached, skipping non-remainder frames. It uses OpenCV to read and write image data and handles file writing.",
        "type": "comment"
    },
    "2418": {
        "file_id": 259,
        "content": "        labelName = f'{f\"{index}\".zfill(12)}.txt'\n        with open(os.path.join(basepath, train_label_path, labelName), \"w+\") as f:\n            content = \" \".join(([\"0\"] + [f\"{number:.3f}\" for number in dataPoints]))\n            f.write(content)\n        cv2.imwrite(os.path.join(basepath, train_path, imageName), image)\n        del image\n    else:\n        break\ncap.release()\ndel cap\nprint(\"dataset created.\")",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_dataset.py:153-166"
    },
    "2419": {
        "file_id": 259,
        "content": "This code creates a dataset by iterating over data points and saving them as labels in text files. It also saves corresponding images as JPEGs. Finally, it prints \"dataset created.\" after the loop ends.",
        "type": "comment"
    },
    "2420": {
        "file_id": 260,
        "content": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py",
        "type": "filepath"
    },
    "2421": {
        "file_id": 260,
        "content": "This code generates a COCO PIP dataset, creates background images with stripes, calculates text colors, applies random text overlays using OpenCV's putText function, and performs various image processing tasks to create a COCO-style pip dataset.",
        "type": "summary"
    },
    "2422": {
        "file_id": 260,
        "content": "# use what? better use some standard library.\n# you must know where you have put all these images.\n# DONE: remember to upload dataset creation things to kaggle as separate python scripts and execute it in separate process to prevent memory leaks (hopefully)\nimport cv2\nimport numpy as np\nimport os\nfrom string import punctuation\nimport random\n# import itertools\nfrom PIL import Image, ImageDraw\nimageBasePath = \"/kaggle/input/mscoco/mscoco_resized/train2014\"\nimagePaths = [\n    fpath\n    for fpath in os.listdir(imageBasePath)\n    if fpath.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n]\ntrain_path = \"images/train\"\ntest_path = \"images/test\"\ntrain_label_path = \"labels/train\"\ntest_label_path = \"labels/test\"\nbasepath = \"pip_dataset\"\ntrain_path_relative = os.path.join(basepath, train_path)\ntrain_label_path_relative = os.path.join(basepath, train_label_path)\nwidth = 800\nhalf_width = int(width / 2)  # either use 1,2,4 images.\ntextTotalHeight = 300  # either add to top or bottom.\ngetMarginRatio = lambda: random.choice(\n    [0, random.random() * 0.15, random.random() * 0.1, random.random() * 0.05]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:1-37"
    },
    "2423": {
        "file_id": 260,
        "content": "The code is importing necessary libraries and setting up the required paths for image and label files. It will create a PIP dataset by combining images and labels, resizing them to 800 width, and possibly adding text with a random margin ratio. The final dataset will be saved in a specified directory. Memory leaks are mentioned as a concern, so separate scripts are recommended for execution.",
        "type": "comment"
    },
    "2424": {
        "file_id": 260,
        "content": ")  # this margin is used randomly. we can make it 0 or as is.\ntextOrigin = (-30, 30)\nfontScale = 1\nfont = cv2.FONT_HERSHEY_SIMPLEX\nfontThickness = 2\ngetRadius = lambda: random.randint(1, 30)\nimageIndex = (\n    sorted(\n        [int(fpath.split(\".\")[0]) for fpath in os.listdir(train_path_relative)],\n        key=lambda index: -index,\n    )[0]\n    + 1\n)  # shall be increased on demand.\nprint(\"START MARKING PICTURES WITH INDEX:\", imageIndex)\nMAX_COCO_PIP_IMAGE_COUNT = 10000  # well, super huge. is it?\n# don't insert 20000 cause it will break shit.\nalphabets = \"abcdefghijklmnopqrstuvwxyz\"\nALPHABETS = alphabets.upper()\nnumbers = \"0123456789\"\ncharacterList = list(alphabets + ALPHABETS + numbers + punctuation + \" \")\ngetRandomCharacter = lambda: random.choice(characterList)\ngetRandomCharacters = lambda charCount: \"\".join(\n    [getRandomCharacter() for _ in range(charCount)]\n)\ngetRandomLinesOfCharacters = lambda lineCount, charCount: \"\\r\".join(\n    [getRandomCharacters(charCount) for _ in range(lineCount)]\n)\nimageFormats = [1, 2, 4]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:38-73"
    },
    "2425": {
        "file_id": 260,
        "content": "This code initializes variables for creating a COCO PIP dataset. It sets text origin, font scale, and font type. It defines functions to get random character or characters, and handles image formats. The image index is incremented and the maximum allowed image count is set.",
        "type": "comment"
    },
    "2426": {
        "file_id": 260,
        "content": "textFormats = [\"up\", \"down\", \"none\"]\nbackgroundFormats = [\"solidColor\", \"horizontalStripes\", \"verticalStripes\", \"gradients\"]\ncolors = [\n    (0, 0, 0),\n    (255, 255, 255),\n    (0, 0, 192),\n    (255, 255, 64),\n    (0, 255, 0),\n    (0, 0, 255),\n    (255, 0, 0),\n]\ncolorsNumpyArray = [np.array(color) for color in colors]\ncolorsWithIndex = [(index, color) for index, color in enumerate(colors)]\n# we are not doing this while testing.\n# imageFormat = random.choice(imageFormats)\n# textFormat = random.choice(textFormats)\n# backgroundFormat = random.choice(backgroundFormats)\ndef get_gradient_2d(start, stop, width, height, is_horizontal):\n    if is_horizontal:\n        return np.tile(np.linspace(start, stop, width), (height, 1))\n    else:\n        return np.tile(np.linspace(start, stop, height), (width, 1)).T\ndef get_gradient_3d(width, height, start_list, stop_list, is_horizontal_list):\n    result = np.zeros((height, width, len(start_list)), dtype=np.float64)\n    for i, (start, stop, is_horizontal) in enumerate(\n        zip(start_list, stop_list, is_horizontal_list)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:74-104"
    },
    "2427": {
        "file_id": 260,
        "content": "This code generates a COCO-style dataset for object detection using random color combinations. It includes lists of text formats, background formats, and colors, which are then converted to numpy arrays. The code also defines functions to generate 2D and 3D gradients for backgrounds. However, image format, text format, and background format selections are commented out while testing.",
        "type": "comment"
    },
    "2428": {
        "file_id": 260,
        "content": "    ):\n        result[:, :, i] = get_gradient_2d(start, stop, width, height, is_horizontal)\n    return result.astype(np.uint8)\n# for imageFormat, textFormat, backgroundFormat in itertools.product(\n#     imageFormats, textFormats, backgroundFormats\n# ):  # you can use these things to get test output picture names.\nprint(\"creating coco pip dataset:\")\nimport progressbar\nfor _i in progressbar.progressbar(range(MAX_COCO_PIP_IMAGE_COUNT)):\n    imageFormat = random.choice(imageFormats)\n    textFormat = random.choice(textFormats)\n    backgroundFormat = random.choice(backgroundFormats)\n    colorDistances = {}\n    selectedImages = [\n        cv2.imread(os.path.join(imageBasePath, imagePath), cv2.IMREAD_COLOR)\n        for imagePath in random.sample(imagePaths, k=imageFormat)\n    ]\n    for image in selectedImages:\n        averageColor = np.average(image.reshape((-1, 3)), axis=0)\n        for index, colorNumpyArray in enumerate(colorsNumpyArray):\n            colorDistances[index] = colorDistances.get(index, []) + [\n                np.sum(np.abs(averageColor - colorNumpyArray))",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:105-130"
    },
    "2429": {
        "file_id": 260,
        "content": "Creating a COCO PIP dataset: randomly selects image, text, and background formats to generate test output pictures. Chooses multiple images for each format, averages their colors, compares them with color arrays, and adds distances to the dictionary.",
        "type": "comment"
    },
    "2430": {
        "file_id": 260,
        "content": "            ]\n    sortedColorsWithIndex = sorted(\n        colorsWithIndex, key=lambda element: -np.sum(colorDistances[element[0]])\n    )  # the further the better.\n    # sortedColors = [color for _, color in sortedColorsWithIndex]\n    ## create background first.\n    imageCanvasHeight = half_width if imageFormat == 2 else width\n    textCanvasHeight = 0 if textFormat == \"none\" else textTotalHeight\n    backgroundShape = (imageCanvasHeight + textCanvasHeight, width, 3)  # height, width\n    _, color_main = sortedColorsWithIndex[0]\n    if backgroundFormat in [\"horizontalStripes\", \"verticalStripes\", \"gradients\"]:\n        # fill background with color_main first.\n        _, color_sub = sortedColorsWithIndex[1]\n        if backgroundFormat in [\"horizontalStripes\", \"verticalStripes\"]:\n            backgroundImage = np.zeros(backgroundShape, dtype=np.uint8)\n            backgroundImage[:, :, 0] = color_main[0]\n            backgroundImage[:, :, 1] = color_main[1]\n            backgroundImage[:, :, 2] = color_main[2]\n            stripeCount = random.randint(2, 5)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:131-156"
    },
    "2431": {
        "file_id": 260,
        "content": "Code creates a background for an image based on the furthest color from the given colors. It sorts the colors by distance from their average and chooses the furthest one. If the background format is \"horizontalStripes\", \"verticalStripes\" or \"gradients\", it fills the background with this color and another color chosen from the sorted list, then generates a random stripe count for the background image.",
        "type": "comment"
    },
    "2432": {
        "file_id": 260,
        "content": "            if backgroundFormat == \"verticalStripes\":  # slice width\n                arr = np.linspace(0, backgroundShape[1], stripeCount + 1)\n                for width_start, width_end in [\n                    (int(arr[i]), int(arr[i + 1]))\n                    for i in range(stripeCount)\n                    if i % 2 == 1\n                ]:\n                    backgroundImage[:, width_start:width_end, 0] = color_sub[0]\n                    backgroundImage[:, width_start:width_end, 1] = color_sub[1]\n                    backgroundImage[:, width_start:width_end, 2] = color_sub[2]\n            else:  # horizontal. slice height.\n                arr = np.linspace(0, backgroundShape[0], stripeCount + 1)\n                for height_start, height_end in [\n                    (int(arr[i]), int(arr[i + 1]))\n                    for i in range(stripeCount)\n                    if i % 2 == 1\n                ]:\n                    backgroundImage[height_start:height_end, :, 0] = color_sub[0]\n                    backgroundImage[height_start:height_end, :, 1] = color_sub[1]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:157-176"
    },
    "2433": {
        "file_id": 260,
        "content": "Code snippet generates a background image with vertical or horizontal stripes based on the `backgroundFormat`. For the \"verticalStripes\" format, it creates an array of strip widths and sets the corresponding pixel values for each strip. Otherwise, for the \"horizontal\" format, it creates an array of strip heights and sets the corresponding pixel values for each strip.",
        "type": "comment"
    },
    "2434": {
        "file_id": 260,
        "content": "                    backgroundImage[height_start:height_end, :, 2] = color_sub[2]\n        else:  # gradient!\n            is_horizontal = [False, False, False]\n            is_horizontal[random.randint(0, 2)] = True\n            backgroundImage = get_gradient_3d(\n                backgroundShape[1],\n                backgroundShape[0],\n                color_main,\n                color_sub,\n                is_horizontal,\n            )\n    else:  # pure color.\n        backgroundImage = np.zeros(backgroundShape, dtype=np.uint8)\n        backgroundImage[:, :, 0] = color_main[0]\n        backgroundImage[:, :, 1] = color_main[1]\n        backgroundImage[:, :, 2] = color_main[2]\n    ## next, paint text!\n    if textFormat != \"none\":\n        ## only calculate text color when needed.\n        backgroundAverageColor = np.average(backgroundImage.reshape((-1, 3)), axis=0)\n        textColorNumpyArray = sorted(\n            colorsNumpyArray,\n            key=lambda colorNumpyArray: -np.sum(\n                np.abs(backgroundAverageColor - np.array(colorNumpyArray))",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:177-201"
    },
    "2435": {
        "file_id": 260,
        "content": "This code generates background images based on the given parameters: pure color, gradient, or a combination of both. It also calculates the text color by comparing the background image's average color with a list of colors to find the best match.",
        "type": "comment"
    },
    "2436": {
        "file_id": 260,
        "content": "            ),\n        )[0]\n        textColor = textColorNumpyArray.tolist()\n        # let's paint it all over the place!\n        textShift = 40\n        # TODO: check if string is **just enough** to fill the background.\n        for textLineIndex in range(\n            int((backgroundShape[0] / (textTotalHeight + width)) * 27)\n        ):\n            baseNumber = 50\n            baseNumber2 = random.randint(1, baseNumber)\n            textContent = random.choice(\n                [\n                    \"\",\n                    (\" \" * baseNumber2)\n                    + getRandomCharacters(random.randint(0, baseNumber - baseNumber2)),\n                ]\n            )\n            backgroundImage = cv2.putText(\n                backgroundImage,\n                textContent,\n                (textOrigin[0], textOrigin[1] + textShift * textLineIndex),\n                font,\n                fontScale,\n                textColor,\n                fontThickness,\n                cv2.LINE_AA,\n            )\n    ## put pictures!\n    imageCanvasShape = (imageCanvasHeight, width, 3)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:202-232"
    },
    "2437": {
        "file_id": 260,
        "content": "This code generates a random text overlay on an image using OpenCV's putText function. It randomly selects and modifies a character string, then applies it to the image at various locations. The background shape is used to determine the number of overlays generated.",
        "type": "comment"
    },
    "2438": {
        "file_id": 260,
        "content": "    imageMask = Image.new(\n        \"RGB\", (imageCanvasShape[1], imageCanvasShape[0]), \"black\"\n    )  # width, height?\n    draw = ImageDraw.Draw(imageMask)\n    imageCanvas = np.zeros(imageCanvasShape, dtype=np.uint8)\n    imageCoordinates = []\n    if imageFormat == 1:\n        image = selectedImages[0]\n        imageShape = image.shape\n        margin = getMarginRatio()\n        base = width * (1 - margin * 2)\n        imageHeight, imageWidth = imageShape[:2]\n        if imageHeight > imageWidth:\n            imageShape = (int(base * (imageWidth / imageHeight)), int(base))\n        else:\n            imageShape = (int(base), int(base * (imageHeight / imageWidth)))\n        # print(image.shape)\n        image = cv2.resize(image, imageShape)\n        x0 = int((width - imageShape[0]) / 2)\n        x1 = x0 + imageShape[0]\n        y0 = int((width - imageShape[1]) / 2)\n        y1 = y0 + imageShape[1]\n        if random.random() > 0.5:\n            draw.rectangle((x0, y0, x1, y1), fill=\"white\")\n        else:\n            draw.rounded_rectangle(",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:234-263"
    },
    "2439": {
        "file_id": 260,
        "content": "Creates a mask image for given shape, draws on it based on the image format and random selection, then resizes the selected image according to the new shape. It also determines the coordinates for drawing rounded rectangles on the mask.",
        "type": "comment"
    },
    "2440": {
        "file_id": 260,
        "content": "                (x0, y0, x1, y1),\n                fill=\"white\",\n                radius=min(int(x1 - x0) / 2, int(y1 - y0) / 2, getRadius()),\n            )\n        # print(\"___\")\n        # print(imageShape)\n        # print(imageCanvas.shape)\n        # print(image.shape)\n        # print(x0,x1,x1-x0)\n        # print(y0,y1,y1-y0)\n        # print(\"___\")\n        # cv2.imshow(\"mask\", np.array(imageMask))\n        # cv2.waitKey(0)\n        imageCanvas[y0 : image.shape[0] + y0, x0 : image.shape[1] + x0, :] = image\n        imageCoordinates.append(\n            (\n                x0 + image.shape[1] / 2,\n                y0 + image.shape[0] / 2,\n                image.shape[1],\n                image.shape[0],\n            )\n        )  # x_center, y_center, width, height\n    else:\n        basePoints = [\n            (x * half_width, y * half_width)\n            for x, y in [(0, 0), (1, 0), (1, 1), (0, 1)]\n        ]  # width, height\n        for index, image in enumerate(selectedImages):\n            imageShape = image.shape\n            margin = getMarginRatio()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:264-296"
    },
    "2441": {
        "file_id": 260,
        "content": "This code is creating a mask for an image, adjusting the radius for the ellipse shape, and then composites it with other images if needed. It also calculates the base points for a rectangle, and gets the image shapes of each selected image in the list. The \"else\" part suggests that there is a condition being checked before this code block is executed. The function getMarginRatio() and getRadius() are used to calculate the margins and radius of the ellipse respectively.",
        "type": "comment"
    },
    "2442": {
        "file_id": 260,
        "content": "            base = half_width * (1 - margin * 2)\n            imageHeight, imageWidth = imageShape[:2]\n            if imageHeight > imageWidth:\n                imageShape = (int(base * (imageWidth / imageHeight)), int(base))\n            else:\n                imageShape = (int(base), int(base * (imageHeight / imageWidth)))\n            image = cv2.resize(image, imageShape)\n            x0 = int((half_width - imageShape[0]) / 2) + basePoints[index][0]\n            x1 = x0 + imageShape[0]\n            y0 = int((half_width - imageShape[1]) / 2) + basePoints[index][1]\n            y1 = y0 + imageShape[1]\n            if random.random() > 0.5:\n                draw.rectangle((x0, y0, x1, y1), fill=\"white\")\n            else:\n                draw.rounded_rectangle(\n                    (x0, y0, x1, y1),\n                    fill=\"white\",\n                    radius=min(int(x1 - x0) / 2, int(y1 - y0) / 2, getRadius()),\n                )\n            imageCanvas[y0 : image.shape[0] + y0, x0 : image.shape[1] + x0, :] = image\n            imageCoordinates.append(",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:297-321"
    },
    "2443": {
        "file_id": 260,
        "content": "Resizing image to fit within specified bounds and applying rectangle or rounded rectangle based on random chance, then combining with canvas image.",
        "type": "comment"
    },
    "2444": {
        "file_id": 260,
        "content": "                (\n                    x0 + image.shape[1] / 2,\n                    y0 + image.shape[0] / 2,\n                    image.shape[1],\n                    image.shape[0],\n                )\n            )  # x_center, y_center, width, height\n    ## mix images with mask\n    imageMaskNumpyArray = np.array(imageMask) / 255  # float64\n    imageMaskNumpyArrayInverted = 1 - imageMaskNumpyArray\n    x0 = 0\n    y0 = textTotalHeight if textFormat == \"up\" else 0\n    backgroundImage[y0 : y0 + imageCanvasShape[0], x0 : x0 + imageCanvasShape[1], :] = (\n        backgroundImage[y0 : y0 + imageCanvasShape[0], x0 : x0 + imageCanvasShape[1], :]\n        * imageMaskNumpyArrayInverted\n    ).astype(np.uint8) + (imageCanvas * imageMaskNumpyArray).astype(np.uint8)\n    # print()\n    ## get labels which will be exported to txt\n    contents = []\n    for coord in imageCoordinates:\n        x_center_relative, y_center_relative, imWidth, imHeight = coord\n        x_center, y_center = x_center_relative + x0, y_center_relative + y0\n        dataPoints = [",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:322-349"
    },
    "2445": {
        "file_id": 260,
        "content": "Code snippet combines images with a mask, creates a new image by multiplying original image with mask and inverting the result. This modified image is then added to the background image, creating an overlay effect. The code also collects data points for labels that will be exported to txt files.",
        "type": "comment"
    },
    "2446": {
        "file_id": 260,
        "content": "            x_center / backgroundShape[1],\n            y_center / backgroundShape[0],\n            imWidth / backgroundShape[1],\n            imHeight / backgroundShape[0],\n        ]\n        labelString = \" \".join(([\"0\"] + [f\"{number:.3f}\" for number in dataPoints]))\n        contents.append(labelString)\n        # print(\"LABELSTRING?\", labelString)\n    ## preview\n    # previewImageName = f\"{imageFormat}_{textFormat}_{backgroundFormat}.png\"\n    realIndex = imageIndex + _i\n    cv2.imwrite(\n        os.path.join(train_path_relative, f\"{str(realIndex).zfill(12)}.png\"),\n        backgroundImage,\n    )\n    with open(\n        os.path.join(train_label_path_relative, f\"{str(realIndex).zfill(12)}.txt\"), \"w+\"\n    ) as f:\n        f.write(\"\\n\".join(contents))\n    # cv2.imshow(previewImageName, backgroundImage)\n    # cv2.waitKey(0)\nprint(\"coco pip dataset created!\")",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset_standalone.py:350-374"
    },
    "2447": {
        "file_id": 260,
        "content": "Creates COCO-style pip dataset standalone by iterating over images and labels, writing them to train_path_relative and train_label_path_relative, with real indexing. It also prints a confirmation message upon completion.",
        "type": "comment"
    },
    "2448": {
        "file_id": 261,
        "content": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py",
        "type": "filepath"
    },
    "2449": {
        "file_id": 261,
        "content": "The code creates a COCO-PIP dataset by generating four identical images, adjusting parameters randomly. It utilizes numpy arrays and defines functions for gradient images and background colors. It generates bounding boxes, resizes images, and prepares image canvas for data export and preview.",
        "type": "summary"
    },
    "2450": {
        "file_id": 261,
        "content": "# use what? better use some standard library.\n# you must know where you have put all these images.\n# TODO: remember to upload dataset creation things to kaggle as separate python scripts and execute it in separate process to prevent memory leaks (hopefully)\nimport cv2\nimport numpy as np\nimport os\nfrom string import punctuation\nimport random\nimport itertools\nfrom PIL import Image, ImageDraw\nimageBasePath = \"/Users/jamesbrown/Desktop/\"\nimagePaths = [\n    \"Screen Shot 2023-01-17 at 15.35.29.png\"\n] * 4  # let's all be the same, for testing.\nwidth = 800\nhalf_width = int(width / 2)  # either use 1,2,4 images.\ntextTotalHeight = 300  # either add to top or bottom.\ngetMarginRatio = lambda: random.choice(\n    [0, random.random() * 0.15, random.random() * 0.1, random.random() * 0.05]\n)  # this margin is used randomly. we can make it 0 or as is.\ntextOrigin = (-30, 30)\nfontScale = 1\nfont = cv2.FONT_HERSHEY_SIMPLEX\nfontThickness = 2\ngetRadius = lambda: random.randint(1, 30)\nimageIndex = 0  # shall be increased on demand.\nMAX_COCO_PIP_IMAGE_COUNT = 10000  # well, super huge. is it?",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:1-34"
    },
    "2451": {
        "file_id": 261,
        "content": "Code imports necessary libraries and defines variables for creating a COCO-PIP dataset. It uses four identical images, adjusts image size and positioning parameters randomly, and sets maximum image count.",
        "type": "comment"
    },
    "2452": {
        "file_id": 261,
        "content": "alphabets = \"abcdefghijklmnopqrstuvwxyz\"\nALPHABETS = alphabets.upper()\nnumbers = \"0123456789\"\ncharacterList = list(alphabets + ALPHABETS + numbers + punctuation + \" \")\ngetRandomCharacter = lambda: random.choice(characterList)\ngetRandomCharacters = lambda charCount: \"\".join(\n    [getRandomCharacter() for _ in range(charCount)]\n)\ngetRandomLinesOfCharacters = lambda lineCount, charCount: \"\\r\".join(\n    [getRandomCharacters(charCount) for _ in range(lineCount)]\n)\nimageFormats = [1, 2, 4]\ntextFormats = [\"up\", \"down\", \"none\"]\nbackgroundFormats = [\"solidColor\", \"horizontalStripes\", \"verticalStripes\", \"gradients\"]\ncolors = [\n    (0, 0, 0),\n    (255, 255, 255),\n    (0, 0, 192),\n    (255, 255, 64),\n    (0, 255, 0),\n    (0, 0, 255),\n    (255, 0, 0),\n]\ncolorsNumpyArray = [np.array(color) for color in colors]\ncolorsWithIndex = [(index, color) for index, color in enumerate(colors)]\n# we are not doing this while testing.\n# imageFormat = random.choice(imageFormats)\n# textFormat = random.choice(textFormats)\n# backgroundFormat = random.choice(backgroundFormats)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:36-68"
    },
    "2453": {
        "file_id": 261,
        "content": "This code generates random characters, lines of characters, and sets up variables for image, text, and background formats along with colors. It uses a lambda function to generate random characters, joining them into lines. The code also includes a list of color options and converts them into numpy arrays. However, while testing, the code is not choosing random values from imageFormats, textFormats, and backgroundFormats.",
        "type": "comment"
    },
    "2454": {
        "file_id": 261,
        "content": "def get_gradient_2d(start, stop, width, height, is_horizontal):\n    if is_horizontal:\n        return np.tile(np.linspace(start, stop, width), (height, 1))\n    else:\n        return np.tile(np.linspace(start, stop, height), (width, 1)).T\ndef get_gradient_3d(width, height, start_list, stop_list, is_horizontal_list):\n    result = np.zeros((height, width, len(start_list)), dtype=np.float64)\n    for i, (start, stop, is_horizontal) in enumerate(\n        zip(start_list, stop_list, is_horizontal_list)\n    ):\n        result[:, :, i] = get_gradient_2d(start, stop, width, height, is_horizontal)\n    return result.astype(np.uint8)\nfor imageFormat, textFormat, backgroundFormat in itertools.product(\n    imageFormats, textFormats, backgroundFormats\n):  # you can use these things to get test output picture names.\n    colorDistances = {}\n    selectedImages = [\n        cv2.imread(os.path.join(imageBasePath, imagePath), cv2.IMREAD_COLOR)\n        for imagePath in random.sample(imagePaths, k=imageFormat)\n    ]\n    for image in selectedImages:",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:71-95"
    },
    "2455": {
        "file_id": 261,
        "content": "This code defines two functions: `get_gradient_2d` and `get_gradient_3d`. The former creates a 2D gradient image based on a start, stop value, width, height, and whether the gradient should be horizontal or vertical. The latter function generates a 3D gradient image by applying the former function to multiple pairs of start/stop values in different layers. The code then uses `itertools.product` to generate combinations of image, text, and background formats for creating test output picture names. It reads images from `imageBasePath` based on the selected imagePaths and applies colorDistance calculations.",
        "type": "comment"
    },
    "2456": {
        "file_id": 261,
        "content": "        averageColor = np.average(image.reshape((-1, 3)), axis=0)\n        for index, colorNumpyArray in enumerate(colorsNumpyArray):\n            colorDistances[index] = colorDistances.get(index, []) + [\n                np.sum(np.abs(averageColor - colorNumpyArray))\n            ]\n    sortedColorsWithIndex = sorted(\n        colorsWithIndex, key=lambda element: -np.sum(colorDistances[element[0]])\n    )  # the further the better.\n    # sortedColors = [color for _, color in sortedColorsWithIndex]\n    ## create background first.\n    imageCanvasHeight = half_width if imageFormat == 2 else width\n    textCanvasHeight = 0 if textFormat == \"none\" else textTotalHeight\n    backgroundShape = (imageCanvasHeight + textCanvasHeight, width, 3)  # height, width\n    _, color_main = sortedColorsWithIndex[0]\n    if backgroundFormat in [\"horizontalStripes\", \"verticalStripes\", \"gradients\"]:\n        # fill background with color_main first.\n        _, color_sub = sortedColorsWithIndex[1]\n        if backgroundFormat in [\"horizontalStripes\", \"verticalStripes\"]:",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:96-118"
    },
    "2457": {
        "file_id": 261,
        "content": "This code calculates the average color of an image, then compares it to a set of colors to determine their distances. It sorts these colors by distance and uses the furthest as the main background color. If the format requires more than one color (stripes or gradients), it also takes the second-closest color as the sub color.",
        "type": "comment"
    },
    "2458": {
        "file_id": 261,
        "content": "            backgroundImage = np.zeros(backgroundShape, dtype=np.uint8)\n            backgroundImage[:, :, 0] = color_main[0]\n            backgroundImage[:, :, 1] = color_main[1]\n            backgroundImage[:, :, 2] = color_main[2]\n            stripeCount = random.randint(2, 5)\n            if backgroundFormat == \"verticalStripes\":  # slice width\n                arr = np.linspace(0, backgroundShape[1], stripeCount + 1)\n                for width_start, width_end in [\n                    (int(arr[i]), int(arr[i + 1]))\n                    for i in range(stripeCount)\n                    if i % 2 == 1\n                ]:\n                    backgroundImage[:, width_start:width_end, 0] = color_sub[0]\n                    backgroundImage[:, width_start:width_end, 1] = color_sub[1]\n                    backgroundImage[:, width_start:width_end, 2] = color_sub[2]\n            else:  # horizontal. slice height.\n                arr = np.linspace(0, backgroundShape[0], stripeCount + 1)\n                for height_start, height_end in [",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:120-139"
    },
    "2459": {
        "file_id": 261,
        "content": "This code creates a background image with vertical or horizontal stripes based on the 'backgroundFormat' parameter. It first initializes a background image, then randomly determines the number of stripes (2-5) using 'stripeCount'. Depending on the format, it slices the image width or height into equal parts and assigns colors to each stripe section with 'arr', 'width_start', 'width_end' or 'height_start', 'height_end' variables.",
        "type": "comment"
    },
    "2460": {
        "file_id": 261,
        "content": "                    (int(arr[i]), int(arr[i + 1]))\n                    for i in range(stripeCount)\n                    if i % 2 == 1\n                ]:\n                    backgroundImage[height_start:height_end, :, 0] = color_sub[0]\n                    backgroundImage[height_start:height_end, :, 1] = color_sub[1]\n                    backgroundImage[height_start:height_end, :, 2] = color_sub[2]\n        else:  # gradient!\n            is_horizontal = [False, False, False]\n            is_horizontal[random.randint(0, 2)] = True\n            backgroundImage = get_gradient_3d(\n                backgroundShape[1],\n                backgroundShape[0],\n                color_main,\n                color_sub,\n                is_horizontal,\n            )\n    else:  # pure color.\n        backgroundImage = np.zeros(backgroundShape, dtype=np.uint8)\n        backgroundImage[:, :, 0] = color_main[0]\n        backgroundImage[:, :, 1] = color_main[1]\n        backgroundImage[:, :, 2] = color_main[2]\n    ## next, paint text!\n    if textFormat != \"none\":",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:140-164"
    },
    "2461": {
        "file_id": 261,
        "content": "This code determines the background image of the image by either assigning a solid color, gradient or pure color depending on the input. It also paints text if the format is not \"none\".",
        "type": "comment"
    },
    "2462": {
        "file_id": 261,
        "content": "        ## only calculate text color when needed.\n        backgroundAverageColor = np.average(backgroundImage.reshape((-1, 3)), axis=0)\n        textColorNumpyArray = sorted(\n            colorsNumpyArray,\n            key=lambda colorNumpyArray: -np.sum(\n                np.abs(backgroundAverageColor - np.array(colorNumpyArray))\n            ),\n        )[0]\n        textColor = textColorNumpyArray.tolist()\n        # let's paint it all over the place!\n        textShift = 40\n        # TODO: check if string is **just enough** to fill the background.\n        for textLineIndex in range(\n            int((backgroundShape[0] / (textTotalHeight + width)) * 27)\n        ):\n            baseNumber = 50\n            baseNumber2 = random.randint(1, baseNumber)\n            textContent = random.choice(\n                [\n                    \"\",\n                    (\" \" * baseNumber2)\n                    + getRandomCharacters(random.randint(0, baseNumber - baseNumber2)),\n                ]\n            )\n            backgroundImage = cv2.putText(",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:165-189"
    },
    "2463": {
        "file_id": 261,
        "content": "This code calculates a text color that is complementary to the background image. It then generates random texts and places them on the image with varying positions and sizes, using OpenCV's putText function.",
        "type": "comment"
    },
    "2464": {
        "file_id": 261,
        "content": "                backgroundImage,\n                textContent,\n                (textOrigin[0], textOrigin[1] + textShift * textLineIndex),\n                font,\n                fontScale,\n                textColor,\n                fontThickness,\n                cv2.LINE_AA,\n            )\n    ## put pictures!\n    imageCanvasShape = (imageCanvasHeight, width, 3)\n    imageMask = Image.new(\n        \"RGB\", (imageCanvasShape[1], imageCanvasShape[0]), \"black\"\n    )  # width, height?\n    draw = ImageDraw.Draw(imageMask)\n    imageCanvas = np.zeros(imageCanvasShape, dtype=np.uint8)\n    imageCoordinates = []\n    if imageFormat == 1:\n        image = selectedImages[0]\n        imageShape = image.shape\n        margin = getMarginRatio()\n        base = width * (1 - margin * 2)\n        imageHeight, imageWidth = imageShape[:2]\n        if imageHeight > imageWidth:\n            imageShape = (int(base * (imageWidth / imageHeight)), int(base))\n        else:\n            imageShape = (int(base), int(base * (imageHeight / imageWidth)))\n        # print(image.shape)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:190-221"
    },
    "2465": {
        "file_id": 261,
        "content": "This code prepares an image canvas for a specific image format. It creates an image mask with the same dimensions as the canvas and fills it with black color. It then initializes the main image canvas with zeros and starts preparing an array of coordinates for drawing images onto the canvas based on the selected image format.",
        "type": "comment"
    },
    "2466": {
        "file_id": 261,
        "content": "        image = cv2.resize(image, imageShape)\n        x0 = int((width - imageShape[0]) / 2)\n        x1 = x0 + imageShape[0]\n        y0 = int((width - imageShape[1]) / 2)\n        y1 = y0 + imageShape[1]\n        if random.random() > 0.5:\n            draw.rectangle((x0, y0, x1, y1), fill=\"white\")\n        else:\n            draw.rounded_rectangle(\n                (x0, y0, x1, y1),\n                fill=\"white\",\n                radius=min(int(x1 - x0) / 2, int(y1 - y0) / 2, getRadius()),\n            )\n        # print(\"___\")\n        # print(imageShape)\n        # print(imageCanvas.shape)\n        # print(image.shape)\n        # print(x0,x1,x1-x0)\n        # print(y0,y1,y1-y0)\n        # print(\"___\")\n        # cv2.imshow(\"mask\", np.array(imageMask))\n        # cv2.waitKey(0)\n        imageCanvas[y0 : image.shape[0] + y0, x0 : image.shape[1] + x0, :] = image\n        imageCoordinates.append(\n            (\n                x0 + image.shape[1] / 2,\n                y0 + image.shape[0] / 2,\n                image.shape[1],\n                image.shape[0],",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:222-254"
    },
    "2467": {
        "file_id": 261,
        "content": "The code resizes an image, generates a bounding box around the image, and randomly chooses between drawing a rectangle or rounded rectangle with white fill color. It then combines the image and the canvas by assigning the image to specific coordinates on the canvas and appends the bounding box coordinates to the imageCoordinates list.",
        "type": "comment"
    },
    "2468": {
        "file_id": 261,
        "content": "            )\n        )  # x_center, y_center, width, height\n    else:\n        basePoints = [\n            (x * half_width, y * half_width)\n            for x, y in [(0, 0), (1, 0), (1, 1), (0, 1)]\n        ]  # width, height\n        for index, image in enumerate(selectedImages):\n            imageShape = image.shape\n            margin = getMarginRatio()\n            base = half_width * (1 - margin * 2)\n            imageHeight, imageWidth = imageShape[:2]\n            if imageHeight > imageWidth:\n                imageShape = (int(base * (imageWidth / imageHeight)), int(base))\n            else:\n                imageShape = (int(base), int(base * (imageHeight / imageWidth)))\n            image = cv2.resize(image, imageShape)\n            x0 = int((half_width - imageShape[0]) / 2) + basePoints[index][0]\n            x1 = x0 + imageShape[0]\n            y0 = int((half_width - imageShape[1]) / 2) + basePoints[index][1]\n            y1 = y0 + imageShape[1]\n            if random.random() > 0.5:\n                draw.rectangle((x0, y0, x1, y1), fill=\"white\")",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:255-281"
    },
    "2469": {
        "file_id": 261,
        "content": "This code resizes images to fit a specified rectangle shape and randomly colors the rectangles white or leaves them transparent.",
        "type": "comment"
    },
    "2470": {
        "file_id": 261,
        "content": "            else:\n                draw.rounded_rectangle(\n                    (x0, y0, x1, y1),\n                    fill=\"white\",\n                    radius=min(int(x1 - x0) / 2, int(y1 - y0) / 2, getRadius()),\n                )\n            imageCanvas[y0 : image.shape[0] + y0, x0 : image.shape[1] + x0, :] = image\n            imageCoordinates.append(\n                (\n                    x0 + image.shape[1] / 2,\n                    y0 + image.shape[0] / 2,\n                    image.shape[1],\n                    image.shape[0],\n                )\n            )  # x_center, y_center, width, height\n    ## mix images with mask\n    imageMaskNumpyArray = np.array(imageMask) / 255  # float64\n    imageMaskNumpyArrayInverted = 1 - imageMaskNumpyArray\n    x0 = 0\n    y0 = textTotalHeight if textFormat == \"up\" else 0\n    backgroundImage[y0 : y0 + imageCanvasShape[0], x0 : x0 + imageCanvasShape[1], :] = (\n        backgroundImage[y0 : y0 + imageCanvasShape[0], x0 : x0 + imageCanvasShape[1], :]\n        * imageMaskNumpyArrayInverted",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:282-308"
    },
    "2471": {
        "file_id": 261,
        "content": "This code creates a rounded rectangle with white fill, then combines it with an image and stores the coordinates. It also adjusts mask images and blends them into a background image using numpy arrays.",
        "type": "comment"
    },
    "2472": {
        "file_id": 261,
        "content": "    ).astype(np.uint8) + (imageCanvas * imageMaskNumpyArray).astype(np.uint8)\n    print()\n    ## get labels which will be exported to txt\n    for coord in imageCoordinates:\n        x_center_relative, y_center_relative, imWidth, imHeight = coord\n        x_center, y_center = x_center_relative + x0, y_center_relative + y0\n        dataPoints = [\n            x_center / backgroundShape[1],\n            y_center / backgroundShape[0],\n            imWidth / backgroundShape[1],\n            imHeight / backgroundShape[0],\n        ]\n        labelString = \" \".join(([\"0\"] + [f\"{number:.3f}\" for number in dataPoints]))\n        print(\"LABELSTRING?\", labelString)\n    ## preview\n    previewImageName = f\"{imageFormat}_{textFormat}_{backgroundFormat}.png\"\n    cv2.imshow(previewImageName, backgroundImage)\n    cv2.waitKey(0)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/create_coco_pip_dataset.py:309-329"
    },
    "2473": {
        "file_id": 261,
        "content": "This code segment performs image manipulation, extracts coordinates, and generates labels for data export. It also creates a preview image before saving.",
        "type": "comment"
    },
    "2474": {
        "file_id": 262,
        "content": "/tests/anime_highlight_cuts/theme_collector/bv2av.py",
        "type": "filepath"
    },
    "2475": {
        "file_id": 262,
        "content": "This code defines functions for converting BV and AV IDs. It uses a table to perform the conversion, where 'dec' function is used for decoding BV to AV and 'enc' function is used for encoding AV to BV. The 'bv_av_conversion' function takes a string input as source and returns the corresponding converted ID based on whether it starts with 'BV' or 'AV'. If the input is invalid, it prompts the user to reenter.",
        "type": "summary"
    },
    "2476": {
        "file_id": 262,
        "content": "table = 'fZodR9XQDSUm21yCkr6zBqiveYah8bt4xsWpHnJE7jL5VG3guMTKNPAwcF'\ntr = {}\nfor i in range(58):\n    tr[table[i]] = i\ns = [11, 10, 3, 8, 4, 6]\nxor = 177451812\nadd = 8728348608\ndef dec(x):\n    r = 0\n    for i in range(6):\n        r += tr[x[s[i]]] * 58 ** i\n    return (r - add) ^ xor\ndef enc(x):\n    x = (x ^ xor) + add\n    r = list('BV1  4 1 7  ')\n    for i in range(6):\n        r[s[i]] = table[x // 58 ** i % 58]\n    return ''.join(r)\ndef bv_av_conversion(source:str):\n    print(\"BVAV,BVAV:\") \n    av_bv =source+\"  \"\n    head = str(av_bv[0]) + str(av_bv[1])\n    av = [\"av\", \"AV\", \"Av\", \"aV\"]\n    bv = [\"bv\", \"BV\", \"Bv\", \"bV\"]\n    if head in av:\n        val = (enc(int(av_bv[2:-2])))\n    elif head in bv:\n        val = f\"av{dec('BV' + av_bv[2:-2])}\"\n    else:\n        print(\"\")\n        val = None\n    return val",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/bv2av.py:3-40"
    },
    "2477": {
        "file_id": 262,
        "content": "This code defines functions for converting BV and AV IDs. It uses a table to perform the conversion, where 'dec' function is used for decoding BV to AV and 'enc' function is used for encoding AV to BV. The 'bv_av_conversion' function takes a string input as source and returns the corresponding converted ID based on whether it starts with 'BV' or 'AV'. If the input is invalid, it prompts the user to reenter.",
        "type": "comment"
    },
    "2478": {
        "file_id": 263,
        "content": "/tests/anime_highlight_cuts/theme_collector/bilibili_anime_compilation_finder.py",
        "type": "filepath"
    },
    "2479": {
        "file_id": 263,
        "content": "This code defines a dictionary of tags related to video themes for Bilibili anime compilations. The \"static\" tags include general anime and manga categories, while the \"optional\" tags have more specific recommendations or lists. These tags serve as seeds for analyzing and categorizing videos during compilation processing.",
        "type": "summary"
    },
    "2480": {
        "file_id": 263,
        "content": "# find our target video.\n# you may find uploaders, keywords, tags, recommended videos, video collections/playlists and filter by analyzers (check if is in the target format)\n# how did vscode recommend this shit to me?\n# from sklearn.semi_supervised import LabelSpreading\n#  \ntags = {  # select 1 for each.\n    \"static\": [\n        [\"\", \"\", \"\"],\n        [\n            \"\",\n            \"\",\n            \"\",\n            \"\",\n            \"\",\n        ],\n    ],\n    \"optional\": [  # select one or not select any.\n        [\"\", \"\", \"\", \"\", \"\", \"\"],\n        [\"\", \"\", \"\"],\n    ],\n    # these are seeds. you may have different tags added along the way.\n}",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/bilibili_anime_compilation_finder.py:1-24"
    },
    "2481": {
        "file_id": 263,
        "content": "This code defines a dictionary of tags related to video themes for Bilibili anime compilations. The \"static\" tags include general anime and manga categories, while the \"optional\" tags have more specific recommendations or lists. These tags serve as seeds for analyzing and categorizing videos during compilation processing.",
        "type": "comment"
    },
    "2482": {
        "file_id": 264,
        "content": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py",
        "type": "filepath"
    },
    "2483": {
        "file_id": 264,
        "content": "The code reads video frames, selects the region of interest (ROI), and writes data to a CSV file for each frame in the list. It handles default values if ROI is not found and releases resources upon completion.",
        "type": "summary"
    },
    "2484": {
        "file_id": 264,
        "content": "# check if is the video we want and extract data or discard.\n# maybe you want some challange, so you can make one, right?\n# videos = [\n#     \"286760784_part1-00001.mp4\",\n#     \"329297394_part1-00001.mp4\",\n#     \"541755429_part1-00001.mp4\",\n#     \"842224692_part1-00001.mp4\",\n# ]\nimport os\n# videos = [fpath for fpath in os.listdir(\".\") if fpath.endswith(\".mp4\")]\nvideos = [\"480138800_part1.mp4\"] # mine video, classic!\n# we create dataset here.\n# use some short cuts for progression.\nframe_step = 10\nimport cv2\nimport progressbar\nfrom pynput.keyboard import Listener\nlastKey = [\"not_c\"]\ndef on_press(key):\n    lastKey[0] = \"not_c\"\n    try:\n        # print(\"alphanumeric key {0} pressed\".format(key.char))\n        if key.char in [\"c\", \"C\"]:\n            lastKey[0] = \"c\"\n    except AttributeError:\n        # print(\"special key {0} pressed\".format(key))\n        ...\ndef on_release(key):\n    # print(\"{0} released\".format(key))\n    ...\nlistener = Listener(on_press=on_press, on_release=on_release)\nlistener.start()\n# with listener:\n#     listener.join()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py:1-48"
    },
    "2485": {
        "file_id": 264,
        "content": "This code checks if the video file matches the desired format, creates a dataset, and uses shortcuts for progression. It also listens for keyboard input to determine when to stop running.",
        "type": "comment"
    },
    "2486": {
        "file_id": 264,
        "content": "# how do you arrange such data?\nfields = [\"filename\", \"frame_index\", \"x\", \"y\", \"w\", \"h\"]\nimport csv\nfor index, video in enumerate(videos):\n    with open(f'{video.split(\".\")[0]}.csv', \"w+\") as csvfile:\n        csvwriter = csv.writer(csvfile)\n        csvwriter.writerow(fields)\n        print(\"reading video:\", index)\n        roi = None\n        cap = cv2.VideoCapture(video)\n        for vindex in progressbar.progressbar(\n            range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), frame_step)\n        ):\n            cap.set(cv2.CAP_PROP_POS_FRAMES, vindex)\n            succ, image = cap.read()\n            if succ:\n                roi_new = cv2.selectROI(\"roi\", image)\n                # key=cv2.waitKey(0)\n                print(\"roi_new:\", roi_new)\n                print(\"last key:\", lastKey[0])\n                # print()\n                # print('keycode:',key)\n                if roi_new == (0, 0, 0, 0):\n                    if lastKey[0] == \"c\":\n                        # this is cancelled. roi will be nothing!\n                        roi = None",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py:50-77"
    },
    "2487": {
        "file_id": 264,
        "content": "This code reads a video and allows the user to select a region of interest (ROI) from each frame. It then writes the frame index, x, y, width, and height of the ROI in a CSV file for each frame of the video. The process is repeated for each video in the list.",
        "type": "comment"
    },
    "2488": {
        "file_id": 264,
        "content": "                else:\n                    roi = roi_new\n                print(\"roi:\", roi)\n                for i in range(frame_step):\n                    roi_index = vindex + i\n                    data = [video, roi_index]\n                    if roi == None:\n                        data += [0, 0, 0, 0]\n                    else:\n                        data += list(roi)\n                    csvwriter.writerow(data)\n        cap.release()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_frame_cropper_labeller.py:78-89"
    },
    "2489": {
        "file_id": 264,
        "content": "This code reads video frames, determines the region of interest (ROI), and writes data to a CSV file. If the ROI is not found, it adds default values. The loop iterates through each frame step, updating the ROI index and writing the data. Finally, it releases the video capture resource.",
        "type": "comment"
    },
    "2490": {
        "file_id": 265,
        "content": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py",
        "type": "filepath"
    },
    "2491": {
        "file_id": 265,
        "content": "Code uses yt-dlp to download Bilibili videos and handles errors. Snippet lists current directory files, checks filenames against \"expectedNamePrefix\", and prints \"TARGET FOUND!\" if a match is found.",
        "type": "summary"
    },
    "2492": {
        "file_id": 265,
        "content": "# we name downloaded video using some agreements.\nimport os\n# yt-dlp --skip-download -j https://www.bilibili.com/video/BV1e54y1y7qy\n# i guess it is because we are using proxies.\n# no? what the heck?\n# remapped /opt/homebrew/bin/yt-dlp from homebrew's (dependency of mpv) to /Users/jamesbrown/Library/Python/3.8/bin/yt-dlp. really annoying when trying to update (will install python 3.11 (heck!))\n# version outdated. fuck man.\n# yt-dlp --download-sections \"*0:00:03-0:01:00\" --playlist-items \"1\" https://www.bilibili.com/video/BV1Fs411k7e9\nvideoIDs = [\n    \"BV1e54y1y7qy\",  # 842224692_part1-00001\n    \"BV1Qf4y197bt\",  # great challange, 286760784\n    \"BV1bi4y1g7Gd\",  # watermark, full screen, 541755429\n    \"BV1PA411n7N6\",  # shit jumping around, 329297394\n]\nvideoID = videoIDs[3]\nfrom bv2av import bv_av_conversion\nvideoIDAlternative = bv_av_conversion(videoID)\nimport re\nif videoIDAlternative is None: # not av or bv. shit happened!\n    raise Exception(\"Possible shit happening when parsing bilibili video id:\", videoID)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py:1-26"
    },
    "2493": {
        "file_id": 265,
        "content": "This code downloads videos from Bilibili using yt-dlp and converts the video ID to a valid format. It handles potential errors by raising exceptions if the conversion fails or if an alternative conversion is required. The code also mentions some issues related to the yt-dlp version, outdated dependencies, and updating Python.",
        "type": "comment"
    },
    "2494": {
        "file_id": 265,
        "content": "else:\n    if videoIDAlternative.startswith(\"av\"):\n        videoAVID, videoBVID = videoIDAlternative, videoID\n    else:\n        videoBVID, videoAVID = videoIDAlternative, videoID\nprint(videoAVID, type(videoAVID))\nvideoAID = re.findall(r\"\\d+\", videoAVID)[0]\nurl = f\"https://www.bilibili.com/video/{videoBVID}\"  # only one single page.\n# 290 seconds.\n# section example:\n# 0:05:00-0:06:30\n# import time\n# secondsToHHMMSS = lambda seconds:time.strftime('%H:%M:%S', time.gmtime(seconds))\n# some formats are not working. fuck.\nplaylistIndex = \"1\"\n# start = secondsToHHMMSS(100)\n# end = secondsToHHMMSS(150)\n# print('TIMESPAN:',start, end)\nnameFormat = \"%(id)s-%(autonumber)s.%(ext)s\"\ncmd = f'yt-dlp --playlist-items \"{playlistIndex}\" -o \"{nameFormat}\" \"{url}\"'\n# cmd=f'yt-dlp --download-sections \"*{start}-{end}\" --playlist-items \"{playlistIndex}\" -o \"{nameFormat}\"  \"{url}\"'\nos.system(cmd)\nautonumber = \"1\".zfill(5)\nexpectedNamePrefix = f\"{videoAID}_part{playlistIndex}-{autonumber}\"\nprint(\"expected filename prefix:\", expectedNamePrefix)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py:27-59"
    },
    "2495": {
        "file_id": 265,
        "content": "Code snippet downloads videos from Bilibili using yt-dlp and saves them as parts with specified video IDs. It converts video IDs to the expected filename prefix and executes the command to download the videos.",
        "type": "comment"
    },
    "2496": {
        "file_id": 265,
        "content": "files = os.listdir(\".\")\nfor fname in files:\n    if fname.startswith(expectedNamePrefix):\n        print(\"TARGET FOUND!\")\n        print(\"FILENAME:\", fname)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/theme_collector/anime_video_downloader.py:60-65"
    },
    "2497": {
        "file_id": 265,
        "content": "This code snippet lists all files in the current directory and checks if any filename starts with the given \"expectedNamePrefix\". If a match is found, it prints \"TARGET FOUND!\" along with the filename.",
        "type": "comment"
    },
    "2498": {
        "file_id": 266,
        "content": "/tests/anime_highlight_cuts/theme_collector/anime_compilation_video_metadata.py",
        "type": "filepath"
    },
    "2499": {
        "file_id": 266,
        "content": "This Python script utilizes yt-dlp and Bilibili API to retrieve bilibili video metadata, unique identifiers, and related info. Error handling is needed for missing tags.",
        "type": "summary"
    }
}