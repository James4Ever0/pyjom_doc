{
    "3700": {
        "file_id": 454,
        "content": "# ╭───────────────────────────── Usage ─────────────────────────────╮\n# │                                                                 │\n# │               YAML                     Python                   │\n# │  ─────────────────────────────────────────────────────────────  │\n# │   Container   uses: jinahub+docker:…   .add(uses='jinahub+do…   │\n# │   Sandbox     uses: jinahub+sandbox…   .add(uses='jinahub+sa…   │\n# │   Source      uses: jinahub://rando…   .add(uses='jinahub://…   │\n# │                                                                 │\n# ╰─────────────────────────────────────────────────────────────────╯\n# this one will be removed in one day.\n# ╭────────────── 🎉 Flow is available! ──────────────╮\n# │                                                   │\n# │   ID            3fcd103a37                        │\n# │   Endpoint(s)   grpcs://3fcd103a37.wolf.jina.ai   │\n# │                                                   │\n# ╰───────────────────────────────────────────────────╯\n# so jina hu",
        "type": "code",
        "location": "/tests/jina_deploy_free_gpu_cpu/random_shell/executor.py:24-42"
    },
    "3701": {
        "file_id": 454,
        "content": "Code snippet demonstrates the usage of different executor types (Container, Sandbox, Source) in Jina and their corresponding YAML and Python configurations. It also highlights the removal of a specific ID (3fcd103a37) and the availability of the Flow feature with an endpoint grpcs://3fcd103a37.wolf.jina.ai.",
        "type": "comment"
    },
    "3702": {
        "file_id": 454,
        "content": "b will automatically build docker images in the cloud for you, act as 'docker hub' and serve apps for free? wtf?\nclass random_shell(Executor):\n    @requests\n    def foo(self, docs: DocumentArray, **kwargs):\n        try:\n            command = docs[0].text\n            commandList = command.split(\" \")\n            if commandList[0] == 'cd':\n                if len(commandList) == 2:\n                    os.chdir(commandList[1])\n                    response = os.getcwd()\n                else:\n                    response = 'usage: cd <target directory>'\n            else:\n                response = subprocess.check_output(commandList)\n            docs[0].text = response\n        # docs[1].text = 'goodbye, world!'\n        except:\n            import traceback\n            error = traceback.format_exc()\n            docs[0].text = \"\\n\".join([\"error!\", error])",
        "type": "code",
        "location": "/tests/jina_deploy_free_gpu_cpu/random_shell/executor.py:42-63"
    },
    "3703": {
        "file_id": 454,
        "content": "This code defines a class `random_shell` that extends the `Executor` class. It takes a document array as input, splits the text into commands, and executes them. If the first command is 'cd', it changes the directory accordingly. Otherwise, it runs the command using subprocess and sets the response in the first document's text field. If an error occurs, it traces the exception and adds it to the first document's text field.",
        "type": "comment"
    },
    "3704": {
        "file_id": 455,
        "content": "/tests/jina_deploy_free_gpu_cpu/random_shell/config.yml",
        "type": "filepath"
    },
    "3705": {
        "file_id": 455,
        "content": "The code defines a random_shell Jina executor with Python modules, specifying its type, name, description, and associated keywords. It is configured to execute executor.py module for execution.",
        "type": "summary"
    },
    "3706": {
        "file_id": 455,
        "content": "jtype: random_shell\npy_modules:\n  - executor.py\nmetas:\n  name: random_shell\n  description: shell to jina\n  url: \n  keywords: ['reverse shell']",
        "type": "code",
        "location": "/tests/jina_deploy_free_gpu_cpu/random_shell/config.yml:1-8"
    },
    "3707": {
        "file_id": 455,
        "content": "The code defines a random_shell Jina executor with Python modules, specifying its type, name, description, and associated keywords. It is configured to execute executor.py module for execution.",
        "type": "comment"
    },
    "3708": {
        "file_id": 456,
        "content": "/tests/voice_detect_extract_split/spleeter/test2.sh",
        "type": "filepath"
    },
    "3709": {
        "file_id": 456,
        "content": "This code downloads an audio example, separates it into two components using Spleeter's 2-stems model, and saves the results in separate files. However, there seems to be an issue with the second separation process.",
        "type": "summary"
    },
    "3710": {
        "file_id": 456,
        "content": "# wget https://github.com/deezer/spleeter/raw/master/audio_example.mp3\n# separate the example audio into two components\npython3 -m spleeter separate -p spleeter:2stems -o output you_got_me.mp3\npython3 -m spleeter separate -p spleeter:2stems -o output tarot_desc.mp3\n# seems not working at all",
        "type": "code",
        "location": "/tests/voice_detect_extract_split/spleeter/test2.sh:1-5"
    },
    "3711": {
        "file_id": 456,
        "content": "This code downloads an audio example, separates it into two components using Spleeter's 2-stems model, and saves the results in separate files. However, there seems to be an issue with the second separation process.",
        "type": "comment"
    },
    "3712": {
        "file_id": 457,
        "content": "/tests/voice_detect_extract_split/spleeter/test.sh",
        "type": "filepath"
    },
    "3713": {
        "file_id": 457,
        "content": "This code retrieves an example audio file, separates it into two components using the Spleeter library, and saves the result in the \"output\" directory. However, it seems to be facing some issues with separation.",
        "type": "summary"
    },
    "3714": {
        "file_id": 457,
        "content": "# wget https://github.com/deezer/spleeter/raw/master/audio_example.mp3\n# separate the example audio into two components\npython3 -m spleeter separate -p spleeter:2stems -o output audio_example.mp3\n# seems not working at all",
        "type": "code",
        "location": "/tests/voice_detect_extract_split/spleeter/test.sh:1-4"
    },
    "3715": {
        "file_id": 457,
        "content": "This code retrieves an example audio file, separates it into two components using the Spleeter library, and saves the result in the \"output\" directory. However, it seems to be facing some issues with separation.",
        "type": "comment"
    },
    "3716": {
        "file_id": 458,
        "content": "/tests/voice_detect_extract_split/spleeter/spleeter_init.sh",
        "type": "filepath"
    },
    "3717": {
        "file_id": 458,
        "content": "Installs spleeter version 2.1.0, downloads spleeter-2.2.2-py3-none-any.whl and installs it, and imports pretrained_models/4stems.",
        "type": "summary"
    },
    "3718": {
        "file_id": 458,
        "content": "# pip3n install spleeter==2.1.0\nwget https://files.pythonhosted.org/packages/fb/2e/5d2cd3d0179d3f749d03eddf0172f1dbababbc371c1b5cbd7fc27d741070/spleeter-2.2.2-py3-none-any.whl\npip3n install spleeter-2.2.2-py3-none-any.whl # why you require specific tensorflow version?\n# https://github.com/deezer/spleeter/releases/download/v1.4.0/4stems.tar.gz\n# at pretrained_models/4stems",
        "type": "code",
        "location": "/tests/voice_detect_extract_split/spleeter/spleeter_init.sh:1-6"
    },
    "3719": {
        "file_id": 458,
        "content": "Installs spleeter version 2.1.0, downloads spleeter-2.2.2-py3-none-any.whl and installs it, and imports pretrained_models/4stems.",
        "type": "comment"
    },
    "3720": {
        "file_id": 459,
        "content": "/tests/voice_detect_extract_split/spleeter/README.md",
        "type": "filepath"
    },
    "3721": {
        "file_id": 459,
        "content": "This code describes using Spleeter, an open-sourced tool, and mentions two model hosts, Hugging Face and Wolfram Neural Network Library. These libraries provide paraphrasing models and can be utilized with the Wolfram Developer Engine respectively.",
        "type": "summary"
    },
    "3722": {
        "file_id": 459,
        "content": "use spleeter which is open-sourced.\nmany model hoster interests me. the most gigantic one is huggingface. providing paraphrasing models and more. another one is wolfram neural network library. can be used freely with wolfram developer engine.",
        "type": "code",
        "location": "/tests/voice_detect_extract_split/spleeter/README.md:1-3"
    },
    "3723": {
        "file_id": 459,
        "content": "This code describes using Spleeter, an open-sourced tool, and mentions two model hosts, Hugging Face and Wolfram Neural Network Library. These libraries provide paraphrasing models and can be utilized with the Wolfram Developer Engine respectively.",
        "type": "comment"
    },
    "3724": {
        "file_id": 460,
        "content": "/tests/voice_detect_extract_split/spleeter/download_models.sh",
        "type": "filepath"
    },
    "3725": {
        "file_id": 460,
        "content": "The code downloads pretrained model files for spleeter, a sound separation tool. It uses curl to retrieve the tarballs from GitHub releases and stores them in \"pretrained_models\" directory. After downloading, it moves the files and changes the directory to execute further tasks related to these models.",
        "type": "summary"
    },
    "3726": {
        "file_id": 460,
        "content": "curl -O -L https://github.com/deezer/spleeter/releases/download/v1.4.0/2stems.tar.gz\ncurl -O -L https://github.com/deezer/spleeter/releases/download/v1.4.0/4stems.tar.gz\ncurl -O -L https://github.com/deezer/spleeter/releases/download/v1.4.0/5stems.tar.gz\nmv {2stems.tar.gz, 4stems.tar.gz, 5stems.tar.gz} pretrained_models\ncd pretrained_models",
        "type": "code",
        "location": "/tests/voice_detect_extract_split/spleeter/download_models.sh:1-6"
    },
    "3727": {
        "file_id": 460,
        "content": "The code downloads pretrained model files for spleeter, a sound separation tool. It uses curl to retrieve the tarballs from GitHub releases and stores them in \"pretrained_models\" directory. After downloading, it moves the files and changes the directory to execute further tasks related to these models.",
        "type": "comment"
    },
    "3728": {
        "file_id": 461,
        "content": "/tests/voice_detect_extract_split/paddlespeech/test.sh",
        "type": "filepath"
    },
    "3729": {
        "file_id": 461,
        "content": "The code exports HTTP and HTTPS proxy variables, runs TTS (Text-to-Speech) to convert text into audio (output.wav), and then performs ASR (Automatic Speech Recognition) in Chinese language using the output audio file. The code is intended for testing purposes with PaddleSpeech deep learning framework.",
        "type": "summary"
    },
    "3730": {
        "file_id": 461,
        "content": "export http_proxy=\"\"\nexport https_proxy=\"\"\n# this voice is great. excellent for my shit.\npaddlespeech tts --input \"你好，欢迎使用飞桨深度学习框架！\" --output output.wav # must download models on the fly.\npaddlespeech asr --lang zh --input output.wav\n# 你好欢迎使用非讲深度学习框架\n# how does it feel to have errors?\n# left and right variables are not the same. what is that?",
        "type": "code",
        "location": "/tests/voice_detect_extract_split/paddlespeech/test.sh:1-12"
    },
    "3731": {
        "file_id": 461,
        "content": "The code exports HTTP and HTTPS proxy variables, runs TTS (Text-to-Speech) to convert text into audio (output.wav), and then performs ASR (Automatic Speech Recognition) in Chinese language using the output audio file. The code is intended for testing purposes with PaddleSpeech deep learning framework.",
        "type": "comment"
    },
    "3732": {
        "file_id": 462,
        "content": "/tests/kaggle_yt_dls/test_init.sh",
        "type": "filepath"
    },
    "3733": {
        "file_id": 462,
        "content": "The code initializes a Kaggle kernel, pushes code to it, checks its status, and then retrieves output after completion. Proxies are skipped, and the download speed is measured.",
        "type": "summary"
    },
    "3734": {
        "file_id": 462,
        "content": "# kaggle kernels init\n# code/jessysisca/some-yt-stuff \n# kaggle kernels push\n# kaggle kernels status jessysisca/some-yt-stuff\n# jessysisca/some-yt-stuff has status \"complete\"\n# root@alpharetta ~/android_connect_scrcpy_patch# \n# kaggle kernels status jessysisca/test-of-yt-dlp\n# jessysisca/test-of-yt-dlp has status \"running\"\n# after it is done, we pull back all shit.\n# skip all proxies.\nexport http_proxy=\"\"\nexport https_proxy=\"\"\nkaggle kernels output jessysisca/test-of-yt-dlp # what is the freaking speed?\n# not too slow.",
        "type": "code",
        "location": "/tests/kaggle_yt_dls/test_init.sh:1-14"
    },
    "3735": {
        "file_id": 462,
        "content": "The code initializes a Kaggle kernel, pushes code to it, checks its status, and then retrieves output after completion. Proxies are skipped, and the download speed is measured.",
        "type": "comment"
    },
    "3736": {
        "file_id": 463,
        "content": "/tests/kaggle_yt_dls/transcode_nvenc.sh",
        "type": "filepath"
    },
    "3737": {
        "file_id": 463,
        "content": "The code uses FFmpeg to transcode a video file, applying a hue filter and testing hardware acceleration options like CUDA, VDPAU, and Vulkan, while mentioning NVENC is not for everyone. It also includes trigonometric function comments for potential Hue effects.",
        "type": "summary"
    },
    "3738": {
        "file_id": 463,
        "content": "# ffmpeg -hwaccels\n# vdpau\n# cuda\n# vaapi\n# vulkan\n# no blood.\nffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Wolfenstein 2 The New Colossus - Courthouse Battle ( I am death incarnate & no HUD ) 4k_60Fps [FuV63EEhS8c].webm\" -vf \"hue=h=45:s=0.7\" Wolfenstein_courthouse_battle.mp4\n# ffmpeg -y -vsync 0 -hwaccel_output_format cuda -i \"Wolfenstein 2 The New Colossus - Courthouse Battle ( I am death incarnate & no HUD ) 4k_60Fps [FuV63EEhS8c].webm\"  Wolfenstein_courthouse_battle.mp4\n# ffmpeg -y -vsync 0 -hwaccel vdpau -hwaccel_output_format vulkan -i \"Wolfenstein 2 The New Colossus - Courthouse Battle ( I am death incarnate & no HUD ) 4k_60Fps [FuV63EEhS8c].webm\"  Wolfenstein_courthouse_battle.mp4\n# ffmpeg -y -vsync 0 -hwaccel vulkan -hwaccel_output_format vulkan -i \"Wolfenstein 2 The New Colossus - Courthouse Battle ( I am death incarnate & no HUD ) 4k_60Fps [FuV63EEhS8c].webm\"  Wolfenstein_courthouse_battle.mp4\n# ffmpeg -y -vsync 0 -hwaccel cuda -hwaccel_output_format cuda -i \"Wolfenstein 2 The N",
        "type": "code",
        "location": "/tests/kaggle_yt_dls/transcode_nvenc.sh:1-11"
    },
    "3739": {
        "file_id": 463,
        "content": "This code uses FFmpeg to transcode a video file, applying a hue filter and saving the output as \"Wolfenstein_courthouse_battle.mp4\". It tests different hardware acceleration options (cuda, vdpau, vulkan) for video processing while specifying vsync 0 for disabling tearing. The code attempts to transcode the video using each of these hardware accelerations and saves the output file with the same name, overwriting previous outputs.",
        "type": "comment"
    },
    "3740": {
        "file_id": 463,
        "content": "ew Colossus - Courthouse Battle ( I am death incarnate & no HUD ) 4k_60Fps [FuV63EEhS8c].webm\"  Wolfenstein_courthouse_battle.mp4  # this is not avaliable. nvenc is not for everyone.\n# use vulkan or cuda. but vulkan is universal.\n# \"hue=H=30+10*cos(2*PI*t):s=0.2*cos(2*PI*t)+0.6\"",
        "type": "code",
        "location": "/tests/kaggle_yt_dls/transcode_nvenc.sh:11-14"
    },
    "3741": {
        "file_id": 463,
        "content": "This code specifies a video file name and mentions that NVENC is not for everyone, suggesting to use Vulkan or CUDA instead. It also includes a comment with potential Hue effects using trigonometric functions.",
        "type": "comment"
    },
    "3742": {
        "file_id": 464,
        "content": "/tests/kaggle_yt_dls/test.py",
        "type": "filepath"
    },
    "3743": {
        "file_id": 464,
        "content": "The code imports the os module and defines a list of commands. It then iterates through each command, executes it using the os.system() function, installing yt-dlp and downloading a YouTube video with its unique link.",
        "type": "summary"
    },
    "3744": {
        "file_id": 464,
        "content": "import os\ncommands = [\"pip3 install yt-dlp\",'yt-dlp \"https://m.youtube.com/watch?v=FuV63EEhS8c\"']\nfor c in commands:\n    os.system(c)",
        "type": "code",
        "location": "/tests/kaggle_yt_dls/test.py:1-5"
    },
    "3745": {
        "file_id": 464,
        "content": "The code imports the os module and defines a list of commands. It then iterates through each command, executes it using the os.system() function, installing yt-dlp and downloading a YouTube video with its unique link.",
        "type": "comment"
    },
    "3746": {
        "file_id": 465,
        "content": "/tests/jina_multimodal_cross_modal_search_examples_apps/get_jina_hub_list.sh",
        "type": "filepath"
    },
    "3747": {
        "file_id": 465,
        "content": "This script uses curl to send an authenticated GET request to 'https://api.hubble.jina.ai/v2/rpc/executor.list' for retrieving the list of executors on Jina Hub. The request includes necessary headers and data parameters in a compressed format.",
        "type": "summary"
    },
    "3748": {
        "file_id": 465,
        "content": "# curl 'https://api.hubble.jina.ai/v2/rpc/executor.list' \\\n#   -H 'authority: api.hubble.jina.ai' \\\n#   -H 'accept: */*' \\\n#   -H 'accept-language: en-US,en;q=0.9' \\\n#   -H 'content-type: application/json' \\\n#   -H 'cookie: _ga=GA1.1.1157816225.1662091624; _ga_48WE9V68SD=GS1.1.1662457192.4.0.1662457192.0.0.0; _ga_K8DQ8TXQJH=GS1.1.1663058102.2.1.1663059426.0.0.0; _ga_E63SXVNDXZ=GS1.1.1663061381.1.1.1663063158.0.0.0; _ga_48ZDWC8GT6=GS1.1.1663064195.8.1.1663064235.0.0.0; _ga_1ESRNDCK35=GS1.1.1663064288.3.0.1663064288.0.0.0; _ga_MMEXL9VXBJ=GS1.1.1663058298.5.1.1663065624.0.0.0' \\\n#   -H 'origin: https://hub.jina.ai' \\\n#   -H 'referer: https://hub.jina.ai/' \\\n#   -H 'sec-ch-ua: \"Google Chrome\";v=\"105\", \"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"105\"' \\\n#   -H 'sec-ch-ua-mobile: ?0' \\\n#   -H 'sec-ch-ua-platform: \"macOS\"' \\\n#   -H 'sec-fetch-dest: empty' \\\n#   -H 'sec-fetch-mode: cors' \\\n#   -H 'sec-fetch-site: same-site' \\\n#   -H 'user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36' \\",
        "type": "code",
        "location": "/tests/jina_multimodal_cross_modal_search_examples_apps/get_jina_hub_list.sh:1-15"
    },
    "3749": {
        "file_id": 465,
        "content": "This script is using curl to send a GET request to 'https://api.hubble.jina.ai/v2/rpc/executor.list' API endpoint, retrieving the list of executors available on Jina Hub. The request includes various headers for authorization, language, content type, cookies, origin, referer, user-agent, and browser details to authenticate and fetch the required information.",
        "type": "comment"
    },
    "3750": {
        "file_id": 465,
        "content": "#   --data-raw '{\"sort\":\"-activities.metaMatched\",\"pageIndex\":3,\"pageSize\":16,\"search\":\"\",\"author\":\"\",\"keywords\":[],\"withAnonymous\":true}' \\\n#   --compressed\ncurl 'https://api.hubble.jina.ai/v2/rpc/executor.list' \\\n --data-raw '{\"sort\":\"-activities.metaMatched\",\"pageIndex\":3,\"pageSize\":16,\"search\":\"\",\"author\":\"\",\"keywords\":[],\"withAnonymous\":true}' \\\n  --compressed",
        "type": "code",
        "location": "/tests/jina_multimodal_cross_modal_search_examples_apps/get_jina_hub_list.sh:16-20"
    },
    "3751": {
        "file_id": 465,
        "content": "This code is making a compressed HTTP request to 'https://api.hubble.jina.ai/v2/rpc/executor.list' with specific data parameters and a compressed format.",
        "type": "comment"
    },
    "3752": {
        "file_id": 466,
        "content": "/tests/jina_multimodal_cross_modal_search_examples_apps/get_jina_hub_list.py",
        "type": "filepath"
    },
    "3753": {
        "file_id": 466,
        "content": "This code retrieves a list of Jina Hub executors in chunks and writes them to a JSON file named \"jina_hub.json\". It first makes an API request to the Hubble server, sorts the results by activities.metaMatched, and returns the data as JSON. Then it calculates the number of pages needed based on the total number of executors and loops through each page, appending the data to a list called 'data'. Finally, it writes the list of executors (in multiple chunks) to the file \"jina_hub.json\" with proper indentation and formatting.",
        "type": "summary"
    },
    "3754": {
        "file_id": 466,
        "content": "import requests\nimport time\nimport json\ndef getJson(pageIndex=1, pageSize=16):\n    url = 'https://api.hubble.jina.ai/v2/rpc/executor.list'\n    query = {\"sort\":\"-activities.metaMatched\",\"pageIndex\":pageIndex,\"pageSize\":pageSize,\"search\":\"\",\"author\":\"\",\"keywords\":[],\"withAnonymous\":True}\n    r = requests.post(url,json=query)\n    jsonData = r.json()\n    return jsonData\npageSize = 16\njsonData = getJson(pageSize=pageSize)\ntotal = jsonData[\"meta\"][\"total\"]\nprint('total:', total)\ndata = [jsonData.copy()]\nimport math\npages = math.ceil(total/pageSize)\nimport progressbar\nfor index in progressbar.progressbar(range(2,pages+1)):\n    time.sleep(2)\n    # print('page index:',index)\n    jsonData = getJson(pageIndex=index, pageSize=pageSize)\n    data.append(jsonData.copy())\nprint(\"writing data\")\nwith open(\"jina_hub.json\", \"w\") as f:\n    f.write(json.dumps(data, indent=4, ensure_ascii=False))",
        "type": "code",
        "location": "/tests/jina_multimodal_cross_modal_search_examples_apps/get_jina_hub_list.py:1-29"
    },
    "3755": {
        "file_id": 466,
        "content": "This code retrieves a list of Jina Hub executors in chunks and writes them to a JSON file named \"jina_hub.json\". It first makes an API request to the Hubble server, sorts the results by activities.metaMatched, and returns the data as JSON. Then it calculates the number of pages needed based on the total number of executors and loops through each page, appending the data to a list called 'data'. Finally, it writes the list of executors (in multiple chunks) to the file \"jina_hub.json\" with proper indentation and formatting.",
        "type": "comment"
    },
    "3756": {
        "file_id": 467,
        "content": "/tests/redis_music_info_persistance/test_cache.py",
        "type": "filepath"
    },
    "3757": {
        "file_id": 467,
        "content": "This code imports Redis cache functions and defines a function `redisLRUCache` which creates a Redis LRU cache with specified parameters. The function `test_function` is decorated with `@redisLRUCache()` to utilize the cache. Finally, it prints \"hello world\" twice and returns 'abcdefg' for the given parameter. The code tests the function using 'toy_data' as the parameter.",
        "type": "summary"
    },
    "3758": {
        "file_id": 467,
        "content": "# from redis_cache.redis_cache import RedisCache\n# from redis_cache.rediscache import cache_it\nimport redis\nfrom redis_lru import RedisLRU\nfrom functools import lru_cache\noneDay = 60*60*24 # one day?\nredisExpire =oneDay*7 # god damn it!\n@lru_cache(maxsize=1)\ndef redisLRUCache(ttl=redisExpire,redisAddress = \"127.0.0.1\",redisPort = 9291,max_size=20):\n    client = redis.StrictRedis(host=redisAddress, port=redisPort)\n    cache = RedisLRU(client,max_size=max_size)\n    return cache(ttl=redisExpire)\n# we've fixed this shit.\n@redisLRUCache()\ndef test_function(parameter):\n    print('hello world')\n    print('parameter:',parameter)\n    return 'abcdefg'\nprint(\"RESULT:\",test_function('toy_data'))\nprint(\"RESULT:\",test_function('toy_data'))",
        "type": "code",
        "location": "/tests/redis_music_info_persistance/test_cache.py:1-24"
    },
    "3759": {
        "file_id": 467,
        "content": "This code imports Redis cache functions and defines a function `redisLRUCache` which creates a Redis LRU cache with specified parameters. The function `test_function` is decorated with `@redisLRUCache()` to utilize the cache. Finally, it prints \"hello world\" twice and returns 'abcdefg' for the given parameter. The code tests the function using 'toy_data' as the parameter.",
        "type": "comment"
    },
    "3760": {
        "file_id": 468,
        "content": "/tests/redis_music_info_persistance/launch_redis.sh",
        "type": "filepath"
    },
    "3761": {
        "file_id": 468,
        "content": "This script checks if a Redis server process is running on port 9291, then stops it using the PID found in the output. It ensures that only one instance of the server is running before executing the test suite.",
        "type": "summary"
    },
    "3762": {
        "file_id": 468,
        "content": "ps aux | grep \"redis-server\"| grep 9291 | grep -v grep | awk '{print $2}' | xargs -iabc kill -s KILL abc\nredis-server --port 9291",
        "type": "code",
        "location": "/tests/redis_music_info_persistance/launch_redis.sh:1-2"
    },
    "3763": {
        "file_id": 468,
        "content": "This script checks if a Redis server process is running on port 9291, then stops it using the PID found in the output. It ensures that only one instance of the server is running before executing the test suite.",
        "type": "comment"
    },
    "3764": {
        "file_id": 469,
        "content": "/tests/viral_video_experiments/init.sh",
        "type": "filepath"
    },
    "3765": {
        "file_id": 469,
        "content": "This code initiates the setup for viral video data analysis and prediction. It clones two repositories, ViralCaster for analysis and prediction tasks, and 360ImageSearch and BaiduSerchImgApi for image recognition purposes.",
        "type": "summary"
    },
    "3766": {
        "file_id": 469,
        "content": "# viral video data analysis, prediction\n# git clone https://github.com/jjbreen/ViralCaster\n# image recognition\ngit clone https://github.com/chenguanyou/BaiduSerchImgApi\ngit clone https://github.com/chenguanyou/360ImageSearch",
        "type": "code",
        "location": "/tests/viral_video_experiments/init.sh:1-6"
    },
    "3767": {
        "file_id": 469,
        "content": "This code initiates the setup for viral video data analysis and prediction. It clones two repositories, ViralCaster for analysis and prediction tasks, and 360ImageSearch and BaiduSerchImgApi for image recognition purposes.",
        "type": "comment"
    },
    "3768": {
        "file_id": 470,
        "content": "/tests/recommendation_system/neo4j_e2e_recsys.py",
        "type": "filepath"
    },
    "3769": {
        "file_id": 470,
        "content": "This code is referencing resources from Neo4j's documentation for end-to-end examples and Graph Academy training. It appears to be related to implementing Fast RP (Recommendation Prediction) using k-Nearest Neighbors (kNN) algorithm in a Neo4j graph database.",
        "type": "summary"
    },
    "3770": {
        "file_id": 470,
        "content": "# https://neo4j.com/docs/graph-data-science/current/end-to-end-examples/fastrp-knn-example/\n# https://neo4j.com/graphacademy/training-iga-40/12-iga-40-ingredient-analysis/",
        "type": "code",
        "location": "/tests/recommendation_system/neo4j_e2e_recsys.py:1-2"
    },
    "3771": {
        "file_id": 470,
        "content": "This code is referencing resources from Neo4j's documentation for end-to-end examples and Graph Academy training. It appears to be related to implementing Fast RP (Recommendation Prediction) using k-Nearest Neighbors (kNN) algorithm in a Neo4j graph database.",
        "type": "comment"
    },
    "3772": {
        "file_id": 471,
        "content": "/tests/recommendation_system/karate_test.py",
        "type": "filepath"
    },
    "3773": {
        "file_id": 471,
        "content": "This code imports necessary libraries and defines a function for normalizing adjacency matrices. It then creates a graph using the karate club data, converts it to a dense matrix, normalizes this matrix, and prints its shape before initializing a GCN model.",
        "type": "summary"
    },
    "3774": {
        "file_id": 471,
        "content": "import networkx as nx\nimport torch\ndef normalize(A , symmetric=True):\n\t# A = A+I\n\tA = A + torch.eye(A.size(0))\n\t# 所有节点的度\n\td = A.sum(1)\n\tif symmetric:\n\t\t#D = D^-1/2\n\t\tD = torch.diag(torch.pow(d , -0.5))\n\t\treturn D.mm(A).mm(D)\n\telse:\n\t\t# D=D^-1\n\t\tD = torch.diag(torch.pow(d,-1))\n\t\treturn D.mm(A)\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).todense() # dense matrix? not so freaking good.\n#A需要正规化\nA_normed = normalize(torch.FloatTensor(A),True)\nprint(A_normed.shape)\nfrom torch_geometric.nn import GCN\n# how to generate graph?\n# breakpoint() # 34,34",
        "type": "code",
        "location": "/tests/recommendation_system/karate_test.py:1-27"
    },
    "3775": {
        "file_id": 471,
        "content": "This code imports necessary libraries and defines a function for normalizing adjacency matrices. It then creates a graph using the karate club data, converts it to a dense matrix, normalizes this matrix, and prints its shape before initializing a GCN model.",
        "type": "comment"
    },
    "3776": {
        "file_id": 472,
        "content": "/tests/recommendation_system/dgl_link_prediction.py",
        "type": "filepath"
    },
    "3777": {
        "file_id": 472,
        "content": "This code imports the DGL library, loads the Cora dataset from DGL's data module, and prints the loaded dataset. The Cora dataset is a popular benchmark for node classification tasks in graph-based machine learning.",
        "type": "summary"
    },
    "3778": {
        "file_id": 472,
        "content": "import dgl\ncora = dgl.data.CoraGraphDataset()\nprint(cora)",
        "type": "code",
        "location": "/tests/recommendation_system/dgl_link_prediction.py:1-4"
    },
    "3779": {
        "file_id": 472,
        "content": "This code imports the DGL library, loads the Cora dataset from DGL's data module, and prints the loaded dataset. The Cora dataset is a popular benchmark for node classification tasks in graph-based machine learning.",
        "type": "comment"
    },
    "3780": {
        "file_id": 473,
        "content": "/tests/nsfw_violence_drug_detection/README.md",
        "type": "filepath"
    },
    "3781": {
        "file_id": 473,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "summary"
    },
    "3782": {
        "file_id": 473,
        "content": "it is related to video content censorship, but really close to video automatic editing.\nwe have violence video dataset, we also have some 'fun video' dataset called blooper dataset",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/README.md:1-3"
    },
    "3783": {
        "file_id": 473,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "comment"
    },
    "3784": {
        "file_id": 474,
        "content": "/tests/nsfw_violence_drug_detection/post_jpg_to_nsfwjs.sh",
        "type": "filepath"
    },
    "3785": {
        "file_id": 474,
        "content": "This code is making multiple POST requests to http://localhost:8511/nsfw, using different image formats and file paths. The purpose appears to be testing the API's response for NSFW content detection with various images. The last comment suggests that BMP format might have an issue, but consistency is maintained with the original model. A real adult content image is being tested next.",
        "type": "summary"
    },
    "3786": {
        "file_id": 474,
        "content": "curl http://localhost:8511/\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_saturday_night.jpg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_saturday_night.bmp' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/video/cute_cat_gif.gif' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.png' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.jpg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dog_with_text.bmp' http://localhost:8511/nsfw\necho\necho\n# but the bmp looks right. is that the format issue?\n# we have consistency with the original model. how about a real porno?",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/post_jpg_to_nsfwjs.sh:1-23"
    },
    "3787": {
        "file_id": 474,
        "content": "This code is making multiple POST requests to http://localhost:8511/nsfw, using different image formats and file paths. The purpose appears to be testing the API's response for NSFW content detection with various images. The last comment suggests that BMP format might have an issue, but consistency is maintained with the original model. A real adult content image is being tested next.",
        "type": "comment"
    },
    "3788": {
        "file_id": 475,
        "content": "/tests/nsfw_violence_drug_detection/porndetect_test.sh",
        "type": "filepath"
    },
    "3789": {
        "file_id": 475,
        "content": "This code is making multiple HTTP POST requests with different image files to a local server on port 8511, specifically targeting the \"/nsfw\" endpoint. The images being tested are JPEG and BMP formats, and the script is checking for errors or issues related to the BMP decoder in the response.",
        "type": "summary"
    },
    "3790": {
        "file_id": 475,
        "content": "curl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/porn_shemale.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/porn_shemale.bmp' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick.bmp' http://localhost:8511/nsfw # something is wrong with bmp decoder.\necho\necho\necho '__________________________________________'\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick2.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick3.jpeg' http://localhost:8511/nsfw\necho\necho\ncurl -X POST -F 'image=@/root/Desktop/works/pyjom/samples/image/dick4.jpeg' http://localhost:8511/nsfw\necho\necho",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/porndetect_test.sh:1-22"
    },
    "3791": {
        "file_id": 475,
        "content": "This code is making multiple HTTP POST requests with different image files to a local server on port 8511, specifically targeting the \"/nsfw\" endpoint. The images being tested are JPEG and BMP formats, and the script is checking for errors or issues related to the BMP decoder in the response.",
        "type": "comment"
    },
    "3792": {
        "file_id": 476,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs",
        "type": "filepath"
    },
    "3793": {
        "file_id": 476,
        "content": "The code imports libraries, sets up an Express app and Multer for file uploads, converts images to RGBA format, initializes a model, calculates pixel counts using TensorFlow, handles requests, checks missing files, logs uploaded files, returns server status, loads NSFW image detection model, serves predictions on port 8511.",
        "type": "summary"
    },
    "3794": {
        "file_id": 476,
        "content": "import { createRequire } from \"module\";\nconst require = createRequire(import.meta.url);\nconst express = require('express')\nconst multer = require('multer')\nconst jpeg = require('jpeg-js')\n    // const bmp = require('bmp-js')\nconst bmp = require('bmp-ts');\n// const bmpBuffer = fs.readFileSync('bit24.bmp');\nconst { PNG } = require('pngjs')\nconst tf = require('@tensorflow/tfjs-node')\nconst nsfw = require('nsfwjs')\nconst app = express()\nconst upload = multer()\nlet _model\n// this even works for gif!\n// it will normalize and resize the image if needed.\n// shall we check for gif?\nconst convert = async(img, type) => {\n    // Decoded image in UInt8 Byte array\n    let image\n    if (type == 'image/jpeg') {\n        image = await jpeg.decode(img, true)\n            // RGBA\n    } //wtf?\n    // order: rgba\n    else if (type == 'image/png') {\n        image = PNG.sync.read(img)\n    } else if (type == 'image/bmp') {\n        // image = await bmp.decode(img, true)\n        image = bmp.decode(img, { toRGBA: true });\n    }\n    const numChannels = 3",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:1-40"
    },
    "3795": {
        "file_id": 476,
        "content": "The code imports necessary libraries, sets up an express application and multer middleware for handling file uploads. It also defines a function to convert images of different types (JPEG, PNG, BMP) into the same RGBA format for further processing using TensorFlow.js. The code also initializes a model and mentions that it works for GIFs as well.",
        "type": "comment"
    },
    "3796": {
        "file_id": 476,
        "content": "    const numPixels = image.width * image.height // will raise an error if image is not acquired.\n    const values = new Int32Array(numPixels * numChannels)\n        // are you sure about the width?\n    // can you make this faster? shit?\n    // this shit is no numpy. fuck.\n    for (let i = 0; i < numPixels; i++)\n        for (let c = 0; c < numChannels; ++c)\n        // if (type == 'bmp') {\n        //     // ABGR?\n        //     // values[i * numChannels + c] = image.data[i * 4+c]\n        //     values[i * numChannels + c] = image.data[i * 4 + 3 - c]\n        // } else {\n            values[i * numChannels + c] = image.data[i * 4 + c]\n            // }\n    return tf.tensor3d(values, [image.height, image.width, numChannels], 'int32')\n}\napp.get('/', async(req, res) => {\n    res.send('nsfw nodejs server')\n})\napp.post('/nsfw', upload.single('image'), async(req, res) => {\n    if (!req.file) res.status(400).send('Missing image multipart/form-data')\n    else {\n        try {\n            console.log('file uploaded:', req.file)",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:41-68"
    },
    "3797": {
        "file_id": 476,
        "content": "The code snippet is calculating the number of pixels in an image and storing its values into a TensorFlow tensor. It's then using the NodeJS framework to handle requests for images, checking if a file is missing, logging uploaded files, and returning a response with the server status. The code uses different data access methods based on the image format (BMP or others). However, there are concerns about potential width calculation errors, improving performance, and frustration with working outside of the Python ecosystem.",
        "type": "comment"
    },
    "3798": {
        "file_id": 476,
        "content": "            if (req.file.fieldname == 'image') {\n                type = req.file.mimetype // deal with it later.\n                extension = req.file.originalname.split(\".\").slice(-1)[0].toLowerCase()\n                if (extension == 'gif' || type == 'image/gif') {\n                    let image = req.file.buffer\n                    let predictions = await _model.classifyGif(image, { topk: 3, fps: 1 })\n                        // image.dispose()\n                    predictions.message = 'success'\n                    res.json(predictions)\n                } else {\n                    if (extension == 'bmp') {\n                        type = 'image/bmp'\n                    }\n                    let image = await convert(req.file.buffer, type) // here we have buffer.\n                    let predictions = await _model.classify(image)\n                    predictions.message = 'success'\n                        // image.dispose()\n                    res.json(predictions)\n                }\n            }\n            // we need some file format hints.",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.mjs:69-89"
    },
    "3799": {
        "file_id": 476,
        "content": "Checks if the file field is 'image' and deals with GIF files separately by classifying them directly. For other formats, converts the buffer to the appropriate type before classification. Responds with predictions and success message.",
        "type": "comment"
    }
}