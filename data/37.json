{
    "3700": {
        "file_id": 447,
        "content": "import pylrc\nwith open(\"some_lyrics.json.lrc\",\"r\") as f:\n    lrc_string = f.read()\n    subs = pylrc.parse(lrc_string)\n    for sub in subs:\n        time_in_secs = sub.time\n        content = sub.text\n    # skip those which are too short.\n    # print(subs)\n    # breakpoint()",
        "type": "code",
        "location": "/tests/music_analysis/lyric_change_detector/read_lyrics.py:1-11"
    },
    "3701": {
        "file_id": 447,
        "content": "Reading lyrics from \"some_lyrics.json.lrc\" file using pylrc library, parsing the LRC format and storing time and content for each subtitle in subs variable.",
        "type": "comment"
    },
    "3702": {
        "file_id": 448,
        "content": "/tests/nearly_duplicate_frames_detection_removal/fast_vqa_test.sh",
        "type": "filepath"
    },
    "3703": {
        "file_id": 448,
        "content": "Code changes the video file being tested, mentions quality scores and potential issues with large white areas, suggests using k-NN (k=5), and runs the VQA script on a CPU.",
        "type": "summary"
    },
    "3704": {
        "file_id": 448,
        "content": "cd FAST-VQA\n# VIDEO=\"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"\n# The quality score of the video is 0.11833.\nVIDEO=\"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.mp4\"\n# The quality score of the video is 0.12778.\n# nothing serious. it does not produce significant shits.\npython3 vqa.py -o ./options/fast/f3dvqa-b.yml -v $VIDEO -d cpu\n# another feature is that this video produces a large area in white, which is not what we really want.\n# use knn?\n# k=5",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/fast_vqa_test.sh:1-13"
    },
    "3705": {
        "file_id": 448,
        "content": "Code changes the video file being tested, mentions quality scores and potential issues with large white areas, suggests using k-NN (k=5), and runs the VQA script on a CPU.",
        "type": "comment"
    },
    "3706": {
        "file_id": 449,
        "content": "/tests/nearly_duplicate_frames_detection_removal/knn_similar_color_extraction.py",
        "type": "filepath"
    },
    "3707": {
        "file_id": 449,
        "content": "The user is experiencing issues with image centrality and nearby center percentages when using OpenCV (cv2) and MiniBatchKMeans for clustering in numpy. The code extracts similar color frames, calculates percentages of nearby centers, and prints related statistics to calculate overall centrality.",
        "type": "summary"
    },
    "3708": {
        "file_id": 449,
        "content": "# i'd say i want centrality below 6 percent. what's the catch?\n# we'd like to adjust the shift.\n# another tip: you have forgot the spatial coordinates.\n# fuck!\n# src = \"/root/Desktop/works/pyjom/samples/image/cute_cat.bmp\"\n# CENTRALITY: 0.00 %\n# single not go beyond 4 percent.\n# total not go beyond 6 percent.\n# is that right? fuck?\n# src = \"/root/Desktop/works/pyjom/samples/image/dog_with_text.png\"\n# and yet this does not look right.\n# NEARBY CENTER PERCENTAGE: 0.84 %\n# CENTRALITY: 2.57 %\n# src = \"/root/Desktop/works/pyjom/samples/image/miku_on_green.png\"\n# for this one we have double centers. fuck.\n# CENTRALITY: 181.80 %\n# it is off the charge!\n# with text. a meme.\n# src = \"/root/Desktop/works/pyjom/samples/image/dog_saturday_night.bmp\"\n# CENTRALITY: 1.26 %\n# src = \"/root/Desktop/works/pyjom/samples/image/similar_color_extraction.bmp\"  # use some filter first, or rather not to?\n# CENTER: [254.62436869 254.63794192 254.79734848]\n# POSITIVE COUNT: 188772\n# SUM: 566316.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 81.93 %",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_similar_color_extraction.py:1-35"
    },
    "3709": {
        "file_id": 449,
        "content": "The code snippet is displaying image centrality, nearby center percentage, and other related information for several images. The user seems to be adjusting the shift and working with spatial coordinates. However, they are encountering issues like double centers and results that do not look right. They seem to be unsure about some parameters and considering using a filter on an image.",
        "type": "comment"
    },
    "3710": {
        "file_id": 449,
        "content": "# CENTRALITY: 82.33 %\n# let's try some cats.\n# the filter: removegrain\n# src = \"/root/Desktop/works/pyjom/samples/image/kitty_flash.bmp\"  # use some filter first, or rather not to?\n# CENTER: [1.37254902 2.34313725 9.46078431]\n# POSITIVE COUNT: 2600\n# SUM: 7800.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 3.91 %\n# CENTRALITY: 3.91 %\n# now the 八点半配音\n# src = \"/root/Desktop/works/pyjom/samples/image/is_this_duck.bmp\"\n# CENTER: [252.66293811 177.62005966 126.37844892]\n# POSITIVE COUNT: 222893\n# SUM: 668679.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 36.49 %\n# CENTRALITY: 36.55 %\n# likely to be the blue.\nsrc = \"/root/Desktop/works/pyjom/samples/image/pig_really.bmp\"\n# multiple centers.\n# CENTER: [246.76865924 226.40763256 216.41472476]\n# POSITIVE COUNT: 95497\n# SUM: 286491.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 6.74 %\n# CENTRALITY: 7.32 %\nimport numpy as np\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nimport cv2\nimage = cv2.imread(src)\nshape = image.shape\nif len(shape) != 3:\n    print(\"weird shit.\")",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_similar_color_extraction.py:36-75"
    },
    "3711": {
        "file_id": 449,
        "content": "This code reads an image from a specific file and applies filters to detect and remove duplicate frames. The results include information about centrality, positive counts, nearby center percentages, and more. The code uses OpenCV (cv2) for image processing and numpy for array manipulation.",
        "type": "comment"
    },
    "3712": {
        "file_id": 449,
        "content": "if shape[2] != 3:\n    print(\"depth not right.\")\n# for i in range(3):\n#     image[:,:,i] = i\n# col_0, col_1 = shape[:2]\n# coords = []\n# for c0 in range(col_0):\n#     for c1 in range(col_1):\n#         coords.append((c0,c1))\n# coords = np.array(coords)\n# print(image.reshape(-1,3))\nreshapedImage = image.reshape(-1, 3)  # are you sure about this?\nlength, depth = reshapedImage.shape\nsample_size_limit = 5000\nreshapedImageIndexs = np.arange(0, length)\n# so now it is good.\nsampleIndexs = np.random.choice(reshapedImageIndexs, size=min(sample_size_limit, length))\nprint(sampleIndexs)\nprint(sampleIndexs.shape)\nsample_size = len(sampleIndexs)\nsample = reshapedImageIndexs[sampleIndexs]\nsample = reshapedImage[sample, :]\nprint(sample)\nprint(sample.shape)\n# breakpoint()\n# sampleCoords = coords[sampleIndexs]\n# sample = np.hstack([sample, sampleCoords])\n# print(sample)\n# print(sample.shape)\n# breakpoint()\n# warning: OOM?\n# now cluster shit shall we?\n# from sklearn.neighbors import NearestNeighbors\n# neigh = NearestNeighbors(n_neighbors=5)",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_similar_color_extraction.py:76-119"
    },
    "3713": {
        "file_id": 449,
        "content": "The code extracts color samples from an image and selects a random sample of up to 5000 indices. It then reshapes the image into a 1D array, creates new sample indices, retrieves the sample data, and prepares for clustering.",
        "type": "comment"
    },
    "3714": {
        "file_id": 449,
        "content": "# X = sample\n# neigh.fit(X)\n# A = neigh.kneighbors_graph(X)\n# A.toarray()\n# print(A)\n# print(A.shape) # sparse matrix? wtf?\nfrom sklearn.cluster import MiniBatchKMeans  # better?\n# from sklearn.cluster import KMeans\nX = sample\nbatch_size = 45\n# kmeans = KMeans(n_clusters=5).fit(X) # not deterministic please?\nn_clusters = 5\nkmeans = MiniBatchKMeans(\n    init=\"k-means++\",\n    n_clusters=n_clusters,\n    batch_size=batch_size,\n    # n_init=10,\n    max_no_improvement=10,\n    verbose=0,\n).fit(X)\n# from lazero.utils import inspectObject\n# inspectObject(kmeans)\n# breakpoint()\nlabels = kmeans.labels_\ncluster_centers = kmeans.cluster_centers_\nprint(labels)\nprint(cluster_centers)\nlabel_percentage = {\n    x: np.count_nonzero(labels == x) / sample_size for x in range(n_clusters)\n}\nflagged_image = image.copy()\nflagged_image[:,:,:] = 1 # every element is 1 now.\nepsilon = 0.01 # shit man.\npercents = []\nshift=2\nfor center in cluster_centers:\n    # fetch area nearby given center\n    # center = center5[:3]\n    # center_int = center.astype(np.uint8)",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_similar_color_extraction.py:120-161"
    },
    "3715": {
        "file_id": 449,
        "content": "This code performs clustering using MiniBatchKMeans to find clusters in a dataset, extracts cluster centers, calculates label percentages for each cluster, and then sets the entire flagged image to 1 before iterating through cluster centers and performing an unknown operation on nearby areas.",
        "type": "comment"
    },
    "3716": {
        "file_id": 449,
        "content": "    # i just don't know what the fuck is going on here.\n    upper = center + shift\n    lower = center - shift\n    mask = cv2.inRange(image, lower, upper)\n    # not image.\n    output = cv2.bitwise_and(flagged_image, flagged_image, mask=mask)\n    # print(output)\n    # print(output.shape)\n    mOutput = output.reshape(-1, 3)\n    mOutput = np.sum(mOutput, axis=1)\n    mSum = sum(mOutput)\n    # breakpoint()\n    positive_count = np.count_nonzero(abs(mOutput - 3) < epsilon)\n    percent = positive_count/len(mOutput)\n    # print(mOutput)\n    # print(mOutput.shape)\n    # breakpoint()\n    print(\"CENTER:\",center)\n    print('POSITIVE COUNT:', positive_count)\n    print(\"SUM:\", mSum, \"MIN:\", min(mOutput), 'MAX:', max(mOutput))\n    print(\"NEARBY CENTER PERCENTAGE: {:.2f} %\".format(percent*100))\n    percents.append(percent)\nprint(\"CENTRALITY: {:.2f} %\".format(sum(percents)*100))",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_similar_color_extraction.py:162-185"
    },
    "3717": {
        "file_id": 449,
        "content": "This code extracts similar color frames and calculates the percentage of nearby centers. It reshapes the output, sums values, counts non-zero absolute differences, and calculates the percentage of nearby centers. The code then appends the percentages to a list for later calculation of centrality. Finally, it prints various statistics about the image and calculates the overall centrality based on the accumulated percentages.",
        "type": "comment"
    },
    "3718": {
        "file_id": 450,
        "content": "/tests/nearly_duplicate_frames_detection_removal/knn_spatial_similar_color_extraction.py",
        "type": "filepath"
    },
    "3719": {
        "file_id": 450,
        "content": "The code tests centrality thresholds for nearly duplicate frames using OpenCV and numpy, addresses issues like double centers and incorrect percentages, and performs clustering with MiniBatchKMeans.",
        "type": "summary"
    },
    "3720": {
        "file_id": 450,
        "content": "# i'd say i want centrality below 6 percent. what's the catch?\n# we'd like to adjust the shift.\n# another tip: you have forgot the spatial coordinates.\n# fuck!\nsrc = \"/root/Desktop/works/pyjom/samples/image/cute_cat.bmp\"\n# CENTRALITY: 0.00 %\n# single not go beyond 4 percent.\n# total not go beyond 6 percent.\n# is that right? fuck?\n# src = \"/root/Desktop/works/pyjom/samples/image/dog_with_text.png\"\n# and yet this does not look right.\n# NEARBY CENTER PERCENTAGE: 0.84 %\n# CENTRALITY: 2.57 %\n# src = \"/root/Desktop/works/pyjom/samples/image/miku_on_green.png\"\n# for this one we have double centers. fuck.\n# CENTRALITY: 181.80 %\n# it is off the charge!\n# with text. a meme.\n# src = \"/root/Desktop/works/pyjom/samples/image/dog_saturday_night.bmp\"\n# CENTRALITY: 1.26 %\n# src = \"/root/Desktop/works/pyjom/samples/image/similar_color_extraction.bmp\"  # use some filter first, or rather not to?\n# CENTER: [254.62436869 254.63794192 254.79734848]\n# POSITIVE COUNT: 188772\n# SUM: 566316.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 81.93 %",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_spatial_similar_color_extraction.py:1-35"
    },
    "3721": {
        "file_id": 450,
        "content": "The code appears to be testing and adjusting the centrality threshold for detecting nearly duplicate frames. The author is experimenting with different image file sources, and discussing various issues encountered during the process, such as double centers and incorrect centrality percentages. They also mention using filters for certain images.",
        "type": "comment"
    },
    "3722": {
        "file_id": 450,
        "content": "# CENTRALITY: 82.33 %\n# let's try some cats.\n# the filter: removegrain\n# src = \"/root/Desktop/works/pyjom/samples/image/kitty_flash.bmp\"  # use some filter first, or rather not to?\n# CENTER: [1.37254902 2.34313725 9.46078431]\n# POSITIVE COUNT: 2600\n# SUM: 7800.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 3.91 %\n# CENTRALITY: 3.91 %\n# now the 八点半配音\n# src = \"/root/Desktop/works/pyjom/samples/image/is_this_duck.bmp\"\n# CENTER: [252.66293811 177.62005966 126.37844892]\n# POSITIVE COUNT: 222893\n# SUM: 668679.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 36.49 %\n# CENTRALITY: 36.55 %\n# likely to be the blue.\n# src = \"/root/Desktop/works/pyjom/samples/image/pig_really.bmp\"\n# multiple centers.\n# CENTER: [246.76865924 226.40763256 216.41472476]\n# POSITIVE COUNT: 95497\n# SUM: 286491.0 MIN: 0 MAX: 3\n# NEARBY CENTER PERCENTAGE: 6.74 %\n# CENTRALITY: 7.32 %\nimport numpy as np\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nuse_spatial=True\nimport cv2\nimage = cv2.imread(src)\nshape = image.shape\nif len(shape) != 3:",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_spatial_similar_color_extraction.py:36-76"
    },
    "3723": {
        "file_id": 450,
        "content": "This code reads an image from a specified source and checks if it's in the correct format (RGB). It then calculates the centrality and nearby center percentage, likely for duplicate frame detection. The code uses OpenCV to load images and numpy for data manipulation. The code has three different examples with different results: one cat image with high centrality and nearby center percentage, a duck image with very high centrality and nearby center percentage, and a pig image with multiple centers and lower centrality.",
        "type": "comment"
    },
    "3724": {
        "file_id": 450,
        "content": "    print(\"weird shit.\")\nif shape[2] != 3:\n    print(\"depth not right.\")\n# for i in range(3):\n#     image[:,:,i] = i\nif use_spatial:\n    col_0, col_1 = shape[:2]\n    coords = []\n    bias_0 = 2\n    bias_1 = 2\n    for c0 in range(col_0):\n        for c1 in range(col_1):\n            coords.append((bias_0*c0/col_0,bias_1*c1/col_1))\n    coords = np.array(coords)\n# print(image.reshape(-1,3))\nreshapedImage = image.reshape(-1, 3)  # are you sure about this?\nlength, depth = reshapedImage.shape\nsample_size_limit = 5000\nreshapedImageIndexs = np.arange(0, length)\n# so now it is good.\nsampleIndexs = np.random.choice(reshapedImageIndexs, size=min(sample_size_limit, length))\nprint(sampleIndexs)\nprint(sampleIndexs.shape)\nsample_size = len(sampleIndexs)\nsample = reshapedImageIndexs[sampleIndexs]\nsample = reshapedImage[sample, :]\nprint(sample)\nprint(sample.shape)\n# breakpoint()\nif use_spatial:\n    sampleCoords = coords[sampleIndexs]\n    sample = np.hstack([sample, sampleCoords])\n    print(sample)\n    print(sample.shape)\n# breakpoint()\n# warning: OOM?",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_spatial_similar_color_extraction.py:77-123"
    },
    "3725": {
        "file_id": 450,
        "content": "This code checks if the image depth is correct, then it reshapes and extracts samples from an image for further processing. The code also includes an option to use spatial coordinates, which are added as additional features to the sample data.",
        "type": "comment"
    },
    "3726": {
        "file_id": 450,
        "content": "# now cluster shit shall we?\n# from sklearn.neighbors import NearestNeighbors\n# neigh = NearestNeighbors(n_neighbors=5)\n# X = sample\n# neigh.fit(X)\n# A = neigh.kneighbors_graph(X)\n# A.toarray()\n# print(A)\n# print(A.shape) # sparse matrix? wtf?\nfrom sklearn.cluster import MiniBatchKMeans  # better?\n# from sklearn.cluster import KMeans\nX = sample\nbatch_size = 45\n# kmeans = KMeans(n_clusters=5).fit(X) # not deterministic please?\nn_clusters = 5\nkmeans = MiniBatchKMeans(\n    init=\"k-means++\",\n    n_clusters=n_clusters,\n    batch_size=batch_size,\n    # n_init=10,\n    max_no_improvement=10,\n    verbose=0,\n).fit(X)\n# from lazero.utils import inspectObject\n# inspectObject(kmeans)\n# breakpoint()\nlabels = kmeans.labels_\ncluster_centers = kmeans.cluster_centers_\nprint(labels)\nprint(cluster_centers)\nlabel_percentage = {\n    x: np.count_nonzero(labels == x) / sample_size for x in range(n_clusters)\n}\nflagged_image = image.copy()\nflagged_image[:,:,:] = 1 # every element is 1 now.\nepsilon = 0.01 # shit man.\npercents = []\nshift=2\nfor center5 in cluster_centers:",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_spatial_similar_color_extraction.py:124-165"
    },
    "3727": {
        "file_id": 450,
        "content": "Code is performing clustering using MiniBatchKMeans from sklearn.cluster, with n_clusters=5 and batch_size=45 to handle larger datasets. After fitting the data, it prints labels and cluster centers. Then, it calculates label percentages based on the labels assigned by KMeans, initializes a flagged image with all elements set to 1, and starts iterating through each cluster center to perform further operations (not shown in code snippet).",
        "type": "comment"
    },
    "3728": {
        "file_id": 450,
        "content": "    # fetch area nearby given center\n    if use_spatial:\n        center = center5[:3]\n    else:\n        center = center5\n    # center_int = center.astype(np.uint8)\n    # i just don't know what the fuck is going on here.\n    upper = center + shift\n    lower = center - shift\n    mask = cv2.inRange(image, lower, upper)\n    # not image.\n    output = cv2.bitwise_and(flagged_image, flagged_image, mask=mask)\n    # print(output)\n    # print(output.shape)\n    mOutput = output.reshape(-1, 3)\n    mOutput = np.sum(mOutput, axis=1)\n    mSum = sum(mOutput)\n    # breakpoint()\n    positive_count = np.count_nonzero(abs(mOutput - 3) < epsilon)\n    percent = positive_count/len(mOutput)\n    # print(mOutput)\n    # print(mOutput.shape)\n    # breakpoint()\n    print(\"CENTER:\",center)\n    print('POSITIVE COUNT:', positive_count)\n    print(\"SUM:\", mSum, \"MIN:\", min(mOutput), 'MAX:', max(mOutput))\n    print(\"NEARBY CENTER PERCENTAGE: {:.2f} %\".format(percent*100))\n    percents.append(percent)\nprint(\"CENTRALITY: {:.2f} %\".format(sum(percents)*100))",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/knn_spatial_similar_color_extraction.py:166-195"
    },
    "3729": {
        "file_id": 450,
        "content": "The code calculates the centrality of a center by extracting nearby pixel values and checking if they are within a specified epsilon threshold. It uses image processing functions from OpenCV (cv2) and numpy for masking, reshaping, and summing operations. The code then prints various metrics related to the center's centrality, such as positive count, sum of pixel values, minimum and maximum values, and finally calculates the overall centrality percentage.",
        "type": "comment"
    },
    "3730": {
        "file_id": 451,
        "content": "/tests/nearly_duplicate_frames_detection_removal/pyav_effective_fps.py",
        "type": "filepath"
    },
    "3731": {
        "file_id": 451,
        "content": "This code measures the keyframe percentage in a video file using Python and the AV library. It opens a video source, iterates over each frame, appends the keyframes to a list, calculates the percentage of keyframes relative to total frames, and prints the result.",
        "type": "summary"
    },
    "3732": {
        "file_id": 451,
        "content": "import av\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps_blend.mp4\"  # this is evil. it defeats my shit.\n# KEYFRAME PERCENT: 1.36 %\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"  # this is evil. it defeats my shit.\n# KEYFRAME PERCENT: 0.76 %\n# wtf?\n# even smaller.\nsource = \"/root/Desktop/works/pyjom/samples/video/karaoke_effects_source.mp4\"\ncontainer = av.open(source)\nmList = []\nfor frame in container.decode(video=0):\n    mList.append(frame.key_frame)\nprint(\"KEYFRAME PERCENT: {:.2f} %\".format(100*sum(mList)/len(mList)))",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/pyav_effective_fps.py:1-18"
    },
    "3733": {
        "file_id": 451,
        "content": "This code measures the keyframe percentage in a video file using Python and the AV library. It opens a video source, iterates over each frame, appends the keyframes to a list, calculates the percentage of keyframes relative to total frames, and prints the result.",
        "type": "comment"
    },
    "3734": {
        "file_id": 452,
        "content": "/tests/nearly_duplicate_frames_detection_removal/test.py",
        "type": "filepath"
    },
    "3735": {
        "file_id": 452,
        "content": "The code imports libraries, checks for still images, and uses scene detection with the scenedetect library. It retrieves video duration, sets adaptive detector, and stores results in an output file. Another code reads a CSV file into a DataFrame, prints first 5 rows, and pauses execution at breakpoint.",
        "type": "summary"
    },
    "3736": {
        "file_id": 452,
        "content": "# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection.gif\"  # this is evil. it defeats my shit.\nsource = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps_blend.mp4\"  # this is evil. it defeats my shit.\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.gif\"  # this is evil. it defeats my shit.\n# is it still image?\n# we can also detect more shits. right?\nimport sys\nimport os\nos.chdir(\"../../\")\nsys.path.append(\".\")\nfrom pyjom.commons import extract_span\nimport scenedetect\nfrom caer.video.frames_and_fps import get_duration\nstats_file_path = \"/media/root/parrot/pyjom/tests/nearly_duplicate_frames_detection_removal/output.csv\"\nduration = get_duration(source)\nprint(\"DURATION:\", duration)\ncuts = scenedetect.detect(\n    video_path=source, stats_file_path=stats_file_path, show_progress=True, \n    # detector=scenedetect.ContentDetector()\n    detector=scenedetect.AdaptiveDetector(),\n) # no fucking cuts???\nimport pandas",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/test.py:1-28"
    },
    "3737": {
        "file_id": 452,
        "content": "Code imports necessary libraries, checks if the source is a still image, and uses scenedetect library for scene detection. It gets video duration, sets adaptive detector, and stores results in output.csv file. No cuts are found in the video.",
        "type": "comment"
    },
    "3738": {
        "file_id": 452,
        "content": "df = pandas.read_csv(stats_file_path)\nprint(df.head())\nbreakpoint()",
        "type": "code",
        "location": "/tests/nearly_duplicate_frames_detection_removal/test.py:30-32"
    },
    "3739": {
        "file_id": 452,
        "content": "This code reads a CSV file (stats_file_path) into a pandas DataFrame named 'df', then prints the first 5 rows of the DataFrame, and finally pauses execution at this breakpoint.",
        "type": "comment"
    },
    "3740": {
        "file_id": 453,
        "content": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/babel_decorator.js",
        "type": "filepath"
    },
    "3741": {
        "file_id": 453,
        "content": "This code defines a decorator function using Babel's plugin for JavaScript syntax decorators. It wraps a function, logs the arguments passed to it, and then calls the original function. The decorated function, `myfunc`, is called with 'myval', and its return value is logged to the console.",
        "type": "summary"
    },
    "3742": {
        "file_id": 453,
        "content": "// require(\"@babel/core\").transformSync(\"code\", {\n//     plugins: [\"@babel/plugin-syntax-decorators\"]\n//   });\nfunction dec(func){\n    function innerfunc(...args){\n        console.log('calling func with args:', args)\n        func(...args)\n    }\n    return innerfunc\n}\n@dec\nfunction myfunc(val){\n    return val\n}\nval = myfunc('myval')\nconsole.log('val:', val)",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/babel_decorator.js:2-19"
    },
    "3743": {
        "file_id": 453,
        "content": "This code defines a decorator function using Babel's plugin for JavaScript syntax decorators. It wraps a function, logs the arguments passed to it, and then calls the original function. The decorated function, `myfunc`, is called with 'myval', and its return value is logged to the console.",
        "type": "comment"
    },
    "3744": {
        "file_id": 454,
        "content": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/cypher_inline.js",
        "type": "filepath"
    },
    "3745": {
        "file_id": 454,
        "content": "This code defines two functions for creating SQL statements and a Query class with unclear inline function usage, potentially due to JavaScript's inconsistent behavior. It also logs undefined variables to the console.",
        "type": "summary"
    },
    "3746": {
        "file_id": 454,
        "content": "// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\n// official javascript driver\n// https://neo4j.com/developer/javascript/\nvar cypher = function(strArray, ...opts) { // this is bad.\n    console.log('input:', strArray, opts) // here we've got the thing.\n    // passed here. good.\n    // this will be good.\n    // suppose we put string, object into this thing.\n    // suppose we quote the thing.\n    return strArray;\n}\nvar sql = function(str) { return str; }\nvar myexpression = {obj:2}; // not supplied to cypher?\n// create (n)-[:married]->(r) [object Object]\n// wtf?\nvar myexpression2 = '3';\nvar b = `create (n)-[:married]->(r) ${myexpression}`\nconsole.log(b) // create (n)-[:married]->(r) 2\n    // this will format the thing.\nvar a = cypher `create (n:person{name:${myexpression}})-[:married]->(r) ${myexpression2}`; // well that's good.\nconsole.log(a);\nconst query = sql `SELECT * FROM users`;\nconsole.log(query);\n// function otherfunc(){\n//     console.log('calling otherfunc')\n//     return 'other func'",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/cypher_inline.js:2-28"
    },
    "3747": {
        "file_id": 454,
        "content": "The code defines two functions, `cypher` and `sql`, which create SQL statements using template literals. The `cypher` function takes a string array and optional parameters, while the `sql` function only takes a single string parameter. The code demonstrates how to use these functions by creating a Cypher query with placeholders for dynamic values and executing a SELECT query.",
        "type": "comment"
    },
    "3748": {
        "file_id": 454,
        "content": "// }\n// function myfunc() {\n//     otherfunc()\n//     return query;\n// }\n// // __export__\n// // console.log(module.loaded) // false\n// // export all functions?\n// module.exports = {otherfunc, myfunc} // also some bloated shit.\n// which one you want? damn...\n// you want some object?\n// what if they are interdependent?\n// this is some other strange shit.\n// exports = {\n//         otherfunc: () => {\n//             console.log('calling otherfunc');\n//             return 'otherfunc'\n//         },\n//         myfunc: () => {\n//             exports.otherfunc() // strange shit.\n//             return query;\n//         }\n//     }\n//     // console.log(module)\n// module.exports = exports // must use this to export things.\n// this is self-reference.\nclass Query {\n    constructor(a, b) {\n        this.a = a\n        this.b = b\n    }\n    static otherfunc() {\n        // otherfunc() {\n        console.log('calling otherfunc');\n        return 'otherfunc'\n    }\n    static myfunc(...args) {\n        // static myfunc() {\n            console.log('myfunc args:',args)",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/cypher_inline.js:29-71"
    },
    "3749": {
        "file_id": 454,
        "content": "The code defines a class \"Query\" with two static methods: \"otherfunc\" and \"myfunc\". \"otherfunc\" is called within \"myfunc\", creating an interdependence between the two functions. The code exports the entire class, using self-reference for the static methods.",
        "type": "comment"
    },
    "3750": {
        "file_id": 454,
        "content": "        Query.otherfunc() // strange shit.\n            // this.otherfunc() // still working for static functions.\n            // javascript is a beast.\n        return query;\n    }\n}\nmodule.exports = { Query }\n    // console.log(.cypher)\n    // console.log('QUERY?',globalThis.Query, this.sql) // all undefinded.",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/cypher_inline.js:72-80"
    },
    "3751": {
        "file_id": 454,
        "content": "This code defines a Query class with a strange inline function call and exports it. The otherfunc() is called inside the Query class, but its purpose is unclear. JavaScript's behavior for static functions versus instance methods seems inconsistent here. The code also logs variables to the console, but they are all undefined.",
        "type": "comment"
    },
    "3752": {
        "file_id": 455,
        "content": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/hy_repl_normal.py",
        "type": "filepath"
    },
    "3753": {
        "file_id": 455,
        "content": "The code imports the HyREPL module from hy.cmdline and initializes an instance of it called \"repl\". It prints a message before running the REPL, then runs the REPL using the repl.run() method. After that, it prints another message after the REPL. The code aims to demonstrate a normal usage of HyREPL.",
        "type": "summary"
    },
    "3754": {
        "file_id": 455,
        "content": "import hy.cmdline\n# this is different. no access to hidden member.\nprint('message before repl')\nrepl = hy.cmdline.HyREPL() # this is not reliable. exit will exit this shit for good.\nrepl.run()\nprint('message after repl')\n# no message after repl?",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/hy_repl_normal.py:1-7"
    },
    "3755": {
        "file_id": 455,
        "content": "The code imports the HyREPL module from hy.cmdline and initializes an instance of it called \"repl\". It prints a message before running the REPL, then runs the REPL using the repl.run() method. After that, it prints another message after the REPL. The code aims to demonstrate a normal usage of HyREPL.",
        "type": "comment"
    },
    "3756": {
        "file_id": 456,
        "content": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/mtest.py",
        "type": "filepath"
    },
    "3757": {
        "file_id": 456,
        "content": "The code defines an exception named \"my exception\" and lists the available attributes and methods for this exception class. It also defines a function named \"shit\" that raises an Exception with the message 'shit' and returns the string \"value\".",
        "type": "summary"
    },
    "3758": {
        "file_id": 456,
        "content": "e = Exception(\"my exception\")\n# print(dir(e))\n# ['__cause__', '__class__', '__context__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__suppress_context__', '__traceback__', 'args', 'with_traceback']\ndef shit():\n    raise Exception('shit')\n    return \"value\"",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/mtest.py:1-7"
    },
    "3759": {
        "file_id": 456,
        "content": "The code defines an exception named \"my exception\" and lists the available attributes and methods for this exception class. It also defines a function named \"shit\" that raises an Exception with the message 'shit' and returns the string \"value\".",
        "type": "comment"
    },
    "3760": {
        "file_id": 457,
        "content": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/my_module/some_module.py",
        "type": "filepath"
    },
    "3761": {
        "file_id": 457,
        "content": "The code defines a function 'program' within the module 'some_module' that raises an exception. If the file is run directly, it enters a loop that attempts to execute the 'program' function repeatedly, reloading the module after each failure in order to hot fix issues and apply edits while continuing execution.",
        "type": "summary"
    },
    "3762": {
        "file_id": 457,
        "content": "# inside some_module.py\ndef program():\n    raise Exception(\"Exception in program\")\n    # return \"VALUE\"\nif __name__ == \"__main__\":\n    while True:\n        try:\n            import some_module # will it even succeed? doubt this.\n            val = some_module.program()\n            print(\"returned value:\", val)\n            break\n        except:\n            import traceback\n            traceback.print_exc()\n            input('are you done yet?')\n            import importlib\n            importlib.reload(some_module)",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/my_module/some_module.py:1-19"
    },
    "3763": {
        "file_id": 457,
        "content": "The code defines a function 'program' within the module 'some_module' that raises an exception. If the file is run directly, it enters a loop that attempts to execute the 'program' function repeatedly, reloading the module after each failure in order to hot fix issues and apply edits while continuing execution.",
        "type": "comment"
    },
    "3764": {
        "file_id": 458,
        "content": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/sql_inline.py",
        "type": "filepath"
    },
    "3765": {
        "file_id": 458,
        "content": "The code is attempting to utilize the chalk library for creating SQL queries. It first defines a string \"a\" as a SELECT query and \"b\" as a CREATE query in Cypher format. Then, it imports the required modules from JavaScript and initializes the chalk library using \"./cypher_inline.js\". The code then creates an instance of chalk's Query class (q) and calls its myfunc method with some arguments. Finally, it prints the VALUE and type of both 'a' and 'b'.",
        "type": "summary"
    },
    "3766": {
        "file_id": 458,
        "content": "a = \"select * from user\"\nb = \"create (n:person)\"  # cypher # not working!\nfrom javascript import require, globalThis\nchalk = require(\n    \"./cypher_inline.js\"chr\n)  # that might be some drop-in replacement for jinja? should they work together?\n# print(dir(chalk))\n# what the fuck?\nq = chalk.Query # use static method this time?\n# q = chalk.Query(1,2)\nval = q.myfunc(dict(somearg=1)) # this is similar to the original shit.\n# myfunc args: [ { somearg: 1 } ]\n# good?\n# val = chalk.myfunc()\nprint(\"VALUE\", list(val), type(val))  # it can be converted.\nval = q.otherfunc()\n# val = chalk.otherfunc()\nprint(\"VALUE\", val, type(val))  # it can be converted.",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/sql_inline.py:1-22"
    },
    "3767": {
        "file_id": 458,
        "content": "The code is attempting to utilize the chalk library for creating SQL queries. It first defines a string \"a\" as a SELECT query and \"b\" as a CREATE query in Cypher format. Then, it imports the required modules from JavaScript and initializes the chalk library using \"./cypher_inline.js\". The code then creates an instance of chalk's Query class (q) and calls its myfunc method with some arguments. Finally, it prints the VALUE and type of both 'a' and 'b'.",
        "type": "comment"
    },
    "3768": {
        "file_id": 459,
        "content": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/thread_based_program.py",
        "type": "filepath"
    },
    "3769": {
        "file_id": 459,
        "content": "This Python code creates a multithreaded, event-driven program using threading. It starts two threads for main execution and event handling, checking if the event breaks the loop. This basic approach demonstrates multithreading with event-based communication in Python.\n\nSummary in 30 words: Python code utilizes multithreading and event-driven programming to create a program with two threads, one for main execution and another for event handling, checking if an event breaks the loop, showcasing basic approach for multithreading communication.",
        "type": "summary"
    },
    "3770": {
        "file_id": 459,
        "content": "import threading\nevent = threading.Event()\nevent.clear()\n# is it event driven? can we launch repl after this?\ndef program(*args): # in elixir/erlang this is simpler.\n    print('running program')\n    while True:\n        if event.wait(0.00000001):\n            break # this is blocking. fuck. not like elixir in any kind.\n        else:\n            event.set()\n    event.clear()\n    print('begin execution')\n    print(\"arguments:\", args)\n    raise Exception('shit man')\n    event.set()\n    result = 'myresult'\ndef mainThread():\n    threading.Thread(target=program, args=(1,2), daemon=True).start()\n    print('waiting output? probably never.')\n    while True:\n        if event.wait(0.00000001):\n            break # are you sure this is the event you want?\n        else:\n            event.set()\n    print('result:',result) # another thread? are you sharing things?\n    print('main thread execution succeed')\nprint('starting main thread')\nthreading.Thread(target=mainThread, daemon=True).run()\nprint('starting repl')\n# be ready to re-execute the program?",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/thread_based_program.py:1-35"
    },
    "3771": {
        "file_id": 459,
        "content": "This code creates an event-driven, multithreaded program using Python's threading module. It starts two threads: one for the main program execution and another for handling events. The main program runs indefinitely, checking if the event is set to break out of the loop. The main thread also sets the result variable. This code demonstrates a basic approach to multithreaded programming in Python with event-driven communication between threads.",
        "type": "comment"
    },
    "3772": {
        "file_id": 459,
        "content": "# do you want something like nodejs promises?\n# how to reload foreign files? fuck?",
        "type": "code",
        "location": "/tests/neo4j_cypher_builder_template_why_you_suddenly_want_to_create_exceptions_and_find_solutions_to_hot_fix_reloading_and_edit_and_continue/thread_based_program.py:36-37"
    },
    "3773": {
        "file_id": 459,
        "content": "This code snippet seems to express frustration about handling promises in Node.js and the difficulty of reloading foreign files.",
        "type": "comment"
    },
    "3774": {
        "file_id": 460,
        "content": "/tests/nsfw_violence_drug_detection/README.md",
        "type": "filepath"
    },
    "3775": {
        "file_id": 460,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "summary"
    },
    "3776": {
        "file_id": 460,
        "content": "it is related to video content censorship, but really close to video automatic editing.\nwe have violence video dataset, we also have some 'fun video' dataset called blooper dataset",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/README.md:1-3"
    },
    "3777": {
        "file_id": 460,
        "content": "This code is related to video content censorship and automatic editing, using violence and blooper datasets.",
        "type": "comment"
    },
    "3778": {
        "file_id": 461,
        "content": "/tests/nsfw_violence_drug_detection/init_nsfwjs.sh",
        "type": "filepath"
    },
    "3779": {
        "file_id": 461,
        "content": "Installing global dependencies for TF.js, nsfwjs, jpeg-js, express, and multer in the codebase.",
        "type": "summary"
    },
    "3780": {
        "file_id": 461,
        "content": "npm i -g @tensorflow/tfjs-node nsfwjs jpeg-js express multer",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/init_nsfwjs.sh:1-1"
    },
    "3781": {
        "file_id": 461,
        "content": "Installing global dependencies for TF.js, nsfwjs, jpeg-js, express, and multer in the codebase.",
        "type": "comment"
    },
    "3782": {
        "file_id": 462,
        "content": "/tests/nsfw_violence_drug_detection/launch_nodejs_server.sh",
        "type": "filepath"
    },
    "3783": {
        "file_id": 462,
        "content": "This line of code runs a JavaScript file named \"nsfwjs_test.js\" using the Node.js runtime environment. The purpose could be to execute tests or perform specific operations related to nsfw (not safe for work) detection, specifically for violence and drug-related content.",
        "type": "summary"
    },
    "3784": {
        "file_id": 462,
        "content": "node nsfwjs_test.js",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/launch_nodejs_server.sh:1-1"
    },
    "3785": {
        "file_id": 462,
        "content": "This line of code runs a JavaScript file named \"nsfwjs_test.js\" using the Node.js runtime environment. The purpose could be to execute tests or perform specific operations related to nsfw (not safe for work) detection, specifically for violence and drug-related content.",
        "type": "comment"
    },
    "3786": {
        "file_id": 463,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js",
        "type": "filepath"
    },
    "3787": {
        "file_id": 463,
        "content": "This code imports TensorFlow and nsfwjs libraries, processes GIF frames at 1fps, loads a model for classification using predictions, and sets up a file stream to read data in chunks for partial processing.",
        "type": "summary"
    },
    "3788": {
        "file_id": 463,
        "content": "const tf = require('@tensorflow/tfjs-node')\nconst nsfw = require('nsfwjs')\n// predictions [\n//     [\n//       { className: 'Neutral', probability: 0.9845383167266846 },\n//       { className: 'Porn', probability: 0.009829860180616379 },\n//       { className: 'Drawing', probability: 0.003906613681465387 }\n//     ],\n//     [\n//       { className: 'Neutral', probability: 0.9763429760932922 },\n//       { className: 'Porn', probability: 0.014182578772306442 },\n//       { className: 'Drawing', probability: 0.007088858168572187 }\n//     ],\n//     [\n//       { className: 'Neutral', probability: 0.9598317742347717 },\n//       { className: 'Drawing', probability: 0.03286046162247658 },\n//       { className: 'Porn', probability: 0.003989457152783871 }\n//     ]\n//   ]\nfilepath = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n// mechanism: choose three most likely categories per chosen frame, process at 1fps.\n// no other classes?\n// filepath = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js:1-27"
    },
    "3789": {
        "file_id": 463,
        "content": "Code imports TensorFlow and nsfwjs libraries, and defines an array of prediction results for three frames. The filepath is set to \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\". The code chooses the top three categories from each frame, processes them at 1fps, and does not consider other classes.",
        "type": "comment"
    },
    "3790": {
        "file_id": 463,
        "content": "const fs = require('fs');\n// Store file data chunks in this array\nlet chunks = [];\n// We can use this variable to store the final data\nlet fileBuffer;\n// Read file into stream.Readable\nlet fileStream = fs.createReadStream(filepath);\n// An error occurred with the stream\nfileStream.once('error', (err) => {\n    // Be sure to handle this properly!\n    console.error(err);\n});\nlet _model\nconst load_model = async() => {\n    _model = await nsfw.load()\n    console.log('model ready')\n}\n// Keep the model in memory, make sure it's loaded only once\n// File is done being read\nfileStream.once('end', () => {\n    // create the final data Buffer from data chunks;\n    fileBuffer = Buffer.concat(chunks);\n    // do shit here.\n    console.log(\"filebuffer ready\")\n    load_model().then(() => {\n        _model.classifyGif(fileBuffer, { topk: 3, fps: 1 })\n            .then(predictions => console.log('predictions', predictions))\n            .catch(error => console.log('model error', error))\n    })\n    // Of course, you can do anything else you need to here, like emit an event!",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js:29-64"
    },
    "3791": {
        "file_id": 463,
        "content": "The code reads a file into a stream, stores it in chunks, combines the chunks into a final data buffer, and then loads a model to classify the GIF using its predictions. This allows for efficient processing of large files and accurate detection of content.",
        "type": "comment"
    },
    "3792": {
        "file_id": 463,
        "content": "});\n// Data is flushed from fileStream in chunks,\n// this callback will be executed for each chunk\nfileStream.on('data', (chunk) => {\n    chunks.push(chunk); // push data chunk to array\n    // We can perform actions on the partial data we have so far!\n});",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_gif.js:65-73"
    },
    "3793": {
        "file_id": 463,
        "content": "This code snippet sets up a file stream that reads data in chunks. The 'data' event triggers for each chunk, and pushes the chunk into an array (chunks). This allows performing actions on partial data as it arrives.",
        "type": "comment"
    },
    "3794": {
        "file_id": 464,
        "content": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js",
        "type": "filepath"
    },
    "3795": {
        "file_id": 464,
        "content": "The function creates a color mask, processes BMP file header info, handles compression types, and supports various color formats. The code converts images to TensorFlow tensor3d arrays, handles file uploads, loads an NSFW model for classification, and runs on port 8511.",
        "type": "summary"
    },
    "3796": {
        "file_id": 464,
        "content": "// import { createRequire } from \"module\";\n// const require = createRequire(import.meta.url);\n// now we are talking\nfunction maskColor(maskRed, maskGreen, maskBlue, maskAlpha) {\n    const maskRedR = (~maskRed + 1) & maskRed;\n    const maskGreenR = (~maskGreen + 1) & maskGreen;\n    const maskBlueR = (~maskBlue + 1) & maskBlue;\n    const maskAlphaR = (~maskAlpha + 1) & maskAlpha;\n    const shiftedMaskRedL = maskRed / maskRedR + 1;\n    const shiftedMaskGreenL = maskGreen / maskGreenR + 1;\n    const shiftedMaskBlueL = maskBlue / maskBlueR + 1;\n    const shiftedMaskAlphaL = maskAlpha / maskAlphaR + 1;\n    return {\n        shiftRed: (x) => (((x & maskRed) / maskRedR) * 0x100) / shiftedMaskRedL,\n        shiftGreen: (x) => (((x & maskGreen) / maskGreenR) * 0x100) / shiftedMaskGreenL,\n        shiftBlue: (x) => (((x & maskBlue) / maskBlueR) * 0x100) / shiftedMaskBlueL,\n        shiftAlpha: maskAlpha !== 0 ?\n            (x) => (((x & maskAlpha) / maskAlphaR) * 0x100) / shiftedMaskAlphaL :\n            () => 255\n    };",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:1-22"
    },
    "3797": {
        "file_id": 464,
        "content": "This function takes four parameters (maskRed, maskGreen, maskBlue, and maskAlpha) to create a color mask. It performs bitwise operations and calculations to shift the color values and returns an object with functions to shift red, green, blue, and alpha components of any given value. If maskAlpha is not zero, it also returns an additional function for shifting alpha values.",
        "type": "comment"
    },
    "3798": {
        "file_id": 464,
        "content": "}\nvar HeaderTypes;\n(function(HeaderTypes) {\n    HeaderTypes[HeaderTypes[\"BITMAP_INFO_HEADER\"] = 40] = \"BITMAP_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V2_INFO_HEADER\"] = 52] = \"BITMAP_V2_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V3_INFO_HEADER\"] = 56] = \"BITMAP_V3_INFO_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V4_HEADER\"] = 108] = \"BITMAP_V4_HEADER\";\n    HeaderTypes[HeaderTypes[\"BITMAP_V5_HEADER\"] = 124] = \"BITMAP_V5_HEADER\";\n})(HeaderTypes || (HeaderTypes = {}));\nclass BmpDecoder {\n    constructor(buffer, { toRGBA } = { toRGBA: false }) {\n        this.buffer = buffer;\n        this.toRGBA = !!toRGBA;\n        this.pos = 0;\n        this.bottomUp = true;\n        this.flag = this.buffer.toString('utf-8', 0, (this.pos += 2));\n        if (this.flag !== 'BM') {\n            throw new Error('Invalid BMP File');\n        }\n        this.locRed = this.toRGBA ? 0 : 3;\n        this.locGreen = this.toRGBA ? 1 : 2;\n        this.locBlue = this.toRGBA ? 2 : 1;\n        this.locAlpha = this.toRGBA ? 3 : 0;\n        this.parseHeader();",
        "type": "code",
        "location": "/tests/nsfw_violence_drug_detection/nsfwjs_test.js:23-48"
    },
    "3799": {
        "file_id": 464,
        "content": "Class BmpDecoder is created with a buffer and optional toRGBA parameter, which determines the pixel data format. The constructor initializes variables, checks for valid file signature, and sets location indices for RGB(A) values based on toRGBA flag. parseHeader function will be called next.",
        "type": "comment"
    }
}