{
    "5200": {
        "file_id": 666,
        "content": "/tests/karaoke_effects/lyricToAss_test.py",
        "type": "filepath"
    },
    "5201": {
        "file_id": 666,
        "content": "This code imports necessary functions and utilizes them to generate an animated .ass file from a music file and its corresponding .lrc file, then previews it with a sample video.",
        "type": "summary"
    },
    "5202": {
        "file_id": 666,
        "content": "# this is the complete process.\nfrom lyrictoolbox import *\n# from .lyrictoolbox import previewAssWithVideo\n# from .lyrictoolbox import getTextListTranslated\nif __name__ == \"__main__\":\n    musicPath = \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\"\n    lrcPath = \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.lrc\"\n    sample_video = \"/root/Desktop/works/pyjom/samples/video/karaoke_effects_source.mp4\"\n    import os\n    assPath = os.path.abspath(\"test.ass\")\n    lrcToAnimatedAss(musicPath, lrcPath, assPath)\n    previewAssWithVideo(sample_video, assPath)",
        "type": "code",
        "location": "/tests/karaoke_effects/lyricToAss_test.py:1-15"
    },
    "5203": {
        "file_id": 666,
        "content": "This code imports necessary functions and utilizes them to generate an animated .ass file from a music file and its corresponding .lrc file, then previews it with a sample video.",
        "type": "comment"
    },
    "5204": {
        "file_id": 667,
        "content": "/tests/karaoke_effects/loadSomeCustomClashYaml.py",
        "type": "filepath"
    },
    "5205": {
        "file_id": 667,
        "content": "This code imports yaml and defines two functions for converting YAML strings between Python-friendly and Go-compatible formats. It then loads a file (Clash.yaml) using a custom loader, converts the string, and prints the loaded data.",
        "type": "summary"
    },
    "5206": {
        "file_id": 667,
        "content": "import yaml\n# yaml.add_constructor(mCustomLoaderTag, create_ref, Loader)\ndef goYamlToPyYaml(docString):\n    docString = docString.replace(\"!<str>\", \"!!str\")\n    return docString\ndef pyYamlToGoYaml(docString):\n    docString = docString.replace(\"!!str\", \"!<str>\")\n    return docString\nif __name__ == \"__main__\":\n    fileName = \"Clash.yaml\"\n    docString = open(fileName, \"r\").read()\n    mCustomLoaderTag = \"!<str>\"\n    class Ref(object):\n        def __init__(self, data):\n            self.data = data\n        def __repr__(self):\n            return '\"%s\"' % self.data\n    def create_ref(loader, node):\n        # print(dir(loader))\n        # breakpoint()\n        value = loader.costruct_string(node)\n        return Ref(value)\n    class Loader(yaml.SafeLoader):\n        pass\n    docString = goYamlToPyYaml(docString)\n    a = yaml.load(docString)\n    print(a)",
        "type": "code",
        "location": "/tests/karaoke_effects/loadSomeCustomClashYaml.py:1-41"
    },
    "5207": {
        "file_id": 667,
        "content": "This code imports yaml and defines two functions for converting YAML strings between Python-friendly and Go-compatible formats. It then loads a file (Clash.yaml) using a custom loader, converts the string, and prints the loaded data.",
        "type": "comment"
    },
    "5208": {
        "file_id": 668,
        "content": "/tests/karaoke_effects/loadLingua_pyjnius.py",
        "type": "filepath"
    },
    "5209": {
        "file_id": 668,
        "content": "This code imports necessary modules, sets Java classpath, prints a message, creates a language detector object, defines a function to detect language from a sample text, and tests the detector with a sample input.",
        "type": "summary"
    },
    "5210": {
        "file_id": 668,
        "content": "import jnius_config\n# jnius_config.add_options('-Xrs', '-Xmx4096')\njnius_config.set_classpath(\n    \".\", \"/root/Desktop/works/pyjom/tests/karaoke_effects/classpath/lingua.jar\"\n)\nimport jnius\njnius.autoclass(\"java.lang.System\").out.println(\"Running Java Program Using Pyjnius!\")\npyjniusLinguaDetector = (\n    jnius.autoclass(\"com.github.pemistahl.lingua.api.LanguageDetectorBuilder\")\n    .fromAllLanguages()\n    .build()\n)\ndef pyjniusLinguaDetectLanguageLabel(sample):\n    result = pyjniusLinguaDetector.detectLanguageOf(sample)\n    # print(result, type(result))\n    # breakpoint()\n    strResult = result.toString()\n    return strResult\nif __name__ == \"__main__\":\n    sample = \"hello world\"\n    result = pyjniusLinguaDetector.detectLanguageOf(sample)\n    print(result, type(result))\n    # breakpoint()\n    strResult = result.toString()\n    print(strResult, type(strResult))",
        "type": "code",
        "location": "/tests/karaoke_effects/loadLingua_pyjnius.py:1-32"
    },
    "5211": {
        "file_id": 668,
        "content": "This code imports necessary modules, sets Java classpath, prints a message, creates a language detector object, defines a function to detect language from a sample text, and tests the detector with a sample input.",
        "type": "comment"
    },
    "5212": {
        "file_id": 669,
        "content": "/tests/karaoke_effects/load_translator.sh",
        "type": "filepath"
    },
    "5213": {
        "file_id": 669,
        "content": "This code snippet is used to terminate a Tmux session named \"translator\" and then load the configuration file \"translator.yml\" using Tmuxp, likely for testing purposes in the pyjom/tests/karaoke_effects folder.",
        "type": "summary"
    },
    "5214": {
        "file_id": 669,
        "content": "tmux kill-session -t translator\ntmuxp load -y translator.yml",
        "type": "code",
        "location": "/tests/karaoke_effects/load_translator.sh:1-2"
    },
    "5215": {
        "file_id": 669,
        "content": "This code snippet is used to terminate a Tmux session named \"translator\" and then load the configuration file \"translator.yml\" using Tmuxp, likely for testing purposes in the pyjom/tests/karaoke_effects folder.",
        "type": "comment"
    },
    "5216": {
        "file_id": 670,
        "content": "/tests/karaoke_effects/launch_clash.sh",
        "type": "filepath"
    },
    "5217": {
        "file_id": 670,
        "content": "This script sets proxy environment variables, downloads the latest Clash configuration file from two sources and executes clash with the downloaded configuration.",
        "type": "summary"
    },
    "5218": {
        "file_id": 670,
        "content": "export http_proxy=\"\"\nexport https_proxy=\"\"\n# env http_proxy=\"http://localhost:38457\" https_proxy=\"http://localhost:38457\" curl -O https://openit.ml/Clash.yaml\n##########FETCHING LATEST YAML############\n# env http_proxy=\"http://localhost:38457\" https_proxy=\"http://localhost:38457\" curl -O https://raw.githubusercontent.com/yu-steven/openit/main/Clash.yaml\n# python3 get_clash_yaml.py\n##########FETCHING LATEST YAML############\n# refreshing can be ignored since it is not needed.\nclash -f ClashBaseOpenIt.yaml",
        "type": "code",
        "location": "/tests/karaoke_effects/launch_clash.sh:1-10"
    },
    "5219": {
        "file_id": 670,
        "content": "This script sets proxy environment variables, downloads the latest Clash configuration file from two sources and executes clash with the downloaded configuration.",
        "type": "comment"
    },
    "5220": {
        "file_id": 671,
        "content": "/tests/karaoke_effects/in2.ass.j2",
        "type": "filepath"
    },
    "5221": {
        "file_id": 671,
        "content": "This code specifies styles, font sizes, and effects for text in an .ass file, containing dialogue entries with timings, styles, and translations in a SubRip subtitle format. It includes Japanese dialogues with English translations, defining positioning, style, and timing for each text element.",
        "type": "summary"
    },
    "5222": {
        "file_id": 671,
        "content": "﻿[Script Info]\n; Script generated by Aegisub 8975-master-8d77da3\n; http://www.aegisub.org/\nTitle: Default Aegisub file\nScriptType: v4.00+\nWrapStyle: 0\nScaledBorderAndShadow: yes\nYCbCr Matrix: TV.601\nPlayResX: 1600\nPlayResY: 900\n[Aegisub Project Garbage]\nLast Style Storage: Default\nVideo File: ?dummy:23.976000:2250:1920:1080:11:135:226:c\nVideo AR Value: 1.777778\nVideo Zoom Percent: 0.500000\nVideo Position: 349\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,{{defaultFontname or 'Arial'}},{{defaultFontsize or 48}},&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,0,8,25,25,25,1\nStyle: Romaji,{{romajiFontname or 'Migu 1P'}},{{romajiFontsize or 48}},&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,0,8,25,25,25,1\nStyle: Translation,{{translationFontname or 'M",
        "type": "code",
        "location": "/tests/karaoke_effects/in2.ass.j2:1-23"
    },
    "5223": {
        "file_id": 671,
        "content": "This code is an Aegisub script containing the file's title, script type, and other relevant information. It includes styles for default text, Romaji, and translation, specifying their names, font types, sizes, colors, alignments, and margins.",
        "type": "comment"
    },
    "5224": {
        "file_id": 671,
        "content": "igu 1P'}},{{translationFontsize or 46}},&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,0,2,25,25,25,1\nStyle: Kanji,{{kanjiFontname or 'Migu 1P'}},{{kanjiFontsize or 38}},&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,1.8,0,4,25,25,25,1\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\nDialogue: 3,0:00:14.54,0:00:20.72,Romaji,,0,0,0,,{\\k45\\-m1}da{\\k22}re{\\k13}mo {\\k75\\-m1}ga {\\k11}sa{\\k11}ka{\\k46}ra{\\k21}e{\\k8}zu {\\k39}ni {\\k22}mo{\\k25}gu{\\k19}t{\\k66\\-m1}te {\\k15}i{\\k180\\-m1}ku\nDialogue: 3,0:00:21.60,0:00:26.95,Romaji,,0,0,0,,{\\k50}so{\\k21}no {\\k13}me {\\k73\\-m2}o {\\k10}to{\\k10}mo{\\k29}shi{\\k24}bi {\\k19}yo{\\k11}ri {\\k37}ka{\\k22}ga{\\k19}ya{\\k23}ka{\\k44\\-m2}se{\\k130\\-m2}te\nDialogue: 3,0:00:28.52,0:00:31.60,Romaji,,0,0,0,,{\\k13}me{\\k12}za{\\k29\\-m1}su {\\k35\\-m2}sa{\\k26}ki {\\k32}wa {\\k32\\-m1}fu{\\k23\\-m2}ka{\\k106\\-m1}ku\nDialogue: 1,0:00:14.54,0:00:20.72,Kanji,,0,0,0,,{\\k67}誰{\\k13}も{\\k75}が{\\k22}逆{\\k46}ら{\\k21}え{\\k8}ず{\\k39}に{\\k47}潜{\\k19}っ{\\k66}て{\\k15}い{\\k180}く",
        "type": "code",
        "location": "/tests/karaoke_effects/in2.ass.j2:23-31"
    },
    "5225": {
        "file_id": 671,
        "content": "This code defines styles, font sizes, and effects for text in an .ass file, specifying layer, timing, style, and content. It contains four dialogue entries with various texts and styles, including kanji and romaji, with specific timing and positioning on the screen.",
        "type": "comment"
    },
    "5226": {
        "file_id": 671,
        "content": "Dialogue: 0,0:00:21.60,0:00:26.95,Kanji,,0,0,0,m2,{\\k50}そ{\\k21}の{\\k13}目{\\k83}を{\\k39}灯{\\k24}火{\\k19}よ{\\k11}り{\\k78}輝{\\k23}か{\\k44}せ{\\k130}て\nDialogue: 0,0:00:28.52,0:00:31.60,Kanji,,0,0,0,m1,{\\k13}目{\\k12}指{\\k29}す{\\k61}先{\\k32}は{\\k55}深{\\k106}く\nDialogue: 1,0:00:14.54,0:00:20.72,Translation,,0,0,0,,{\\t(-2001,-2000,\\1c&HC7FFB0&\\3c&H1B5306&)\\t(4062,4292,\\1c&HA7B5DC&\\3c&H0C1F57&)\\t(4938,5300,\\1c&HC7FFB0&\\3c&H1B5306&)}Ciò che abbiamo sempre desiderato è sepolto in profondità.\nDialogue: 1,0:00:21.60,0:00:26.95,Translation,,0,0,0,,{\\t(87,87,\\1c&HA7B5DC&\\3c&H0C1F57&)}Malgrado le nostre paure, i nostri occhi brillano più del fuoco.\nDialogue: 1,0:00:28.52,0:00:31.60,Translation,,0,0,0,,{\\t(258,258,\\1c&HFFC390&\\3c&H672414&)}Il nostro obbiettivo è raggiungere quel luogo recondito,",
        "type": "code",
        "location": "/tests/karaoke_effects/in2.ass.j2:32-36"
    },
    "5227": {
        "file_id": 671,
        "content": "This code contains dialogue entries with timings, styles, and translations in a SubRip subtitle file. It includes two dialogues in Japanese and their respective English translations, indicating the positioning, style, and timing of each text element in the subtitle.",
        "type": "comment"
    },
    "5228": {
        "file_id": 672,
        "content": "/tests/karaoke_effects/lrc2ass_py3/test.sh",
        "type": "filepath"
    },
    "5229": {
        "file_id": 672,
        "content": "The code is running an MPV player with no audio, using a subtitle file and video source. It seems that the video's effect is bad, and the time synchronization is incorrect, causing dissatisfaction with the result.",
        "type": "summary"
    },
    "5230": {
        "file_id": 672,
        "content": "rootpath=/Users/jamesbrown/desktop/works/pyjom_remote/\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/lrc2ass_py3/output.s2.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"\n## NOT OK! THIS DUMB SHIT LIBRARY FUCKED MY MIND ##\n## the effect is bad. the time is not right. everything fucked. ##",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/test.sh:1-5"
    },
    "5231": {
        "file_id": 672,
        "content": "The code is running an MPV player with no audio, using a subtitle file and video source. It seems that the video's effect is bad, and the time synchronization is incorrect, causing dissatisfaction with the result.",
        "type": "comment"
    },
    "5232": {
        "file_id": 673,
        "content": "/tests/karaoke_effects/lrc2ass_py3/README.md",
        "type": "filepath"
    },
    "5233": {
        "file_id": 673,
        "content": "This Python 3 script converts LRC files to ASS format with karaoke effects, supports multiple timing tags, and auto-chooses end timings. It is primarily for Chinese but may encounter errors in non-Chinese languages or wrong text codings. Future improvements include English support, annotations, file list input, reusability, and debugging.",
        "type": "summary"
    },
    "5234": {
        "file_id": 673,
        "content": "# lrc2ass_py3\nA simple Python 3.x script is used for changing your LRC file into ASS subtitle with karaoke effect tags\n一个用于将LRC歌词文件转换为ASS字幕文件的简单Python脚本。\nThe first full python script written by myself.\n我自己编写的第一个完整的Python脚本\nCopyright(c) 2020 yyfll (MIT)\n# WON'T UPDATE IN THE FUTURE\n# Dependent\n* chardet (lrc2ass_py3 >= 1.0.0c)\n# Update\n## 1.0.0c\n* Support chardet character encoding detector.\n* A few improvements\n## 1.0.0b\n* Support LRC offset tag.\n* Default LRC offset can be set.\n* Simplify program.\n# English Readme\nPoor English.\n## What can lrc2ass_py3 do?\n* Change your LRC script to ASS script.\n* Very easy to use.\n* Support Multi timing tags in a single line.\n* Support auto choose end timing if can't find timing in the end of the line.\n* Support LRC offset tag.\n## What will cause error?\n* A lrc file in wrong text coding (such as use utf-8 read gbk file.)\n* A lrc line without the timing tag in the line ahead. (haven't tested)\n## WARNING\n* Only CHINESE are supported.\n> All the information show in console and the annotations in python script are written in CHINESE,",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/README.md:1-41"
    },
    "5235": {
        "file_id": 673,
        "content": "This is a simple Python 3 script for converting LRC files to ASS with karaoke effects. It requires the chardet library, supports multiple timing tags, and auto-chooses end timings if not specified. However, it's only for Chinese and may encounter errors if the LRC file is in the wrong text coding or lacks a timing tag on certain lines.",
        "type": "comment"
    },
    "5236": {
        "file_id": 673,
        "content": ">\n> It doesn't mean lrc2ass_py3 can't work on your LRC in English.\n>\n> So it doesn't have any influence on output a correct ASS script if you use English or any other language.\n# 简体中文 Readme\n## lrc2ass_py3可以做什么？\n* 将你的LRC歌词文件转换为ASS字幕文件\n* 使用起来非常简单\n* 支持一个歌词行多个时间标签（即卡拉OK效果）\n* 支持在找不到歌词行的结束时间时，自动选择结束时间\n* 支持时间偏移标签（offset）\n## 有什么可能会导致错误的？\n* 读取了非指定文本编码的LRC歌词文件（比如像用utf-8编码读取gbk编码的文件）\n* 歌词行开头没有指定起始时间的时间标签（这还没有经过测试）\n## 警告\n* 只支持中文\n> 所有的控制台输出及文件内注释都是用中文写的\n>\n> 这并不意味着lrc2ass_py3不能处理非中文的LRC文件\n>\n> 所以这并不会对输出一个正确ASS字幕文件产生任何影响\n# To do\n* Full English supported\n* Full Chinese annotation\n* File list input\n* Reusable\n* Endless debugging",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/README.md:42-72"
    },
    "5237": {
        "file_id": 673,
        "content": "This code is a README file for the lrc2ass_py3 tool, which converts LRC karaoke files to ASS format. It supports English and other languages, but has warnings and limitations related to non-Chinese languages and specific encoding formats. The code also includes a To Do list with additional features such as full English support, improved annotations, file list input, reusability, and debugging.",
        "type": "comment"
    },
    "5238": {
        "file_id": 674,
        "content": "/tests/karaoke_effects/lrc2ass_py3/localTest.sh",
        "type": "filepath"
    },
    "5239": {
        "file_id": 674,
        "content": "Code is running mpv player with no audio and loading an .ass subtitle file to display over a video. The user is experiencing issues with the output.",
        "type": "summary"
    },
    "5240": {
        "file_id": 674,
        "content": "rootpath=/root/Desktop/works/pyjom\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/lrc2ass_py3/output.s2.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"\n## NOT OK! THIS DUMB SHIT LIBRARY FUCKED MY MIND ##\n## the effect is bad. the time is not right. everything fucked. ##",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/localTest.sh:1-5"
    },
    "5241": {
        "file_id": 674,
        "content": "Code is running mpv player with no audio and loading an .ass subtitle file to display over a video. The user is experiencing issues with the output.",
        "type": "comment"
    },
    "5242": {
        "file_id": 675,
        "content": "/tests/karaoke_effects/pyonfx_test/view_best_example.sh",
        "type": "filepath"
    },
    "5243": {
        "file_id": 675,
        "content": "This command starts mpv player to display a karaoke video with subtitles. The \"Output.ass\" file contains the lyrics and timing information, and the \"karaoke_effects_source.mp4\" is the video being displayed.",
        "type": "summary"
    },
    "5244": {
        "file_id": 675,
        "content": "mpv --fs --no-audio --sub-file=\"/root/Desktop/works/pyjom/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass\" \"/root/Desktop/works/pyjom/samples/video/karaoke_effects_source.mp4\"",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/view_best_example.sh:1-1"
    },
    "5245": {
        "file_id": 675,
        "content": "This command starts mpv player to display a karaoke video with subtitles. The \"Output.ass\" file contains the lyrics and timing information, and the \"karaoke_effects_source.mp4\" is the video being displayed.",
        "type": "comment"
    },
    "5246": {
        "file_id": 676,
        "content": "/tests/karaoke_effects/pyonfx_test/test.py",
        "type": "filepath"
    },
    "5247": {
        "file_id": 676,
        "content": "The code initializes a variable 'lyricPath' with the path to the LRC file and imports modules 'pyonfx' and 'pylrc'.",
        "type": "summary"
    },
    "5248": {
        "file_id": 676,
        "content": "lyricPath = \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.lrc\"\nimport pyonfx\nimport pylrc",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/test.py:1-3"
    },
    "5249": {
        "file_id": 676,
        "content": "The code initializes a variable 'lyricPath' with the path to the LRC file and imports modules 'pyonfx' and 'pylrc'.",
        "type": "comment"
    },
    "5250": {
        "file_id": 677,
        "content": "/tests/karaoke_effects/pyonfx_test/render_ass_video.sh",
        "type": "filepath"
    },
    "5251": {
        "file_id": 677,
        "content": "This command uses FFmpeg to extract a 60-second segment from the input video \"karaoke_effects_source.mp4\", applying the embedded ASS subtitles from \"Output.ass\" as effects, and saves the result as \"out.mp4\".",
        "type": "summary"
    },
    "5252": {
        "file_id": 677,
        "content": "ffmpeg -y -i \"/root/Desktop/works/pyjom/samples/video/karaoke_effects_source.mp4\" -ss 0 -to 60 -vf \"ass='/root/Desktop/works/pyjom/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass'\" out.mp4",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/render_ass_video.sh:1-1"
    },
    "5253": {
        "file_id": 677,
        "content": "This command uses FFmpeg to extract a 60-second segment from the input video \"karaoke_effects_source.mp4\", applying the embedded ASS subtitles from \"Output.ass\" as effects, and saves the result as \"out.mp4\".",
        "type": "comment"
    },
    "5254": {
        "file_id": 678,
        "content": "/tests/karaoke_effects/pyonfx_test/macos_view_best_example.sh",
        "type": "filepath"
    },
    "5255": {
        "file_id": 678,
        "content": "This script opens a video file with an ASS subtitle file, using mpv player in full screen and without audio. The ASS file contains karaoke effects for the associated video, sourced from pyjom_remote/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner folder.",
        "type": "summary"
    },
    "5256": {
        "file_id": 678,
        "content": "rootpath=/Users/jamesbrown/desktop/works/pyjom_remote/\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/macos_view_best_example.sh:1-2"
    },
    "5257": {
        "file_id": 678,
        "content": "This script opens a video file with an ASS subtitle file, using mpv player in full screen and without audio. The ASS file contains karaoke effects for the associated video, sourced from pyjom_remote/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner folder.",
        "type": "comment"
    },
    "5258": {
        "file_id": 679,
        "content": "/tests/karaoke_effects/pyonfx_test/first_try.py",
        "type": "filepath"
    },
    "5259": {
        "file_id": 679,
        "content": "This code imports the \"pyonfx\" library and uses it to open an ASS file. It then retrieves the file's metadata, styles, and lines of text. The first line's text is modified, and the modified line is written back into the file. The code also attempts to open Aegisub but fails as there isn't one available.",
        "type": "summary"
    },
    "5260": {
        "file_id": 679,
        "content": "from pyonfx import *\nio = Ass(\"in.ass\")\nmeta, styles, lines = io.get_data()\nlines[0].text = \"I am a new line!\"\nio.write_line(lines[0])\nio.save()\n# io.open_aegisub()\n# there's no aegisub.",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/first_try.py:1-11"
    },
    "5261": {
        "file_id": 679,
        "content": "This code imports the \"pyonfx\" library and uses it to open an ASS file. It then retrieves the file's metadata, styles, and lines of text. The first line's text is modified, and the modified line is written back into the file. The code also attempts to open Aegisub but fails as there isn't one available.",
        "type": "comment"
    },
    "5262": {
        "file_id": 680,
        "content": "/tests/vapoursynth_linux_test/cloneBasicRepo.sh",
        "type": "filepath"
    },
    "5263": {
        "file_id": 680,
        "content": "This code is cloning four repositories: ffms2, vsrepo (not useful for non-Windows OSes), Bl4Cc4t's homebrew-vsplugins, and UniversalAl's view. The purpose is to fetch necessary software components for Linux and macOS platforms.",
        "type": "summary"
    },
    "5264": {
        "file_id": 680,
        "content": "git clone https://github.com/FFMS/ffms2\n# git clone https://github.com/vapoursynth/vsrepo not useful for OSes other than Windows\ngit clone https://github.com/Bl4Cc4t/homebrew-vsplugins # checking how to build these things properly on linux/macos\ngit clone https://github.com/UniversalAl/view",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/cloneBasicRepo.sh:1-4"
    },
    "5265": {
        "file_id": 680,
        "content": "This code is cloning four repositories: ffms2, vsrepo (not useful for non-Windows OSes), Bl4Cc4t's homebrew-vsplugins, and UniversalAl's view. The purpose is to fetch necessary software components for Linux and macOS platforms.",
        "type": "comment"
    },
    "5266": {
        "file_id": 681,
        "content": "/tests/vapoursynth_linux_test/basic_test.py",
        "type": "filepath"
    },
    "5267": {
        "file_id": 681,
        "content": "Code imports vapoursynth module and sets video path. It loads the video using ffms2 source, transposes it, then outputs the result without encoding. Opencv may be needed for previewing.",
        "type": "summary"
    },
    "5268": {
        "file_id": 681,
        "content": "videoPath = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# videoPath = \"/Users/jamesbrown/desktop/works/pyjom_remote/samples/video/dog_with_text.mp4\"\nfrom vapoursynth import core\nvideo = core.ffms2.Source(source=videoPath)\nvideo = core.std.Transpose(video)\nvideo.set_output()\n# vspipe is a wrapper around existing apis. vapoursynth can only generate raw frame data so we cannot encode video here alone. maybe we need opencv for this?\n# opencv preview https://github.com/UniversalAl/view",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/basic_test.py:1-10"
    },
    "5269": {
        "file_id": 681,
        "content": "Code imports vapoursynth module and sets video path. It loads the video using ffms2 source, transposes it, then outputs the result without encoding. Opencv may be needed for previewing.",
        "type": "comment"
    },
    "5270": {
        "file_id": 682,
        "content": "/tests/vapoursynth_linux_test/view_test.py",
        "type": "filepath"
    },
    "5271": {
        "file_id": 682,
        "content": "The code imports VapourSynth library functions, creates a Video object with FFMS2 source and option to transpose, but generating previews isn't working as vspipe uses existing APIs and can only generate raw frame data. OpenCV might help; example at https://github.com/UniversalAl/view.",
        "type": "summary"
    },
    "5272": {
        "file_id": 682,
        "content": "videoPath = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# videoPath = \"/Users/jamesbrown/desktop/works/pyjom_remote/samples/video/dog_with_text.mp4\"\n# reference: http://www.vapoursynth.com/doc/pythonreference.html\n# The VideoFrame and AudioFrame classes contains one picture/audio chunk and all the metadata associated with it. It is possible to access the raw data using either get_read_ptr(plane) or get_write_ptr(plane) and get_stride(plane) with ctypes.\n# A more Python friendly wrapping is also available where each plane/channel can be accessed as a Python array using frame[plane/channel].\n# To get a frame simply call get_frame(n) on a clip. Should you desire to get all frames in a clip, use this code:\n# for frame in clip.frames():\n#     # Do stuff with your frame\n#     pass\nfrom vapoursynth import core\nvideo = core.ffms2.Source(source=videoPath)\n# video = core.std.Transpose(video)\n# video.set_output()\n# from viewKali import Preview\n# clip = vs.core.lsmas.LibavSMASHSource('source.mp4')",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/view_test.py:1-23"
    },
    "5273": {
        "file_id": 682,
        "content": "The code imports the necessary functions from the VapourSynth library and defines a video path. It then creates a Video object using the FFMS2 source and provides an option to transpose the video if needed, but it's currently commented out. Additionally, there is a reference to another file called \"viewKali\" where a Preview function may be used, but it's not implemented yet.",
        "type": "comment"
    },
    "5274": {
        "file_id": 682,
        "content": "# seems not working\n# Preview(video)\n# vspipe is a wrapper around existing apis. vapoursynth can only generate raw frame data so we cannot encode video here alone. maybe we need opencv for this?\n# opencv preview https://github.com/UniversalAl/view",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/view_test.py:24-28"
    },
    "5275": {
        "file_id": 682,
        "content": "This code appears to attempt creating a preview using VapourSynth, but the functionality isn't working. It suggests that vspipe is a wrapper around existing APIs and VapourSynth can only generate raw frame data, so encoding a video alone might not be possible. OpenCV might help in generating previews, and there's an example at this GitHub link: https://github.com/UniversalAl/view.",
        "type": "comment"
    },
    "5276": {
        "file_id": 683,
        "content": "/tests/vapoursynth_linux_test/test_ffmpeg_docker.sh",
        "type": "filepath"
    },
    "5277": {
        "file_id": 683,
        "content": "Code snippet attempts to download a video file 'flower_cif.y4m' using wget, and then applies various filters with ffmpeg-tensorflow Docker container to upscale the video resolution by 2x and save it as 'flower_cif_2x.mp4'. The code also provides an alias for easier execution of ffmpeg-tensorflow command and specifies video filter complexities within the ffmpeg command.",
        "type": "summary"
    },
    "5278": {
        "file_id": 683,
        "content": "wget https://media.xiph.org/video/derf/y4m/flower_cif.y4m\n# no good for using docker gpu containers.\n# alias ffmpeg-tensorflow='docker run --rm --gpus all -u $(id -u):$(id -g) -v \"$PWD\":/data -w /data -i miratmu/ffmpeg-tensorflow'\n# ffmpeg-tensorflow -i flower_cif.y4m -filter_complex '[0:v] format=pix_fmts=yuv420p, extractplanes=y+u+v [y][u][v]; [y] sr=dnn_backend=tensorflow:scale_factor=2:model=/models/espcn.pb [y_scaled]; [u] scale=iw*2:ih*2 [u_scaled]; [v] scale=iw*2:ih*2 [v_scaled]; [y_scaled][u_scaled][v_scaled] mergeplanes=0x001020:yuv420p [merged]' -map [merged] -sws_flags lanczos -c:v libx264 -crf 17 -c:a copy -y flower_cif_2x.mp4",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/test_ffmpeg_docker.sh:1-6"
    },
    "5279": {
        "file_id": 683,
        "content": "Code snippet attempts to download a video file 'flower_cif.y4m' using wget, and then applies various filters with ffmpeg-tensorflow Docker container to upscale the video resolution by 2x and save it as 'flower_cif_2x.mp4'. The code also provides an alias for easier execution of ffmpeg-tensorflow command and specifies video filter complexities within the ffmpeg command.",
        "type": "comment"
    },
    "5280": {
        "file_id": 684,
        "content": "/tests/vapoursynth_linux_test/test.sh",
        "type": "filepath"
    },
    "5281": {
        "file_id": 684,
        "content": "This code is running vspipe, a command-line tool for processing video files with VapourSynth script. It takes a .vpy script file as input and uses the -c flag for y4m format output.",
        "type": "summary"
    },
    "5282": {
        "file_id": 684,
        "content": "vspipe -c y4m script.vpy -",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/test.sh:1-1"
    },
    "5283": {
        "file_id": 684,
        "content": "This code is running vspipe, a command-line tool for processing video files with VapourSynth script. It takes a .vpy script file as input and uses the -c flag for y4m format output.",
        "type": "comment"
    },
    "5284": {
        "file_id": 685,
        "content": "/tests/vapoursynth_linux_test/scene_change_detection.sh",
        "type": "filepath"
    },
    "5285": {
        "file_id": 685,
        "content": "This code is using FFmpeg to process a video file, extracting scenes by selecting frames where the scene change is greater than 0.1 and displaying information about each scene change. The output is redirected to null.",
        "type": "summary"
    },
    "5286": {
        "file_id": 685,
        "content": "ffmpeg -hide_banner -i \"/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4\" -an \\\n-filter:v \"select='gt(scene,0.1)',showinfo\" \\\n-f null \\\n- 2>&1",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/scene_change_detection.sh:3-6"
    },
    "5287": {
        "file_id": 685,
        "content": "This code is using FFmpeg to process a video file, extracting scenes by selecting frames where the scene change is greater than 0.1 and displaying information about each scene change. The output is redirected to null.",
        "type": "comment"
    },
    "5288": {
        "file_id": 686,
        "content": "/tests/vapoursynth_linux_test/pure_ffmpeg_interpolate_resolution_denoise.sh",
        "type": "filepath"
    },
    "5289": {
        "file_id": 686,
        "content": "This script uses FFmpeg and TensorFlow to process video files, applying Super Resolution and Edge Preserving Blur filters for improved quality. It utilizes Anaconda libraries for CUDA toolkit and CuDNN in a non-real-time processing manner.",
        "type": "summary"
    },
    "5290": {
        "file_id": 686,
        "content": "# ffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -vf \"minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d\" -r 60 ffmpeg_samoyed.mp4\n# SRCNN=espcn.pb\n# 5fps or something\n# env LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr_models/dnn_models/espcn.pb\"  ffmpeg_samoyed_espcn.mp4\n# 9fps or something\n# ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"yaepblur\"  ffmpeg_samoyed_srcnn.mp4\n# strange shit.\n# env LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur,hqdn3d\"  ffmpeg_samoyed_srcnn.mp4\n# env LD_LIBRARY_PATH=/root/anaco",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/pure_ffmpeg_interpolate_resolution_denoise.sh:1-13"
    },
    "5291": {
        "file_id": 686,
        "content": "The script contains FFmpeg commands to resize, denoise and apply different filters on a GIF file. It uses the TensorFlow model \"espcn.pb\" for super-resolution and the \"yaepblur\" filter. The environment variable LD_LIBRARY_PATH is used to specify paths for CUDA toolkit and CUDNN libraries. The final output is saved as \".mp4\" files with different names.",
        "type": "comment"
    },
    "5292": {
        "file_id": 686,
        "content": "nda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur\"  ffmpeg_samoyed_dctdnoiz.mp4\nenv LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH ffmpeg -i \"/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4\" -y -vf \"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur\"  supertest.mp4\n# dctdnoiz is not for real time processing. it is slow.\n# but somehow it makes the picture great. is it?\n#  TSC hqdn3d            V->V       Apply a High Quality 3D Denoiser.\n# check out all filters by `ffmpeg -filters`\n# yaepblur\n# yet another edge preserving blur filter\n# ffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" -filter \"minterpolate=mi_mode=2\" -r 60 ffmpeg_samoyed.mp4\n# use deep learning models:\n# https://video.stackexchange.com/questions/29337/how-do-the-super-resolution-filters-in-ffmpeg-work",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/pure_ffmpeg_interpolate_resolution_denoise.sh:13-27"
    },
    "5293": {
        "file_id": 686,
        "content": "This code uses FFmpeg to process video files, applying filters like Super Resolution (SR) using deep learning models and Edge Preserving Blur. It utilizes TensorFlow as the dnn_backend for SR filter and Anaconda libraries for CUDA toolkit and CuDNN. The processing is not real-time but improves picture quality.",
        "type": "comment"
    },
    "5294": {
        "file_id": 687,
        "content": "/tests/vapoursynth_linux_test/previewTestVideo.sh",
        "type": "filepath"
    },
    "5295": {
        "file_id": 687,
        "content": "Executing VapourSynth script on Linux, piping the output to FFplay for visualization. No frame-by-frame shift slider available.",
        "type": "summary"
    },
    "5296": {
        "file_id": 687,
        "content": "vspipe -c y4m basic_test.py - | ffplay -i pipe: \n# working! but no frame by frame shift slider avaliable",
        "type": "code",
        "location": "/tests/vapoursynth_linux_test/previewTestVideo.sh:1-2"
    },
    "5297": {
        "file_id": 687,
        "content": "Executing VapourSynth script on Linux, piping the output to FFplay for visualization. No frame-by-frame shift slider available.",
        "type": "comment"
    },
    "5298": {
        "file_id": 688,
        "content": "/tests/vapoursynth_linux_test/pip_examine.sh",
        "type": "filepath"
    },
    "5299": {
        "file_id": 688,
        "content": "The code captures, crops, and saves FFmpeg-generated screenshots from a video at specific timestamps in the \"pip_examine\" directory.",
        "type": "summary"
    }
}