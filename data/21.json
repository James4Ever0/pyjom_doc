{
    "2100": {
        "file_id": 210,
        "content": "/tests/unittest_translate_lyrictoolbox.py",
        "type": "filepath"
    },
    "2101": {
        "file_id": 210,
        "content": "The code imports necessary modules, defines sources as a list of strings, and uses the translate function from pyjom.lyrictoolbox with deepl backend to obtain translations for each source in the list. The results are printed out using sprint.",
        "type": "summary"
    },
    "2102": {
        "file_id": 210,
        "content": "from test_commons import *\nfrom pyjom.lyrictoolbox import translate\nfrom lazero.utils.logger import sprint\nsources = [\"are you ok\", \"are you happy\", \"are you good\", \"are you satisfied\"]\nfor source in sources:\n    result = translate(\n        source, backend=\"deepl\"\n    )  # this is cached. no matter what backend you use.\n    print(\"source:\", source)\n    sprint(\"result:\", result)",
        "type": "code",
        "location": "/tests/unittest_translate_lyrictoolbox.py:1-11"
    },
    "2103": {
        "file_id": 210,
        "content": "The code imports necessary modules, defines sources as a list of strings, and uses the translate function from pyjom.lyrictoolbox with deepl backend to obtain translations for each source in the list. The results are printed out using sprint.",
        "type": "comment"
    },
    "2104": {
        "file_id": 211,
        "content": "/tests/README.md",
        "type": "filepath"
    },
    "2105": {
        "file_id": 211,
        "content": "This code snippet aims to integrate a recommendation system into the existing LLM (Large Language Model) and scrapers. By doing so, it intends to enhance the overall performance and efficiency of the language model and web scraping processes.",
        "type": "summary"
    },
    "2106": {
        "file_id": 211,
        "content": "use recommendation system to enhance our LLM/scrapers",
        "type": "code",
        "location": "/tests/README.md:1-1"
    },
    "2107": {
        "file_id": 211,
        "content": "This code snippet aims to integrate a recommendation system into the existing LLM (Large Language Model) and scrapers. By doing so, it intends to enhance the overall performance and efficiency of the language model and web scraping processes.",
        "type": "comment"
    },
    "2108": {
        "file_id": 212,
        "content": "/tests/modify_package.sh",
        "type": "filepath"
    },
    "2109": {
        "file_id": 212,
        "content": "This script searches for Python files (.py), then replaces specific module imports (\"from modules\", \"from main\", etc.) with their new corresponding pyjom paths using sed command.",
        "type": "summary"
    },
    "2110": {
        "file_id": 212,
        "content": "find | grep -E \".py\\$\" | xargs -iabc sed -i \"s/from modules/from pyjom.modules/g\" abc\nfind | grep -E \".py\\$\" | xargs -iabc sed -i \"s/from main/from pyjom.main/g\" abc \nfind | grep -E \".py\\$\" | xargs -iabc sed -i \"s/from commons/from pyjom.commons/g\" abc\nfind | grep -E \".py\\$\" | xargs -iabc sed -i \"s/from config/from pyjom.config/g\" abc\nfind | grep -E \".py\\$\" | xargs -iabc sed -i \"s/from medialang/from pyjom.medialang/g\" abc\nfind | grep -E \".py\\$\" | xargs -iabc sed -i \"s/from primitives/from pyjom.primitives/g\" abc",
        "type": "code",
        "location": "/pyjom/modify_package.sh:1-6"
    },
    "2111": {
        "file_id": 212,
        "content": "This script searches for Python files (.py), then replaces specific module imports (\"from modules\", \"from main\", etc.) with their new corresponding pyjom paths using sed command.",
        "type": "comment"
    },
    "2112": {
        "file_id": 213,
        "content": "/tests/launch_test_enviroment.sh",
        "type": "filepath"
    },
    "2113": {
        "file_id": 213,
        "content": "The code is a shell script that launches various environments for testing and services, including servers, APIs, and multiple terminal instances for different tests. It includes commands to ensure proper execution without overlap or conflicts.",
        "type": "summary"
    },
    "2114": {
        "file_id": 213,
        "content": "cd /root/Desktop/works/pyjom/tests/\npython3 launch_test_enviroment.py\n# # launch bilibili recommendation server\n# cd /root/Desktop/works/pyjom/tests/bilibili_video_recommendation_server\n# gnome-terminal -- python3 /root/Desktop/works/pyjom/tests/bilibili_video_recommendation_server/test.py\n# # launch qq cqhttp\n# cd /root/Desktop/works/pyjom/tests/qq_go_cqhttp\n# gnome-terminal -- bash /root/Desktop/works/pyjom/tests/qq_go_cqhttp/launch.sh\n# # make sure milvus is running.\n# cd /root/Desktop/works/pyjom/tests/video_phash_deduplication/\n# bash /root/Desktop/works/pyjom/tests/video_phash_deduplication/config_milvus.sh\n# # launch netease api server. we need it to download new music, currently.\n# # video phash is the last step among all filters.\n# cd /root/Desktop/works/pyjom/externals/NeteaseCloudMusicApi\n# gnome-terminal -- bash /root/Desktop/works/pyjom/externals/NeteaseCloudMusicApi/launch.sh # port is 4042. port 4000 is used. don't know why.\n# # how to check avaliability of netease cloud music api?\n# cd /root/Desktop/works/pyjom/tests/karaoke_effects/",
        "type": "code",
        "location": "/tests/launch_test_enviroment.sh:1-23"
    },
    "2115": {
        "file_id": 213,
        "content": "The code is a shell script that launches various environments for testing and services, including a bilibili recommendation server, qq cqhttp, milvus, netease api server. It also includes commands to ensure the servers are running correctly and provides instructions on how to check the availability of the netease cloud music API.",
        "type": "comment"
    },
    "2116": {
        "file_id": 213,
        "content": "# gnome-terminal -- bash /root/Desktop/works/pyjom/tests/karaoke_effects/load_translator.sh\n# sleep 1\n# cd /root/Desktop/works/pyjom/tests/redis_music_info_persistance\n# gnome-terminal -- bash /root/Desktop/works/pyjom/tests/redis_music_info_persistance/launch_redis.sh\n# sleep 1\n# cd /root/Desktop/works/pyjom/tests/random_giphy_gifs/\n# gnome-terminal -- node /root/Desktop/works/pyjom/tests/random_giphy_gifs/nodejs_server.js\n# sleep 1\n# cd /root/Desktop/works/pyjom/tests/nsfw_violence_drug_detection\n# gnome-terminal -- node /root/Desktop/works/pyjom/tests/nsfw_violence_drug_detection/nsfwjs_test.js",
        "type": "code",
        "location": "/tests/launch_test_enviroment.sh:24-36"
    },
    "2117": {
        "file_id": 213,
        "content": "The code launches multiple terminal instances and scripts for different tests, with each instance running a specific script in the project's directory. The \"sleep 1\" command introduces a pause between commands to allow the previous terminal instance to start before proceeding. This ensures proper execution of each test without overlap or conflicts.",
        "type": "comment"
    },
    "2118": {
        "file_id": 214,
        "content": "/tests/launch_test_enviroment.py",
        "type": "filepath"
    },
    "2119": {
        "file_id": 214,
        "content": "The function launches programs, changes directory, and waits for sleep duration. It asserts file existence, handles errors, and runs commands using os.system(). The code sets up a test environment by launching processes and services, specifying options, handling errors, and providing debugging information.",
        "type": "summary"
    },
    "2120": {
        "file_id": 214,
        "content": "import time\nimport os\ndef launchProgramWithTerminal(\n    directory,\n    intepreter,\n    executable,\n    sleep=None,\n    no_terminal=False,\n    keep_on=True,  # preserve error log\n):\n    try:\n        if type(sleep) in [int, float]:\n            if sleep > 0:  # logic shortcut please?\n                time.sleep(sleep)\n            else:\n                raise Exception(\"negative or zero sleep duration:\", sleep)\n        directory = os.path.abspath(directory)\n        assert os.path.exists(directory)\n        os.chdir(directory)\n        executable_path = os.path.join(directory, executable)\n        assert os.path.exists(executable_path)\n        # mkeep_on = (\n        #     \"{}\"\n        #     if (not keep_on) or no_terminal\n        #     else \"bash -c \\\"{}; echo; echo 'error log above...'; date; bash;\\\"\"\n        # )\n        mkeep_on = (\n            \"{}\"\n            if not keep_on\n            else (\n                \"bash -c \\\"{}; if [[ '$!' -ne 0 ]] then; echo; echo 'error log above...'; date; bash; fi;\\\"\"\n                if no_terminal",
        "type": "code",
        "location": "/tests/launch_test_enviroment.py:1-34"
    },
    "2121": {
        "file_id": 214,
        "content": "This function launches a program with its associated terminal, changes directory to the specified path, and optionally waits for a sleep duration. It asserts the existence of the executable file and handles error logs based on keep_on and no_terminal flags.",
        "type": "comment"
    },
    "2122": {
        "file_id": 214,
        "content": "                else \"bash -c \\\"{}; echo; echo 'error log above...'; date; bash;\\\"\"\n            )\n        )\n        command = f'{\"gnome-terminal -- \" if not no_terminal else \"\"}{mkeep_on.format(f\"{intepreter} {executable_path}\")}'\n        return command\n    except:\n        import traceback\n        traceback.print_exc()\n        print(\"failed while launching program with parameters:\")\n        print(\n            f\"[D]:{directory}\\n[I]{intepreter}\\n[E]{executable}\\n[C]{dict(sleep=sleep, no_terminal=no_terminal)}\"\n        )\n        breakpoint()\n    return None\ndef executeCommand(command):\n    print(\"executing command:\", command)\n    os.system(command)\n# common paths\npyjom_directory = \"/root/Desktop/works/pyjom\"\npyjom_tests = os.path.join(pyjom_directory, \"tests\")\npyjom_externals = os.path.join(pyjom_directory, \"externals\")\nkeepalive_bin = '/usr/local/bin/keepalive'\n# interpreters\nnode_exec = \"/usr/bin/node\"\npython3_exec = \"/usr/bin/python3\"\nbash_exec = \"/bin/bash\"\nlaunchList = [\n    # launch billibili recommendation server",
        "type": "code",
        "location": "/tests/launch_test_enviroment.py:35-70"
    },
    "2123": {
        "file_id": 214,
        "content": "This code launches a program with specified parameters and optional Gnome Terminal. It handles potential errors by printing an exception traceback and breakpoint for debugging. The executeCommand function runs the generated command using os.system(). Common paths, interpreters, and a list of programs to launch are defined.",
        "type": "comment"
    },
    "2124": {
        "file_id": 214,
        "content": "    # do this in qq task.\n    # [\n    #     [\n    #         os.path.join(pyjom_tests, \"bilibili_video_recommendation_server\"),\n    #         python3_exec,\n    #         \"test.py\",\n    #     ],\n    #     {},\n    # ],\n    # launch qq cqhttp\n    [[os.path.join(pyjom_tests, \"qq_go_cqhttp\"), bash_exec, \"launch.sh\"], {}],\n    # make sure milvus is running.\n    [\n        [\n            os.path.join(pyjom_tests, \"video_phash_deduplication\"),\n            bash_exec,\n            \"config_milvus.sh\",\n        ],\n        dict(no_terminal=True),\n    ],\n    # launch netease api server. we need it to download new music, currently.\n    # video phash is the last step among all filters.\n    [\n        [os.path.join(pyjom_externals, \"NeteaseCloudMusicApi\"), bash_exec, \"launch.sh\"],\n        {},\n    ],  # port is 4042. port 4000 is used. don't know why.\n    # how to check avaliability of netease cloud music api?\n    [\n        [os.path.join(pyjom_tests, \"karaoke_effects\"), bash_exec, \"load_translator.sh\"],\n        {},\n    ],\n    [\n        [\n            os.path.join(pyjom_tests, \"redis_music_info_persistance\"),",
        "type": "code",
        "location": "/tests/launch_test_enviroment.py:71-104"
    },
    "2125": {
        "file_id": 214,
        "content": "This code is setting up a test environment by launching multiple processes and services. It includes tasks for the bilibili video recommendation server, QQ CQHTTP, Milvus database, Netease Cloud Music API, Karaoke effects, and Redis music info persistence. Each task consists of the location of the executable and any necessary arguments. The code ensures proper execution by specifying different options for each task.",
        "type": "comment"
    },
    "2126": {
        "file_id": 214,
        "content": "            bash_exec,\n            \"launch_redis.sh\",\n        ],\n        dict(sleep=1),\n    ],\n    [\n        [os.path.join(pyjom_tests, \"random_giphy_gifs\"), node_exec, \"nodejs_server.js\"],\n        dict(sleep=1),\n    ],\n    [\n        [\n            os.path.join(pyjom_tests, \"nsfw_violence_drug_detection\"),\n            node_exec,\n            \"nsfwjs_test.js\",\n        ],\n        dict(sleep=1),\n    ],\n    # [\n    #     [\n    #         os.path.join(pyjom_tests, \"bezier_paddlehub_dogcat_detector_serving\"),\n    #         python3_exec,\n    #         \"server.py\",\n    #     ],\n    #     dict(sleep=1),\n    # ],\n]\nfor argumentList, kwargs in launchList:\n    try:\n        assert type(kwargs) == dict\n        [directory, intepreter, executable] = argumentList\n        command = launchProgramWithTerminal(directory, intepreter, executable, **kwargs)\n        if command is None:\n            raise Exception(\"command is None\")\n        else:\n            executeCommand(command)\n    except:\n        import traceback\n        traceback.print_exc()\n        print(\"error when decomposing program launch parameters\")",
        "type": "code",
        "location": "/tests/launch_test_enviroment.py:105-145"
    },
    "2127": {
        "file_id": 214,
        "content": "The code defines a list of argument lists and their corresponding keyword arguments, then iterates through each set of arguments to launch different programs using the specified interpreter and executable. It handles potential errors by catching exceptions and printing the traceback for debugging purposes.",
        "type": "comment"
    },
    "2128": {
        "file_id": 214,
        "content": "        print(f\"[AL]{argumentList}\\n[KW]{kwargs}\")\n        breakpoint()",
        "type": "code",
        "location": "/tests/launch_test_enviroment.py:146-147"
    },
    "2129": {
        "file_id": 214,
        "content": "The code prints a formatted string containing the command-line arguments (in `argumentList`) and keyword arguments (in `kwargs`), then pauses execution at the breakpoint.",
        "type": "comment"
    },
    "2130": {
        "file_id": 215,
        "content": "/tests/experiment_iterate_and_merge_alike_text_regions.py",
        "type": "filepath"
    },
    "2131": {
        "file_id": 215,
        "content": "This code models a finite state machine, compares two lists of coordinates, and creates a new list based on similar elements and a threshold using nested loops. New items are printed and appended to the sample list, while prevList is copied for potential future use or comparison.",
        "type": "summary"
    },
    "2132": {
        "file_id": 215,
        "content": "# finite state machine.\nsample = [\n    [],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [[98, 206, 37, 9]],\n    [[98, 200, 165, 137]],\n    [[98, 200, 165, 137]],\n    [[98, 200, 165, 137]],\n    [[98, 200, 165, 137]],\n    [[98, 200, 165, 137]],\n    [[98, 200, 165, 137]],\n    [],\n    [[5, 118, 88, 362]],\n    [[5, 118, 88, 362]],\n    [[5, 115, 89, 365]],\n    [[5, 115, 89, 365]],\n    [[2, 115, 92, 365]],\n    [[2, 115, 92, 365]],\n    [[2, 115, 92, 365]],\n    [[2, 115, 92, 365]],\n    [[2, 116, 91, 364]],\n    [[2, 116, 52, 364]],\n    [[2, 116, 52, 364]],\n    [[58, 242, 93, 238], [2, 117, 52, 363]],\n    [[58, 241, 94, 239], [7, 117, 47, 363]],\n    [[58, 240, 94, 240]],\n    [[58, 240, 94, 240]],\n    [[58, 240, 94, 240]],\n    [[58, 240, 94, 240]],\n    [[59, 240, 93, 240]],\n    [[59, 240, 93, 240]],\n    [[59, 241, 93, 239]],\n    [[59, 241, 93, 239]],\n    [[59, 241, 93, 239]],\n    [[59, 241, 93, 239]],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [[92, 190, 23, 290]],\n    [[92, 190, 23, 290]],\n    [[92, 190, 23, 290]],",
        "type": "code",
        "location": "/tests/experiment_iterate_and_merge_alike_text_regions.py:1-51"
    },
    "2133": {
        "file_id": 215,
        "content": "This code represents a finite state machine where each sublist within the main list corresponds to a different state. The numbers within the sublists likely represent specific actions, values or conditions associated with that state.",
        "type": "comment"
    },
    "2134": {
        "file_id": 215,
        "content": "    [[90, 190, 25, 290]],\n    [[90, 190, 25, 290]],\n    [[90, 190, 25, 290]],\n    [[90, 190, 25, 290]],\n    [[90, 190, 25, 290]],\n    [[90, 190, 25, 290]],\n    [[92, 190, 23, 290]],\n    [[92, 190, 23, 290]],\n    [[92, 190, 23, 290]],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [],\n    [[31, 151, 7, 329]],\n    [[31, 151, 7, 329]],\n    [[31, 151, 7, 329]],\n    [[31, 149, 7, 331]],\n    [[31, 149, 7, 331]],\n    [[31, 149, 7, 331]],\n    [[31, 149, 7, 331]],\n    [[31, 149, 7, 331]],\n    [[31, 149, 7, 331]],\n    [[31, 149, 7, 331]],\n    [[31, 149, 7, 331]],\n    [],\n    [],\n    [],\n    [],\n]\nprevList = []\nnewList = []\nimport numpy as np\ndef alike(array0, array1, threshold):\n    npArray0, npArray1 = np.array(array0), np.array(array1)\n    return max(abs(npArray0 - npArray1)) <= threshold\nnewSample = []\nfor item in sample:\n    newItem = []\n    for elem in item:\n        for prevElem in prevList:\n            if alike(prevElem, elem, 10):\n                # mAlike = True\n                elem = prevElem.copy()\n                break\n        newItem.append(elem.copy())",
        "type": "code",
        "location": "/tests/experiment_iterate_and_merge_alike_text_regions.py:52-104"
    },
    "2135": {
        "file_id": 215,
        "content": "This code compares two lists of coordinates and checks if the elements within each list are similar to a certain threshold. It then creates a new list where similar elements are replaced with the previous element found in the 'prevList' variable. If an element is not similar, it is simply copied into the new list. The code also includes a nested loop that iterates over the sample and prevList variables to perform these operations.",
        "type": "comment"
    },
    "2136": {
        "file_id": 215,
        "content": "    print(newItem)  # showcase.\n    newSample.append(newItem.copy())\n    prevList = newItem.copy()",
        "type": "code",
        "location": "/tests/experiment_iterate_and_merge_alike_text_regions.py:105-107"
    },
    "2137": {
        "file_id": 215,
        "content": "In this code snippet, a new item is printed to showcase its contents, then it is appended to the sample list as a copy of itself, and finally, the previous list (prevList) is also copied for potential later use or comparison.",
        "type": "comment"
    },
    "2138": {
        "file_id": 216,
        "content": "/tests/dog_cat_demo_not_for_test.mdl",
        "type": "filepath"
    },
    "2139": {
        "file_id": 216,
        "content": "The code defines video properties and lists files in the \"/dev/shm/medialang/online\" directory, including details such as file paths, speeds, dimensions, durations, and silent settings. It includes two video configurations with normal speed, silent mode, and one video cut at 0.54 seconds.",
        "type": "summary"
    },
    "2140": {
        "file_id": 216,
        "content": "(\".mp4\", backend=\"editly\",\n    bgm=\"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.mp3\",\n    fast=true\n)\n# TODO: medialang lacks notes and texts, which might be useful for our video compilation.\n(\"/dev/shm/medialang/online/video_[giphy_gWkCsQZ4YlU1a]_[300x214].gif\",\n    video=true, slient=true, speed=1.043468,\n    cutFrom=0.0, cutTo=2.4\n)\n(\"/dev/shm/medialang/online/video_[giphy_2tNwXMxMpUAsiSbyck]_[480x270].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564027\n)\n(\"/dev/shm/medialang/online/video_[giphy_dTYI2Cu25gsTK]_[242x250].gif\",\n    video=true, slient=true, speed=1.006185,\n    cutFrom=0.0, cutTo=6.5\n)\n(\"/dev/shm/medialang/online/video_[giphy_5Y8xYjHG9AcjWlz23h]_[480x480].gif\",\n    video=true, slient=true, speed=0.997826,\n    cutFrom=0.0, cutTo=4.6\n)\n(\"/dev/shm/medialang/online/video_[giphy_iOGRWFLgGBRTxz7i22]_[270x480].gif\",\n    video=true, slient=true, speed=1.050456,\n    cutFrom=0.0, cutTo=10.2\n)\n(\"/dev/shm/medialang/online/video_[giphy_MB7AnGuoZ0ruqsFM1G]_[480x400].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:1-33"
    },
    "2141": {
        "file_id": 216,
        "content": "This code defines a series of video files with their properties such as file location, video settings (true/false), silence mode (true/false), playback speed, and time duration to be cut from the start and end. The code also mentions that there is a TODO task to add notes and texts to these videos for further use in video compilation.",
        "type": "comment"
    },
    "2142": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=0.934218,\n    cutFrom=0.0, cutTo=3.017544\n)\n(\"/dev/shm/medialang/online/video_[giphy_UuebWyG4pts3rboawU]_[480x480].gif\",\n    video=true, slient=true, speed=0.976488,\n    cutFrom=0.0, cutTo=5.4\n)\n(\"/dev/shm/medialang/online/video_[giphy_kOEYOwSaKbFra]_[350x197].gif\",\n    video=true, slient=true, speed=1.006486,\n    cutFrom=0.0, cutTo=9.3\n)\n(\"/dev/shm/medialang/online/video_[giphy_QGSEGsTr04bPW]_[450x254].gif\",\n    video=true, slient=true, speed=0.833326,\n    cutFrom=0.0, cutTo=2.3\n)\n(\"/dev/shm/medialang/online/video_[giphy_23kXtcba8igBvs8DQ1]_[400x225].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=11.076082\n)\n(\"/dev/shm/medialang/online/video_[giphy_ANWIS2HYfROI8]_[250x250].gif\",\n    video=true, slient=true, speed=1.04277,\n    cutFrom=0.0, cutTo=5.297297\n)\n(\"/dev/shm/medialang/online/video_[giphy_3oEduYITQ7uOYLPZjq]_[480x270].gif\",\n    video=true, slient=true, speed=0.981427,\n    cutFrom=0.0, cutTo=4.985673\n)\n(\"/dev/shm/medialang/online/video_[giphy_26BRGvcRTuqWhoLzW]_[320x320].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:34-68"
    },
    "2143": {
        "file_id": 216,
        "content": "This code is listing multiple video files stored in \"/dev/shm/medialang/online/\" directory. Each file has specific properties like speed, cutFrom, and cutTo timings set for possible processing or playback.",
        "type": "comment"
    },
    "2144": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=0.937354,\n    cutFrom=0.0, cutTo=5.192982\n)\n(\"/dev/shm/medialang/online/video_[giphy_S3KIhtDGjLKWbnwtrQ]_[480x270].gif\",\n    video=true, slient=true, speed=0.990204,\n    cutFrom=0.0, cutTo=7.08\n)\n(\"/dev/shm/medialang/online/video_[giphy_JPayEyQPRCUTe]_[245x177].gif\",\n    video=true, slient=true, speed=0.93862,\n    cutFrom=0.0, cutTo=2.6\n)\n(\"/dev/shm/medialang/online/video_[giphy_TGKnLbfAzkk3DDNt8K]_[320x480].gif\",\n    video=true, slient=true, speed=1.096676,\n    cutFrom=0.0, cutTo=5.066667\n)\n(\"/dev/shm/medialang/online/video_[giphy_3boPPdHk2ueo8]_[480x270].gif\",\n    video=true, slient=true, speed=1.079128,\n    cutFrom=0.0, cutTo=3.0\n)\n(\"/dev/shm/medialang/online/video_[giphy_UvvK8rOSHPxgjo9ryD]_[728x728].gif\",\n    video=true, slient=true, speed=0.999996,\n    cutFrom=0.0, cutTo=6.0\n)\n(\"/dev/shm/medialang/online/video_[giphy_3o6fJ9cQXux6wfA2BO]_[480x264].gif\",\n    video=true, slient=true, speed=0.987647,\n    cutFrom=0.0, cutTo=3.2\n)\n(\"/dev/shm/medialang/online/video_[giphy_OOTtmh8oXrFK5ccNU7]_[460x460].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:69-103"
    },
    "2145": {
        "file_id": 216,
        "content": "The code provides a list of video files along with their properties such as file path, speed and duration. The videos are stored in \"/dev/shm/medialang/online\" directory and have the \".gif\" extension. All videos have \"video=true\", indicating they are video files, and \"slient=true\", indicating no audio track is present. The duration of each video is specified using \"cutFrom\" and \"cutTo\".",
        "type": "comment"
    },
    "2146": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=1.018824,\n    cutFrom=0.0, cutTo=4.004\n)\n(\"/dev/shm/medialang/online/video_[giphy_Dcf2hNSaAiLV6]_[400x300].gif\",\n    video=true, slient=true, speed=0.987007,\n    cutFrom=0.0, cutTo=6.84\n)\n(\"/dev/shm/medialang/online/video_[giphy_yXBqba0Zx8S4]_[480x324].gif\",\n    video=true, slient=true, speed=0.976134,\n    cutFrom=0.0, cutTo=4.5\n)\n(\"/dev/shm/medialang/online/video_[giphy_bhSi84uFsp66s]_[354x306].gif\",\n    video=true, slient=true, speed=1.026876,\n    cutFrom=0.0, cutTo=4.733945\n)\n(\"/dev/shm/medialang/online/video_[giphy_NmGbJwLl7Y4lG]_[480x270].gif\",\n    video=true, slient=true, speed=0.96385,\n    cutFrom=0.0, cutTo=4.0\n)\n(\"/dev/shm/medialang/online/video_[giphy_FOL5mK0tXUmXe]_[450x254].gif\",\n    video=true, slient=true, speed=0.830318,\n    cutFrom=0.0, cutTo=2.3\n)\n(\"/dev/shm/medialang/online/video_[giphy_77vjJEy9IRqJW]_[303x476].gif\",\n    video=true, slient=true, speed=1.192301,\n    cutFrom=0.0, cutTo=4.96\n)\n(\"/dev/shm/medialang/online/video_[giphy_T7nRl5WHw7Yru]_[320x240].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:104-138"
    },
    "2147": {
        "file_id": 216,
        "content": "This code represents a list of video files along with their properties. Each entry in the list contains the file path, video settings (true/false for video and sound, speed), and cut duration details. The files are stored in \"/dev/shm/medialang/online/\" directory.",
        "type": "comment"
    },
    "2148": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=0.883147,\n    cutFrom=0.0, cutTo=3.25\n)\n(\"/dev/shm/medialang/online/video_[giphy_37R1oJeXReoJW]_[291x294].gif\",\n    video=true, slient=true, speed=1.010094,\n    cutFrom=0.0, cutTo=7.0\n)\n(\"/dev/shm/medialang/online/video_[giphy_3oz8xEFHNzQE3VIRCE]_[480x490].gif\",\n    video=true, slient=true, speed=1.010619,\n    cutFrom=0.0, cutTo=4.2042\n)\n(\"/dev/shm/medialang/online/video_[giphy_Bkcls2eA8Fc6A]_[480x480].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=10.692054\n)\n(\"/dev/shm/medialang/online/video_[giphy_11kgieHVYW53lC]_[480x360].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564027\n)\n(\"/dev/shm/medialang/online/video_[giphy_Ev17f0KeO9qkE]_[300x169].gif\",\n    video=true, slient=true, speed=0.817758,\n    cutFrom=0.0, cutTo=3.017544\n)\n(\"/dev/shm/medialang/online/video_[giphy_U7969wTwwtn6KBvEdA]_[384x480].gif\",\n    video=true, slient=true, speed=1.009003,\n    cutFrom=0.0, cutTo=3.733333\n)\n(\"/dev/shm/medialang/online/video_[giphy_IPUFTmRYZqG2s]_[480x270].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:139-173"
    },
    "2149": {
        "file_id": 216,
        "content": "This code contains a list of video file paths along with their properties such as whether they are silent, the playback speed, and the time duration to play.",
        "type": "comment"
    },
    "2150": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=0.973326,\n    cutFrom=0.0, cutTo=5.84\n)\n(\"/dev/shm/medialang/online/video_[giphy_hNRA4W7qJnbpK]_[389x415].gif\",\n    video=true, slient=true, speed=1.15384,\n    cutFrom=0.0, cutTo=4.8\n)\n(\"/dev/shm/medialang/online/video_[giphy_Ul2rAQJqNXp9S]_[400x225].gif\",\n    video=true, slient=true, speed=0.963845,\n    cutFrom=0.0, cutTo=4.0\n)\n(\"/dev/shm/medialang/online/video_[giphy_4MXO2o9MbPBi6M79G6]_[480x270].gif\",\n    video=true, slient=true, speed=0.99367,\n    cutFrom=0.0, cutTo=3.666667\n)\n(\"/dev/shm/medialang/online/video_[giphy_HC995u2L4I7mg]_[300x169].gif\",\n    video=true, slient=true, speed=0.817758,\n    cutFrom=0.0, cutTo=3.017544\n)\n(\"/dev/shm/medialang/online/video_[giphy_i0lkOcXmpcE92]_[400x225].gif\",\n    video=true, slient=true, speed=1.054048,\n    cutFrom=0.0, cutTo=3.9\n)\n(\"/dev/shm/medialang/online/video_[giphy_QxqqwXQuSWufNazWWU]_[448x450].gif\",\n    video=true, slient=true, speed=0.86666,\n    cutFrom=0.0, cutTo=5.2\n)\n(\"/dev/shm/medialang/online/video_[giphy_XlNkepH9WJO3C]_[245x160].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:174-208"
    },
    "2151": {
        "file_id": 216,
        "content": "The code contains a list of video files and their respective details, including file path, video settings (true/false), silent status (true/false), playback speed, and cut duration.",
        "type": "comment"
    },
    "2152": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=0.975598,\n    cutFrom=0.0, cutTo=3.6\n)\n(\"/dev/shm/medialang/online/video_[giphy_cEPFSJokR4hzi]_[480x270].gif\",\n    video=true, slient=true, speed=1.031923,\n    cutFrom=0.0, cutTo=8.08\n)\n(\"/dev/shm/medialang/online/video_[giphy_ghHZVf7kK9379nbcuh]_[442x468].gif\",\n    video=true, slient=true, speed=0.969893,\n    cutFrom=0.0, cutTo=3.578947\n)\n(\"/dev/shm/medialang/online/video_[giphy_5t7AJfJQnmsP5Tm1QS]_[480x480].gif\",\n    video=true, slient=true, speed=1.042304,\n    cutFrom=0.0, cutTo=6.733333\n)\n(\"/dev/shm/medialang/online/video_[giphy_x42zjj678Sr6M]_[420x241].gif\",\n    video=true, slient=true, speed=1.071709,\n    cutFrom=0.0, cutTo=7.92\n)\n(\"/dev/shm/medialang/online/video_[giphy_wBQa0CjlSySUE]_[320x180].gif\",\n    video=true, slient=true, speed=1.005696,\n    cutFrom=0.0, cutTo=8.82\n)\n(\"/dev/shm/medialang/online/video_[giphy_fJdpdS5jaDje8]_[361x194].gif\",\n    video=true, slient=true, speed=0.882244,\n    cutFrom=0.0, cutTo=5.302326\n)\n(\"/dev/shm/medialang/online/video_[giphy_IT4fLZjxyDu24]_[720x540].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:209-243"
    },
    "2153": {
        "file_id": 216,
        "content": "The code defines a list of video files with their respective parameters such as file path, video status, silent status, speed adjustment, and duration. These videos are stored in the \"/dev/shm/medialang/online\" directory and have different dimensions and durations.",
        "type": "comment"
    },
    "2154": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=0.83194,\n    cutFrom=0.0, cutTo=5.0\n)\n(\"/dev/shm/medialang/online/video_[giphy_q9ETKoMaBMsNy]_[300x300].gif\",\n    video=true, slient=true, speed=0.956076,\n    cutFrom=0.0, cutTo=6.16\n)\n(\"/dev/shm/medialang/online/video_[giphy_lQI2sf2qserJsrixfw]_[270x480].gif\",\n    video=true, slient=true, speed=0.992241,\n    cutFrom=0.0, cutTo=6.4\n)\n(\"/dev/shm/medialang/online/video_[giphy_MOgAd5Z2LZRHW]_[338x254].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564\n)\n(\"/dev/shm/medialang/online/video_[giphy_GSsTZNQjPvl1m]_[500x377].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.564\n)\n(\"/dev/shm/medialang/online/video_[giphy_pCyN4mn4MbGCY]_[306x215].gif\",\n    video=true, slient=true, speed=0.984554,\n    cutFrom=0.0, cutTo=7.266055\n)\n(\"/dev/shm/medialang/online/video_[giphy_czpet1H4pnyAE]_[208x296].gif\",\n    video=true, slient=true, speed=1.074398,\n    cutFrom=0.0, cutTo=7.93985\n)\n(\"/dev/shm/medialang/online/video_[giphy_WhCYptDg5hgIg]_[181x180].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:244-278"
    },
    "2155": {
        "file_id": 216,
        "content": "The code provides information about different videos, including their file paths and details such as video and silent settings, playback speeds, and specific cut durations.",
        "type": "comment"
    },
    "2156": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=1.017585,\n    cutFrom=0.0, cutTo=7.52\n)\n(\"/dev/shm/medialang/online/video_[giphy_pytb6SgEJuPGE]_[250x246].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=10.512054\n)\n(\"/dev/shm/medialang/online/video_[giphy_zUdFehNEYEMFi]_[406x293].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=10.500082\n)\n(\"/dev/shm/medialang/online/video_[giphy_1xl9CXjjK64iFItin7]_[480x480].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.552\n)\n(\"/dev/shm/medialang/online/video_[giphy_1WbITXJruDYLgYPPgy]_[400x480].gif\",\n    video=true, slient=true, speed=1.174338,\n    cutFrom=0.0, cutTo=8.666667\n)\n(\"/dev/shm/medialang/online/video_[giphy_l1Joh6GmLESwGYjmw]_[480x352].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.552\n)\n(\"/dev/shm/medialang/online/video_[giphy_9EcYmq8ofAAkbIlooc]_[480x480].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.552\n)\n(\"/dev/shm/medialang/online/video_[giphy_PdSfuPb8ZGV9P2w5IP]_[384x480].gif\",",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:279-313"
    },
    "2157": {
        "file_id": 216,
        "content": "The code defines a list of video files along with their properties like video and silent status, speed, and cut duration. Each file is identified by its path and has the extension \".gif\". The video files are stored in the \"/dev/shm/medialang/online/\" directory.",
        "type": "comment"
    },
    "2158": {
        "file_id": 216,
        "content": "    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.552\n)\n(\"/dev/shm/medialang/online/video_[giphy_JQL87nbjGPYL52tCvF]_[270x480].gif\",\n    video=true, slient=true, speed=1.2,\n    cutFrom=0.0, cutTo=0.54\n)",
        "type": "code",
        "location": "/tests/dog_cat_demo_not_for_test.mdl:314-321"
    },
    "2159": {
        "file_id": 216,
        "content": "The code represents two video configurations with the following attributes:\n1. Both videos are set to play at normal speed (speed=1.2) and silent mode (silent=true).\n2. The first video will be played entirely, while the second video's duration will end at 0.54 seconds from the start (cutFrom=0.0, cutTo=0.54).",
        "type": "comment"
    },
    "2160": {
        "file_id": 217,
        "content": "/tests/check_json_update.py",
        "type": "filepath"
    },
    "2161": {
        "file_id": 217,
        "content": "The code imports necessary modules and defines a dictionary called mdict. It then prints the original dictionary, applies a JSON update operation on the \"b\" key within the \"a\" list, and finally prints the updated result.",
        "type": "summary"
    },
    "2162": {
        "file_id": 217,
        "content": "from test_commons import *\nfrom pyjom.commons import jsonUpdate\nmdict = {\"a\": [1, 2, 3, {\"b\": [4, 5]}]}\nprint(\"ORIGINAL:\", mdict)\njsonUpdate(mdict, [\"a\", 3, \"b\", 0], 2)\nprint(\"RESULT:\", mdict)",
        "type": "code",
        "location": "/tests/check_json_update.py:1-7"
    },
    "2163": {
        "file_id": 217,
        "content": "The code imports necessary modules and defines a dictionary called mdict. It then prints the original dictionary, applies a JSON update operation on the \"b\" key within the \"a\" list, and finally prints the updated result.",
        "type": "comment"
    },
    "2164": {
        "file_id": 218,
        "content": "/tests/audio_volume_meter/test_volume_meter.py",
        "type": "filepath"
    },
    "2165": {
        "file_id": 218,
        "content": "This code calculates audio parameters, generates vocal slices, and clusters segments using KMeans for labeling. It merges adjacent segments with similar labels and stores the updated labels.",
        "type": "summary"
    },
    "2166": {
        "file_id": 218,
        "content": "# usually yelling is not always funny. but we can do speech to text. taking longer time though... pinpoint the cue time.\n# often some exclamation attempts like repetation or louder sounds.\naudio_src = \"/media/root/help/pyjom/samples/audio/dog_with_text/vocals.wav\"\n# heard of dog woooling.\n# import audioop\nimport pydub\ntimestep = 0.1  # my time setting.\naudiofile = pydub.AudioSegment.from_wav(audio_src)\nframe_rate = audiofile.frame_rate\nseconds = audiofile.duration_seconds\nprint(frame_rate)  # 44100.\nprint(seconds)  # sample length\nimport math\nimport numpy as np\nfrom talib import stream\n# frame_rate2 = frame_rate *timestep\nmilistep = 1000 * timestep\nma_step = 10  # one second of buffer size. or more. timeperiod=ma_step\nstd_arr, maxval_arr, abs_nonzero_arr = [], [], []\ndef getPaddingMovingAverage(myarray, timeperiod=10):\n    lt = math.ceil(timeperiod / 2)\n    rt = timeperiod - lt\n    len_myarray = len(myarray)\n    max_index = len_myarray - 1\n    result_array = []\n    for i in range(len_myarray):\n        start_index = i - lt",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:1-37"
    },
    "2167": {
        "file_id": 218,
        "content": "Code imports PyDub, sets timestep and frame rate variables from audio file duration and frame rate. Imports math, numpy and talib.stream. Defines function getPaddingMovingAverage to calculate moving average with padding, taking an array and time period as parameters. Initializes std_arr, maxval_arr and abs_nonzero_arr lists for further calculations.",
        "type": "comment"
    },
    "2168": {
        "file_id": 218,
        "content": "        start_index = max(0, start_index)\n        end_index = i + rt\n        end_index = min(end_index, max_index)\n        array_slice = myarray[start_index:end_index]\n        arr_slice_length = end_index - start_index\n        val = sum(array_slice) / arr_slice_length\n        # val = np.median(array_slice)\n        result_array.append(val)\n    return result_array\nmsteps = math.ceil(seconds / timestep)\nfor i in range(msteps):\n    # print(frame_rate2)\n    # probably in miliseconds.\n    segment = audiofile[i * milistep : (i + 1) * milistep]\n    data = segment.get_array_of_samples()\n    # containes two channels. 4410*2\n    darray = np.array(data)\n    print(darray.shape)\n    std = np.std(darray)\n    abs_darray = abs(darray)\n    maxval = np.max(abs_darray)\n    abs_nonzero = np.average(abs_darray)\n    print(\"STD:{} MAX:{} AVG:{}\".format(std, maxval, abs_nonzero))\n    std_arr.append(std)\n    # ma_std = stream.SMA(np.array(std_arr[-ma_step:]).astype(np.float64))\n    maxval_arr.append(maxval)\n    # ma_maxval = stream.SMA(np.array(maxval_arr[-ma_step:]).astype(np.float64))",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:38-67"
    },
    "2169": {
        "file_id": 218,
        "content": "This code calculates the standard deviation, maximum value, and average of absolute values for a given audio segment. It appends the calculated values to respective lists and potentially calculates moving averages. The code utilizes numpy functions for array processing and the SMA function from the stream module (possibly) for calculating moving averages.",
        "type": "comment"
    },
    "2170": {
        "file_id": 218,
        "content": "    abs_nonzero_arr.append(abs_nonzero)\n    # ma_abs_nonzero = stream.SMA(np.array(abs_nonzero_arr[-ma_step:]).astype(np.float64))\n    # breakpoint()\n    # print(\"MA_STD:{} MA_MAX:{} MA_AVG:{}\".format(ma_std,ma_maxval,ma_abs_nonzero))\n    # print(data)\n    # breakpoint()\n    # maxAudioValue =audioop.max(data,2)\n    # print(\"STEP:\",i,\"VOLUME:\",maxAudioValue)\nstd_arr0 = getPaddingMovingAverage(std_arr, timeperiod=20)\nmaxval_arr0 = getPaddingMovingAverage(maxval_arr, timeperiod=20)\nabs_nonzero_arr0 = getPaddingMovingAverage(abs_nonzero_arr, timeperiod=20)\nma_std_arr = getPaddingMovingAverage(std_arr, timeperiod=60)\nma_maxval_arr = getPaddingMovingAverage(maxval_arr, timeperiod=60)\nma_abs_nonzero_arr = getPaddingMovingAverage(abs_nonzero_arr, timeperiod=60)\n# just use one freaking example as my conclusion.\nstatus = \"end\"\nvocal_slices = []\nvocal_slice = []\nfinal_index = msteps - 1\n# could you use clustering.\n# like time versus duration.\navg_std = []\nfor i in range(msteps):\n    a, b, c = std_arr0[i], maxval_arr0[i], abs_nonzero_arr0[i]",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:68-92"
    },
    "2171": {
        "file_id": 218,
        "content": "This code calculates the moving average for various audio parameters (std_arr, maxval_arr, and abs_nonzero_arr) over different time periods. It then generates a vocal slice based on these moving averages for each step in the range of msteps. The final index is set to be one less than the total number of steps, and an average list is created.",
        "type": "comment"
    },
    "2172": {
        "file_id": 218,
        "content": "    a0, b0, c0 = ma_std_arr[i], ma_maxval_arr[i], ma_abs_nonzero_arr[i]\n    if status == \"end\":\n        # startpoint = a0 < a\n        startpoint = a0 < a or b0 < b or c0 < c\n        if startpoint:\n            vocal_slice.append(i)\n            avg_std.append(a)\n            status = \"start\"\n    else:\n        avg_std.append(a)\n        # endpoint = a0 > a\n        endpoint = a0 > a and b0 > b and c0 > c\n        if endpoint:\n            vocal_slice.append(i)\n            # vocal_slice[1] = i\n            status = \"end\"\n            vocal_slices.append([vocal_slice, np.average(avg_std)])\n            vocal_slice = []\n            avg_std = []\nif len(vocal_slice) == 1:\n    vocal_slice.append(final_index)\n    vocal_slices.append([vocal_slice, np.average(avg_std)])\ntime_rate = timestep\ntimed_vocal_slices = [\n    [[x[0][0] * time_rate, x[0][1] * time_rate], x[1]] for x in vocal_slices\n]\nd2_data = []\nd1_data = []\nfor slice_vocal in timed_vocal_slices:\n    print(slice_vocal)  # it could be two dimentional. both for length and volume?",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:93-123"
    },
    "2173": {
        "file_id": 218,
        "content": "The code is iterating through an array of data and dividing it into segments based on threshold values for average, maximum, and absolute non-zero values. These segments are classified as either \"start\" or \"end\", and the indices of the start and end points are stored in separate lists. If a segment only has one point, it is added to the list of vocal slices along with the average of the threshold values. The code then calculates the time rate and creates two-dimensional lists of timed vocal slices (segment start and end times), and data for d1 and d2. Finally, the code prints the timed vocal slices, which could be in a two-dimensional format representing length and volume.",
        "type": "comment"
    },
    "2174": {
        "file_id": 218,
        "content": "    # to find best shit you need grouping.\n    a, b = slice_vocal[0]\n    length = b - a\n    d2_data.append([length, slice_vocal[1]])\n    d1_data.append([slice_vocal[1]])\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2)\nkm = kmeans.fit(d1_data)\nlabels = km.labels_\nlabel_indexs = {i: labels[i] for i in range(len(labels))}\n# print(label_index)\nnew_labels = []\nmergeTimeGap = 0.5\nlb_new = 0\nlast_elem = None\nfor index, data in enumerate(timed_vocal_slices):\n    # data = timed_vocal_slices\n    [start, end], std = data\n    label = label_indexs[index]\n    if last_elem == None:\n        last_elem = [[start, end], label]\n    else:\n        [[last_start, last_end], last_label] = last_elem\n        if start - last_end < mergeTimeGap and last_label == label:\n            pass\n            # last_elem = [[start,end],label]\n        else:\n            lb_new += 1\n        last_elem = [[start, end], label]\n    new_labels.append(lb_new)\n    print(\"DATA:\", data, \"LABEL:\", label, \"NEW_LABEL:\", lb_new)",
        "type": "code",
        "location": "/tests/audio_volume_meter/test_volume_meter.py:124-157"
    },
    "2175": {
        "file_id": 218,
        "content": "This code is grouping vocal segments based on their start and end timestamps. It uses KMeans clustering from sklearn to assign labels to each segment, then merges adjacent segments with the same label if they are less than a certain time gap apart. The new_labels list stores the updated labels for each segment.",
        "type": "comment"
    },
    "2176": {
        "file_id": 219,
        "content": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/test.py",
        "type": "filepath"
    },
    "2177": {
        "file_id": 219,
        "content": "This code fetches and tests proxies, sets up a connection gateway, makes a GET request to \"https://deepl.com\" using the valid proxy, prints first 100 bytes and status code, and displays \"deepl response\".",
        "type": "summary"
    },
    "2178": {
        "file_id": 219,
        "content": "# from download_from_multiple_websites_at_once import concurrentGet\nfrom lazero.network.proxy.clash import (\n    getProxyList,\n    testProxyList,\n    getConnectionGateway,\n    setProxyConfig,\n    setProxyWithSelector,\n)\nimport requests\nif __name__ == \"__main__\":\n    # validProxyDelayList = []\n    proxyList = getProxyList(debug=True)\n    # pprint.pprint(result)\n    validProxyDelayList = testProxyList(proxyList, timeout=5000)\n    #     pprint(gateway)\n    #     {'allow-lan': True,\n    #  'authentication': [],\n    #  'bind-address': '*',\n    #  'ipv6': False,\n    #  'log-level': 'info',\n    #  'mixed-port': 0,\n    #  'mode': 'rule',\n    #  'port': 8381,\n    #  'redir-port': 0,\n    #  'socks-port': 0,\n    #  'tproxy-port': 0}\n    gateway = getConnectionGateway()\n    print(\"valid proxies:\", len(validProxyDelayList))\n    validProxyName = validProxyDelayList[0][\"name\"]\n    # if no valid proxy, better do another run.\n    setProxyConfig(mode=\"Global\")\n    # you can switch to 'Rule' if you want the baidu translation\n    setProxyWithSelector(validProxyName, debug=True)",
        "type": "code",
        "location": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/test.py:1-34"
    },
    "2179": {
        "file_id": 219,
        "content": "This code fetches the proxy list from Clash, tests the proxies for validity, sets up a connection gateway, and configures the global proxy using Clash's functions. It prints the number of valid proxies found and sets a specific valid proxy for further use.",
        "type": "comment"
    },
    "2180": {
        "file_id": 219,
        "content": "    # now use the proxy!\n    r = requests.get(\"https://deepl.com\", proxies={\"http\": gateway, \"https\": gateway})\n    print()\n    print(r.content[:100])\n    print(r.status_code)\n    print(\"deepl response\")",
        "type": "code",
        "location": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/test.py:35-40"
    },
    "2181": {
        "file_id": 219,
        "content": "Using the proxy, make a GET request to \"https://deepl.com\", print the first 100 bytes of response content and status code, then display \"deepl response\".",
        "type": "comment"
    },
    "2182": {
        "file_id": 220,
        "content": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/download_from_multiple_websites_at_once.py",
        "type": "filepath"
    },
    "2183": {
        "file_id": 220,
        "content": "This code imports the \"concurrentGet\" function from the \"lzero.network.asyncio\" module, which allows for making concurrent HTTP GET requests asynchronously.",
        "type": "summary"
    },
    "2184": {
        "file_id": 220,
        "content": "from lazero.network.asyncio import concurrentGet",
        "type": "code",
        "location": "/tests/aiohttp_python_clash_delay_proxy_set_proxy/download_from_multiple_websites_at_once.py:1-1"
    },
    "2185": {
        "file_id": 220,
        "content": "This code imports the \"concurrentGet\" function from the \"lzero.network.asyncio\" module, which allows for making concurrent HTTP GET requests asynchronously.",
        "type": "comment"
    },
    "2186": {
        "file_id": 221,
        "content": "/tests/basic_pitch_multi_midi_conversion/test.sh",
        "type": "filepath"
    },
    "2187": {
        "file_id": 221,
        "content": "Creates a new folder called \"output_path\", then uses the 'basic-pitch' command to convert MIDI files from \"/media/root/help/pyjom/tests/bilibili_practices/bilibili_tarot/some_bgm.mp3\" into audio format, saving them in the newly created folder.",
        "type": "summary"
    },
    "2188": {
        "file_id": 221,
        "content": "mkdir output_path\nbasic-pitch --sonify-midi output_path /media/root/help/pyjom/tests/bilibili_practices/bilibili_tarot/some_bgm.mp3",
        "type": "code",
        "location": "/tests/basic_pitch_multi_midi_conversion/test.sh:1-2"
    },
    "2189": {
        "file_id": 221,
        "content": "Creates a new folder called \"output_path\", then uses the 'basic-pitch' command to convert MIDI files from \"/media/root/help/pyjom/tests/bilibili_practices/bilibili_tarot/some_bgm.mp3\" into audio format, saving them in the newly created folder.",
        "type": "comment"
    },
    "2190": {
        "file_id": 222,
        "content": "/tests/cpm_chinese_chitchat_model_gpt2/test.sh",
        "type": "filepath"
    },
    "2191": {
        "file_id": 222,
        "content": "This code changes the directory to GPT2-chitchat, checks RAM consumption and urges to buy new RAM for CPU model testing. It runs 'interact.py' with no CUDA and using a specific model path.",
        "type": "summary"
    },
    "2192": {
        "file_id": 222,
        "content": "# no fucking gpu. just test how much RAM it consumes.\ncd GPT2-chitchat # 1.8GB mem consumption. freaking hell.\n# BUY NEW RAM AND RUN MODELS ON CPU!\npython3 interact.py --no_cuda --model_path ../model",
        "type": "code",
        "location": "/tests/cpm_chinese_chitchat_model_gpt2/test.sh:1-4"
    },
    "2193": {
        "file_id": 222,
        "content": "This code changes the directory to GPT2-chitchat, checks RAM consumption and urges to buy new RAM for CPU model testing. It runs 'interact.py' with no CUDA and using a specific model path.",
        "type": "comment"
    },
    "2194": {
        "file_id": 223,
        "content": "/tests/cpm_chinese_chitchat_model_gpt2/init.sh",
        "type": "filepath"
    },
    "2195": {
        "file_id": 223,
        "content": "Code is cloning the GPT2-chitchat repository with a single commit from GitHub.",
        "type": "summary"
    },
    "2196": {
        "file_id": 223,
        "content": "git clone --depth 1 https://github.com/yangjianxin1/GPT2-chitchat",
        "type": "code",
        "location": "/tests/cpm_chinese_chitchat_model_gpt2/init.sh:1-1"
    },
    "2197": {
        "file_id": 223,
        "content": "Code is cloning the GPT2-chitchat repository with a single commit from GitHub.",
        "type": "comment"
    },
    "2198": {
        "file_id": 224,
        "content": "/tests/conversation_talk_apis/api_tests.py",
        "type": "filepath"
    },
    "2199": {
        "file_id": 224,
        "content": "This code imports modules, disables proxies, and uses requests library to send POST requests to Weibo API's direct messaging endpoint. It creates and sends messages, retrieves responses in JSON format, interacts with Weibo and OwnThink APIs, checks user messages against responses, performs API tests using checkApi function for different chatbot instances.",
        "type": "summary"
    }
}