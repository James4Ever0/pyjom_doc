{
    "4700": {
        "file_id": 613,
        "content": "                    \"width\": up_image_width,  # float numbers.\n                    \"height\": up_image_height,\n                },\n            ],\n        },\n        {\"duration\": 0.5, \"layers\": [{\"type\": \"fill-color\", \"color\": \"#000000\"}]},\n    ],\n}\nfrom lazero.filesystem.io import writeJsonObjectToFile\nwriteJsonObjectToFile(template_name, editlyJson)\nimport subprocess\n# use xvfb you SOB\ncommand = [\n    \"xvfb-run\",\n    \"editly\",\n    template_name,\n]  # no need to specify --out outputPath here\nsubprocess.run(command)",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/create_sample_video_with_fade_and_metadata.py:87-108"
    },
    "4701": {
        "file_id": 613,
        "content": "Code writes a JSON object for Editly video template, saves it to file, and runs the Editly software using subprocess with xvfb.",
        "type": "comment"
    },
    "4702": {
        "file_id": 614,
        "content": "/tests/bilibili_video_recommendation_server/sample_video/tts.py",
        "type": "filepath"
    },
    "4703": {
        "file_id": 614,
        "content": "This Python script converts text to speech using argparse, argues SSML input, and connects to Microsoft Cognitive Services TTS endpoint. It also handles time fixes, timestamps, and async WebSocket communication with potential API key authentication, runs on an asyncio event loop, and writes audio responses to a file.",
        "type": "summary"
    },
    "4704": {
        "file_id": 614,
        "content": "# 来源 https://github.com/OS984/DiscordBotBackend/blob/3b06b8be39e4dbc07722b0afefeee4c18c136102/NeuralTTS.py\n# A completely innocent attempt to borrow proprietary Microsoft technology for a much better TTS experience\nimport requests\nimport websockets\nimport asyncio\nfrom datetime import datetime\nimport time\nimport re\nimport uuid\nimport argparse\n'''命令行参数解析'''\ndef parseArgs():\n    parser = argparse.ArgumentParser(description='text2speech')\n    parser.add_argument('--input', dest='input', help='SSML(语音合成标记语言)的路径', type=str, required=True)\n    parser.add_argument('--output', dest='output', help='保存mp3文件的路径', type=str, required=False)\n    args = parser.parse_args()\n    return args\n# Fix the time to match Americanisms\ndef hr_cr(hr):\n    corrected = (hr - 1) % 24\n    return str(corrected)\n# Add zeros in the right places i.e 22:1:5 -> 22:01:05\ndef fr(input_string):\n    corr = ''\n    i = 2 - len(input_string)\n    while (i > 0):\n        corr += '0'\n        i -= 1\n    return corr + input_string\n# Generate X-Timestamp all correctly formatted",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:1-35"
    },
    "4705": {
        "file_id": 614,
        "content": "This code is a Python file that utilizes the `argparse` library to parse command-line arguments. The purpose of this script seems to be text-to-speech conversion, where it accepts an SSML (Speech Synthesis Markup Language) input file and outputs an MP3 audio file. It also includes functions for fixing time formats to match American conventions and generating formatted timestamps.",
        "type": "comment"
    },
    "4706": {
        "file_id": 614,
        "content": "def getXTime():\n    now = datetime.now()\n    return fr(str(now.year)) + '-' + fr(str(now.month)) + '-' + fr(str(now.day)) + 'T' + fr(hr_cr(int(now.hour))) + ':' + fr(str(now.minute)) + ':' + fr(str(now.second)) + '.' + str(now.microsecond)[:3] + 'Z'\n# Async function for actually communicating with the websocket\nasync def transferMsTTSData(SSML_text, outputPath):\n    # endpoint1 = \"https://azure.microsoft.com/en-gb/services/cognitive-services/text-to-speech/\"\n    # r = requests.get(endpoint1)\n    # main_web_content = r.text\n    # # They hid the Auth key assignment for the websocket in the main body of the webpage....\n    # token_expr = re.compile('token: \\\"(.*?)\\\"', re.DOTALL)\n    # Auth_Token = re.findall(token_expr, main_web_content)[0]\n    # req_id = str('%032x' % random.getrandbits(128)).upper()\n    # req_id is generated by uuid.\n    req_id = uuid.uuid4().hex.upper()\n    print(req_id)\n    # wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId=577D1E595EEB45979BA26C056A519073",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:36-52"
    },
    "4707": {
        "file_id": 614,
        "content": "This code defines two functions: `getXTime` and `transferMsTTSData`. The `getXTime` function returns the current date and time in a specific format. The `transferMsTTSData` function is an asynchronous function responsible for communicating with a WebSocket endpoint, potentially using an API key to authenticate the request. It generates a unique ID (req_id) and prints it before potentially making the WebSocket connection.",
        "type": "comment"
    },
    "4708": {
        "file_id": 614,
        "content": "    # endpoint2 = \"wss://eastus.tts.speech.microsoft.com/cognitiveservices/websocket/v1?Authorization=\" + \\\n    #     Auth_Token + \"&X-ConnectionId=\" + req_id\n    # 目前该接口没有认证可能很快失效\n    endpoint2 = f\"wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId={req_id}\"\n    async with websockets.connect(endpoint2) as websocket:\n        payload_1 = '{\"context\":{\"system\":{\"name\":\"SpeechSDK\",\"version\":\"1.12.1-rc.1\",\"build\":\"JavaScript\",\"lang\":\"JavaScript\",\"os\":{\"platform\":\"Browser/Linux x86_64\",\"name\":\"Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0\",\"version\":\"5.0 (X11)\"}}}}'\n        message_1 = 'Path : speech.config\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/json\\r\\n\\r\\n' + payload_1\n        await websocket.send(message_1)\n        payload_2 = '{\"synthesis\":{\"audio\":{\"metadataOptions\":{\"sentenceBoundaryEnabled\":false,\"wordBoundaryEnabled\":false},\"outputFormat\":\"audio-16khz-32kbitrate-mono-mp3\"}}}'",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:53-63"
    },
    "4709": {
        "file_id": 614,
        "content": "This code connects to the Microsoft Cognitive Services TTS (Text-to-Speech) websocket endpoint, sends two payloads for speech synthesis, and sets various headers such as Authorization, X-ConnectionId, Content-Type, etc. The current authentication may expire soon, so a new temporary endpoint is used instead of the original one.",
        "type": "comment"
    },
    "4710": {
        "file_id": 614,
        "content": "        message_2 = 'Path : synthesis.context\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/json\\r\\n\\r\\n' + payload_2\n        await websocket.send(message_2)\n        # payload_3 = '<speak xmlns=\"http://www.w3.org/2001/10/synthesis\" xmlns:mstts=\"http://www.w3.org/2001/mstts\" xmlns:emo=\"http://www.w3.org/2009/10/emotionml\" version=\"1.0\" xml:lang=\"en-US\"><voice name=\"' + voice + '\"><mstts:express-as style=\"General\"><prosody rate=\"'+spd+'%\" pitch=\"'+ptc+'%\">'+ msg_content +'</prosody></mstts:express-as></voice></speak>'\n        payload_3 = SSML_text\n        message_3 = 'Path: ssml\\r\\nX-RequestId: ' + req_id + '\\r\\nX-Timestamp: ' + \\\n            getXTime() + '\\r\\nContent-Type: application/ssml+xml\\r\\n\\r\\n' + payload_3\n        await websocket.send(message_3)\n        # Checks for close connection message\n        end_resp_pat = re.compile('Path:turn.end')\n        audio_stream = b''\n        while(True):\n            response = await websocket.recv()",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:64-78"
    },
    "4711": {
        "file_id": 614,
        "content": "Sends text to TTS service for synthesis and awaits response. Stores the SSML XML for audio customization. Sends SSML XML payload for final audio output generation. Continuously receives response from websocket until 'turn.end' path detected, storing data in audio_stream variable.",
        "type": "comment"
    },
    "4712": {
        "file_id": 614,
        "content": "            print('receiving...')\n            # Make sure the message isn't telling us to stop\n            if (re.search(end_resp_pat, str(response)) == None):\n                # Check if our response is text data or the audio bytes\n                if type(response) == type(bytes()):\n                    # Extract binary data\n                    try:\n                        needle = b'Path:audio\\r\\n'\n                        start_ind = response.find(needle) + len(needle)\n                        audio_stream += response[start_ind:]\n                    except:\n                        pass\n            else:\n                break\n        with open(f'{outputPath}.mp3', 'wb') as audio_out:\n            audio_out.write(audio_stream)\nasync def mainSeq(SSML_text, outputPath):\n    await transferMsTTSData(SSML_text, outputPath)\ndef get_SSML(path):\n    with open(path,'r',encoding='utf-8') as f:\n        return f.read()\nif __name__ == \"__main__\":\n    args = parseArgs()\n    SSML_text = get_SSML(args.input)\n    output_path = args.output if args.output else 'output_'+ str(int(time.time()*1000))",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:79-107"
    },
    "4713": {
        "file_id": 614,
        "content": "This code snippet is a part of a TTS (Text-to-Speech) server implementation. It receives an audio response from the server, checks if it's text or binary data, and writes the audio to a file. The `mainSeq` function initiates the transfer process by calling `transferMsTTSData` function with SSML text and output path. The `get_SSML` function reads SSML text from input file. The code is run as a main program after parsing command-line arguments using `parseArgs()`.",
        "type": "comment"
    },
    "4714": {
        "file_id": 614,
        "content": "    asyncio.get_event_loop().run_until_complete(mainSeq(SSML_text, output_path))\n    print('completed')\n    # python tts.py --input SSML.xml\n    # python tts.py --input SSML.xml --output 保存文件名",
        "type": "code",
        "location": "/tests/bilibili_video_recommendation_server/sample_video/tts.py:108-111"
    },
    "4715": {
        "file_id": 614,
        "content": "This code calls the `mainSeq` function with SSML text and output path, using asyncio event loop to run until completion. It prints \"completed\" upon execution. The two command examples show how to input an SSML file and optionally specify an output filename.",
        "type": "comment"
    },
    "4716": {
        "file_id": 615,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/viewRenderResult.sh",
        "type": "filepath"
    },
    "4717": {
        "file_id": 615,
        "content": "This code is creating a shell script named \"viewer.sh\" which lists the output files and runs \"ffplay\" on each file in sequence, with a 3-second pause between them. It then executes this script using bash to display the output files sequentially.",
        "type": "summary"
    },
    "4718": {
        "file_id": 615,
        "content": "ls -1 output | awk '{print \"ffplay -i output/\"$1\" -autoexit; sleep 3\" }' > viewer.sh\nbash viewer.sh",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/viewRenderResult.sh:1-2"
    },
    "4719": {
        "file_id": 615,
        "content": "This code is creating a shell script named \"viewer.sh\" which lists the output files and runs \"ffplay\" on each file in sequence, with a 3-second pause between them. It then executes this script using bash to display the output files sequentially.",
        "type": "comment"
    },
    "4720": {
        "file_id": 616,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/viewer.sh",
        "type": "filepath"
    },
    "4721": {
        "file_id": 616,
        "content": "The code utilizes ffplay to sequentially play FLV files with a 3-second delay between each, then exits.",
        "type": "summary"
    },
    "4722": {
        "file_id": 616,
        "content": "ffplay -i output/0.flv -autoexit; sleep 3\nffplay -i output/10.flv -autoexit; sleep 3\nffplay -i output/11.flv -autoexit; sleep 3\nffplay -i output/12.flv -autoexit; sleep 3\nffplay -i output/13.flv -autoexit; sleep 3\nffplay -i output/14.flv -autoexit; sleep 3\nffplay -i output/15.flv -autoexit; sleep 3\nffplay -i output/16.flv -autoexit; sleep 3\nffplay -i output/17.flv -autoexit; sleep 3\nffplay -i output/19.flv -autoexit; sleep 3\nffplay -i output/1.flv -autoexit; sleep 3\nffplay -i output/20.flv -autoexit; sleep 3\nffplay -i output/21.flv -autoexit; sleep 3\nffplay -i output/22.flv -autoexit; sleep 3\nffplay -i output/23.flv -autoexit; sleep 3\nffplay -i output/24.flv -autoexit; sleep 3\nffplay -i output/25.flv -autoexit; sleep 3\nffplay -i output/26.flv -autoexit; sleep 3\nffplay -i output/27.flv -autoexit; sleep 3\nffplay -i output/28.flv -autoexit; sleep 3\nffplay -i output/29.flv -autoexit; sleep 3\nffplay -i output/2.flv -autoexit; sleep 3\nffplay -i output/30.flv -autoexit; sleep 3\nffplay -i output/31.flv -autoexit; sleep 3",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/viewer.sh:1-24"
    },
    "4723": {
        "file_id": 616,
        "content": "This code uses ffplay to sequentially play videos from \"output/0.flv\" to \"output/31.flv\" with a 3-second delay between each video, then exits.",
        "type": "comment"
    },
    "4724": {
        "file_id": 616,
        "content": "ffplay -i output/35.flv -autoexit; sleep 3\nffplay -i output/38.flv -autoexit; sleep 3\nffplay -i output/39.flv -autoexit; sleep 3\nffplay -i output/3.flv -autoexit; sleep 3\nffplay -i output/40.flv -autoexit; sleep 3\nffplay -i output/4.flv -autoexit; sleep 3\nffplay -i output/5.flv -autoexit; sleep 3\nffplay -i output/6.flv -autoexit; sleep 3\nffplay -i output/7.flv -autoexit; sleep 3\nffplay -i output/8.flv -autoexit; sleep 3",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/viewer.sh:25-34"
    },
    "4725": {
        "file_id": 616,
        "content": "This code plays and auto-exits various FLV files in order, with pauses between each playback.",
        "type": "comment"
    },
    "4726": {
        "file_id": 617,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/render.sh",
        "type": "filepath"
    },
    "4727": {
        "file_id": 617,
        "content": "This code utilizes FFmpeg to extract three 3-second video clips from 'sample.mp4' at specific time points, saving them as separate output files numbered 60-62 in the 'output' directory.",
        "type": "summary"
    },
    "4728": {
        "file_id": 617,
        "content": "ffmpeg -y -ss 00:00:00.100000 -to 00:00:07.733000 -i sample.mp4  output/0.flv\nffmpeg -y -ss 00:00:07.933000 -to 00:00:14.300000 -i sample.mp4  output/1.flv\nffmpeg -y -ss 00:00:14.500000 -to 00:00:15.767000 -i sample.mp4  output/2.flv\nffmpeg -y -ss 00:00:15.967000 -to 00:00:17.800000 -i sample.mp4  output/3.flv\nffmpeg -y -ss 00:00:18.000000 -to 00:00:20.967000 -i sample.mp4  output/4.flv\nffmpeg -y -ss 00:00:21.167000 -to 00:00:24.167000 -i sample.mp4  output/5.flv\nffmpeg -y -ss 00:00:24.367000 -to 00:00:27.467000 -i sample.mp4  output/6.flv\nffmpeg -y -ss 00:00:27.667000 -to 00:00:31.233000 -i sample.mp4  output/7.flv\nffmpeg -y -ss 00:00:31.433000 -to 00:00:33.300000 -i sample.mp4  output/8.flv\nffmpeg -y -ss 00:00:34.100000 -to 00:00:37.467000 -i sample.mp4  output/10.flv\nffmpeg -y -ss 00:00:37.667000 -to 00:00:40.633000 -i sample.mp4  output/11.flv\nffmpeg -y -ss 00:00:40.833000 -to 00:00:44.200000 -i sample.mp4  output/12.flv\nffmpeg -y -ss 00:00:44.400000 -to 00:00:50.600000 -i sample.mp4  output/13.flv",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/render.sh:1-13"
    },
    "4729": {
        "file_id": 617,
        "content": "This code extracts and saves multiple clips from the sample.mp4 video file, each with varying start and end times, into separate output files numbered 0 to 13.ffmpeg command is used for extraction and '-y' flag overwrites existing outputs without prompting.",
        "type": "comment"
    },
    "4730": {
        "file_id": 617,
        "content": "ffmpeg -y -ss 00:00:50.800000 -to 00:00:56.266000 -i sample.mp4  output/14.flv\nffmpeg -y -ss 00:00:56.466000 -to 00:00:59.700000 -i sample.mp4  output/15.flv\nffmpeg -y -ss 00:00:59.900000 -to 00:01:01.900000 -i sample.mp4  output/16.flv\nffmpeg -y -ss 00:01:02.100000 -to 00:01:04.800000 -i sample.mp4  output/17.flv\nffmpeg -y -ss 00:01:05.800000 -to 00:01:07.100000 -i sample.mp4  output/19.flv\nffmpeg -y -ss 00:01:07.300000 -to 00:01:09.166000 -i sample.mp4  output/20.flv\nffmpeg -y -ss 00:01:09.366000 -to 00:01:10.466000 -i sample.mp4  output/21.flv\nffmpeg -y -ss 00:01:10.666000 -to 00:01:13.400000 -i sample.mp4  output/22.flv\nffmpeg -y -ss 00:01:13.600000 -to 00:01:15.100000 -i sample.mp4  output/23.flv\nffmpeg -y -ss 00:01:15.300000 -to 00:01:16.700000 -i sample.mp4  output/24.flv\nffmpeg -y -ss 00:01:16.900000 -to 00:01:20.166000 -i sample.mp4  output/25.flv\nffmpeg -y -ss 00:01:20.366000 -to 00:01:21.800000 -i sample.mp4  output/26.flv\nffmpeg -y -ss 00:01:22.000000 -to 00:01:23.266000 -i sample.mp4  output/27.flv",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/render.sh:14-26"
    },
    "4731": {
        "file_id": 617,
        "content": "The code uses FFmpeg to extract multiple video clips from a single input file, each with varying start and end times. It creates output files numbered 14-27, representing separate sections of the original video.",
        "type": "comment"
    },
    "4732": {
        "file_id": 617,
        "content": "ffmpeg -y -ss 00:01:23.466000 -to 00:01:26.633000 -i sample.mp4  output/28.flv\nffmpeg -y -ss 00:01:26.833000 -to 00:01:28.300000 -i sample.mp4  output/29.flv\nffmpeg -y -ss 00:01:28.500000 -to 00:01:29.700000 -i sample.mp4  output/30.flv\nffmpeg -y -ss 00:01:29.900000 -to 00:01:33.266000 -i sample.mp4  output/31.flv\nffmpeg -y -ss 00:01:35.500000 -to 00:01:36.266000 -i sample.mp4  output/35.flv\nffmpeg -y -ss 00:01:38.000000 -to 00:01:41.800000 -i sample.mp4  output/38.flv\nffmpeg -y -ss 00:01:42.000000 -to 00:01:42.800000 -i sample.mp4  output/39.flv\nffmpeg -y -ss 00:01:43.000000 -to 00:01:44.933000 -i sample.mp4  output/40.flv\nffmpeg -y -ss 00:01:45.133000 -to 00:01:47.933000 -i sample.mp4  output/41.flv\nffmpeg -y -ss 00:01:48.133000 -to 00:01:49.533000 -i sample.mp4  output/42.flv\nffmpeg -y -ss 00:01:49.733000 -to 00:01:52.533000 -i sample.mp4  output/43.flv\nffmpeg -y -ss 00:01:52.733000 -to 00:01:55.633000 -i sample.mp4  output/44.flv\nffmpeg -y -ss 00:01:55.833000 -to 00:01:59.666000 -i sample.mp4  output/45.flv",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/render.sh:27-39"
    },
    "4733": {
        "file_id": 617,
        "content": "This code uses ffmpeg to extract individual video scenes from a given input file, \"sample.mp4\". It specifies the start and end times for each scene, and outputs separate .flv files named \"output/xx.flv\" where xx corresponds to the scene number.",
        "type": "comment"
    },
    "4734": {
        "file_id": 617,
        "content": "ffmpeg -y -ss 00:01:59.866000 -to 00:02:06.300000 -i sample.mp4  output/46.flv\nffmpeg -y -ss 00:02:06.500000 -to 00:02:12.599000 -i sample.mp4  output/47.flv\nffmpeg -y -ss 00:02:12.799000 -to 00:02:14.233000 -i sample.mp4  output/48.flv\nffmpeg -y -ss 00:02:14.433000 -to 00:02:18.066000 -i sample.mp4  output/49.flv\nffmpeg -y -ss 00:02:18.266000 -to 00:02:20.499000 -i sample.mp4  output/50.flv\nffmpeg -y -ss 00:02:21.299000 -to 00:02:22.666000 -i sample.mp4  output/52.flv\nffmpeg -y -ss 00:02:22.866000 -to 00:02:25.966000 -i sample.mp4  output/53.flv\nffmpeg -y -ss 00:02:26.166000 -to 00:02:31.066000 -i sample.mp4  output/54.flv\nffmpeg -y -ss 00:02:31.266000 -to 00:02:34.533000 -i sample.mp4  output/55.flv\nffmpeg -y -ss 00:02:34.733000 -to 00:02:39.366000 -i sample.mp4  output/56.flv\nffmpeg -y -ss 00:02:39.566000 -to 00:02:42.399000 -i sample.mp4  output/57.flv\nffmpeg -y -ss 00:02:42.599000 -to 00:02:45.433000 -i sample.mp4  output/58.flv\nffmpeg -y -ss 00:02:45.633000 -to 00:02:47.799000 -i sample.mp4  output/59.flv",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/render.sh:40-52"
    },
    "4735": {
        "file_id": 617,
        "content": "The code uses FFmpeg to extract specific segments of the video file \"sample.mp4\", from different starting and ending timestamps, and save them as separate output files named \"output/[number].flv\". Each command is executed one after another, resulting in a total of 59 output files.",
        "type": "comment"
    },
    "4736": {
        "file_id": 617,
        "content": "ffmpeg -y -ss 00:02:47.999000 -to 00:02:50.966000 -i sample.mp4  output/60.flv\nffmpeg -y -ss 00:02:51.166000 -to 00:02:53.866000 -i sample.mp4  output/61.flv\nffmpeg -y -ss 00:02:54.066000 -to 00:02:58.799000 -i sample.mp4  output/62.flv",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/render.sh:53-55"
    },
    "4737": {
        "file_id": 617,
        "content": "The code uses FFmpeg to extract three segments of 3 seconds each, starting at different time points (02:51.166, 02:54.066, and 02:57.251), from the input video 'sample.mp4' and saves them as separate output files ('output/60.flv', 'output/61.flv', and 'output/62.flv').",
        "type": "comment"
    },
    "4738": {
        "file_id": 618,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/preview_clips.sh",
        "type": "filepath"
    },
    "4739": {
        "file_id": 618,
        "content": "This code plays and pauses \"sample.mp4\" with ffplay for analysis or scene extraction, introducing 3-second delays between playback sessions.",
        "type": "summary"
    },
    "4740": {
        "file_id": 618,
        "content": "ffplay -ss 00:00:00.000 -t 7.833 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:07.833 -t 6.567 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:14.400 -t 1.467 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:15.867 -t 2.033 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:17.900 -t 3.167 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:21.067 -t 3.2 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:24.267 -t 3.3 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:27.567 -t 3.767 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:31.333 -t 2.067 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:33.400 -t 0.6 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:34.000 -t 3.567 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:37.567 -t 3.167 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:40.733 -t 3.567 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:44.300 -t 6.4 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:50.700 -t 5.667 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:00:56.366 -t 3.433 -i sample.mp4 -autoexit ",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/preview_clips.sh:1-31"
    },
    "4741": {
        "file_id": 618,
        "content": "This code plays and automatically exits various clips from the sample.mp4 video with specific start times and durations, followed by a 3-second pause between each clip playback.",
        "type": "comment"
    },
    "4742": {
        "file_id": 618,
        "content": "sleep 3\nffplay -ss 00:00:59.800 -t 2.2 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:02.000 -t 2.9 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:04.900 -t 0.8 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:05.700 -t 1.5 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:07.200 -t 2.067 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:09.266 -t 1.3 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:10.566 -t 2.933 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:13.500 -t 1.7 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:15.200 -t 1.6 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:16.800 -t 3.467 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:20.266 -t 1.633 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:21.900 -t 1.467 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:23.366 -t 3.367 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:26.733 -t 1.667 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:28.400 -t 1.4 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:29.800 -t 3.567 -i sample.mp4 -autoexit ",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/preview_clips.sh:32-63"
    },
    "4743": {
        "file_id": 618,
        "content": "This code uses ffplay to play predefined segments of a video file \"sample.mp4\" with specified start and stop times, allowing for analysis or extraction of specific scenes. The sleep commands introduce pauses between each command execution, ensuring the video segment plays before moving on to the next one.",
        "type": "comment"
    },
    "4744": {
        "file_id": 618,
        "content": "sleep 3\nffplay -ss 00:01:33.366 -t 0.733 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:34.100 -t 0.6 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:34.700 -t 0.7 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:35.400 -t 0.967 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:36.366 -t 0.733 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:37.100 -t 0.8 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:37.900 -t 4.0 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:41.900 -t 1.0 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:42.900 -t 2.133 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:45.033 -t 3.0 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:48.033 -t 1.6 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:49.633 -t 3.0 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:52.633 -t 3.1 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:55.733 -t 4.033 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:01:59.766 -t 6.633 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:06.400 -t 6.3 -i sample.mp4 -autoexit ",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/preview_clips.sh:64-95"
    },
    "4745": {
        "file_id": 618,
        "content": "The code is executing ffplay with different start times and durations to preview clips from a sample video file. It waits 3 seconds between each command execution.",
        "type": "comment"
    },
    "4746": {
        "file_id": 618,
        "content": "sleep 3\nffplay -ss 00:02:12.699 -t 1.633 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:14.333 -t 3.833 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:18.166 -t 2.433 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:20.599 -t 0.6 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:21.199 -t 1.567 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:22.766 -t 3.3 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:26.066 -t 5.1 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:31.166 -t 3.467 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:34.633 -t 4.833 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:39.466 -t 3.033 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:42.499 -t 3.033 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:45.533 -t 2.367 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:47.899 -t 3.167 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:51.066 -t 2.9 -i sample.mp4 -autoexit \nsleep 3\nffplay -ss 00:02:53.966 -t 4.933 -i sample.mp4 -autoexit \nsleep 3",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/preview_clips.sh:96-126"
    },
    "4747": {
        "file_id": 618,
        "content": "The code uses the ffplay command to play specific segments of a video file, \"sample.mp4\", with varying start times and durations. The -autoexit flag ensures that each playback session ends automatically after completion. Sleep commands are used between ffplay calls, introducing delays of 3 seconds each time.",
        "type": "comment"
    },
    "4748": {
        "file_id": 619,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py",
        "type": "filepath"
    },
    "4749": {
        "file_id": 619,
        "content": "The code reads CSV data, calculates statistics for video scene lengths, generates FFmpeg commands with duration threshold handling, filters and selects scenes based on even spacing criteria using random functions. The `getNeighborIndexs` function helps find neighboring values that meet specific thresholds.",
        "type": "summary"
    },
    "4750": {
        "file_id": 619,
        "content": "import pandas\nmetric = \"video.stats.csv\"\nmetric = pandas.read_csv(metric)\nscenes = \"sample_scenes.csv\"\nwith open(scenes, \"r\") as f:\n    content = f.read()\n    lines = content.split(\"\\n\")\n    timecodeList = lines[0]\n    scenes = \"\\n\".join(lines[1:])\n    from io import StringIO\n    scenes = StringIO(scenes)\ntimecodeList = timecodeList.split(\",\")\ntimecodeList[0] = \"00:00:00.000\"\nscenes = pandas.read_csv(scenes)\nlengths = []\nsceneCuts = []\nfor index, row in scenes.iterrows():\n    # print(row)\n    # breakpoint()\n    start, end = row[\"Start Timecode\"], row[\"End Timecode\"]\n    length = row[\"Length (seconds)\"]\n    sceneCuts.append((start, end, length))\n    # print(start, end)\n    # please calculate the length!\n    lengths.append(length)\n    # print(length, type(length)) # float.\nflag = \"filter\"\nfilename = \"sample.mp4\"\nif flag == \"calculate_statistics\":\n    import numpy\n    std = numpy.std(lengths)\n    mean = numpy.mean(lengths)\n    print(std, mean)\n    # 1.6674874515595588 2.839698412698412\n    print(min(lengths), max(lengths))",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:1-46"
    },
    "4751": {
        "file_id": 619,
        "content": "This code reads data from two CSV files and performs calculations on the \"Length (seconds)\" values for each scene in a video. It calculates the standard deviation, mean, minimum, and maximum of these lengths. The resulting values are then printed to the console.",
        "type": "comment"
    },
    "4752": {
        "file_id": 619,
        "content": "    min(lengths), max(lengths)\n    # 0.6 7.833\n    # strange though.\n    # shall we adjust this accordingly? how to generate this shit?\nelif flag == \"generate_ffplay\":\n    for (start, end, duration) in sceneCuts:\n        print(\"ffplay -ss %s -t %s -i %s -autoexit \" % (start, duration, filename))\n        print(\"sleep 3\")\nelif flag == \"render\":\n    import os\n    import datetime\n    durationThreshold = 0.6674874515595588\n    mTimeDelta = datetime.timedelta(milliseconds=100)  # 0.1 seconds\n    getTimeObject = lambda timeString: datetime.datetime.strptime(\n        timeString, \"%H:%M:%S.%f\"\n    )\n    getTimeString = lambda timeObject: timeObject.strftime(\"%H:%M:%S.%f\")\n    if not os.path.exists(\"output\"):\n        os.mkdir(\"output\")\n    for index, (start, end, duration) in enumerate(sceneCuts):\n        estimatedDuration = duration - 0.2\n        if estimatedDuration < durationThreshold:\n            continue\n        start2 = getTimeObject(start) + mTimeDelta\n        end2 = getTimeObject(end) - mTimeDelta\n        start2, end2 = getTimeString(start2), getTimeString(end2)",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:47-73"
    },
    "4753": {
        "file_id": 619,
        "content": "This code segment is responsible for generating FFmpeg commands to play and render video scenes, with additional handling of scene duration threshold. It also checks if the output directory exists and creates it if necessary. The code adjusts start and end times by subtracting or adding 0.2 seconds from the original duration and compares the estimated duration to a given threshold before proceeding with FFmpeg commands.",
        "type": "comment"
    },
    "4754": {
        "file_id": 619,
        "content": "        output = \"output/%d.flv\" % index\n        print(\"ffmpeg -y -ss %s -to %s -i %s %s\" % (start2, end2, filename, output))\nelif (\n    flag == \"filter\"\n):  # to make sure the selected set will be evenly spaced. no two elements will get closer to each other than 5 seconds.\n    import random\n    durationMinThreshold = 0.6\n    durationMaxThreshold = 7.833\n    fakeQualificationFunction = lambda: random.uniform(\n        durationMinThreshold, durationMaxThreshold\n    )\n    fakeAcceptFunction = lambda: random.random() > 0.5\n    # select the closest one! must be closer than 0.9 to 1.1\n    candidates = []\n    import datetime\n    getTimeObject = lambda timeString: datetime.datetime.strptime(\n        timeString, \"%H:%M:%S.%f\"\n    )\n    getTimeString = lambda timeObject: timeObject.strftime(\"%H:%M:%S.%f\")\n    mTimeDelta = datetime.timedelta(milliseconds=100)  # 0.1 seconds\n    standardStartDatetime = datetime.datetime(year=1900, month=1, day=1)\n    standardStartTimestamp = standardStartDatetime.timestamp()\n    getTimestamp = lambda timeObject: timeObject.timestamp() - standardStartTimestamp",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:74-99"
    },
    "4755": {
        "file_id": 619,
        "content": "This code snippet is responsible for filtering and selecting video scenes based on specific duration criteria. It ensures that the selected set of scenes is evenly spaced, with no two elements being closer than 5 seconds. The code uses random functions to generate duration thresholds and filters candidate scenes accordingly. It also includes time-related functions for converting between string and datetime formats, and calculating timestamps from datetimes.",
        "type": "comment"
    },
    "4756": {
        "file_id": 619,
        "content": "    for index, (start, end, duration) in enumerate(sceneCuts):\n        estimatedDurationAfterCut = duration - 0.2\n        if (\n            estimatedDurationAfterCut < durationMinThreshold\n            or estimatedDurationAfterCut > durationMaxThreshold\n        ):\n            continue\n        startCutDatetime = getTimeObject(start) + mTimeDelta\n        endCutDatetime = getTimeObject(end) - mTimeDelta\n        # print(getTimeStamp(startDatetime), getTimeStamp(endDatetime))\n        # print(startDatetime, endDatetime)\n        startCutTimestamp, endCutTimestamp = getTimestamp(\n            startCutDatetime\n        ), getTimestamp(endCutDatetime)\n        candidates.append(\n            (startCutTimestamp, endCutTimestamp, estimatedDurationAfterCut)\n        )\n    shuffledCandidates = [\n        (index, startCutDatetime, endCutDatetime, estimatedDurationAfterCut)\n        for index, (\n            startCutDatetime,\n            endCutDatetime,\n            estimatedDurationAfterCut,\n        ) in enumerate(candidates)\n    ]\n    random.shuffle(shuffledCandidates)",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:101-127"
    },
    "4757": {
        "file_id": 619,
        "content": "Iterates through scene cuts, filters based on duration threshold, converts timestamps to Unix timestamps, appends as candidates, shuffles the candidates and assigns index.",
        "type": "comment"
    },
    "4758": {
        "file_id": 619,
        "content": "    bannedIndexs = set()\n    neighborThreshold = 5\n    def getNeighborIndexs(index, candidates, neighborThreshold, checkNeighbor):\n        assert neighborThreshold > 0\n        assert index < len(candidates) and index >= 0\n        leftNeighbors = candidates[:index][::-1]\n        rightNeighbors = candidates[index + 1 :]\n        neighborIndexs = []\n        for mIndex, neighbor in enumerate(leftNeighbors):\n            currentIndex = index - mIndex - 1\n            assert candidates[currentIndex] == neighbor\n            assert currentIndex >= 0 and currentIndex < len(candidates)\n            if checkNeighbor(neighbor, candidates[index]):\n                neighborIndexs.append(currentIndex)\n                print(\"left index:\", currentIndex)\n            else:\n                break\n        for mIndex, neighbor in enumerate(rightNeighbors):\n            currentIndex = index + mIndex + 1\n            assert candidates[currentIndex] == neighbor\n            assert currentIndex >= 0 and currentIndex < len(candidates)\n            if checkNeighbor(neighbor, candidates[index]):",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:128-150"
    },
    "4759": {
        "file_id": 619,
        "content": "This function, `getNeighborIndexs`, takes an index, a list of candidates, and two parameters: `neighborThreshold` and `checkNeighbor`. It checks the neighboring values from both sides of the given index, appending their indices to the list if they satisfy a certain condition defined by `checkNeighbor`. It prints the left indices found while iterating through the candidates.",
        "type": "comment"
    },
    "4760": {
        "file_id": 619,
        "content": "                neighborIndexs.append(currentIndex)\n                print(\"right index:\", currentIndex)\n            else:\n                break\n        return neighborIndexs\n    def checkNeighborForClipCandiates(clip_a, clip_b, threshold):\n        assert threshold > 0\n        s_a, e_a, l_a = clip_a\n        s_b, e_b, l_b = clip_b\n        e_min = min(e_a, e_b)\n        s_max = max(s_a, s_b)\n        distance = s_max - e_min\n        return distance < threshold  # check if is neighbor\n    while True:\n        print(\"BANNED:\", len(bannedIndexs), \"TOTAL:\", len(candidates))\n        target = fakeQualificationFunction()\n        isSimilar = lambda a, b, threshold: min(a, b) / max(a, b) >= threshold\n        similarThreshold = 0.9\n        if len(bannedIndexs) == len(shuffledCandidates):\n            print(\"No avaliable candidates\")\n            break\n        for (\n            index,\n            startCutDatetime,\n            endCutDatetime,\n            estimatedDurationAfterCut,\n        ) in shuffledCandidates:\n            if index in bannedIndexs:",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:151-180"
    },
    "4761": {
        "file_id": 619,
        "content": "The code is iterating over candidate indexes and checking if they are neighbors. It appends the current index to a list of neighborIndexs, and checks if two clips are neighbors using a threshold value. If there are no available candidates left, it breaks the loop.",
        "type": "comment"
    },
    "4762": {
        "file_id": 619,
        "content": "                continue\n            if isSimilar(estimatedDurationAfterCut, target, similarThreshold):\n                accept = fakeAcceptFunction()\n                if accept:\n                    print(\n                        \"Accepting candidate\",\n                        (\n                            index,\n                            startCutDatetime,\n                            endCutDatetime,\n                            estimatedDurationAfterCut,\n                        ),\n                    )\n                    print(\"target:\", target)\n                    bannedIndexs.add(index)\n                    neighborIndexs = getNeighborIndexs(\n                        index,\n                        candidates,\n                        neighborThreshold,\n                        lambda a, b: checkNeighborForClipCandiates(\n                            a, b, neighborThreshold\n                        ),\n                    )\n                    print(\"NEIGHBOR INDEXS:\", neighborIndexs)\n                    for neighborIndex in neighborIndexs:",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:181-205"
    },
    "4763": {
        "file_id": 619,
        "content": "This code continues until finding a candidate that meets the similarity threshold, then accepts it if the fake acceptance function returns true. If accepted, it prints information about the candidate and its neighbors, along with the target duration.",
        "type": "comment"
    },
    "4764": {
        "file_id": 619,
        "content": "                        bannedIndexs.add(neighborIndex)\n                        print(\"also banned:\", neighborIndex, candidates[neighborIndex])\n        random.shuffle(shuffledCandidates)",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/load_data_do_experiment.py:206-208"
    },
    "4765": {
        "file_id": 619,
        "content": "The code adds the current neighbor index to a list of banned indices, prints it along with the candidate at that index, and then shuffles the remaining candidates.",
        "type": "comment"
    },
    "4766": {
        "file_id": 620,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/get_scene_cuts.sh",
        "type": "filepath"
    },
    "4767": {
        "file_id": 620,
        "content": "This code uses the SceneDetect library to detect scenes in a video file and split it into separate clips based on scene changes. It opens the video, creates a SceneManager object, adds a ContentDetector with a threshold value, detects scenes using the detector, retrieves the list of detected scenes, and then splits the video using ffmpeg according to the scene list.",
        "type": "summary"
    },
    "4768": {
        "file_id": 620,
        "content": "scenedetect -i sample.mp4 -s video.stats.csv detect-content list-scenes -f sample_scenes.csv\n# for dynamic analysis:\n# https://github.com/Breakthrough/PySceneDetect/README.md\n# from scenedetect import open_video, SceneManager, split_video_ffmpeg\n# from scenedetect.detectors import ContentDetector\n# from scenedetect.video_splitter import split_video_ffmpeg\n# def split_video_into_scenes(video_path, threshold=27.0):\n#     # Open our video, create a scene manager, and add a detector.\n#     video = open_video(video_path)\n#     scene_manager = SceneManager()\n#     scene_manager.add_detector(\n#         ContentDetector(threshold=threshold))\n#     scene_manager.detect_scenes(video, show_progress=True)\n#     scene_list = scene_manager.get_scene_list()\n#     split_video_ffmpeg(video_path, scene_list, show_progress=True)",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/get_scene_cuts.sh:1-16"
    },
    "4769": {
        "file_id": 620,
        "content": "This code uses the SceneDetect library to detect scenes in a video file and split it into separate clips based on scene changes. It opens the video, creates a SceneManager object, adds a ContentDetector with a threshold value, detects scenes using the detector, retrieves the list of detected scenes, and then splits the video using ffmpeg according to the scene list.",
        "type": "comment"
    },
    "4770": {
        "file_id": 621,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/generate_random_clip_lengths.py",
        "type": "filepath"
    },
    "4771": {
        "file_id": 621,
        "content": "This code generates 30 random clip lengths using a truncated Gaussian distribution with mean and standard deviation, ensuring values are within specified bounds. It utilizes the truncnorm function from scipy.stats for generating the distribution.",
        "type": "summary"
    },
    "4772": {
        "file_id": 621,
        "content": "std, mean = 1.6674874515595588, 2.839698412698412\nscale, loc = std, mean\n# using gaussian distribution\n# accepting both mean and standard deviation\n# this is truncated gaussian, not just normal distribution\nmyclip_a, myclip_b = 0.6, 7.833\n# while you need to make sure the value is in bound.\n# import random\nfrom scipy.stats import truncnorm\na, b = (myclip_a - loc) / scale, (myclip_b - loc) / scale\nrandVar = truncnorm(a,b)\nrandomFunction = lambda: randVar.rvs(1)[0]*scale+loc\n# inBound = lambda number: min(nMax, max(nMin, number))\n# randomFunction = lambda: inBound(random.gauss(mean, std))\nfor _ in range(30):\n    print(randomFunction())",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/generate_random_clip_lengths.py:1-21"
    },
    "4773": {
        "file_id": 621,
        "content": "This code generates 30 random clip lengths using a truncated Gaussian distribution with mean and standard deviation, ensuring values are within specified bounds. It utilizes the truncnorm function from scipy.stats for generating the distribution.",
        "type": "comment"
    },
    "4774": {
        "file_id": 622,
        "content": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/download_sample.sh",
        "type": "filepath"
    },
    "4775": {
        "file_id": 622,
        "content": "This code uses yt-dlp to download a sample video from Bilibili at the given URL and save it as \"sample.mp4\".",
        "type": "summary"
    },
    "4776": {
        "file_id": 622,
        "content": "yt-dlp -o sample.mp4 https://www.bilibili.com/video/BV1HS4y1w7PK",
        "type": "code",
        "location": "/tests/calculate_separate_video_scene_duration_in_dog_video_with_bgm/download_sample.sh:1-1"
    },
    "4777": {
        "file_id": 622,
        "content": "This code uses yt-dlp to download a sample video from Bilibili at the given URL and save it as \"sample.mp4\".",
        "type": "comment"
    },
    "4778": {
        "file_id": 623,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md",
        "type": "filepath"
    },
    "4779": {
        "file_id": 623,
        "content": "This code covers device discovery, Termux daemon, remote unlock with ADB and scrcpy client, focused window titles, downloading a macOS keylogger, and executes input tests on the X server.",
        "type": "summary"
    },
    "4780": {
        "file_id": 623,
        "content": "device discovery, termux daemon, remote unlock\nunlock requires screenshot and input events.\nhttps://technastic.com/unlock-android-phone-pin-pattern-adb/\nclick ok after input password:\nhttps://stackoverflow.com/questions/29072501/how-to-unlock-android-phone-through-adb\nscrcpy client\nhttps://github.com/leng-yue/py-scrcpy-client\nhttps://leng-yue.github.io/py-scrcpy-client/guide.html#bind-events\nyou want to use android emulator on macos m1?\nhttps://github.com/google/android-emulator-m1-preview/releases/tag/0.3\ncheck android screen lock/unlock state\nhttps://android.stackexchange.com/questions/191086/adb-commands-to-get-screen-state-and-locked-state\nBonjour/Avahi/Zeroconf\nlogic: if the kill switch is off, when no physical input events happens, or not focused on scrcpy window with keyboard/mouse input events on pc for some time, allow to interact with the phone.\nget physical events:\nwarning: this command could be offline for a short period of time after using the scrcpy. must automatically reconnect if the device is not offline.",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md:1-30"
    },
    "4781": {
        "file_id": 623,
        "content": "This code focuses on device discovery, termux daemon, remote unlock, using scrcpy client and android emulator on MacOS M1. It includes links for unlocking Android phone through ADB, checking screen lock/unlock state, utilizing Bonjour/Avahi/Zeroconf logic, handling physical events and reconnecting if necessary.",
        "type": "comment"
    },
    "4782": {
        "file_id": 623,
        "content": "```bash\nadb -s 192.168.10.3:5555 shell getevent\n```\nto get focused window title:\nhint: for headless ssh sessions, must set apropriate xorg environment variables, eg: `env XAUTHORITY=\"/run/user/0/gdm/Xauthority\" DISPLAY=:1 python3`\ngeneral method:\n```python\nimport pywinctl\npywinctl.getActiveWindowTitle()\n```\nfor linux:\n```bash\nwatch -n 2 xdotool getactivewindow getwindowname\n```\nfor macos: (allow permission first, deprecated since it will not get the window title instead of the program name)\nhttps://alvinalexander.com/mac-os-x/applescript-unix-mac-osx-foreground-application-result/\n(where is the window name?)\n```bash\nsleep 3 && osascript -e 'tell application \"System Events\"' -e 'set frontApp to name of first application process whose frontmost is true' -e 'end tell'\n```\nto get input events on macos:\ndownload keylogger here:\nhttps://hackernoon.com/writing-an-keylogger-for-macos-in-python-24adfa22722\nhttps://github.com/beatsbears/pkl?ref=hackernoon.com\n```bash\npython pkl_nowriting.py\n```\ninput events on linux:\n```bash",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md:32-68"
    },
    "4783": {
        "file_id": 623,
        "content": "This code provides methods to obtain the focused window title on different operating systems: Bash commands for Android devices and Windows, Python script for Linux, Applescript for macOS. Additionally, it mentions downloading a keylogger for capturing input events on macOS.",
        "type": "comment"
    },
    "4784": {
        "file_id": 623,
        "content": "xinput test-xi2 --root\n```",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md:69-70"
    },
    "4785": {
        "file_id": 623,
        "content": "Executes an input test on the X server, affecting all connected devices.",
        "type": "comment"
    },
    "4786": {
        "file_id": 624,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/unlock_phone_on_given_ip.py",
        "type": "filepath"
    },
    "4787": {
        "file_id": 624,
        "content": "Device address is set to connect to the phone on a specific IP and port for further interactions.",
        "type": "summary"
    },
    "4788": {
        "file_id": 624,
        "content": "# first, check phone status.\ndevice_address = \"192.168.10.3:5555\"",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/unlock_phone_on_given_ip.py:1-2"
    },
    "4789": {
        "file_id": 624,
        "content": "Device address is set to connect to the phone on a specific IP and port for further interactions.",
        "type": "comment"
    },
    "4790": {
        "file_id": 625,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py",
        "type": "filepath"
    },
    "4791": {
        "file_id": 625,
        "content": "This Python script logs keystrokes and mouse events via Cocoa, for educational purposes, requires privilege settings adjustment, and has an event loop with interrupt handling.",
        "type": "summary"
    },
    "4792": {
        "file_id": 625,
        "content": "#!/usr/bin/env python\n\"\"\"\npkl.py\n:author: Andrew Scott\n:date: 9-3-2018\nIf executed successfully this script will log key strokes until the process is killed.\nThis script is for EDUCATIONAL PURPOSES ONLY. \n\"\"\"\n# can be run without root, but must enable the privilege in privacy settings\nimport os, sys\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom AppKit import NSApplication, NSApp\nfrom Foundation import NSObject\nfrom Cocoa import (\n    NSEvent,\n    NSKeyDownMask, # keyboard\n    NSLeftMouseUpMask, # mouse\n    NSLeftMouseDownMask,\n    NSLeftMouseDraggedMask,\n    NSRightMouseDownMask,\n    NSRightMouseDraggedMask,\n    NSRightMouseUpMask,\n    NSMouseMovedMask,\n)\nfrom PyObjCTools import AppHelper\n# NSLeftMouseUpMask, NSLeftMouseDownMask, NSLeftMouseDraggedMask, NSRightMouseDownMask, NSRightMouseDraggedMask, NSRightMouseUpMask, NSMouseMovedMask\nclass AppDelegate(NSObject):\n    \"\"\"\n    The App Delegate creates a mask to detect the key being pressed and adds\n    a global monitor for this mask.",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:1-38"
    },
    "4793": {
        "file_id": 625,
        "content": "This Python script logs key strokes until the process is killed, intended for educational purposes only. It uses AppKit and Foundation modules from Cocoa and PyObjCTools to create an app delegate that detects keyboard and mouse events without root access, but requires enabling privilege in privacy settings.",
        "type": "comment"
    },
    "4794": {
        "file_id": 625,
        "content": "    \"\"\"\n    def applicationDidFinishLaunching_(self, notification):\n        mask_down = NSKeyDownMask\n        mouse_masks = [\n            NSLeftMouseUpMask,\n            NSLeftMouseDownMask,\n            NSLeftMouseDraggedMask,\n            NSRightMouseDownMask,\n            NSRightMouseDraggedMask,\n            NSRightMouseUpMask,\n            NSMouseMovedMask,\n        ]\n        NSEvent.addGlobalMonitorForEventsMatchingMask_handler_(mask_down, key_handler)\n        for mouse_mask in mouse_masks:\n            NSEvent.addGlobalMonitorForEventsMatchingMask_handler_(\n                mouse_mask, mouse_handler\n            )\n# w = Writer()\ndef mouse_handler(event):\n    import time\n    print(\"mouse have actions\", time.time())\ndef key_handler(event):\n    \"\"\"\n    Translates the key press events into readable characters if one exists\n    the key code is also recorded for non-character input.\n    \"\"\"\n    try:\n        capture_char = event.characters()\n        capture_raw = event.keyCode()\n        print(capture_char, capture_raw)\n        # w.write_to_log(capture_char, capture_raw)",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:39-74"
    },
    "4795": {
        "file_id": 625,
        "content": "The code sets up event handlers for various mouse actions and keyboard events. It adds a global monitor to track these events, and when an event occurs, it logs the characters (if any) and keyCode. The code also includes functions for handling the mouse and key events, but they do not appear to perform any specific actions beyond logging.",
        "type": "comment"
    },
    "4796": {
        "file_id": 625,
        "content": "    except KeyboardInterrupt:\n        AppHelper.stopEventLoop()\nif __name__ == \"__main__\":\n    app = NSApplication.sharedApplication()\n    delegate = AppDelegate.alloc().init()\n    NSApp().setDelegate_(delegate)\n    AppHelper.runEventLoop()",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:75-83"
    },
    "4797": {
        "file_id": 625,
        "content": "The code sets up an event loop and handles interrupts, ensuring that the application properly terminates when needed.",
        "type": "comment"
    },
    "4798": {
        "file_id": 626,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier_with_masscan_scapy.py",
        "type": "filepath"
    },
    "4799": {
        "file_id": 626,
        "content": "This code uses Masscan to scan for open ports, connects to the desired port with AdbWrapper, and stores connected addresses in a list. It is part of a script for controlling devices over the network.",
        "type": "summary"
    }
}