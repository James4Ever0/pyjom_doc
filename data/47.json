{
    "4700": {
        "file_id": 591,
        "content": "_DOWNLOAD_URL = f\"https://subconverter.speedupvpn.com/sub?target=clash&url={urllib.parse.quote_plus(DIRECT_LINK)}&insert=false&emoji=true&list=false&tfo=false&scv=false&fdn=false&sort=false&new_name=true\" # use quote_plus since the slash is not welcomed.\nALL_PROXIES_LOCATION = [\"proxies\", \"ğŸ”° èŠ‚ç‚¹é€‰æ‹©\", \"all\"]\nPROXY_GROUP_EXCEPTIONS = [\"ğŸŸ æ¼ç½‘ä¹‹é±¼\"]\nPROXY_GROUP_SPECIALS = [\"ğŸ¯ å…¨çƒç›´è¿\", \"ğŸ”° èŠ‚ç‚¹é€‰æ‹©\", \"â™»ï¸ è‡ªåŠ¨é€‰æ‹©\"]\n# r = requests.get(target)\n# text = r.text\n# json_obj = yaml.safe_load(text)\n# port: 7890\n# socks5 port: 7891\n# controller: http://localhost:9090\n# PUT http://localhost:9090/providers/proxies/default\n# all_proxies_url = \"http://localhost:9090/proxies/\"\n# one_proxy_url = \"http://localhost:9090/proxies/{}\".format(proxy_name)\n# delay test url: http://localhost:9090/proxies/%F0%9F%87%A8%F0%9F%87%B3%20CN%2014%EF%BD%9Copenit.ml/delay?timeout=2000&url=https://www.baidu.com\nfrom loadSomeCustomClashYaml import goYamlToPyYaml, pyYamlToGoYaml\ndef jsonLocate(jsonObj, location=[]):\n    try:\n        if location != []:\n            return jsonLocate(jsonObj[location[0]], location[1:])",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:30-56"
    },
    "4701": {
        "file_id": 591,
        "content": "Code fetches clash configuration data from a URL, extracts necessary information like controller URL and proxy port numbers, and handles exceptions for non-matching group names. The code also defines URLs for accessing the proxy list or specific proxies, and includes a delay test URL to check connection speed. A function `jsonLocate` is used for locating values within a JSON object using a given location path.",
        "type": "comment"
    },
    "4702": {
        "file_id": 591,
        "content": "        return jsonObj\n    except:\n        print(\"KEY %s DOES NOT EXIST!\", \".\".join(location))\n        return None\ndef find_proxy_names(\n    test_url=\"http://localhost:9911/proxies/\", location=ALL_PROXIES_LOCATION\n):\n    import requests\n    r = requests.get(test_url)\n    import json\n    data = json.loads(r.text)\n    proxy_names = jsonLocate(data, location=location)\n    if proxy_names == None:\n        print(\"SOMEHOW WE FAILED TO FETCH THE PROXY LIST\")\n        return []\n    else:\n        return proxy_names\n## FIND DELAY ##\ndef find_tested_proxy_names(\n    timeout=3000,\n    urltest=\"https://m.tujia.com\",\n    test_url=\"http://localhost:9911/proxies/\",\n    location=ALL_PROXIES_LOCATION,\n    forbidden_names=[\"DIRECT\", \"REJECT\", \"GLOBAL\"],\n):\n    import requests\n    import json\n    proxy_names = find_proxy_names(test_url, location)\n    if proxy_names == []:\n        return []\n    def get_delay(name):\n        url = \"{}{}/delay?timeout={}&url={}\".format(test_url, name, timeout, urltest)\n        r = requests.get(url)\n        response_json = r.text",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:57-98"
    },
    "4703": {
        "file_id": 591,
        "content": "The code defines a function to find tested proxy names, utilizes the requests library for API calls, and uses JSON to locate data. The find_proxy_names function retrieves a list of proxy names from a specific URL and location. If unsuccessful, it returns an empty list. The find_tested_proxy_names function finds tested proxy names by calling find_proxy_names and then checks delays for each proxy name using the 'get_delay' function.",
        "type": "comment"
    },
    "4704": {
        "file_id": 591,
        "content": "        response_json = json.loads(response_json)\n        if \"delay\" in response_json.keys():\n            delay = response_json[\"delay\"]\n        else:\n            delay = None\n        return delay\n    direct_delay = get_delay(\"DIRECT\")\n    if direct_delay is None:\n        direct_delay = 300  # approximate delay 300ms\n    candidates = []\n    import progressbar  # 3 minutes.\n    for name in progressbar.progressbar(\n        [x for x in proxy_names if x not in forbidden_names]\n    ):\n        # if name in forbidden_names: continue\n        # delay = get_delay(name)\n        # if delay is not None:\n        candidates.append((name, 3))\n    print(\"PROXY CANDIDATES: %d\" % len(candidates))\n    for elem in candidates:\n        print(elem)\n    return candidates\ndef setClashProxy(proxy_name, control_port=9911):\n    import requests\n    import json\n    selector = \"GLOBAL\"\n    try:\n        r = requests.put(\n            \"http://localhost:{}/proxies/{}\".format(control_port, selector),\n            data=json.dumps({\"name\": proxy_name}, ensure_ascii=False).encode(),",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:99-133"
    },
    "4705": {
        "file_id": 591,
        "content": "Function to get proxy delay and return a list of candidates for setting the Clash proxy. First, it retrieves the delay for each proxy name from direct or API response, then creates a list of candidate proxies with a default delay of 300ms if not available. Finally, prints the number of candidate proxies and their names, returning the list.",
        "type": "comment"
    },
    "4706": {
        "file_id": 591,
        "content": "        )\n        assert r.status_code == 204\n        # assert r.status_code =\n    except:\n        import traceback\n        traceback.print_exc()\n        breakpoint()\n# with open(\"ClashBaseOpenIt.yaml\", 'r') as f:\n#     cachedDNSConfig = yaml.load(f,yaml.FullLoader)\ndef refineClashYaml(clashYamlPath=\"Clash3.yaml\", advanced=True):\n    with open(clashYamlPath, \"r\") as f:\n        data = f.read()\n    from loadSomeCustomClashYaml import goYamlToPyYaml, pyYamlToGoYaml\n    import yaml\n    data = goYamlToPyYaml(data)\n    data = yaml.safe_load(data)\n    data[\"port\"] = 8381\n    base_url = \"127.0.0.1:9911\"\n    data[\"external-controller\"] = base_url\n    if \"socks-port\" in data.keys():\n        del data[\"socks-port\"]\n    # breakpoint()\n    if advanced:\n        # print(data['proxies'])\n        key = \"proxy-groups\"\n        updatedProxy = []\n        updateIndex = 0\n        for index, proxy in enumerate(data[key]):\n            # breakpoint()\n            if proxy[\"name\"] in PROXY_GROUP_EXCEPTIONS:\n                # print(proxy)\n                # breakpoint()",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:134-173"
    },
    "4707": {
        "file_id": 591,
        "content": "This code defines a function `refineClashYaml` that takes a path to a Clash YAML configuration file and an optional \"advanced\" parameter. It opens the file, converts its contents from Go-style YAML to Python-friendly YAML, loads it using the `yaml.safe_load()` function, then modifies some fields (e.g., sets a new port and specifies a base URL). If \"advanced\" is True, it iterates through the \"proxy-groups\" section, removing certain proxies if they match a list of exceptions.",
        "type": "comment"
    },
    "4708": {
        "file_id": 591,
        "content": "                updateIndex = index\n                updatedProxy = proxy.copy()\n                updatedProxy[\"proxies\"] = [\n                    elem\n                    for elem in proxy[\"proxies\"]\n                    if elem not in PROXY_GROUP_SPECIALS\n                ]\n                updatedProxy[\"url\"] = \"https://media4.giphy.com\"\n                updatedProxy[\"interval\"] = 300\n                updatedProxy[\"tolerance\"] = 50\n                break\n        data[key][updateIndex] = updatedProxy\n        # for item in data['proxies']:\n        #     print(item)\n        # del data[\"rules\"]\n        # data[\"mode\"] = \"global\"\n    # data[\"dns\"] = cachedDNSConfig\n    data[\"dns\"] = {\n        \"enable\": True,\n        \"enhanced-mode\": \"redir-host\",\n        \"fake-ip-filter\": [\"*.lan\", \"localhost.ptlogin2.qq.com\"],\n        \"fake-ip-range\": \"198.18.0.1/16\",\n        \"fallback\": [\n            \"8.8.8.8\",\n            \"1.1.1.1\",\n            \"tls://dns.rubyfish.cn:853\",\n            \"tls://1.0.0.1:853\",\n            \"tls://dns.google:853\",",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:174-202"
    },
    "4709": {
        "file_id": 591,
        "content": "This code updates the proxy settings and DNS configuration for a program. It removes special proxies, sets new URL, interval, and tolerance values, and enables DNS with specific configurations like enhanced mode and fake IP range.",
        "type": "comment"
    },
    "4710": {
        "file_id": 591,
        "content": "            \"https://dns.rubyfish.cn/dns-query\",\n            \"https://cloudflare-dns.com/dns-query\",\n            \"https://dns.google/dns-query\",\n        ],\n        \"fallback-filter\": {\"geoip\": True, \"ipcidr\": [\"240.0.0.0/4\"]},\n        \"ipv6\": False,\n        \"listen\": \"0.0.0.0:61\",  # key?\n        \"nameserver\": [\n            \"223.5.5.5\",\n            \"180.76.76.76\",\n            \"119.29.29.29\",\n            \"117.50.10.10\",\n            \"114.114.114.114\",\n        ],\n    }\n    # data = pyYamlToGoYaml(data)\n    data_dump = yaml.safe_dump(data, allow_unicode=True)\n    data_dump = pyYamlToGoYaml(data_dump)\n    with open(clashYamlPath, \"w\") as f:\n        f.write(data_dump)\n    \"\"\"\n    import requests\n    import json\n    base_url =  \"http://127.0.0.1:9022\"\n    url = \"/proxies/\"\n    r = requests.put(base_url+url+\"GLOBAL\",data=json.dumps({\"name\":name},ensure_ascii=False).encode())\n    assert r.status_code == 204\n    \"\"\"\ndef getClashYaml(clashYamlPath=\"Clash3.yaml\", url: str = CLASH_CONFIG_DOWNLOAD_URL):\n    import requests\n    #",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:203-240"
    },
    "4711": {
        "file_id": 591,
        "content": "This code sets up a DNS server for Clash, a proxy tool. It provides a list of DNS servers and fallback filters to be used by the program. The data is converted to YAML format and written into a file named \"Clash3.yaml\". Then, it sends an HTTP PUT request to the Clash API endpoint to update the configuration.",
        "type": "comment"
    },
    "4712": {
        "file_id": 591,
        "content": " url = \"https://raw.githubusercontents.com/yu-steven/openit/main/Clash.yaml\" # some subtle difference!\n    # url = 'https://cdn.staticaly.com/gh/yu-steven/openit/main/Clash.yaml'\n    # url = \"https://raw.kgithub.com/yu-steven/openit/main/Clash.yaml\"\n    r = requests.get(url)\n    with open(clashYamlPath, \"w+\") as f:\n        f.write(r.text)\n    print(\"FETCHING CLASH YAML DONE.\")\n    print(\"SAVED AT %s\" % clashYamlPath)\nfrom lazero.program import asyncThread\n@asyncThread\ndef updateClashYaml(clashYamlPath=\"Clash3.yaml\", control_port=9911, advanced=True):\n    getClashYaml(clashYamlPath=clashYamlPath)\n    # if refine:\n    refineClashYaml(clashYamlPath=clashYamlPath, advanced=advanced)\n    import requests\n    import json\n    full_config_path = os.path.abspath(clashYamlPath)\n    try:\n        r = requests.put(\n            \"http://localhost:{}/configs\".format(control_port),\n            data=json.dumps({\"path\": full_config_path}, ensure_ascii=False).encode(),\n        )\n        # print('REPLY CONTENT:',r.content)\n        # breakpoint()",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:240-269"
    },
    "4713": {
        "file_id": 591,
        "content": "This code fetches the latest Clash YAML configuration file from a specified URL and saves it to a local file. It then updates the Clash configuration by sending the updated file path to the Clash control port. The function can be called asynchronously with optional arguments for the Clash YAML file name, control port, and advanced settings refinement.",
        "type": "comment"
    },
    "4714": {
        "file_id": 591,
        "content": "        assert r.status_code == 204\n        # might be the problem.\n        # TODO: check why the fuck clash server cannot decode the config in utf-8 'unexpected end of data'\n        print(\"SUCCESSFULLY UPDATED THIS PROXY LIST\")\n        return True\n    except:\n        import traceback\n        traceback.print_exc()\n        # breakpoint()\n        print(\"SOME ERROR WHILE FETCHING CLASH OPENIT SCRIPT\")\n        return False\n# this can act as a server as well?\n# simplicity in mind.\nimport schedule\nschedule.every(30).minutes.do(updateClashYaml)\nupdateClashYaml()\nfrom flask import Flask, request\nport = 8677\napp = Flask(__name__)\ndef checkProxyExists(proxy):\n    return proxy in find_proxy_names()\n# from typing import Union\n@app.route(\"/\", methods=[\"GET\"])\ndef serverHello():\n    try:\n        schedule.run_pending()\n    except:\n        pass\n    return \"clash update controller\"\n@app.route(\"/checkProxy\", methods=[\"GET\"])\ndef checkProxyAPI():\n    proxy = request.args[\"proxy\"]\n    print(\"CHECKING PROXY:\", proxy)\n    exists = checkProxyExists(proxy)",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:270-318"
    },
    "4715": {
        "file_id": 591,
        "content": "The code is a Flask application that acts as a server, updates the Clash proxy list every 30 minutes, and provides two APIs: one to check if a proxy exists in the list and another for fetching the Clash OpenIT script. An error message is displayed when there's an issue while fetching the script, and it prints the exception stack trace using traceback. The application runs on port 8677.",
        "type": "comment"
    },
    "4716": {
        "file_id": 591,
        "content": "    return {\"exists\": exists}\n@app.route(\"/useDirect\", methods=[\"GET\"])\ndef useDirectAPI():\n    proxy_name = \"DIRECT\"\n    schedule.run_pending()\n    setClashProxy(proxy_name)\n    return \"refresh proxy to %s\" % proxy_name\n@app.route(\"/refreshProxy\", methods=[\"GET\"])\ndef refreshProxyAPI():\n    suggest = None\n    if \"suggest\" in request.args.keys():\n        suggest = request.args[\"suggest\"]\n        print(\"SUGGESTED PROXY:\", suggest)\n    schedule.run_pending()\n    if suggest:\n        if checkProxyExists(suggest):\n            setClashProxy(suggest)\n            return \"refresh suggested proxy to %s\" % suggest\n    proxy_names = find_proxy_names()\n    if proxy_names == []:\n        return \"failed to find a proxy\"\n    import random\n    proxy_name = random.choice(proxy_names)\n    setClashProxy(proxy_name)\n    return \"refresh proxy to %s\" % proxy_name\nif __name__ == \"__main__\":\n    app.run(port=port, threaded=True, use_reloader=False)",
        "type": "code",
        "location": "/tests/karaoke_effects/clash_auto_update.py:319-353"
    },
    "4717": {
        "file_id": 591,
        "content": "The code defines three routes (\"/useDirect\", \"/refreshProxy\") and a function to set the Clash proxy. The \"/useDirect\" route sets the proxy directly to DIRECT. The \"/refreshProxy\" route, if a suggested proxy is provided in the request, sets it as the current proxy. If not, it randomly selects one from available proxies. The code also runs pending tasks and checks if a proxy exists before setting it.",
        "type": "comment"
    },
    "4718": {
        "file_id": 592,
        "content": "/tests/karaoke_effects/pyonfx_test/view_best_example.sh",
        "type": "filepath"
    },
    "4719": {
        "file_id": 592,
        "content": "This command starts mpv player to display a karaoke video with subtitles. The \"Output.ass\" file contains the lyrics and timing information, and the \"karaoke_effects_source.mp4\" is the video being displayed.",
        "type": "summary"
    },
    "4720": {
        "file_id": 592,
        "content": "mpv --fs --no-audio --sub-file=\"/root/Desktop/works/pyjom/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass\" \"/root/Desktop/works/pyjom/samples/video/karaoke_effects_source.mp4\"",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/view_best_example.sh:1-1"
    },
    "4721": {
        "file_id": 592,
        "content": "This command starts mpv player to display a karaoke video with subtitles. The \"Output.ass\" file contains the lyrics and timing information, and the \"karaoke_effects_source.mp4\" is the video being displayed.",
        "type": "comment"
    },
    "4722": {
        "file_id": 593,
        "content": "/tests/karaoke_effects/pyonfx_test/test.py",
        "type": "filepath"
    },
    "4723": {
        "file_id": 593,
        "content": "The code initializes a variable 'lyricPath' with the path to the LRC file and imports modules 'pyonfx' and 'pylrc'.",
        "type": "summary"
    },
    "4724": {
        "file_id": 593,
        "content": "lyricPath = \"/root/Desktop/works/pyjom/tests/music_analysis/exciting_bgm.lrc\"\nimport pyonfx\nimport pylrc",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/test.py:1-3"
    },
    "4725": {
        "file_id": 593,
        "content": "The code initializes a variable 'lyricPath' with the path to the LRC file and imports modules 'pyonfx' and 'pylrc'.",
        "type": "comment"
    },
    "4726": {
        "file_id": 594,
        "content": "/tests/karaoke_effects/pyonfx_test/render_ass_video.sh",
        "type": "filepath"
    },
    "4727": {
        "file_id": 594,
        "content": "This command uses FFmpeg to extract a 60-second segment from the input video \"karaoke_effects_source.mp4\", applying the embedded ASS subtitles from \"Output.ass\" as effects, and saves the result as \"out.mp4\".",
        "type": "summary"
    },
    "4728": {
        "file_id": 594,
        "content": "ffmpeg -y -i \"/root/Desktop/works/pyjom/samples/video/karaoke_effects_source.mp4\" -ss 0 -to 60 -vf \"ass='/root/Desktop/works/pyjom/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass'\" out.mp4",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/render_ass_video.sh:1-1"
    },
    "4729": {
        "file_id": 594,
        "content": "This command uses FFmpeg to extract a 60-second segment from the input video \"karaoke_effects_source.mp4\", applying the embedded ASS subtitles from \"Output.ass\" as effects, and saves the result as \"out.mp4\".",
        "type": "comment"
    },
    "4730": {
        "file_id": 595,
        "content": "/tests/karaoke_effects/pyonfx_test/macos_view_best_example.sh",
        "type": "filepath"
    },
    "4731": {
        "file_id": 595,
        "content": "This script opens a video file with an ASS subtitle file, using mpv player in full screen and without audio. The ASS file contains karaoke effects for the associated video, sourced from pyjom_remote/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner folder.",
        "type": "summary"
    },
    "4732": {
        "file_id": 595,
        "content": "rootpath=/Users/jamesbrown/desktop/works/pyjom_remote/\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/macos_view_best_example.sh:1-2"
    },
    "4733": {
        "file_id": 595,
        "content": "This script opens a video file with an ASS subtitle file, using mpv player in full screen and without audio. The ASS file contains karaoke effects for the associated video, sourced from pyjom_remote/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner folder.",
        "type": "comment"
    },
    "4734": {
        "file_id": 596,
        "content": "/tests/karaoke_effects/pyonfx_test/first_try.py",
        "type": "filepath"
    },
    "4735": {
        "file_id": 596,
        "content": "This code imports the \"pyonfx\" library and uses it to open an ASS file. It then retrieves the file's metadata, styles, and lines of text. The first line's text is modified, and the modified line is written back into the file. The code also attempts to open Aegisub but fails as there isn't one available.",
        "type": "summary"
    },
    "4736": {
        "file_id": 596,
        "content": "from pyonfx import *\nio = Ass(\"in.ass\")\nmeta, styles, lines = io.get_data()\nlines[0].text = \"I am a new line!\"\nio.write_line(lines[0])\nio.save()\n# io.open_aegisub()\n# there's no aegisub.",
        "type": "code",
        "location": "/tests/karaoke_effects/pyonfx_test/first_try.py:1-11"
    },
    "4737": {
        "file_id": 596,
        "content": "This code imports the \"pyonfx\" library and uses it to open an ASS file. It then retrieves the file's metadata, styles, and lines of text. The first line's text is modified, and the modified line is written back into the file. The code also attempts to open Aegisub but fails as there isn't one available.",
        "type": "comment"
    },
    "4738": {
        "file_id": 597,
        "content": "/tests/karaoke_effects/lrc2ass_py3/test.sh",
        "type": "filepath"
    },
    "4739": {
        "file_id": 597,
        "content": "The code is running an MPV player with no audio, using a subtitle file and video source. It seems that the video's effect is bad, and the time synchronization is incorrect, causing dissatisfaction with the result.",
        "type": "summary"
    },
    "4740": {
        "file_id": 597,
        "content": "rootpath=/Users/jamesbrown/desktop/works/pyjom_remote/\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/lrc2ass_py3/output.s2.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"\n## NOT OK! THIS DUMB SHIT LIBRARY FUCKED MY MIND ##\n## the effect is bad. the time is not right. everything fucked. ##",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/test.sh:1-5"
    },
    "4741": {
        "file_id": 597,
        "content": "The code is running an MPV player with no audio, using a subtitle file and video source. It seems that the video's effect is bad, and the time synchronization is incorrect, causing dissatisfaction with the result.",
        "type": "comment"
    },
    "4742": {
        "file_id": 598,
        "content": "/tests/karaoke_effects/lrc2ass_py3/README.md",
        "type": "filepath"
    },
    "4743": {
        "file_id": 598,
        "content": "This Python 3 script converts LRC files to ASS format with karaoke effects, supports multiple timing tags, and auto-chooses end timings. It is primarily for Chinese but may encounter errors in non-Chinese languages or wrong text codings. Future improvements include English support, annotations, file list input, reusability, and debugging.",
        "type": "summary"
    },
    "4744": {
        "file_id": 598,
        "content": "# lrc2ass_py3\nA simple Python 3.x script is used for changing your LRC file into ASS subtitle with karaoke effect tags\nä¸€ä¸ªç”¨äºå°†LRCæ­Œè¯æ–‡ä»¶è½¬æ¢ä¸ºASSå­—å¹•æ–‡ä»¶çš„ç®€å•Pythonè„šæœ¬ã€‚\nThe first full python script written by myself.\næˆ‘è‡ªå·±ç¼–å†™çš„ç¬¬ä¸€ä¸ªå®Œæ•´çš„Pythonè„šæœ¬\nCopyright(c) 2020 yyfll (MIT)\n# WON'T UPDATE IN THE FUTURE\n# Dependent\n* chardet (lrc2ass_py3 >= 1.0.0c)\n# Update\n## 1.0.0c\n* Support chardet character encoding detector.\n* A few improvements\n## 1.0.0b\n* Support LRC offset tag.\n* Default LRC offset can be set.\n* Simplify program.\n# English Readme\nPoor English.\n## What can lrc2ass_py3 do?\n* Change your LRC script to ASS script.\n* Very easy to use.\n* Support Multi timing tags in a single line.\n* Support auto choose end timing if can't find timing in the end of the line.\n* Support LRC offset tag.\n## What will cause error?\n* A lrc file in wrong text coding (such as use utf-8 read gbk file.)\n* A lrc line without the timing tag in the line ahead. (haven't tested)\n## WARNING\n* Only CHINESE are supported.\n> All the information show in console and the annotations in python script are written in CHINESE,",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/README.md:1-41"
    },
    "4745": {
        "file_id": 598,
        "content": "This is a simple Python 3 script for converting LRC files to ASS with karaoke effects. It requires the chardet library, supports multiple timing tags, and auto-chooses end timings if not specified. However, it's only for Chinese and may encounter errors if the LRC file is in the wrong text coding or lacks a timing tag on certain lines.",
        "type": "comment"
    },
    "4746": {
        "file_id": 598,
        "content": ">\n> It doesn't mean lrc2ass_py3 can't work on your LRC in English.\n>\n> So it doesn't have any influence on output a correct ASS script if you use English or any other language.\n# ç®€ä½“ä¸­æ–‡ Readme\n## lrc2ass_py3å¯ä»¥åšä»€ä¹ˆï¼Ÿ\n* å°†ä½ çš„LRCæ­Œè¯æ–‡ä»¶è½¬æ¢ä¸ºASSå­—å¹•æ–‡ä»¶\n* ä½¿ç”¨èµ·æ¥éå¸¸ç®€å•\n* æ”¯æŒä¸€ä¸ªæ­Œè¯è¡Œå¤šä¸ªæ—¶é—´æ ‡ç­¾ï¼ˆå³å¡æ‹‰OKæ•ˆæœï¼‰\n* æ”¯æŒåœ¨æ‰¾ä¸åˆ°æ­Œè¯è¡Œçš„ç»“æŸæ—¶é—´æ—¶ï¼Œè‡ªåŠ¨é€‰æ‹©ç»“æŸæ—¶é—´\n* æ”¯æŒæ—¶é—´åç§»æ ‡ç­¾ï¼ˆoffsetï¼‰\n## æœ‰ä»€ä¹ˆå¯èƒ½ä¼šå¯¼è‡´é”™è¯¯çš„ï¼Ÿ\n* è¯»å–äº†éæŒ‡å®šæ–‡æœ¬ç¼–ç çš„LRCæ­Œè¯æ–‡ä»¶ï¼ˆæ¯”å¦‚åƒç”¨utf-8ç¼–ç è¯»å–gbkç¼–ç çš„æ–‡ä»¶ï¼‰\n* æ­Œè¯è¡Œå¼€å¤´æ²¡æœ‰æŒ‡å®šèµ·å§‹æ—¶é—´çš„æ—¶é—´æ ‡ç­¾ï¼ˆè¿™è¿˜æ²¡æœ‰ç»è¿‡æµ‹è¯•ï¼‰\n## è­¦å‘Š\n* åªæ”¯æŒä¸­æ–‡\n> æ‰€æœ‰çš„æ§åˆ¶å°è¾“å‡ºåŠæ–‡ä»¶å†…æ³¨é‡Šéƒ½æ˜¯ç”¨ä¸­æ–‡å†™çš„\n>\n> è¿™å¹¶ä¸æ„å‘³ç€lrc2ass_py3ä¸èƒ½å¤„ç†éä¸­æ–‡çš„LRCæ–‡ä»¶\n>\n> æ‰€ä»¥è¿™å¹¶ä¸ä¼šå¯¹è¾“å‡ºä¸€ä¸ªæ­£ç¡®ASSå­—å¹•æ–‡ä»¶äº§ç”Ÿä»»ä½•å½±å“\n# To do\n* Full English supported\n* Full Chinese annotation\n* File list input\n* Reusable\n* Endless debugging",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/README.md:42-72"
    },
    "4747": {
        "file_id": 598,
        "content": "This code is a README file for the lrc2ass_py3 tool, which converts LRC karaoke files to ASS format. It supports English and other languages, but has warnings and limitations related to non-Chinese languages and specific encoding formats. The code also includes a To Do list with additional features such as full English support, improved annotations, file list input, reusability, and debugging.",
        "type": "comment"
    },
    "4748": {
        "file_id": 599,
        "content": "/tests/karaoke_effects/lrc2ass_py3/localTest.sh",
        "type": "filepath"
    },
    "4749": {
        "file_id": 599,
        "content": "Code is running mpv player with no audio and loading an .ass subtitle file to display over a video. The user is experiencing issues with the output.",
        "type": "summary"
    },
    "4750": {
        "file_id": 599,
        "content": "rootpath=/root/Desktop/works/pyjom\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/lrc2ass_py3/output.s2.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"\n## NOT OK! THIS DUMB SHIT LIBRARY FUCKED MY MIND ##\n## the effect is bad. the time is not right. everything fucked. ##",
        "type": "code",
        "location": "/tests/karaoke_effects/lrc2ass_py3/localTest.sh:1-5"
    },
    "4751": {
        "file_id": 599,
        "content": "Code is running mpv player with no audio and loading an .ass subtitle file to display over a video. The user is experiencing issues with the output.",
        "type": "comment"
    },
    "4752": {
        "file_id": 600,
        "content": "/tests/post_numpy_array/server.py",
        "type": "filepath"
    },
    "4753": {
        "file_id": 600,
        "content": "The code sets up a FastAPI server on port 5463, defines an endpoint that receives an image and returns \"good\", and runs a non-blocking Uvicorn server.",
        "type": "summary"
    },
    "4754": {
        "file_id": 600,
        "content": "SERVER_PORT=5463\nif __name__ == '__main__':\n    # from pydantic import BaseModel\n    # import numpy as np\n    import numpy_serializer\n    # from typing import Union\n    # class Image(BaseModel):\n    #     image:Union[str,bytes]\n    from fastapi import FastAPI, Body\n    app = FastAPI()\n    @app.post(\"/\")\n    def receiveImage(image:bytes=Body(default=None),\n        isBytes:bool =False,\n    encoding:str='utf-8', debug:bool=False):\n        # return book\n        # print('image type:',type(image))\n        # print(image)\n        import urllib.parse\n        image = image.removeprefix(b'image=') # fuck man.\n        image = urllib.parse.unquote_to_bytes(image)\n        if debug:\n            print(\"isBytes:\",isBytes)\n        if not isBytes:\n            image = image.decode(encoding) #fuck?\n            # read image from path, url\n        else:\n            image = numpy_serializer.from_bytes(image)\n        if debug:\n            print('shape?',image.shape)\n            print('image?',image)\n        return \"good\"\n    import uvicorn\n ",
        "type": "code",
        "location": "/tests/post_numpy_array/server.py:2-39"
    },
    "4755": {
        "file_id": 600,
        "content": "This code is setting up a FastAPI server on port 5463. It defines an endpoint at the root (\"/\") that receives an image either in bytes or as a string, and returns \"good\" as a response. The image data can be decoded from bytes using numpy_serializer or read from a file or URL if it's received as a string.",
        "type": "comment"
    },
    "4756": {
        "file_id": 600,
        "content": "   # checking: https://9to5answer.com/python-how-to-use-fastapi-and-uvicorn-run-without-blocking-the-thread\n    def run(host='0.0.0.0',port=SERVER_PORT): \n        \"\"\"\n        This function to run configured uvicorn server.\n        \"\"\"\n        uvicorn.run(app=app, host=host, port=port)\n    run()",
        "type": "code",
        "location": "/tests/post_numpy_array/server.py:39-46"
    },
    "4757": {
        "file_id": 600,
        "content": "This function runs a configured Uvicorn server non-blocking, allowing concurrent tasks.",
        "type": "comment"
    },
    "4758": {
        "file_id": 601,
        "content": "/tests/post_numpy_array/client.py",
        "type": "filepath"
    },
    "4759": {
        "file_id": 601,
        "content": "Importing numpy, requests, and numpy_serializer; using SERVER_PORT from server module; creating a test image array; converting the image to bytes using numpy_serializer; sending the image data as a POST request to localhost; printing the response received. Includes a malformatted docstring function with textwrap usage.",
        "type": "summary"
    },
    "4760": {
        "file_id": 601,
        "content": "import numpy as np\nimport requests\nimport numpy_serializer\n# this is pure magic. shit.\nfrom server import SERVER_PORT\nimage = np.array([1,2,3])\nimage_bytes = numpy_serializer.to_bytes(image)\ndata = {'image':image_bytes}\nprint(\"BYTES?\", image_bytes)\nr = requests.post(\"http://localhost:{}\".format(SERVER_PORT),data=data,params={'isBytes':True,'debug':True})\nprint('RESPONSE?',r.text)\ndef docstring(): # malformat\n    import textwrap\n    a =\"\"\"\n    lmn\n    abcdefg \n    hijk\n    \"\"\"\n    print(a)\n    print()\n    print(textwrap.dedent(a))\n    # inspect.cleandoc\n    # https://9to5answer.com/how-to-remove-extra-indentation-of-python-triple-quoted-multi-line-strings\ndocstring()",
        "type": "code",
        "location": "/tests/post_numpy_array/client.py:1-28"
    },
    "4761": {
        "file_id": 601,
        "content": "Importing numpy, requests, and numpy_serializer; using SERVER_PORT from server module; creating a test image array; converting the image to bytes using numpy_serializer; sending the image data as a POST request to localhost; printing the response received. Includes a malformatted docstring function with textwrap usage.",
        "type": "comment"
    },
    "4762": {
        "file_id": 602,
        "content": "/tests/patch_requests_timeout/server.py",
        "type": "filepath"
    },
    "4763": {
        "file_id": 602,
        "content": "This code sets up a FastAPI server using uvicorn, listens on port 9341, and has a single route (\"/\") that returns \"hello world\" after a 10-second delay. The run() function is used to start the configured uvicorn server.",
        "type": "summary"
    },
    "4764": {
        "file_id": 602,
        "content": "SERVER_PORT = 9341\nif __name__ == \"__main__\":\n    from fastapi import FastAPI\n    app = FastAPI()\n    import time\n    @app.get(\"/\")\n    def receiveImage():\n        time.sleep(10)\n        return \"hello world\"\n    import uvicorn\n    # checking: https://9to5answer.com/python-how-to-use-fastapi-and-uvicorn-run-without-blocking-the-thread\n    def run(host='0.0.0.0',port=SERVER_PORT): \n        \"\"\"\n        This function to run configured uvicorn server.\n        \"\"\"\n        uvicorn.run(app=app, host=host, port=port)\n    run()",
        "type": "code",
        "location": "/tests/patch_requests_timeout/server.py:1-21"
    },
    "4765": {
        "file_id": 602,
        "content": "This code sets up a FastAPI server using uvicorn, listens on port 9341, and has a single route (\"/\") that returns \"hello world\" after a 10-second delay. The run() function is used to start the configured uvicorn server.",
        "type": "comment"
    },
    "4766": {
        "file_id": 603,
        "content": "/tests/patch_requests_timeout/client.py",
        "type": "filepath"
    },
    "4767": {
        "file_id": 603,
        "content": "This code patches the requests library to set a default timeout for all requests made using it. It uses patchy module to modify the HTTPAdapter's send method, checking if a timeout is provided and setting it to REQUESTS_TIMEOUT (3 seconds) if none is given. The patch is then applied using the patchy module.",
        "type": "summary"
    },
    "4768": {
        "file_id": 603,
        "content": "import patchy\nfrom requests.adapters import HTTPAdapter\nREQUESTS_TIMEOUT=3 # working! great.\ndef patch_requests_default_timeout() -> None:\n    \"\"\"\n    Set a default timeout for all requests made with â€œrequestsâ€.\n    Upstream is waiting on this longstanding issue:\n    https://github.com/psf/requests/issues/3070\n    \"\"\"\n    patchy.patch(\n        HTTPAdapter.send,\n        f\"\"\"\\\n        @@ -14,6 +14,8 @@\n             :param proxies: (optional) The proxies dictionary to apply to the request.\n             :rtype: requests.Response\n             \\\"\"\"\n        +    if timeout is None:\n        +        timeout = {REQUESTS_TIMEOUT}\n             try:\n                 conn = self.get_connection(request.url, proxies)\n        \"\"\",\n    )\npatch_requests_default_timeout()\nimport requests\nfrom server import SERVER_PORT\nr = requests.get(f\"http://localhost:{SERVER_PORT}\")",
        "type": "code",
        "location": "/tests/patch_requests_timeout/client.py:2-36"
    },
    "4769": {
        "file_id": 603,
        "content": "This code patches the requests library to set a default timeout for all requests made using it. It uses patchy module to modify the HTTPAdapter's send method, checking if a timeout is provided and setting it to REQUESTS_TIMEOUT (3 seconds) if none is given. The patch is then applied using the patchy module.",
        "type": "comment"
    },
    "4770": {
        "file_id": 604,
        "content": "/tests/optical_flow/sparse_cpu.py",
        "type": "filepath"
    },
    "4771": {
        "file_id": 604,
        "content": "The code initializes an App object, tracks key points using PyrLK algorithm, calculates optical flow between frames, maintains maximum length of tracks and displays results. It uses OpenCV, numpy and Flownet2-pytorch model for processing and detecting key points.",
        "type": "summary"
    },
    "4772": {
        "file_id": 604,
        "content": "#coding=utf-8\nimport numpy as np\nimport cv2\n# from common import anorm2, draw_str\n# from time import clock\nimport cmath\nlk_params = dict(winSize=(15, 15),\n                 maxLevel=2,\n                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n# maxCorners : è®¾ç½®æœ€å¤šè¿”å›çš„å…³é”®ç‚¹æ•°é‡ã€‚\n# qualityLevel : ååº”ä¸€ä¸ªåƒç´ ç‚¹å¼ºåº¦æœ‰å¤šå¼ºæ‰èƒ½æˆä¸ºå…³é”®ç‚¹ã€‚\n# minDistance : å…³é”®ç‚¹ä¹‹é—´çš„æœ€å°‘åƒç´ ç‚¹ã€‚\n# blockSize : è®¡ç®—ä¸€ä¸ªåƒç´ ç‚¹æ˜¯å¦ä¸ºå…³é”®ç‚¹æ—¶æ‰€å–çš„åŒºåŸŸå¤§å°ã€‚\n# useHarrisDetector :ä½¿ç”¨åŸå£°çš„ Harris è§’ä¾¦æµ‹å™¨æˆ–æœ€å°ç‰¹å¾å€¼æ ‡å‡†ã€‚\n# k : ä¸€ä¸ªç”¨åœ¨Harrisä¾¦æµ‹å™¨ä¸­çš„è‡ªç”±å˜é‡ã€‚\nfeature_params = dict(maxCorners=5000000,\n                      qualityLevel=0.1,\n                      minDistance=7,\n                      blockSize=7)\nclass App:\n    def __init__(self, video_src):  # æ„é€ æ–¹æ³•ï¼Œåˆå§‹åŒ–ä¸€äº›å‚æ•°å’Œè§†é¢‘è·¯å¾„\n        self.track_len = 10\n        self.detect_interval = 1\n        self.tracks = []\n        self.cam = cv2.VideoCapture(video_src)\n        self.frame_idx = 0\n        self.num = 0\n        self.i = 0\n        self.all_distance = 0\n        self.count = 0\n    def run(self):  # å…‰æµè¿è¡Œæ–¹æ³•\n        while True:\n            ret, frame = self.cam.read()  # è¯»å–è§†é¢‘å¸§",
        "type": "code",
        "location": "/tests/optical_flow/sparse_cpu.py:1-37"
    },
    "4773": {
        "file_id": 604,
        "content": "App class initialization and video reading\n\nCode for creating and initializing the App object, capturing video frames from a specified source.",
        "type": "comment"
    },
    "4774": {
        "file_id": 604,
        "content": "            if ret == True:\n                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # è½¬åŒ–ä¸ºç°åº¦è™šå›¾åƒ\n                # vis = frame.copy()\n                h, w = frame.shape[:2]\n                vis = np.ones((h, w), )\n                f = open('./shuibo_8_LK(x1,y1,x2,y2).txt','w+')\n                if len(self.tracks) > 0:  # æ£€æµ‹åˆ°è§’ç‚¹åè¿›è¡Œå…‰æµè·Ÿè¸ª\n                    img0, img1 = self.prev_gray, frame_gray\n                    p0 = np.float32([tr[-1] for tr in self.tracks]).reshape(-1, 1, 2)\n                    \"\"\"\n                    nextPts, status, err = calcOpticalFlowPyrLK(prevImg, nextImg, prevPts[, nextPts[, status[, \n                    err[, winSize[, maxLevel[, criteria[, flags[, minEigThreshold]]]]]]]])\n                    å‚æ•°è¯´æ˜ï¼š\n                      prevImage å‰ä¸€å¸§8-bitå›¾åƒ\n                      nextImage å½“å‰å¸§8-bitå›¾åƒ\n                      prevPts å¾…è·Ÿè¸ªçš„ç‰¹å¾ç‚¹å‘é‡\n                      nextPts è¾“å‡ºè·Ÿè¸ªç‰¹å¾ç‚¹å‘é‡\n                      status ç‰¹å¾ç‚¹æ˜¯å¦æ‰¾åˆ°ï¼Œæ‰¾åˆ°çš„çŠ¶æ€ä¸º1ï¼Œæœªæ‰¾åˆ°çš„çŠ¶æ€ä¸º0\n                      err è¾“å‡ºé”™è¯¯å‘é‡ï¼Œï¼ˆä¸å¤ªç†è§£ç”¨é€”...ï¼‰\n                      winSize æœç´¢çª—å£çš„å¤§å°",
        "type": "code",
        "location": "/tests/optical_flow/sparse_cpu.py:38-58"
    },
    "4775": {
        "file_id": 604,
        "content": "This code is performing optical flow tracking using the Pyramid Lucas-Kanade algorithm (PyrLK) on a video frame. It reads the previous and current frames, detects key points in the previous frame, calculates the new positions of these key points in the current frame, and updates the tracks list if any key point is found. The status array indicates whether each tracked point was found or not, and err presumably contains error information related to tracking. The code writes the x and y coordinates of each tracked point to a text file.",
        "type": "comment"
    },
    "4776": {
        "file_id": 604,
        "content": "                      maxLevel æœ€å¤§çš„é‡‘å­—å¡”å±‚æ•°\n                      flags å¯é€‰æ ‡è¯†ï¼šOPTFLOW_USE_INITIAL_FLOW   OPTFLOW_LK_GET_MIN_EIGENVALS\n                    \"\"\"\n                    p1, st, err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None,\n                                                           **lk_params)  # å‰ä¸€å¸§çš„è§’ç‚¹å’Œå½“å‰å¸§çš„å›¾åƒä½œä¸ºè¾“å…¥æ¥å¾—åˆ°è§’ç‚¹åœ¨å½“å‰å¸§çš„ä½ç½®\n                    p0r, st, err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None,\n                                                            **lk_params)  # å½“å‰å¸§è·Ÿè¸ªåˆ°çš„è§’ç‚¹åŠå›¾åƒå’Œå‰ä¸€å¸§çš„å›¾åƒä½œä¸ºè¾“å…¥æ¥æ‰¾åˆ°å‰ä¸€å¸§çš„è§’ç‚¹ä½ç½®\n                    d = abs(p0 - p0r).reshape(-1, 2).max(-1)  # å¾—åˆ°è§’ç‚¹å›æº¯ä¸å‰ä¸€å¸§å®é™…è§’ç‚¹çš„ä½ç½®å˜åŒ–å…³ç³»\n                    # good = d < 1  # åˆ¤æ–­då†…çš„å€¼æ˜¯å¦å°äº1ï¼Œå¤§äº1è·Ÿè¸ªè¢«è®¤ä¸ºæ˜¯é”™è¯¯çš„è·Ÿè¸ªç‚¹\n                    good=d\n                    new_tracks = []\n                    for tr, (x, y), good_flag in zip(self.tracks, p1.reshape(-1, 2), good):  # å°†è·Ÿè¸ªæ­£ç¡®çš„ç‚¹åˆ—å…¥æˆåŠŸè·Ÿè¸ªç‚¹\n                        if not good_flag:\n                            continue\n                        tr.append((x, y))#træ˜¯å‰ä¸€å¸§çš„è§’ç‚¹ï¼Œä¸å½“å‰å¸§çš„è§’ç‚¹(x,y)åˆå¹¶ã€‚æ ‡å¿—ä¸ºgood_flag",
        "type": "code",
        "location": "/tests/optical_flow/sparse_cpu.py:59-74"
    },
    "4777": {
        "file_id": 604,
        "content": "This code calculates optical flow between two images using cv2.calcOpticalFlowPyrLK, tracking points from one image to another. It then compares the tracked points with the actual points and measures the displacement. Points with displacement greater than 1 are considered as incorrect and removed. The remaining points form new_tracks, which is a list of successful tracks.",
        "type": "comment"
    },
    "4778": {
        "file_id": 604,
        "content": "                        if len(tr) > self.track_len:\n                            del tr[0]\n                        new_tracks.append(tr)\n                        # print(x,y)\n                        # breakpoint()\n                        cv2.circle(vis, (int(x), int(y)), 2, (0, 255, 0), -1)#å½“å‰å¸§è§’ç‚¹ç”»åœ†\n                    self.tracks = new_tracks #self.tracksä¸­çš„å€¼çš„æ ¼å¼æ˜¯ï¼š(å‰ä¸€å¸§è§’ç‚¹)(å½“å‰å¸§è§’ç‚¹)\n                    # print(self.tracks[0])\n                    # print(self.tracks[1])\n                    distance = 0\n                    for tr in self.tracks:\n                        # tr[0]=list(tr[0])\n                        # tr[1]=list(tr[1])\n                        x1=tr[0][0]\n                        y1=tr[0][1]\n                        x2 = tr[1][0]\n                        y2 = tr[1][1]\n                        f.writelines([ str(x1), ' ', str(y1), ' ', str(x2), ' ', str(y2),'\\n'])\n                        dis=cmath.sqrt((x2-x1)*(x2-x1)+(y2-y1)*(y2-y1))\n                        #æ­£ç¡®è¿½è¸ªçš„ç‚¹çš„ä¸ªæ•°\n                        print(len(self.tracks))",
        "type": "code",
        "location": "/tests/optical_flow/sparse_cpu.py:75-98"
    },
    "4779": {
        "file_id": 604,
        "content": "This code tracks optical flow points across multiple frames, storing the tracked points in 'tracks'. It appends new tracks and deletes old ones to maintain a maximum length. The x and y coordinates of current points are plotted on a visualization ('vis'). Finally, it calculates the Euclidean distance between consecutive points and writes them into file 'f', while printing the total number of correctly tracked points.",
        "type": "comment"
    },
    "4780": {
        "file_id": 604,
        "content": "                        #æ¯ä¸€ä¸ªæ­£ç¡®è¿½è¸ªçš„ç‚¹çš„åƒç´ ç‚¹çš„ä½ç§»\n                        print(dis.real)\n                        distance=distance+dis\n                    len_tracks = len(self.tracks)\n                    if len_tracks == 0:continue\n                    distance=distance/len_tracks\n                    self.all_distance=self.all_distance+distance\n                    self.count=self.count+1\n                    print(\"æ¯ä¸€å¸§åƒç´ ç‚¹å¹³å‡ä½ç§»ï¼š\",distance,\"ç¬¬å‡ å¸§ï¼š\",self.count)\n                    print(\"æ‰€æœ‰å¸§å¹³å‡ä½ç§»ï¼š\",(self.all_distance/self.count).real)\n                f.close()\n                if self.frame_idx % self.detect_interval == 0:  #æ¯1å¸§æ£€æµ‹ä¸€æ¬¡ç‰¹å¾ç‚¹\n                    mask = np.zeros_like(frame_gray)  # åˆå§‹åŒ–å’Œè§†é¢‘å¤§å°ç›¸åŒçš„å›¾åƒ\n                    mask[:] = 255  # å°†maskèµ‹å€¼255ä¹Ÿå°±æ˜¯ç®—å…¨éƒ¨å›¾åƒçš„è§’ç‚¹\n                    for x, y in [np.int32(tr[-1]) for tr in self.tracks]:  #è·Ÿè¸ªçš„è§’ç‚¹ç”»åœ†\n                        cv2.circle(mask, (x, y), 5, 0, -1)\n                    p = cv2.goodFeaturesToTrack(frame_gray, mask=mask, **feature_params)  # åƒç´ çº§åˆ«è§’ç‚¹æ£€æµ‹\n                    if p is not None:",
        "type": "code",
        "location": "/tests/optical_flow/sparse_cpu.py:99-117"
    },
    "4781": {
        "file_id": 604,
        "content": "Code calculates average pixel point displacement between frames and prints the results. It keeps track of all pixel point movements in a frame and counts the number of frames. The code checks for features every 1 frame, initializes a mask image, detects corners using goodFeaturesToTrack function, and stores the result if it is not None.",
        "type": "comment"
    },
    "4782": {
        "file_id": 604,
        "content": "                        for x, y in np.float32(p).reshape(-1, 2):\n                            self.tracks.append([(x, y)])  # å°†æ£€æµ‹åˆ°çš„è§’ç‚¹æ”¾åœ¨å¾…è·Ÿè¸ªåºåˆ—ä¸­\n                self.frame_idx += 1\n                self.prev_gray = frame_gray\n                cv2.imshow('lk_track', vis)\n            # ch = 0xFF & \n            if cv2.waitKey(20) == \"q\":\n                # cv2.imwrite(\"./mashiti-result4.png\", vis)\n                break\n# # get flownet2-pytorch source\n# git clone https://github.com/NVIDIA/flownet2-pytorch.git\n# cd flownet2-pytorch\n# # install custom layers\n# bash install.sh\ndef main():\n    import sys\n    try:\n        video_src = sys.argv[1]\n    except:\n        # video_src = \"./F/8/shuibo_8.avi\"\n        video_src = \"/media/root/help/pyjom/samples/video/dog_with_text.mp4\"\n    # print\n    # __doc__\n    App(video_src).run()\n    cv2.destroyAllWindows()\nif __name__ == '__main__':\n    main()",
        "type": "code",
        "location": "/tests/optical_flow/sparse_cpu.py:118-151"
    },
    "4783": {
        "file_id": 604,
        "content": "This code is a part of a video processing program. It reads frames from a video source, detects key points in each frame using the LK tracker, tracks these key points across successive frames to estimate optical flow, and displays the results. The code uses OpenCV library for image processing, numpy for numerical computations, and cv2.waitKey() function for window handling. It also imports a Flownet2-pytorch model from a git repository and installs custom layers.",
        "type": "comment"
    },
    "4784": {
        "file_id": 605,
        "content": "/tests/optical_flow/nvidia_of_test.py",
        "type": "filepath"
    },
    "4785": {
        "file_id": 605,
        "content": "The code converts video frames to grayscale, creates an optical flow object, and uploads the first two frames to GPU for calculation. It downloads a GPU flow, visualizes it using flow_vis library, displays in a window, and quits on 'q'. No garbage collection is performed.",
        "type": "summary"
    },
    "4786": {
        "file_id": 605,
        "content": "from nvidia_common import *\nimport numpy as np \nimport cv2\nimport flow_vis\nvideo_file = \"/media/root/help/pyjom/samples/video/dog_with_text.mp4\"\n# this is the fastest.\nvideo = cv2.VideoCapture(video_file)\nret, img = video.read()\nprevImg = img.copy()\nwhile True:\n    ret, img = video.read()\n    if img is None: break\n    else:\n        frame1 = prevImg\n        frame1 = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n        frame2 = img # why freaking grayscale?\n        frame2 =  cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n        prevImg = img.copy()\n        perfPreset = 5\n        gpuId=0\n        # nvof = cv2.cuda_NvidiaOpticalFlow_2_0.create((frame1.shape[1], frame1.shape[0]),5, False, False, False, 0)\n        gpu_flow =cv2.cuda_FarnebackOpticalFlow.create(5, 0.5, False,\n                                                        15, 3, 5, 1.2, 0)\n        gpu_frame_a = cv2.cuda_GpuMat()\n        gpu_frame_b = cv2.cuda_GpuMat()\n        gpu_frame_a.upload(frame1)\n        gpu_frame_b.upload(frame2)\n        # -- exec flow --\n        gpu_flow = cv2.cuda_FarnebackOpticalFlow.calc(gpu_flow, gpu_frame_a,",
        "type": "code",
        "location": "/tests/optical_flow/nvidia_of_test.py:1-36"
    },
    "4787": {
        "file_id": 605,
        "content": "Reading video file, converting frames to grayscale, creating optical flow object with specified parameters, and uploading the first two frames to GPU for calculation.",
        "type": "comment"
    },
    "4788": {
        "file_id": 605,
        "content": "                                                      gpu_frame_b, None)\n        gpu_flow = gpu_flow.download()\n        # gpu_flow = gpu_flow.transpose(2,0,1)\n        # print(gpu_flow.shape())\n        # breakpoint()\n        # gpu_flow = th.from_numpy(gpu_flow).half()\n        # cv2.writeOpticalFlow('OpticalFlow.flo', flowUpSampled)\n        visualize = flow_vis.flow_to_color(gpu_flow, convert_to_bgr=False)\n        cv2.imshow(\"OPTFLOW\",visualize)\n        if cv2.waitKey(20) == chr(\"q\"):\n            print(\"QUIT THIS SHIT\")\n            break\n        # nvof.collectGarbage()",
        "type": "code",
        "location": "/tests/optical_flow/nvidia_of_test.py:37-53"
    },
    "4789": {
        "file_id": 605,
        "content": "This code downloads a GPU flow, potentially transposes it and prints its shape, then visualizes the flow using flow_vis library. It displays the visualization in a window and quits when 'q' is pressed. No garbage collection is performed.",
        "type": "comment"
    },
    "4790": {
        "file_id": 606,
        "content": "/tests/optical_flow/nvidia_common.py",
        "type": "filepath"
    },
    "4791": {
        "file_id": 606,
        "content": "This code is for setting the path to the OpenCV library for Turing architecture. It first determines the site-packages directory and then checks if there's a specific folder for the current Python version containing .so files, which are loaded into sys.path. If only one such folder exists, it gets added to sys.path before importing cv2. The code prints dir(cv2) for information or potentially debugging purposes.",
        "type": "summary"
    },
    "4792": {
        "file_id": 606,
        "content": "import pathlib\nimport site\nimport sys\n# optical flow sdk is exclusively for Turing architecture.\n# this is root. this is not site-packages.\n# site_path = pathlib.Path([x for x in site.getsitepackages() if \"site-packages\" in x][0])\nsite_path = pathlib.Path(\"/usr/local/lib/python3.9/site-packages\")\ncv2_libs_dir = site_path / 'cv2' / f'python-{sys.version_info.major}.{sys.version_info.minor}'\nprint(cv2_libs_dir)\ncv2_libs = sorted(cv2_libs_dir.glob(\"*.so\"))\nif len(cv2_libs) == 1:\n    print(\"INSERTING:\",cv2_libs[0].parent)\n    sys.path.insert(1, str(cv2_libs[0].parent))\nimport cv2\nprint(dir(cv2)) # shit?",
        "type": "code",
        "location": "/tests/optical_flow/nvidia_common.py:1-19"
    },
    "4793": {
        "file_id": 606,
        "content": "This code is for setting the path to the OpenCV library for Turing architecture. It first determines the site-packages directory and then checks if there's a specific folder for the current Python version containing .so files, which are loaded into sys.path. If only one such folder exists, it gets added to sys.path before importing cv2. The code prints dir(cv2) for information or potentially debugging purposes.",
        "type": "comment"
    },
    "4794": {
        "file_id": 607,
        "content": "/tests/optical_flow/mmof_test/get_frame_flow.py",
        "type": "filepath"
    },
    "4795": {
        "file_id": 607,
        "content": "This code reads frames from a video file, converts them to grayscale (optional), and saves the 40th frame as \"frame0.png\" and the next frame as \"frame1.png\". The loop continues until it encounters an empty frame (none) indicating the end of the video.",
        "type": "summary"
    },
    "4796": {
        "file_id": 607,
        "content": "import cv2\nvideo_file = \"/media/root/help/pyjom/samples/video/dog_with_text.mp4\"\nvideo = cv2.VideoCapture(video_file)\nret, img = video.read()\nprevImg = img.copy()\ncounter = 0\nwhile True:\n    ret, img = video.read()\n    if img is None: break\n    else:\n        frame1 = prevImg\n        # frame1 = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n        frame2 = img # why freaking grayscale?\n        # frame2 =  cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n        if counter == 40:\n            cv2.imwrite(\"frame0.png\",frame1)\n            cv2.imwrite(\"frame1.png\",frame2)\n        prevImg = img.copy()\n        counter +=1",
        "type": "code",
        "location": "/tests/optical_flow/mmof_test/get_frame_flow.py:1-23"
    },
    "4797": {
        "file_id": 607,
        "content": "This code reads frames from a video file, converts them to grayscale (optional), and saves the 40th frame as \"frame0.png\" and the next frame as \"frame1.png\". The loop continues until it encounters an empty frame (none) indicating the end of the video.",
        "type": "comment"
    },
    "4798": {
        "file_id": 608,
        "content": "/tests/optical_flow/mmof_test/execute_me.py",
        "type": "filepath"
    },
    "4799": {
        "file_id": 608,
        "content": "This code initializes an MMFlow model and performs optical flow calculation on video frames, visualizing results and breaking the loop when \"q\" is pressed. It uses BGR to grayscale conversion and can perform Canny edge detection.",
        "type": "summary"
    }
}