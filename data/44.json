{
    "4400": {
        "file_id": 573,
        "content": "/tests/topic_modeling/english_test.py",
        "type": "filepath"
    },
    "4401": {
        "file_id": 573,
        "content": "This code utilizes NLTK, Spacy and TextBlob for text preprocessing, stemming, lemmatization, and token iteration. It processes tokens, collects POS and text values, stores them, and checks for \"-PRON-\" absence.",
        "type": "summary"
    },
    "4402": {
        "file_id": 573,
        "content": "# https://huggingface.co/spacy/en_core_web_sm\n# https://medium.com/analytics-vidhya/nlp-essentials-removing-stopwords-and-performing-text-normalization-using-nltk-and-spacy-in-python-2c4024d2e343\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom lazero.utils import inspectObject\n# metalazero belongs to lazero package.\nset(stopwords.words(\"english\"))\ntext = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \nindeed the vaguest idea where the wood and river in question were.\"\"\"\nstop_words = set(stopwords.words(\"english\"))\nword_tokens = word_tokenize(text)\nfiltered_sentence = []\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)\nStem_words = []\nps = PorterStemmer()\nfor w in filtered_sentence:\n    rootWord = ps.stem(w)\n    Stem_words.append(rootWord)",
        "type": "code",
        "location": "/tests/topic_modeling/english_test.py:1-30"
    },
    "4403": {
        "file_id": 573,
        "content": "This code uses NLTK and Spacy libraries to perform text preprocessing. It loads the English stopwords, tokenizes the input text, removes stopwords, applies stemming using PorterStemmer, and stores the resulting words in Stem_words list.",
        "type": "comment"
    },
    "4404": {
        "file_id": 573,
        "content": "print(filtered_sentence) # 1st step\nprint(Stem_words) # 3rd step\n# from textblob lib import Word method\n# if textblobTest:\nfrom textblob import Word\ntext = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \nfishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \nindeed the vaguest idea where the wood and river in question were.\"\"\"\nlem = []\nfor i in text.split():\n    word1 = Word(i).lemmatize(\"n\")\n    word2 = Word(word1).lemmatize(\"v\")\n    word3 = Word(word2).lemmatize(\"a\")\n    lem.append(Word(word3).lemmatize())\nprint(lem) # incorrect and shitty. don't know what is its use\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\ndoc = nlp(\n    \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had indeed the vaguest idea where the wood and river in question were.\"\"\"",
        "type": "code",
        "location": "/tests/topic_modeling/english_test.py:31-56"
    },
    "4405": {
        "file_id": 573,
        "content": "Code imports the TextBlob library and uses lemmatization to simplify words in a given text. It first prints the original list of lemmatized words, then loads the English language model from TextBlob, and applies it to the same text, likely resulting in similar but potentially different lemmatized words. The purpose of this code is unclear due to incorrect usage and possible redundancy.",
        "type": "comment"
    },
    "4406": {
        "file_id": 573,
        "content": ")\n# the sentence spliter includes unwanted \"\\n\" char\nlemma_word1 = []\n# this shit has the lang tag. it might be useful for language detection. really?\nfor token in doc:\n    # print(\"LEMMA\", token.lemma_)\n    # not reliable.\n    # ['ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_dep', 'has_extension', 'has_head', 'has_morph', 'has_vector', 'head', 'i', 'idx', 'iob_strings', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_end', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'pref",
        "type": "code",
        "location": "/tests/topic_modeling/english_test.py:57-66"
    },
    "4407": {
        "file_id": 573,
        "content": "This code segment seems to be part of a natural language processing (NLP) task. It appears to be iterating through each token in the given document and potentially performing some operations or extractions on them. The variable 'lemma_word1' is initially empty but will presumably store lemmatized words from the tokens, which could be useful for further analysis.",
        "type": "comment"
    },
    "4408": {
        "file_id": 573,
        "content": "ix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'set_morph', 'shape', 'shape_', 'similarity', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n    # print(dir(token))\n    # breakpoint()\n    # inspectObject(token)\n    elem = (token.pos_, token.text)\n    # breakpoint()\n    lemma_word1.append(elem)\nprint(lemma_word1)  # there is no such -PRON- thing.\n# 2nd step.",
        "type": "code",
        "location": "/tests/topic_modeling/english_test.py:66-74"
    },
    "4409": {
        "file_id": 573,
        "content": "The code appears to be processing tokens and collecting their pos (part of speech) and text values. These values are stored in the lemma_word1 list for further use, while a \"breakpoint()\" is included for debugging purposes, and a print statement shows that there is no \"-PRON-\" element present. The code continues with a 2nd step, implying further processing may follow.",
        "type": "comment"
    },
    "4410": {
        "file_id": 574,
        "content": "/tests/update_progressbar_network/test.py",
        "type": "filepath"
    },
    "4411": {
        "file_id": 574,
        "content": "This FastAPI server allows progress updates via network, with endpoints for starting, resetting, and updating tqdm progress bars, along with functions for opening and closing the progress bar.",
        "type": "summary"
    },
    "4412": {
        "file_id": 574,
        "content": "# try to update progressbar via network.\nfrom fastapi import FastAPI\napp = FastAPI()\nfrom tqdm import tqdm\nt = None\n@app.get('/')\ndef hello():\n    return 'progressbar server'\n# not routing this to network.\ndef close_progressbar():\n    global t\n    if t is not None:\n        try:\n            t.close()\n            return {'msg':'success'}\n        except:\n            import traceback\n            traceback.print_exc()\n            print('error closing progressbar')\n            return {'msg':'error closing progressbar'}\n@app.get('/reset')\ndef reset(total: int, name:str='random task'): # pass the iteration count\n    global t\n    close_progressbar()\n    print('processing:', name)\n    t = tqdm(total=total)\n    return {'msg':'success'}\n@app.get('/update')\ndef update_progressbar(progress: int=1):\n    global t\n    if t is not None:\n        try:\n            t.clear()\n            t.update(progress)\n            return {'msg':'success'}\n        except:\n            import traceback\n            traceback.print_exc()\n            print(\"error when updating progessbar\")",
        "type": "code",
        "location": "/tests/update_progressbar_network/test.py:1-46"
    },
    "4413": {
        "file_id": 574,
        "content": "This code sets up a FastAPI server to handle progress updates via network. It includes endpoints for starting, resetting, and updating a tqdm progress bar. The server also includes functions for opening and closing the progress bar.",
        "type": "comment"
    },
    "4414": {
        "file_id": 574,
        "content": "            return {'msg':'error when updating progessbar'}\n    else:\n        print('no progressbar available')\n        return {'msg':'no progressbar available'}\n@app.get('/close')\ndef close():\n    close_progressbar()\n    return {'msg':'success'}",
        "type": "code",
        "location": "/tests/update_progressbar_network/test.py:47-56"
    },
    "4415": {
        "file_id": 574,
        "content": "This code handles a GET route for closing the progressbar and returns success or error messages based on the availability of the progressbar.",
        "type": "comment"
    },
    "4416": {
        "file_id": 575,
        "content": "/tests/update_progressbar_network/load_session.sh",
        "type": "filepath"
    },
    "4417": {
        "file_id": 575,
        "content": "The code snippet is using tmux, a terminal multiplexer, to kill an existing session (online_dog_cat_generator_test) and then load a new session from the test.yaml configuration file. This may be used for testing or managing different terminal sessions efficiently.",
        "type": "summary"
    },
    "4418": {
        "file_id": 575,
        "content": "tmux kill-session -t online_dog_cat_generator_test\ntmuxp load test.yaml",
        "type": "code",
        "location": "/tests/update_progressbar_network/load_session.sh:1-2"
    },
    "4419": {
        "file_id": 575,
        "content": "The code snippet is using tmux, a terminal multiplexer, to kill an existing session (online_dog_cat_generator_test) and then load a new session from the test.yaml configuration file. This may be used for testing or managing different terminal sessions efficiently.",
        "type": "comment"
    },
    "4420": {
        "file_id": 576,
        "content": "/tests/update_progressbar_network/client.py",
        "type": "filepath"
    },
    "4421": {
        "file_id": 576,
        "content": "Code defines a class \"netProgressbar\" that establishes a connection to a progress bar server, allows resetting and updating the progress bar through HTTP requests.",
        "type": "summary"
    },
    "4422": {
        "file_id": 576,
        "content": "import requests\nclass netProgressbar:\n    def __init__(self, port = 8576, message = 'progressbar server'):\n        from lazero.network import waitForServerUp\n        self.port = port\n        self.message = message\n        waitForServerUp(port=port, message=message)\n    def reset(self, total:int):\n        requests.get('http://localhost:{}/reset'.format(self.port),proxies=None,params = {'total':total})\n    def update(self,progress:int=1):\n        requests.get('http://localhost:8576/update',proxies=None, params={'progress':progress})",
        "type": "code",
        "location": "/tests/update_progressbar_network/client.py:1-12"
    },
    "4423": {
        "file_id": 576,
        "content": "Code defines a class \"netProgressbar\" that establishes a connection to a progress bar server, allows resetting and updating the progress bar through HTTP requests.",
        "type": "comment"
    },
    "4424": {
        "file_id": 577,
        "content": "/tests/update_progressbar_network/test.sh",
        "type": "filepath"
    },
    "4425": {
        "file_id": 577,
        "content": "This command runs the Uvicorn web server for a Python application, listening on port 8576. It sets the log level to critical and enables auto-reloading of the app when changes are made.",
        "type": "summary"
    },
    "4426": {
        "file_id": 577,
        "content": "python3 -m uvicorn --port 8576  --log-level critical test:app --reload",
        "type": "code",
        "location": "/tests/update_progressbar_network/test.sh:1-1"
    },
    "4427": {
        "file_id": 577,
        "content": "This command runs the Uvicorn web server for a Python application, listening on port 8576. It sets the log level to critical and enables auto-reloading of the app when changes are made.",
        "type": "comment"
    },
    "4428": {
        "file_id": 578,
        "content": "/tests/update_progressbar_network/test.yaml",
        "type": "filepath"
    },
    "4429": {
        "file_id": 578,
        "content": "This code configures a tmux session for running tests. The session has two panes: one running Python client.py and another executing test.sh in Bash.",
        "type": "summary"
    },
    "4430": {
        "file_id": 578,
        "content": "session_name: online_dog_cat_generator_test\nstart_directory: /root/Desktop/works/pyjom/tests/update_progressbar_network\nwindows:\n- layout: main-horizontal\n  options:\n    main-pane-height: 30\n  panes:\n  - shell_command:\n    - python3 client.py\n  - shell_command:\n    - bash test.sh\n  window_name: progressbar window",
        "type": "code",
        "location": "/tests/update_progressbar_network/test.yaml:1-12"
    },
    "4431": {
        "file_id": 578,
        "content": "This code configures a tmux session for running tests. The session has two panes: one running Python client.py and another executing test.sh in Bash.",
        "type": "comment"
    },
    "4432": {
        "file_id": 579,
        "content": "/tests/spatial_temporal_slice_pip/test.py",
        "type": "filepath"
    },
    "4433": {
        "file_id": 579,
        "content": "This code is loading a video file and reading frames from it using OpenCV's VideoCapture class. It continues to read frames until the frame cannot be retrieved, at which point it breaks out of the loop. The code seems to have some issues with low speed and possibly dealing with videos that have been detected as problematic by PIP (presumably a different part of the codebase).",
        "type": "summary"
    },
    "4434": {
        "file_id": 579,
        "content": "target_video = \"/media/root/help/pyjom/samples/video/LiGlReJ4i.mp4\" # 娜姐驾到 卡成傻逼\n# you should quit those which has unexpected long frame processing loops.\n# mask the area which has text on it. fill the area and blur the boundary.\n# you could also trash those videos with pip detected.\nimport cv2\n# shit it has low speed... canny\ncap = cv2.VideoCapture(target_video)\nret = 1\nwhile True:\n    ret, frame = cap.read()\n    if ret is None: break",
        "type": "code",
        "location": "/tests/spatial_temporal_slice_pip/test.py:1-19"
    },
    "4435": {
        "file_id": 579,
        "content": "This code is loading a video file and reading frames from it using OpenCV's VideoCapture class. It continues to read frames until the frame cannot be retrieved, at which point it breaks out of the loop. The code seems to have some issues with low speed and possibly dealing with videos that have been detected as problematic by PIP (presumably a different part of the codebase).",
        "type": "comment"
    },
    "4436": {
        "file_id": 580,
        "content": "/tests/motion_vector_estimation/test.sh",
        "type": "filepath"
    },
    "4437": {
        "file_id": 580,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "summary"
    },
    "4438": {
        "file_id": 580,
        "content": "bash ./run.sh python3.10 extract_mvs.py vid_h264.mp4 --preview --verbose",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.sh:1-1"
    },
    "4439": {
        "file_id": 580,
        "content": "This command runs a Python script (extract_mvs.py) using Python 3.10, processing the video file vid_h264.mp4. It includes options for previewing output and verbose logging.",
        "type": "comment"
    },
    "4440": {
        "file_id": 581,
        "content": "/tests/motion_vector_estimation/test.py",
        "type": "filepath"
    },
    "4441": {
        "file_id": 581,
        "content": "The code processes video frames and estimates motion vectors, then plots the results using matplotlib and handles potential errors. It uses pandas, numpy, and OpenCV for calculations.",
        "type": "summary"
    },
    "4442": {
        "file_id": 581,
        "content": "# it contains subpixel motion vectors. fucking hell\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# change source?\n# gif containers does not have motion vectors.\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n# without mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_without_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_without_mestimate.mp4\"\n# with mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"\nsource = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\nfrom lazero.utils.importers import cv2_custom_build_init\ncv2_custom_build_init()\nfrom mvextractor.videocap import VideoCap",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:1-25"
    },
    "4443": {
        "file_id": 581,
        "content": "This code is setting the source video file path for various test cases involving motion vector estimation. The files include different types of videos such as MP4 and GIF, with and without mestimate data, and nearly duplicate frame detection tests. It also initializes custom CV2 build and imports necessary modules.",
        "type": "comment"
    },
    "4444": {
        "file_id": 581,
        "content": "from caer.video.frames_and_fps import count_frames, get_res\nimport cv2\nframesCount = count_frames(source)\nres = get_res(source)  # (width, height)\nprint(\"RES: %s\" % str(res))\nres_x, res_y = res\nframe_common_divisor = min(res_x, res_y)\nimport math\ndef cartesianDistance(d2vector):\n    try:\n        x, y = d2vector\n        return math.sqrt(x**2 + y**2)\n    except:\n        print('item unpackable.', d2vector)\n        return 0\ndef XYWHToDiagonal(x, y, w, h):\n    return (x, y), (x + w, y + h)\n# 如果整除16那么就在这个范围里面 如果不整除范围就要扩大 扩大到相应的16的倍数\ndef get16Value(res_x):\n    rem_x = res_x % 16\n    val = res_x // 16\n    if rem_x != 0:\n        val += 1\n    return val\nx_16val = get16Value(res_x)\ny_16val = get16Value(res_y)\nmotion_render_frame = (x_16val * 16, y_16val * 16)\ntotal_block_weights = x_16val * y_16val * 2 * 2\ncap = VideoCap()\ncap.open(source)  # wtf is going on here?\n# if there is nothing we will breakup\n# visualize, show_picture = True, True\nvisualize, show_picture = False, False\n# so there can only be one such macroblock\ndef checkMacroBlock(value):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:26-75"
    },
    "4445": {
        "file_id": 581,
        "content": "This code is initializing variables and functions related to video processing. It calculates the resolution of a source, determines if it's divisible by 16, adjusts if necessary, and sets up variables for motion vector estimation and visualization. The VideoCap class is opened but its functionality remains unclear. The checkMacroBlock function checks for one macroblock value.",
        "type": "comment"
    },
    "4446": {
        "file_id": 581,
        "content": "    for mod in [16, 8]:\n        modValue = value % mod\n        if modValue == mod / 2:\n            return mod\n    # if not satisfied, we are shit.\nfrom functools import lru_cache\n@lru_cache(maxsize=4)\ndef getModXModYFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = checkMacroBlock(block_x), checkMacroBlock(block_y)\n    if mod_x is not None and mod_y is not None:\n        return mod_x, mod_y\n    else:\n        print(\"block center coordinates\", blockCenterCoordinates)\n        print(\"WTF IS GOING ON WITH THE BLOCK CENTER\")\n        breakpoint()\n        return 0, 0\ndef getRectangleXYWHFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    mod_x_half, mod_y_half = mod_x / 2, mod_y / 2\n    x, y, w, h = block_x - mod_x_half, block_y - mod_y_half, mod_x, mod_y\n    return tuple([int(elem) for elem in [x, y, w, h]])\ndef getBlockWeightFromBlockCenterCoordinates(blockCenterCoordinates):",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:76-107"
    },
    "4447": {
        "file_id": 581,
        "content": "This code defines several functions for handling block center coordinates in a specific context. It checks the modulo value of the coordinates to determine the size and position of the blocks, and uses these values to calculate the rectangle's dimensions and the block weight. The `lru_cache` decorator is used to cache the results of the `getModXModYFromBlockCenterCoordinates` function to improve performance.",
        "type": "comment"
    },
    "4448": {
        "file_id": 581,
        "content": "    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    weights = mod_x * mod_y / 8 / 8\n    return weights\nimport progressbar\nimport numpy as np\n# max_dst_x, max_dst_y = 0,0\ndef averageMotionVectors(motion_vector_list):\n    if len(motion_vector_list) == 0:\n        average_tuple = (0, 0)\n    if len(motion_vector_list) > 1:\n        marray = np.array(motion_vector_list)\n        # print(\"MAKING AVERAGE:\")\n        # print(marray)\n        average = np.average(marray, axis=0)\n        # breakpoint()\n        average_tuple = tuple(average)\n    else:\n        average_tuple = tuple(motion_vector_list[0])\n    return average_tuple\nmotion_area_ratio_array = []\n# average_weighted_motion_vector_array = []\n# average_global_weighted_motion_vector_array = []\naverage_weighted_motion_vector_cartesian_array = []\naverage_global_weighted_motion_vector_cartesian_array = []\naverage_weighted_motion_vectors_filtered_cartesian_distance_array = []\naverage_global_weighted_motion_vectors_filtered_cartesian_distance_array = []",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:108-140"
    },
    "4449": {
        "file_id": 581,
        "content": "Function to calculate the average motion vectors based on a list of motion vectors. If the list is empty, returns (0, 0). If the list has more than one vector, calculates the average and returns it as a tuple. Else, returns the first vector in the list.\n\nInitializes arrays for storing average_weighted_motion_vector_cartesian, average_global_weighted_motion_vector_cartesian, average_weighted_motion_vectors_filtered_cartesian_distance, and average_global_weighted_motion_vectors_filtered_cartesian_distance.",
        "type": "comment"
    },
    "4450": {
        "file_id": 581,
        "content": "for _ in progressbar.progressbar(range(framesCount)):\n    success, frame, motion_vectors, frame_type, timestamp = cap.read()\n    height, width, channels = frame.shape\n    # breakpoint()\n    if success:\n        # what is the content of this motion vector?\n        # print(motion_vectors)\n        # import pandas as pd\n        # df = pd.DataFrame(motion_vectors)\n        # df = pd.DataFrame(motion_vectors,index=['source_index','unk0','unk1','src_x','src_y','dst_x','dst_y','motion_x','motion_y','motion_scale'])\n        # breakpoint()\n        # print()\n        # print(\"_____________________________\")\n        condition = motion_vectors[:, 0] < 0\n        # print(condition)\n        # print(condition.shape)\n        # breakpoint()\n        motion_vectors_simplified = motion_vectors[condition, :][:, [0, 5, 6, 7, 8, 9]]\n        motion_vectors_scale = motion_vectors_simplified[:, [5]]\n        motion_vectors_scale_inversed = 1 / motion_vectors_scale\n        motion_vectors_with_scale = motion_vectors_simplified[:, [3, 4]]\n        motion_vectors_scale_inversed_stacked = np.hstack(",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:142-163"
    },
    "4451": {
        "file_id": 581,
        "content": "The code reads frames and motion vectors from a video stream, processes them, and stores selected information in separate arrays. It uses pandas for data processing and numpy for array manipulation.",
        "type": "comment"
    },
    "4452": {
        "file_id": 581,
        "content": "            [motion_vectors_scale_inversed] * 2\n        )\n        motion_vectors_restored = (\n            motion_vectors_scale_inversed_stacked * motion_vectors_with_scale\n        )  # just element wise?\n        # print('STACKED:', motion_vectors_scale_inversed_stacked.shape)\n        # print(\"WITH SCALE:\", motion_vectors_with_scale.shape)\n        # print(\"RESTORED:\",motion_vectors_restored.shape)\n        # print(motion_vectors_simplified.shape)\n        # print(motion_vectors_scale.shape)\n        # breakpoint()\n        motion_vectors_dest_coords_restored = np.hstack(\n            [motion_vectors_simplified[:, [1, 2]], motion_vectors_restored]\n        )\n        # motion_vectors_simplified = motion_vectors[:,[0,5,6,7,8]]\n        # motion_vectors_simplified_unique = np.unique(motion_vectors_simplified, axis=0)\n        # print(motion_vectors_simplified_unique.shape, motion_vectors.shape)\n        # breakpoint()\n        motion_vectors_dict = {}\n        for mv in motion_vectors_dest_coords_restored:\n            # drop duplicates first!",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:164-184"
    },
    "4453": {
        "file_id": 581,
        "content": "This code segment is responsible for restoring the motion vectors after scaling and stacking. It performs element-wise multiplication of two arrays, one containing scaled motion vectors and the other being the stacked motion vectors. The result is stored in \"motion_vectors_restored\". Then, it horizontally stacks the simplified motion vector coordinates and the restored ones using numpy's hstack function, resulting in \"motion_vectors_dest_coords_restored\". Finally, a dictionary named \"motion_vectors_dict\" is initialized but not fully populated in this snippet.",
        "type": "comment"
    },
    "4454": {
        "file_id": 581,
        "content": "            (\n                dst_x,  # corresponding macro block.\n                dst_y,  # for destination only\n                motion_x,\n                motion_y,\n                # motion_scale,  # don't know what the fuck is wrong with the motion scale\n            ) = mv.tolist()\n            # say we just want source_index <0, aka mv compared to previous frame\n            # try:\n            #     assert motion_x / motion_scale == src_x - dst_x\n            #     assert motion_y / motion_scale == src_y - dst_y\n            # except:\n            #     print(src_x, dst_x, motion_x, motion_scale)\n            #     print(src_y, dst_y, motion_y, motion_scale)\n            #     print(\"*\" * 20)\n            # it will be inaccurate if we abandon this subpixel precision.\n            # if source_index >= 0:\n            #     continue\n            # if dst_x>max_dst_x:\n            #     max_dst_x = dst_x\n            # if dst_y>max_dst_y:\n            #     max_dst_y = dst_y\n            destCoord = (dst_x, dst_y)\n            motion_vector = (motion_x, motion_y)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:185-208"
    },
    "4455": {
        "file_id": 581,
        "content": "This code segment is related to motion vector estimation in video processing. It calculates the destination coordinates and motion vector for a macro block, but there seems to be an issue with the motion scale. The code tries to assert that the motion_x and motion_y are scaled correctly based on the motion_scale, but it is causing some problem.",
        "type": "comment"
    },
    "4456": {
        "file_id": 581,
        "content": "            # print(destCoord)\n            # breakpoint()\n            if motion_vector == (0, 0):\n                # print(\"zero motion vector detected. skipping\")\n                # breakpoint()\n                continue\n            # print('destination coords:',destCoord)\n            # print('motion vector:',motion_vector)\n            motion_vectors_dict.update(\n                {destCoord: motion_vectors_dict.get(destCoord, []) + [motion_vector]}\n            )\n            # you know, different frame sources may lead to different results.\n            # these vectors could overlap. which one you want to keep? the smaller ones or the bigger ones?\n            # if destCoord in destCoords:\n            #     print(\"SKIPPING DUPLICATE DESTCOORD:\", destCoord)\n            #     print(\"PREVIOUS MV\",prevMV)\n            #     print(\"CURRENT MV\", mv)\n            #     continue\n            # else:\n            #     destCoords.add(destCoord)\n            # prevMV = mv\n            # try:\n            #     # src_x, src_y may not apply the same rule.",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:209-232"
    },
    "4457": {
        "file_id": 581,
        "content": "This code checks if a motion vector is zero and skips processing if it is. It then updates a dictionary of motion vectors by adding the new motion vector to the destination coordinate, while considering potential overlaps with other motion vectors.",
        "type": "comment"
    },
    "4458": {
        "file_id": 581,
        "content": "            #     # assert src_x % 16 == 8\n            #     # assert src_y % 16 == 8\n            #     assert checkMacroBlock(dst_x) is not None\n            #     assert checkMacroBlock(dst_y) is not None\n            #     # assert dst_x<=res_x # dst_x can go beyond the res_x\n            #     # assert dst_y<=res_y\n            #     # so all rules applied.\n            # except:\n            #     # print('source',src_x, src_y)\n            #     print(\"res\", res_x, res_y)\n            #     print('destionation',dst_x, dst_y)\n            #     print('motion',motion_x, motion_y)\n            #     print(\"scale\",motion_scale)\n        motion_vectors_dict_averaged = {\n            key: averageMotionVectors(motion_vectors_dict[key])\n            for key in motion_vectors_dict.keys()\n        }\n        # assuming no duplicates?\n        weighted_motion_vectors = []\n        weights = []\n        rectangles = []\n        motion_vectors_filtered = []  # for getting data later?\n        for (\n            blockCenterCoordinates,\n            average_motion_vector,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:233-257"
    },
    "4459": {
        "file_id": 581,
        "content": "Testing macro block placement, asserting non-null checkMacroBlock results for dst_x and dst_y, asserting within res limits (dst_x <= res_x), and handling exceptions with error printing. Averages motion vectors using averageMotionVectors function. Creates weightedMotionVectors list and weights list. Initializing rectangles and motionVectorsFiltered for later use.",
        "type": "comment"
    },
    "4460": {
        "file_id": 581,
        "content": "        ) in motion_vectors_dict_averaged.items():\n            if average_motion_vector == (0, 0):\n                continue\n                # wtf is this? why fucking zero?\n                # print('skipping zero average motion vector')\n                # print(\"destination coords\", key)\n                # print('average motion vector', average_motion_vector)\n            else:\n                m_x, m_y = average_motion_vector\n                motion_vectors_filtered.append(average_motion_vector)\n                rectangle_XYWH = getRectangleXYWHFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                rectangles.append(rectangle_XYWH)\n                blockWeight = getBlockWeightFromBlockCenterCoordinates(\n                    blockCenterCoordinates\n                )\n                weights.append(blockWeight)\n                weighted_motion_vectors.append(\n                    (\n                        m_x * blockWeight / frame_common_divisor,\n                        m_y * blockWeight / frame_common_divisor,",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:258-279"
    },
    "4461": {
        "file_id": 581,
        "content": "This code block is filtering and processing motion vectors from a dictionary. It skips any average motion vector that is (0, 0) and then proceeds to calculate the weighted motion vectors by multiplying the motion vector with block weight and dividing it by a frame common divisor. The resulting coordinates are stored in 'weighted_motion_vectors'.",
        "type": "comment"
    },
    "4462": {
        "file_id": 581,
        "content": "                    )\n                )\n        weighted_motion_vectors = np.array(weighted_motion_vectors)\n        sum_weighted_motion_vector = np.sum(weighted_motion_vectors, axis=0)\n        average_global_weighted_motion_vector = (\n            sum_weighted_motion_vector / total_block_weights\n        )\n        sum_weights = sum(weights)\n        average_weighted_motion_vector = sum_weighted_motion_vector / sum_weights\n        motion_area_ratio = sum_weights / total_block_weights\n        # print(motion_vectors.shape)\n        motion_vectors_filtered_cartesian_distance = [\n            cartesianDistance(vector) for vector in motion_vectors_filtered\n        ] + [\n            0\n        ]  # to avoid errors.\n        motion_vectors_filtered_cartesian_distance = np.array(\n            motion_vectors_filtered_cartesian_distance\n        )\n        cartesianWeights = weights + [0]\n        cartesianWeights = np.array(cartesianWeights)\n        cartesianWeightsSum = np.sum(cartesianWeights)\n        weighted_motion_vectors_filtered_cartesian_distance = (",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:280-304"
    },
    "4463": {
        "file_id": 581,
        "content": "This code calculates the weighted average motion vector and the average weighted motion vector for motion vectors in a block. It also determines the motion area ratio, applies cartesian distance to filtered motion vectors, and stores them with corresponding weights.",
        "type": "comment"
    },
    "4464": {
        "file_id": 581,
        "content": "            motion_vectors_filtered_cartesian_distance * cartesianWeights\n        )\n        sum_weighted_motion_vectors_filtered_cartesian_distance = np.sum(\n            weighted_motion_vectors_filtered_cartesian_distance\n        )\n        # print(\"SUM\", sum_weighted_motion_vectors_filtered_cartesian_distance)\n        # breakpoint()\n        average_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance / cartesianWeightsSum\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance = (\n            sum_weighted_motion_vectors_filtered_cartesian_distance\n            / total_block_weights # this is a number, not array!\n        )\n        min_cartesian = min(motion_vectors_filtered_cartesian_distance)\n        max_cartesian = max(motion_vectors_filtered_cartesian_distance)\n        motion_area_ratio_array.append(motion_area_ratio)\n        # print()\n        # print(average_weighted_motion_vector)\n        # print(average_global_weighted_motion_vector)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:305-329"
    },
    "4465": {
        "file_id": 581,
        "content": "This code calculates the average and global-weighted motion vectors for a set of motion vectors, considering their weights and distances. It also finds the minimum and maximum cartesian distance in the list and appends the motion area ratio to an array.",
        "type": "comment"
    },
    "4466": {
        "file_id": 581,
        "content": "        # breakpoint()\n        average_weighted_motion_vector_cartesian=cartesianDistance(average_weighted_motion_vector)\n        average_weighted_motion_vector_cartesian_array.append(average_weighted_motion_vector_cartesian)\n        average_global_weighted_motion_vector_cartesian = cartesianDistance(average_global_weighted_motion_vector)\n        average_global_weighted_motion_vector_cartesian_array.append(\n        average_global_weighted_motion_vector_cartesian\n        )\n        average_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        average_global_weighted_motion_vectors_filtered_cartesian_distance_array.append(\n            average_global_weighted_motion_vectors_filtered_cartesian_distance\n        )\n        if motion_vectors_dict_averaged != {}:\n            # breakpoint()\n            if visualize:\n                print(\"motion_area_ratio\", motion_area_ratio)\n                print(\"average_weighted_motion_vector_cartesian\", average_weighted_motion_vector_cartesian)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:330-348"
    },
    "4467": {
        "file_id": 581,
        "content": "Calculates the average weighted motion vector cartesian distance, appends it to the array and does the same for global vectors. If motion_vectors_dict_averaged is not empty, prints motion_area_ratio and average_weighted_motion_vector_cartesian if visualize is True.",
        "type": "comment"
    },
    "4468": {
        "file_id": 581,
        "content": "                print(\n                    \"average_global_weighted_motion_vecto_cartesianr\",\n                    average_global_weighted_motion_vector_cartesian,\n                )\n                print(\n                    \"average_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                print(\n                    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n                    average_global_weighted_motion_vectors_filtered_cartesian_distance,\n                )\n                motion_mask = np.zeros(\n                    (motion_render_frame[1], motion_render_frame[0], 1)\n                )\n                for index, (x, y, w, h) in enumerate(rectangles):\n                    pt1, pt2 = XYWHToDiagonal(x, y, w, h)\n                    # print(pt1, pt2)\n                    current_cartesian = motion_vectors_filtered_cartesian_distance[\n                        index\n                    ]",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:349-369"
    },
    "4469": {
        "file_id": 581,
        "content": "Calculates and prints average motion vector metrics. Creates a zeroed motion mask. Iterates through rectangles to calculate the current cartesian distance.",
        "type": "comment"
    },
    "4470": {
        "file_id": 581,
        "content": "                    # print(type(pt1), type(pt1[0]))\n                    relative_motion_cartesian = (current_cartesian - min_cartesian) / (\n                        max_cartesian - min_cartesian\n                    )  # must from 0 to 1 so we can plot this,\n                    # relative_motion_cartesian = 255*((current_cartesian-min_cartesian)/(max_cartesian-min_cartesian))\n                    # relative_motion_cartesian = int(relative_motion_cartesian)\n                    # relative_motion_cartesian = min(255,max(0, relative_motion_cartesian))\n                    # breakpoint()\n                    cv2.rectangle(\n                        motion_mask,\n                        pt1,\n                        pt2,\n                        color=(relative_motion_cartesian,),\n                        thickness=-1,\n                    )\n                # should we gaussian blur, threshold this, do convolution and then apply bounding box on it?\n                # # visualize this.\n                if show_picture:\n                    cv2.imshow(\"motion_mask\", motion_mask)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:370-388"
    },
    "4471": {
        "file_id": 581,
        "content": "This code calculates the relative motion vectors for a set of points and plots them on an image using OpenCV. It converts the motion vectors to a range of 0-255, representing the pixel intensity values used in the image plotting. The resulting image is then displayed if the \"show_picture\" flag is set.",
        "type": "comment"
    },
    "4472": {
        "file_id": 581,
        "content": "                    cv2.waitKey(100)\n            # may you create bounding box for this? for tracking motion? or not?\n        # breakpoint()\n    else:\n        break\n# print('max_dst_x', max_dst_x)\n# print('max_dst_y', max_dst_y)\nimport matplotlib.pyplot as plt\n# plt.style.use('dark_background')\na, b = 5,1\nfigure, axis = plt.subplots(a, b)\ndata = [\n    motion_area_ratio_array,\n    # average_weighted_motion_vector_array,\n    # average_global_weighted_motion_vector_array,\n    average_weighted_motion_vector_cartesian_array,\n    average_global_weighted_motion_vector_cartesian_array,\n    average_weighted_motion_vectors_filtered_cartesian_distance_array,\n    average_global_weighted_motion_vectors_filtered_cartesian_distance_array,\n]\ntitles = [\n    \"motion_area_ratio\",\n    # \"average_weighted_motion_vector\",\n    # \"average_global_weighted_motion_vector\",\n    \"average_weighted_motion_vector_cartesian\",\n    \"average_global_weighted_motion_vector_cartesian\",\n    \"average_weighted_motion_vectors_filtered_cartesian_distance\",",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:389-419"
    },
    "4473": {
        "file_id": 581,
        "content": "The code imports matplotlib and creates a figure with subplots. It stores various motion vector related arrays in the \"data\" list, presumably for plotting. These arrays are likely different representations of motion vectors at each point. The code then defines titles corresponding to each array's content.",
        "type": "comment"
    },
    "4474": {
        "file_id": 581,
        "content": "    \"average_global_weighted_motion_vectors_filtered_cartesian_distance\",\n]\n# breakpoint()\nassert len(titles) == len(data)\nassert a*b >= len(titles)\nfor _a in range(a):\n    for _b in range(b):\n        index = _a * b + _b\n        if index > len(data) - 1:\n            break\n        if a == 1:\n            if b == 1:\n                axis[0].plot(data[index])\n                axis[0].set_title(titles[index])\n            else:\n                axis[_b].plot(data[index])\n                axis[_b].set_title(titles[index])\n        elif b == 1:\n            axis[_a].plot(data[index])\n            axis[_a].set_title(titles[index])\n        else:\n            axis[_a, _b].plot(data[index])\n            axis[_a, _b].set_title(titles[index])\nplt.show()",
        "type": "code",
        "location": "/tests/motion_vector_estimation/test.py:420-444"
    },
    "4475": {
        "file_id": 581,
        "content": "This code plots the data using matplotlib and sets titles for each plot based on the corresponding title from the provided list. It checks for potential errors like unequal lengths of 'titles' and 'data', and also handles cases when 'a' or 'b' is 1, adjusting the number of axes accordingly.",
        "type": "comment"
    },
    "4476": {
        "file_id": 582,
        "content": "/tests/motion_vector_estimation/run.sh",
        "type": "filepath"
    },
    "4477": {
        "file_id": 582,
        "content": "This code runs a Docker container using lubo1994/mv-extractor image, mounting the current directory to /home/video_cap within the container and allowing X11 forwarding for graphical user interface support.",
        "type": "summary"
    },
    "4478": {
        "file_id": 582,
        "content": "#!/bin/bash\nxhost +\ndocker run \\\n    -it \\\n    --ipc=host \\\n    --env=\"DISPLAY\" \\\n    -v $(pwd):/home/video_cap \\\n    -v /tmp/.X11-unix:/tmp/.X11-unix:rw \\\n    lubo1994/mv-extractor:latest \\\n    \"$@\"",
        "type": "code",
        "location": "/tests/motion_vector_estimation/run.sh:1-12"
    },
    "4479": {
        "file_id": 582,
        "content": "This code runs a Docker container using lubo1994/mv-extractor image, mounting the current directory to /home/video_cap within the container and allowing X11 forwarding for graphical user interface support.",
        "type": "comment"
    },
    "4480": {
        "file_id": 583,
        "content": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py",
        "type": "filepath"
    },
    "4481": {
        "file_id": 583,
        "content": "The code initializes motion vector estimation, filters horizontal movement, improves accuracy using various techniques, processes motion vectors from coordinates, visualizes motion with OpenCV, creates bounding boxes, and handles further options. The code plots multiple sets of data onto a graph, iterating through lists using nested for loops, creating separate plots if desired, and then displays the graph.",
        "type": "summary"
    },
    "4482": {
        "file_id": 583,
        "content": "###################################################\n# aim to create optical flow here, with directions and convolution\n###################################################\n# it contains subpixel motion vectors. fucking hell\n# source = \"/root/Desktop/works/pyjom/samples/video/dog_with_text.mp4\"\n# change source?\n# gif containers does not have motion vectors.\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling.gif\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps.gif\"\n# without mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_without_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_without_mestimate.mp4\"\n# with mestimate\n# source = \"/root/Desktop/works/pyjom/samples/video/cat_invalid_eye_rolling_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/kitty_flash_15fps_with_mestimate.mp4\"\n# source = \"/root/Desktop/works/pyjom/samples/video/nearly_duplicate_frames_detection_30fps.mp4\"",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:1-22"
    },
    "4483": {
        "file_id": 583,
        "content": "This code aims to create optical flow with motion vectors and convolution, using video files as input. The source file changes depending on the specific test case (with or without mestimate, different videos).",
        "type": "comment"
    },
    "4484": {
        "file_id": 583,
        "content": "source = \"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\nfrom lazero.utils.importers import cv2_custom_build_init\n# from sniffio import current_async_library\ncv2_custom_build_init()\nfrom mvextractor.videocap import VideoCap\nfrom caer.video.frames_and_fps import count_frames, get_res\nimport cv2\nframesCount = count_frames(source)\nres = get_res(source)  # (width, height)\nprint(\"RES: %s\" % str(res))\nres_x, res_y = res\nframe_common_divisor = min(res_x, res_y)\nimport math\ndef cartesianDistance(d2vector):\n    try:\n        x, y = d2vector\n        return math.sqrt(x**2 + y**2)\n    except:\n        print('item unpackable.', d2vector)\n        return 0\ndef XYWHToDiagonal(x, y, w, h):\n    return (x, y), (x + w, y + h)\n# 如果整除16那么就在这个范围里面 如果不整除范围就要扩大 扩大到相应的16的倍数\ndef get16Value(res_x):\n    rem_x = res_x % 16\n    val = res_x // 16\n    if rem_x != 0:\n        val += 1\n    return val\nx_16val = get16Value(res_x)\ny_16val = get16Value(res_y)\nmotion_render_frame = (x_16val * 16, y_16val * 16)\ntotal_block_weights = x_16val * y_16val * 2 * 2",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:24-70"
    },
    "4485": {
        "file_id": 583,
        "content": "This code initializes necessary libraries and imports, gets the resolution of a video source, calculates the frame count, and sets up variables for motion vector estimation. The functions cartesianDistance and XYWHToDiagonal are defined for spatial calculations, and get16Value is used to ensure the resolution is a multiple of 16 for the motion vector estimation process. The total number of block weights is calculated based on the video's resolution.",
        "type": "comment"
    },
    "4486": {
        "file_id": 583,
        "content": "cap = VideoCap()\ncap.open(source)  # wtf is going on here?\n# if there is nothing we will breakup\n# visualize, show_picture = True, True\nvisualize, show_picture = False, False\n# so there can only be one such macroblock\ndef checkMacroBlock(value):\n    for mod in [16, 8]:\n        modValue = value % mod\n        if modValue == mod / 2:\n            return mod\n    # if not satisfied, we are shit.\nfrom functools import lru_cache\n@lru_cache(maxsize=4)\ndef getModXModYFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = checkMacroBlock(block_x), checkMacroBlock(block_y)\n    if mod_x is not None and mod_y is not None:\n        return mod_x, mod_y\n    else:\n        print(\"block center coordinates\", blockCenterCoordinates)\n        print(\"WTF IS GOING ON WITH THE BLOCK CENTER\")\n        breakpoint()\n        return 0, 0\ndef getRectangleXYWHFromBlockCenterCoordinates(blockCenterCoordinates):\n    block_x, block_y = blockCenterCoordinates\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:72-106"
    },
    "4487": {
        "file_id": 583,
        "content": "The code initializes a VideoCap object and opens a specified source. It then defines two functions: `checkMacroBlock` to determine the macroblock size based on given values, and `getModXModYFromBlockCenterCoordinates` to get the modX and modY from block center coordinates using `checkMacroBlock`. The code also includes error handling in case of unexpected block center coordinates.",
        "type": "comment"
    },
    "4488": {
        "file_id": 583,
        "content": "    mod_x_half, mod_y_half = mod_x / 2, mod_y / 2\n    x, y, w, h = block_x - mod_x_half, block_y - mod_y_half, mod_x, mod_y\n    return tuple([int(elem) for elem in [x, y, w, h]])\ndef getBlockWeightFromBlockCenterCoordinates(blockCenterCoordinates):\n    mod_x, mod_y = getModXModYFromBlockCenterCoordinates(blockCenterCoordinates)\n    weights = mod_x * mod_y / 8 / 8\n    return weights\nimport progressbar\nimport numpy as np\n# max_dst_x, max_dst_y = 0,0\ndef averageMotionVectors(motion_vector_list):\n    if len(motion_vector_list) == 0:\n        average_tuple = (0, 0)\n    if len(motion_vector_list) > 1:\n        marray = np.array(motion_vector_list)\n        # print(\"MAKING AVERAGE:\")\n        # print(marray)\n        average = np.average(marray, axis=0)\n        # breakpoint()\n        average_tuple = tuple(average)\n    else:\n        average_tuple = tuple(motion_vector_list[0])\n    return average_tuple\nmotion_area_ratio_array = []\n# average_weighted_motion_vector_array = []\n# average_global_weighted_motion_vector_array = []\naverage_weighted_motion_vector_cartesian_array = []",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:107-142"
    },
    "4489": {
        "file_id": 583,
        "content": "Function `getBlockWeightFromBlockCenterCoordinates` calculates the weight of a block based on its center coordinates.\nThe `averageMotionVectors` function calculates the average motion vector from a list of motion vectors.\n`motion_area_ratio_array` is used to store area ratios for blocks, which will be used in calculations later.",
        "type": "comment"
    },
    "4490": {
        "file_id": 583,
        "content": "average_global_weighted_motion_vector_cartesian_array = []\naverage_weighted_motion_vectors_filtered_cartesian_distance_array = []\naverage_global_weighted_motion_vectors_filtered_cartesian_distance_array = []\nfor _ in progressbar.progressbar(range(framesCount)):\n    success, frame, motion_vectors, frame_type, timestamp = cap.read()\n    height, width, channels = frame.shape\n    # breakpoint()\n    if success:\n        # what is the content of this motion vector?\n        # print(motion_vectors)\n        # import pandas as pd\n        # df = pd.DataFrame(motion_vectors)\n        # df = pd.DataFrame(motion_vectors,index=['source_index','unk0','unk1','src_x','src_y','dst_x','dst_y','motion_x','motion_y','motion_scale'])\n        # breakpoint()\n        # print()\n        # print(\"_____________________________\")\n        condition = motion_vectors[:, 0] < 0\n        # print(condition)\n        # print(condition.shape)\n        # breakpoint()\n        motion_vectors_simplified = motion_vectors[condition, :][:, [0, 5, 6, 7, 8, 9]]",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:143-164"
    },
    "4491": {
        "file_id": 583,
        "content": "This code calculates the motion vectors from video frames and filters them based on a condition. The condition checks if the x-component of the motion vector is less than 0, which may indicate horizontal movement. The code then selects specific columns (x, y coordinates, and scale) from the motion vectors that meet this condition for further processing.",
        "type": "comment"
    },
    "4492": {
        "file_id": 583,
        "content": "        motion_vectors_scale = motion_vectors_simplified[:, [5]]\n        motion_vectors_scale_inversed = 1 / motion_vectors_scale\n        motion_vectors_with_scale = motion_vectors_simplified[:, [3, 4]]\n        motion_vectors_scale_inversed_stacked = np.hstack(\n            [motion_vectors_scale_inversed] * 2\n        )\n        motion_vectors_restored = (\n            motion_vectors_scale_inversed_stacked * motion_vectors_with_scale\n        )  # just element wise?\n        # print('STACKED:', motion_vectors_scale_inversed_stacked.shape)\n        # print(\"WITH SCALE:\", motion_vectors_with_scale.shape)\n        # print(\"RESTORED:\",motion_vectors_restored.shape)\n        # print(motion_vectors_simplified.shape)\n        # print(motion_vectors_scale.shape)\n        # breakpoint()\n        motion_vectors_dest_coords_restored = np.hstack(\n            [motion_vectors_simplified[:, [1, 2]], motion_vectors_restored]\n        )\n        # motion_vectors_simplified = motion_vectors[:,[0,5,6,7,8]]\n        # motion_vectors_simplified_unique = np.unique(motion_vectors_simplified, axis=0)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:165-184"
    },
    "4493": {
        "file_id": 583,
        "content": "This code segment is involved in optical flow calculation. It performs scaling, inverse scaling, and stacking of motion vectors to restore the original motion vector array. The code then concatenates the destination coordinates with restored motion vectors. This process helps in improving the accuracy of motion vector estimation.",
        "type": "comment"
    },
    "4494": {
        "file_id": 583,
        "content": "        # print(motion_vectors_simplified_unique.shape, motion_vectors.shape)\n        # breakpoint()\n        motion_vectors_dict = {}\n        for mv in motion_vectors_dest_coords_restored:\n            # drop duplicates first!\n            (\n                dst_x,  # corresponding macro block.\n                dst_y,  # for destination only\n                motion_x,\n                motion_y,\n                # motion_scale,  # don't know what the fuck is wrong with the motion scale\n            ) = mv.tolist()\n            # say we just want source_index <0, aka mv compared to previous frame\n            # try:\n            #     assert motion_x / motion_scale == src_x - dst_x\n            #     assert motion_y / motion_scale == src_y - dst_y\n            # except:\n            #     print(src_x, dst_x, motion_x, motion_scale)\n            #     print(src_y, dst_y, motion_y, motion_scale)\n            #     print(\"*\" * 20)\n            # it will be inaccurate if we abandon this subpixel precision.\n            # if source_index >= 0:",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:185-206"
    },
    "4495": {
        "file_id": 583,
        "content": "This code segment is extracting and processing motion vectors from a set of coordinates. It is checking for duplicates, performing calculations with source and destination coordinates, and possibly handling inaccuracies caused by subpixel precision. The code seems to be part of a larger process, as it includes debugging statements and references to variables that are not explicitly defined within the provided segment.",
        "type": "comment"
    },
    "4496": {
        "file_id": 583,
        "content": "            #     continue\n            # if dst_x>max_dst_x:\n            #     max_dst_x = dst_x\n            # if dst_y>max_dst_y:\n            #     max_dst_y = dst_y\n            destCoord = (dst_x, dst_y)\n            motion_vector = (motion_x, motion_y)\n            # print(destCoord)\n            # breakpoint()\n            if motion_vector == (0, 0):\n                # print(\"zero motion vector detected. skipping\")\n                # breakpoint()\n                continue\n            # print('destination coords:',destCoord)\n            # print('motion vector:',motion_vector)\n            motion_vectors_dict.update(\n                {destCoord: motion_vectors_dict.get(destCoord, []) + [motion_vector]}\n            )\n            # you know, different frame sources may lead to different results.\n            # these vectors could overlap. which one you want to keep? the smaller ones or the bigger ones?\n            # if destCoord in destCoords:\n            #     print(\"SKIPPING DUPLICATE DESTCOORD:\", destCoord)\n            #     print(\"PREVIOUS MV\",prevMV)",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:207-230"
    },
    "4497": {
        "file_id": 583,
        "content": "This code iterates over motion vectors and updates a dictionary with the destination coordinates and corresponding motion vectors. It skips zero vectors and handles duplicate destinations, but doesn't specify which motion vector to keep in case of overlapping coordinates.",
        "type": "comment"
    },
    "4498": {
        "file_id": 583,
        "content": "            #     print(\"CURRENT MV\", mv)\n            #     continue\n            # else:\n            #     destCoords.add(destCoord)\n            # prevMV = mv\n            # try:\n            #     # src_x, src_y may not apply the same rule.\n            #     # assert src_x % 16 == 8\n            #     # assert src_y % 16 == 8\n            #     assert checkMacroBlock(dst_x) is not None\n            #     assert checkMacroBlock(dst_y) is not None\n            #     # assert dst_x<=res_x # dst_x can go beyond the res_x\n            #     # assert dst_y<=res_y\n            #     # so all rules applied.\n            # except:\n            #     # print('source',src_x, src_y)\n            #     print(\"res\", res_x, res_y)\n            #     print('destionation',dst_x, dst_y)\n            #     print('motion',motion_x, motion_y)\n            #     print(\"scale\",motion_scale)\n        motion_vectors_dict_averaged = {\n            key: averageMotionVectors(motion_vectors_dict[key])\n            for key in motion_vectors_dict.keys()\n        }",
        "type": "code",
        "location": "/tests/motion_vector_estimation/optical_flow_colored_blocks_convolution.py:231-254"
    },
    "4499": {
        "file_id": 583,
        "content": "This code is filtering and averaging motion vectors for macroblocks within a certain range. It checks if the source coordinates follow a specific rule, asserts that valid macroblock check functions are not None, and ensures the destination coordinates do not exceed the resolution limits. If any of these conditions fail, it prints debug information and continues execution. Finally, it calculates the averaged motion vectors for each macroblock in the dictionary.",
        "type": "comment"
    }
}