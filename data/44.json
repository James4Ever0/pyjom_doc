{
    "4400": {
        "file_id": 559,
        "content": "/tests/english_chinese_mixing_spliter/test_tts.py",
        "type": "filepath"
    },
    "4401": {
        "file_id": 559,
        "content": "This code imports TTS module and generates audio from a given text, iterating through analyzed data for each language. English tool is needed as no English option available currently.",
        "type": "summary"
    },
    "4402": {
        "file_id": 559,
        "content": "from paddlebobo_paddletools_tts import TTSExecutor\nfrom english_grepper import analyze_mixed_text\nmtext = \"你这dollar有问题啊\"\n# analyze this shit.\n# you can translate all english into chinese. doesn't hurt.\ntext_analyze_result = analyze_mixed_text(mtext)\n# print(text_analyze_result)\n# breakpoint()\ntts_config = {\"zh\": {\"model_tag\": 'fastspeech2_csmsc-zh',\n                     \"voc_tag\": \"hifigan_csmsc-zh\", \"lang\": \"zh\"}, \"en\": {\"model_tag\": 'fastspeech2_ljspeech-en',\n                                                                          \"voc_tag\": \"hifigan_ljspeech-en\", \"lang\": \"en\"}}\n# tts_config = {\"zh\": {\"model_tag\": 'tacotron2_csmsc-zh',\n#                      \"voc_tag\": \"hifigan_csmsc-zh\", \"lang\": \"zh\"}, \"en\": {\"model_tag\": 'tacotron2_ljspeech-en',\n#                      \"voc_tag\": \"hifigan_ljspeech-en\", \"lang\": \"en\"}}\nfor langid in [\"en\", \"zh\"]:\n    lang_config = tts_config[langid]\n    TTS = TTSExecutor('default.yaml', **lang_config)  # PaddleSpeech语音合成模块\n    # do we need to delete the TTS?\n    for data in text_analyze_result[langid]:",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/test_tts.py:1-25"
    },
    "4403": {
        "file_id": 559,
        "content": "The code imports necessary modules, defines a mixed text string, analyzes the text for English and Chinese segments using 'analyze_mixed_text' function, creates a TTSExecutor object with specified configurations for English (en) and Chinese (zh), and finally, iterates through the analyzed data for each language.",
        "type": "comment"
    },
    "4404": {
        "file_id": 559,
        "content": "        index, text = data[\"index\"], data[\"text\"]\n        wavfile = TTS.run(\n            text=text, output='output_{}_{}.wav'.format(langid, index))  # 合成音频\n    del TTS\n# there is no freaking english shit.\n# we need english tool.\n# you can also translate this shit.",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/test_tts.py:26-32"
    },
    "4405": {
        "file_id": 559,
        "content": "This code is importing the TTS module and running it to generate audio from a given text. The output file name includes the language ID and index, indicating different languages or speakers may be involved. However, an English tool is needed as there currently seems to be no English option available in the existing codebase.",
        "type": "comment"
    },
    "4406": {
        "file_id": 560,
        "content": "/tests/english_chinese_mixing_spliter/sample_strings.txt",
        "type": "filepath"
    },
    "4407": {
        "file_id": 560,
        "content": "The code contains a mix of English and Chinese text, representing a sample of mixed-language strings for testing purposes. It includes phrases such as \"你这dollar有问题啊\" (This dollar has a problem), \"版本号2.1.0alpha\" (Version 2.1.0 alpha), and \"mixed-content warning别说我没提醒你\" (Mixed content warning, I told you not to say anything).",
        "type": "summary"
    },
    "4408": {
        "file_id": 560,
        "content": "你这dollar有问题啊\n2000万巨资！经费燃烧\n版本号2.1.0alpha，但是这个premature state让人担心\nDo not say a word.她睡觉了。mixed-content warning别说我没提醒你",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/sample_strings.txt:1-4"
    },
    "4409": {
        "file_id": 560,
        "content": "The code contains a mix of English and Chinese text, representing a sample of mixed-language strings for testing purposes. It includes phrases such as \"你这dollar有问题啊\" (This dollar has a problem), \"版本号2.1.0alpha\" (Version 2.1.0 alpha), and \"mixed-content warning别说我没提醒你\" (Mixed content warning, I told you not to say anything).",
        "type": "comment"
    },
    "4410": {
        "file_id": 561,
        "content": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py",
        "type": "filepath"
    },
    "4411": {
        "file_id": 561,
        "content": "This code creates a text-to-speech synthesis model, initializes the architecture, and processes English and Chinese models. It concatenates audio files and deletes objects upon deallocation.",
        "type": "summary"
    },
    "4412": {
        "file_id": 561,
        "content": "import os\nimport numpy as np\nimport paddle\nimport soundfile as sf\nimport yaml\nfrom yacs.config import CfgNode\nfrom paddlespeech.cli.utils import download_and_decompress\nfrom paddlespeech.cli.utils import MODEL_HOME\nfrom paddlespeech.t2s.frontend import English\nfrom paddlespeech.s2t.utils.dynamic_import import dynamic_import\nfrom paddlespeech.t2s.frontend.zh_frontend import Frontend\nfrom paddlespeech.t2s.modules.normalizer import ZScore\nfrom paddlespeech.cli.tts.infer import model_alias, pretrained_models\nmodel_alias2 = {\n    # acoustic model\n    \"fastspeech2\": \"paddlespeech.t2s.models.fastspeech2:FastSpeech2\",\n    \"fastspeech2_inference\": \"paddlespeech.t2s.models.fastspeech2:StyleFastSpeech2Inference\",\n    # voc\n    \"pwgan\":\n    \"paddlespeech.t2s.models.parallel_wavegan:PWGGenerator\",\n    \"pwgan_inference\":\n    \"paddlespeech.t2s.models.parallel_wavegan:PWGInference\",\n}\nmodel_alias.update(model_alias2)\n# pretrained_models = {\n#     # fastspeech2\n#     \"fastspeech2_csmsc-zh\": {\n#         'url':\n#         'https://p",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:1-35"
    },
    "4413": {
        "file_id": 561,
        "content": "The code is importing necessary libraries and modules, defining model aliases for acoustic models (fastspeech2) and vocoders (pwgan), and potentially updating pretrained_models dictionary.",
        "type": "comment"
    },
    "4414": {
        "file_id": 561,
        "content": "addlespeech.bj.bcebos.com/Parakeet/released_models/fastspeech2/fastspeech2_nosil_baker_ckpt_0.4.zip',\n#         'md5':\n#         '637d28a5e53aa60275612ba4393d5f22',\n#         'config':\n#         'default.yaml',\n#         'ckpt':\n#         'snapshot_iter_76000.pdz',\n#         'speech_stats':\n#         'speech_stats.npy',\n#         'phones_dict':\n#         'phone_id_map.txt',\n#         'pitch_stats':\n#         'pitch_stats.npy',\n#         'energy_stats':\n#         'energy_stats.npy',\n#     },\n#     # pwgan\n#     \"pwgan_csmsc-zh\": {\n#         'url':\n#         'https://paddlespeech.bj.bcebos.com/Parakeet/released_models/pwgan/pwg_baker_ckpt_0.4.zip',\n#         'md5':\n#         '2e481633325b5bdf0a3823c714d2c117',\n#         'config':\n#         'pwg_default.yaml',\n#         'ckpt':\n#         'pwg_snapshot_iter_400000.pdz',\n#         'speech_stats':\n#         'pwg_stats.npy',\n#     },\n# }\nfor k in [\"fastspeech2_csmsc-zh\",\"fastspeech2_ljspeech-en\"]:\n    model_config = {'pitch_stats':\n        'pitch_stats.npy',\n        'energy_stats':",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:35-69"
    },
    "4415": {
        "file_id": 561,
        "content": "This code is a dictionary containing two models: \"fastspeech2_csmsc-zh\" and \"fastspeech2_ljspeech-en\". Each model has its URL, MD5, config file, checkpoint file, and optional statistics files. These models seem to be used for speech synthesis, as they require pitch and energy stats.",
        "type": "comment"
    },
    "4416": {
        "file_id": 561,
        "content": "        'energy_stats.npy',}\n    pretrained_models[k].update(model_config)\nclass TTSExecutor():\n    def __init__(self, config,model_tag = 'fastspeech2_csmsc-zh', voc_tag = \"pwgan_csmsc-zh\",lang=\"zh\"):\n        langId1 = model_tag.split(\"-\")[-1]\n        langId2 = voc_tag.split(\"-\")[-1]\n        assert langId1 == langId2\n        assert langId2 == lang\n        assert lang in [\"zh\",\"en\"]\n        self.lang = lang\n        # match the freaking dataset!\n        #FastSpeech2 or something else. we need freaking english!\n        am_res_path = self._get_pretrained_path(model_tag)\n        am_config = os.path.join(am_res_path,pretrained_models[model_tag]['config'])\n        am_ckpt = os.path.join(am_res_path,pretrained_models[model_tag]['ckpt'])\n        am_stat = os.path.join(am_res_path, pretrained_models[model_tag]['speech_stats'])\n        # must have phones_dict in acoustic\n        phones_dict = os.path.join(am_res_path, pretrained_models[model_tag]['phones_dict'])\n        # StyleFastSpeech\n        pitch_stats = os.path.join(am_res_path, pretrained_models[model_tag]['pitch_stats'])",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:70-91"
    },
    "4417": {
        "file_id": 561,
        "content": "The code is initializing a TTSExecutor object with config and model_tag parameters. It checks if the model_tag matches the language specified, and then retrieves the necessary paths for the acoustic model, phones dictionary, and pitch statistics using the pretrained_models dictionary.",
        "type": "comment"
    },
    "4418": {
        "file_id": 561,
        "content": "        energy_stats = os.path.join(am_res_path, pretrained_models[model_tag]['energy_stats'])\n        #VOC\n        voc_res_path = self._get_pretrained_path(voc_tag)\n        voc_config = os.path.join(voc_res_path,pretrained_models[voc_tag]['config'])\n        voc_ckpt = os.path.join(voc_res_path,pretrained_models[voc_tag]['ckpt'])\n        voc_stat = os.path.join(voc_res_path, pretrained_models[voc_tag]['speech_stats'])\n        # Init body.\n        with open(am_config) as f:\n            self.am_config = CfgNode(yaml.safe_load(f))\n        with open(voc_config) as f:\n            voc_config = CfgNode(yaml.safe_load(f))\n        with open(config) as f:\n            self.style_config = CfgNode(yaml.safe_load(f))\n        with open(phones_dict, \"r\") as f:\n            phn_id = [line.strip().split() for line in f.readlines()]\n        vocab_size = len(phn_id)\n        #print(\"vocab_size:\", vocab_size)\n        # acoustic model\n        odim = self.am_config.n_mels\n        # wtf?\n        main_name0 = model_tag.split(\"_\")[0]",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:92-118"
    },
    "4419": {
        "file_id": 561,
        "content": "This code is loading pre-trained models and configuration files for an automatic speech recognition (ASR) system. It joins different file paths, opens the configuration files to parse them into CfgNodes, and determines the vocabulary size based on a phone ID list. The code seems to be part of a larger ASR system implementation, initializing variables before using the models for prediction or inference tasks.",
        "type": "comment"
    },
    "4420": {
        "file_id": 561,
        "content": "        am_class = dynamic_import(main_name0, model_alias)\n        am_inference_class = dynamic_import('{}_inference'.format(main_name0), model_alias)\n        am = am_class(idim=vocab_size, odim=odim, spk_num=1, **self.am_config[\"model\"])\n        am.set_state_dict(paddle.load(am_ckpt)[\"main_params\"])\n        am.eval()\n        am_mu, am_std = np.load(am_stat)\n        am_mu = paddle.to_tensor(am_mu)\n        am_std = paddle.to_tensor(am_std)\n        am_normalizer = ZScore(am_mu, am_std)\n        if lang == \"en\":\n            self.am_inference = am_inference_class(am_normalizer, am) # you can also try tensorflowTTS, hifigan with high clarity.\n        else:\n            self.am_inference = am_inference_class(am_normalizer, am, pitch_stats, energy_stats)\n        self.am_inference.eval()\n        # vocoder\n        main_name1 = voc_tag.split(\"_\")[0]\n        voc_class = dynamic_import(main_name1, model_alias)\n        voc_inference_class = dynamic_import('{}_inference'.format(main_name1), model_alias)\n        voc = voc_class(**voc_config[\"generator_params\"])",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:119-141"
    },
    "4421": {
        "file_id": 561,
        "content": "The code dynamically imports classes based on model aliases and tags, instantiates models for speech synthesis and vocoder, loads model parameters and normalization stats, and sets up the inference environment for both English and Chinese languages.",
        "type": "comment"
    },
    "4422": {
        "file_id": 561,
        "content": "        voc.set_state_dict(paddle.load(voc_ckpt)[\"generator_params\"])\n        voc.remove_weight_norm()\n        voc.eval()\n        voc_mu, voc_std = np.load(voc_stat)\n        voc_mu = paddle.to_tensor(voc_mu)\n        voc_std = paddle.to_tensor(voc_std)\n        voc_normalizer = ZScore(voc_mu, voc_std)\n        self.voc_inference = voc_inference_class(voc_normalizer, voc)\n        self.voc_inference.eval()\n        if lang == \"zh\":\n            self.frontend = Frontend(phone_vocab_path=phones_dict, tone_vocab_path=None)\n        elif lang == \"en\":\n            self.phones_dict = os.path.join(\n                am_res_path, pretrained_models[model_tag]['phones_dict'])\n            self.frontend = English(phone_vocab_path=self.phones_dict)\n        else: raise Exception(\"Unknown language ID: {}\".format(lang))\n    def _get_pretrained_path(self, tag):\n        \"\"\"\n        Download and returns pretrained resources path of current task.\n        \"\"\"\n        assert tag in pretrained_models, 'Can not find pretrained resources of {}.'.format(tag)",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:142-164"
    },
    "4423": {
        "file_id": 561,
        "content": "This code sets up a model for text-to-speech (TTS) synthesis. It loads pretrained models and parameters, initializes the model architecture, applies normalization to input features, selects the appropriate frontend for the language (English or Chinese), and provides a method to download pretrained resources.",
        "type": "comment"
    },
    "4424": {
        "file_id": 561,
        "content": "        res_path = os.path.join(MODEL_HOME, tag)\n        decompressed_path = download_and_decompress(pretrained_models[tag],\n                                                    res_path)\n        decompressed_path = os.path.abspath(decompressed_path)\n        return decompressed_path\n    def run(self, text, output):\n        #文本输入\n        sentences = [str(text)]\n        # 长句处理\n        for sentence in sentences:\n            if self.lang == \"zh\":\n                input_ids = self.frontend.get_input_ids(sentence, merge_sentences=False, get_tone_ids=False) # what the heck? no freaking tone?\n            else:\n                input_ids = self.frontend.get_input_ids(sentence, merge_sentences=False) # what the heck? no freaking tone?\n            phone_ids = input_ids[\"phone_ids\"]\n            flags = 0\n            for part_phone_ids in phone_ids:\n                with paddle.no_grad():\n                    if self.lang == \"en\":\n                        mel = self.am_inference(\n                                        part_phone_ids)",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:165-187"
    },
    "4425": {
        "file_id": 561,
        "content": "This code is related to a text-to-speech (TTS) system. It first downloads and decompresses the necessary pretrained model files, then processes the input text into phone_ids, which are used to generate speech using the am_inference function. The code handles both English and Chinese languages but seems to be missing tone information for Chinese.",
        "type": "comment"
    },
    "4426": {
        "file_id": 561,
        "content": "                                        # must get the scale using ffmpeg.\n                    elif self.lang == \"zh\":\n                        mel = self.am_inference(\n                                        part_phone_ids,\n                                        durations=None,\n                                        durations_scale = 1 / float(self.style_config['TTS']['SPEED']),\n                                        durations_bias = None,\n                                        pitch = None,\n                                        pitch_scale = float(self.style_config['TTS']['PITCH']),\n                                        pitch_bias = None,\n                                        energy = float(self.style_config['TTS']['ENERGY']),\n                                        energy_scale = None,\n                                        energy_bias = None,\n                                        )\n                    wav = self.voc_inference(mel)\n                if flags == 0:\n                    wav_all = wav",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:188-204"
    },
    "4427": {
        "file_id": 561,
        "content": "This code chunk performs text-to-speech (TTS) conversion for Chinese language by first obtaining the Mel Spectrogram using `am_inference` function. The Mel Spectrogram is then converted to a WAV audio file using the `voc_inference` function. If flags equals 0, it assigns the result directly to `wav_all`.",
        "type": "comment"
    },
    "4428": {
        "file_id": 561,
        "content": "                    flags = 1\n                else:\n                    wav_all = paddle.concat([wav_all, wav])\n            sf.write(\n                output,\n                wav_all.numpy(),\n                samplerate=self.am_config.fs)\n        return output\n    # def __del__(self):\n    #     del self.voc_inference\n    #     del self.am_inference\n    #     del self.am_config\n    #     del self.style_config\n    #     del self.frontend\n    #     del self",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/paddlebobo_paddletools_tts.py:205-219"
    },
    "4429": {
        "file_id": 561,
        "content": "This code is concatenating audio files and saving them as a single output file. If the flag is set to 1, it stops concatenation and writes the existing audio file. The __del__ method deletes various objects when the instance is deallocated.",
        "type": "comment"
    },
    "4430": {
        "file_id": 562,
        "content": "/tests/english_chinese_mixing_spliter/english_grepper.py",
        "type": "filepath"
    },
    "4431": {
        "file_id": 562,
        "content": "This code searches, formats number lists, and tokenizes mixed English-Chinese text using regex. It iterates over results, updates language and UUID, sorts finalResult, creates dictionaries of index-text pairs for English and Chinese lists, then returns the result.",
        "type": "summary"
    },
    "4432": {
        "file_id": 562,
        "content": "# target = \"sample_strings.txt\"\n# data = open(target,\"r\",encoding=\"utf-8\").read()\n# data = data.split(\"\\n\")\nfrom zhon.hanzi import characters, radicals, punctuation\nimport re\ndef recursiveCompiledSearch(compiledRegex, pattern,initPos=0,resultTotal = []):\n    result = compiledRegex.search(pattern)\n    if result !=None:\n        match = result[0]\n        span = result.span()\n        realSpan = (span[0]+initPos, span[1]+initPos)\n        # initialSpan = span[0]\n        endSpan = span[1]\n        initPos += endSpan\n        mresult = {\"match\":match, \"span\":realSpan}\n        resultTotal.append(mresult)\n        newPattern = pattern[endSpan:]\n        return recursiveCompiledSearch(compiledRegex,newPattern,initPos,resultTotal)\n    else: return resultTotal\nfrom itertools import groupby, count\ndef set_to_range(numberlist):\n    numberlist = list(sorted(numberlist)) # double safety?\n    gpb = groupby(numberlist, lambda n, c=count(): n-next(c))\n    # Then to finish it off, generate the string from the groups.\n    def as_range(iterable): # not sure how to do this part elegantly",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/english_grepper.py:1-32"
    },
    "4433": {
        "file_id": 562,
        "content": "This code defines two functions for searching and formatting number lists. The first function, `recursiveCompiledSearch`, uses regex to search for patterns in a string, recursively appending matches to the result list. The second function, `set_to_range`, sorts a number list and then groups consecutive numbers together into ranges.",
        "type": "comment"
    },
    "4434": {
        "file_id": 562,
        "content": "        l = list(iterable)\n        if len(l) > 1:\n            return (l[0], l[-1]+1)\n        else:\n            return (l[0], l[0]+1)\n    result = [as_range(g) for _, g in gpb]\n    # result = [as_range(g) for _, g in groupby(numberlist, key=lambda n, c=count(): n-next(c))]\n    return result\n    # '1-3,6-7,10'\nimport uuid\ndef get_myuuid(): return str(uuid.uuid4())\ndef get_chinese_result(line,chineseSet):\n    chineseRanges = set_to_range(chineseSet)\n    result = []\n    for r in chineseRanges:\n        text = line[r[0]:r[1]]\n        data = {\"match\":text,\"span\":r,\"lang\":\"zh\",\"uuid\":get_myuuid()}\n        result.append(data)\n    return result\nall_chinese = characters+radicals+punctuation\nenglish = re.compile(r\"([a-zA-Z]+([ \\-,\\.:;?!]+)?)+\")\n# for line in data:\ndef analyze_mixed_text(line):\n    line = line.replace(\"\\n\",\"\")\n    # if len(line) <=3: continue\n    # shall we analyze this shit line by line?\n    # just a fucking try...\n    print(\"LINE DATA: \" + line)\n    eng_result = recursiveCompiledSearch(english,line,initPos=0,resultTotal = []) # recursive curse.",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/english_grepper.py:33-68"
    },
    "4435": {
        "file_id": 562,
        "content": "This function takes a line of mixed English and Chinese text, tokenizes it into ranges of each language, and returns these ranges in a list. It first converts the Chinese characters to their corresponding ranges and then finds English words using a compiled regular expression. The function ignores lines with less than 3 characters and calls another function recursively for further processing.",
        "type": "comment"
    },
    "4436": {
        "file_id": 562,
        "content": "    engSet = []\n    engResult = []\n    for eng in eng_result:\n        print(\"FOUND ENGLISH: \", eng)\n        span = eng[\"span\"]\n        mword = line[span[0]:span[1]]\n        mrange = list(range(span[0],span[1]))\n        engSet += mrange\n        eng2 = eng\n        eng2.update({\"lang\":\"en\",\"uuid\":get_myuuid()})\n        engResult.append(eng2)\n        print(\"VERIFICATION:\",mword)\n    chineseSet = [x for x in range(len(line)) if x not in engSet]\n    chineseResult = get_chinese_result(line,chineseSet)\n    finalResult = chineseResult+engResult\n    finalResult = sorted(finalResult,key=lambda x:x[\"span\"][0])\n    result = {\"en\":[],\"zh\":[]}\n    for index, data in enumerate(finalResult):\n        lang = data[\"lang\"]\n        text = data[\"match\"]\n        result[lang].append({\"index\":index,\"text\":text})\n    return result",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/english_grepper.py:69-90"
    },
    "4437": {
        "file_id": 562,
        "content": "The code iterates over the English results, appends the range of each word to engSet, updates the language and UUID of each result, and then builds a finalResult list. It sorts the finalResult by span[0] (start index) and creates a dictionary with English (en) and Chinese (zh) lists containing index-text pairs. Finally, it returns the result dictionary.",
        "type": "comment"
    },
    "4438": {
        "file_id": 563,
        "content": "/tests/english_chinese_mixing_spliter/default.yaml",
        "type": "filepath"
    },
    "4439": {
        "file_id": 563,
        "content": "This YAML configuration file sets the input and output paths for a GAN-based driving application. It includes options for image and video files, TTS settings, and save directories.",
        "type": "summary"
    },
    "4440": {
        "file_id": 563,
        "content": "GANDRIVING:\n  FOM_INPUT_IMAGE: './file/input/test.png'\n  FOM_DRIVING_VIDEO: './file/input/zimeng.mp4'\n  FOM_OUTPUT_VIDEO: './file/input/test.mp4'\nTTS:\n  SPEED: 1.0\n  PITCH: 1.0\n  ENERGY: 1.0\nSAVEPATH:\n  VIDEO_SAVE_PATH: './file/output/video/'\n  AUDIO_SAVE_PATH: './file/output/audio/'",
        "type": "code",
        "location": "/tests/english_chinese_mixing_spliter/default.yaml:1-13"
    },
    "4441": {
        "file_id": 563,
        "content": "This YAML configuration file sets the input and output paths for a GAN-based driving application. It includes options for image and video files, TTS settings, and save directories.",
        "type": "comment"
    },
    "4442": {
        "file_id": 564,
        "content": "/tests/recommendation_system/neo4j_e2e_recsys.py",
        "type": "filepath"
    },
    "4443": {
        "file_id": 564,
        "content": "This code is referencing resources from Neo4j's documentation for end-to-end examples and Graph Academy training. It appears to be related to implementing Fast RP (Recommendation Prediction) using k-Nearest Neighbors (kNN) algorithm in a Neo4j graph database.",
        "type": "summary"
    },
    "4444": {
        "file_id": 564,
        "content": "# https://neo4j.com/docs/graph-data-science/current/end-to-end-examples/fastrp-knn-example/\n# https://neo4j.com/graphacademy/training-iga-40/12-iga-40-ingredient-analysis/",
        "type": "code",
        "location": "/tests/recommendation_system/neo4j_e2e_recsys.py:1-2"
    },
    "4445": {
        "file_id": 564,
        "content": "This code is referencing resources from Neo4j's documentation for end-to-end examples and Graph Academy training. It appears to be related to implementing Fast RP (Recommendation Prediction) using k-Nearest Neighbors (kNN) algorithm in a Neo4j graph database.",
        "type": "comment"
    },
    "4446": {
        "file_id": 565,
        "content": "/tests/recommendation_system/karate_test.py",
        "type": "filepath"
    },
    "4447": {
        "file_id": 565,
        "content": "This code imports necessary libraries and defines a function for normalizing adjacency matrices. It then creates a graph using the karate club data, converts it to a dense matrix, normalizes this matrix, and prints its shape before initializing a GCN model.",
        "type": "summary"
    },
    "4448": {
        "file_id": 565,
        "content": "import networkx as nx\nimport torch\ndef normalize(A , symmetric=True):\n\t# A = A+I\n\tA = A + torch.eye(A.size(0))\n\t# 所有节点的度\n\td = A.sum(1)\n\tif symmetric:\n\t\t#D = D^-1/2\n\t\tD = torch.diag(torch.pow(d , -0.5))\n\t\treturn D.mm(A).mm(D)\n\telse:\n\t\t# D=D^-1\n\t\tD = torch.diag(torch.pow(d,-1))\n\t\treturn D.mm(A)\nG = nx.karate_club_graph()\nA = nx.adjacency_matrix(G).todense() # dense matrix? not so freaking good.\n#A需要正规化\nA_normed = normalize(torch.FloatTensor(A),True)\nprint(A_normed.shape)\nfrom torch_geometric.nn import GCN\n# how to generate graph?\n# breakpoint() # 34,34",
        "type": "code",
        "location": "/tests/recommendation_system/karate_test.py:1-27"
    },
    "4449": {
        "file_id": 565,
        "content": "This code imports necessary libraries and defines a function for normalizing adjacency matrices. It then creates a graph using the karate club data, converts it to a dense matrix, normalizes this matrix, and prints its shape before initializing a GCN model.",
        "type": "comment"
    },
    "4450": {
        "file_id": 566,
        "content": "/tests/recommendation_system/dgl_link_prediction.py",
        "type": "filepath"
    },
    "4451": {
        "file_id": 566,
        "content": "This code imports the DGL library, loads the Cora dataset from DGL's data module, and prints the loaded dataset. The Cora dataset is a popular benchmark for node classification tasks in graph-based machine learning.",
        "type": "summary"
    },
    "4452": {
        "file_id": 566,
        "content": "import dgl\ncora = dgl.data.CoraGraphDataset()\nprint(cora)",
        "type": "code",
        "location": "/tests/recommendation_system/dgl_link_prediction.py:1-4"
    },
    "4453": {
        "file_id": 566,
        "content": "This code imports the DGL library, loads the Cora dataset from DGL's data module, and prints the loaded dataset. The Cora dataset is a popular benchmark for node classification tasks in graph-based machine learning.",
        "type": "comment"
    },
    "4454": {
        "file_id": 567,
        "content": "/tests/apple_prores_encoding_play/test.sh",
        "type": "filepath"
    },
    "4455": {
        "file_id": 567,
        "content": "This script encodes a video file using FFmpeg with the prores_aw encoder and saves it in an Apple ProRes format. The code uses the vulkan hardware acceleration and sets the output container format to .mkv. It also provides alternative options for encoding in ProRes 422 or 4444 HQ, specifying profile, vendor, bits per MB, and pixel format. It mentions allowed container formats for ProRes as .mov, .mkv, and .mxf.",
        "type": "summary"
    },
    "4456": {
        "file_id": 567,
        "content": "videoPath=\"/root/Desktop/works/pyjom/samples/video/cute_cat_gif.mp4\"\n# prores_aw\nffmpeg -hwaccel vulkan -i $videoPath -c:v prores_ks  output.mkv\n# https://ottverse.com/ffmpeg-convert-to-apple-prores-422-4444-hq/#:~:text=FFmpeg%20contains%20two%20ProRes%20encoders%2C%20the%20prores-aw%20and,option%20to%20choose%20the%20ProRes%20profile%20to%20encode.\n# videoPath=\"/Users/jamesbrown/Desktop/works/pyjom_remote/samples/video/cute_cat_gif.mp4\"\n# ffmpeg -hwaccel videotoolbox -i $videoPath -c:v prores_ks  \\\n# -profile:v 4 \\\n# -vendor apl0 \\\n# -bits_per_mb 8000 \\\n# -pix_fmt yuva444p10le \\ \n# output.mov\n# Do remember to store the output in either of these three formats that are allowed as containers for the ProRes format.\n# .mov (QuickTime)\n# .mkv (Matroska)\n# .mxf (Material eXchange Format)",
        "type": "code",
        "location": "/tests/apple_prores_encoding_play/test.sh:1-16"
    },
    "4457": {
        "file_id": 567,
        "content": "This script encodes a video file using FFmpeg with the prores_aw encoder and saves it in an Apple ProRes format. The code uses the vulkan hardware acceleration and sets the output container format to .mkv. It also provides alternative options for encoding in ProRes 422 or 4444 HQ, specifying profile, vendor, bits per MB, and pixel format. It mentions allowed container formats for ProRes as .mov, .mkv, and .mxf.",
        "type": "comment"
    },
    "4458": {
        "file_id": 568,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md",
        "type": "filepath"
    },
    "4459": {
        "file_id": 568,
        "content": "This code covers device discovery, Termux daemon, remote unlock with ADB and scrcpy client, focused window titles, downloading a macOS keylogger, and executes input tests on the X server.",
        "type": "summary"
    },
    "4460": {
        "file_id": 568,
        "content": "device discovery, termux daemon, remote unlock\nunlock requires screenshot and input events.\nhttps://technastic.com/unlock-android-phone-pin-pattern-adb/\nclick ok after input password:\nhttps://stackoverflow.com/questions/29072501/how-to-unlock-android-phone-through-adb\nscrcpy client\nhttps://github.com/leng-yue/py-scrcpy-client\nhttps://leng-yue.github.io/py-scrcpy-client/guide.html#bind-events\nyou want to use android emulator on macos m1?\nhttps://github.com/google/android-emulator-m1-preview/releases/tag/0.3\ncheck android screen lock/unlock state\nhttps://android.stackexchange.com/questions/191086/adb-commands-to-get-screen-state-and-locked-state\nBonjour/Avahi/Zeroconf\nlogic: if the kill switch is off, when no physical input events happens, or not focused on scrcpy window with keyboard/mouse input events on pc for some time, allow to interact with the phone.\nget physical events:\nwarning: this command could be offline for a short period of time after using the scrcpy. must automatically reconnect if the device is not offline.",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md:1-30"
    },
    "4461": {
        "file_id": 568,
        "content": "This code focuses on device discovery, termux daemon, remote unlock, using scrcpy client and android emulator on MacOS M1. It includes links for unlocking Android phone through ADB, checking screen lock/unlock state, utilizing Bonjour/Avahi/Zeroconf logic, handling physical events and reconnecting if necessary.",
        "type": "comment"
    },
    "4462": {
        "file_id": 568,
        "content": "```bash\nadb -s 192.168.10.3:5555 shell getevent\n```\nto get focused window title:\nhint: for headless ssh sessions, must set apropriate xorg environment variables, eg: `env XAUTHORITY=\"/run/user/0/gdm/Xauthority\" DISPLAY=:1 python3`\ngeneral method:\n```python\nimport pywinctl\npywinctl.getActiveWindowTitle()\n```\nfor linux:\n```bash\nwatch -n 2 xdotool getactivewindow getwindowname\n```\nfor macos: (allow permission first, deprecated since it will not get the window title instead of the program name)\nhttps://alvinalexander.com/mac-os-x/applescript-unix-mac-osx-foreground-application-result/\n(where is the window name?)\n```bash\nsleep 3 && osascript -e 'tell application \"System Events\"' -e 'set frontApp to name of first application process whose frontmost is true' -e 'end tell'\n```\nto get input events on macos:\ndownload keylogger here:\nhttps://hackernoon.com/writing-an-keylogger-for-macos-in-python-24adfa22722\nhttps://github.com/beatsbears/pkl?ref=hackernoon.com\n```bash\npython pkl_nowriting.py\n```\ninput events on linux:\n```bash",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md:32-68"
    },
    "4463": {
        "file_id": 568,
        "content": "This code provides methods to obtain the focused window title on different operating systems: Bash commands for Android devices and Windows, Python script for Linux, Applescript for macOS. Additionally, it mentions downloading a keylogger for capturing input events on macOS.",
        "type": "comment"
    },
    "4464": {
        "file_id": 568,
        "content": "xinput test-xi2 --root\n```",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/README.md:69-70"
    },
    "4465": {
        "file_id": 568,
        "content": "Executes an input test on the X server, affecting all connected devices.",
        "type": "comment"
    },
    "4466": {
        "file_id": 569,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/unlock_phone_on_given_ip.py",
        "type": "filepath"
    },
    "4467": {
        "file_id": 569,
        "content": "Device address is set to connect to the phone on a specific IP and port for further interactions.",
        "type": "summary"
    },
    "4468": {
        "file_id": 569,
        "content": "# first, check phone status.\ndevice_address = \"192.168.10.3:5555\"",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/unlock_phone_on_given_ip.py:1-2"
    },
    "4469": {
        "file_id": 569,
        "content": "Device address is set to connect to the phone on a specific IP and port for further interactions.",
        "type": "comment"
    },
    "4470": {
        "file_id": 570,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py",
        "type": "filepath"
    },
    "4471": {
        "file_id": 570,
        "content": "This Python script logs keystrokes and mouse events via Cocoa, for educational purposes, requires privilege settings adjustment, and has an event loop with interrupt handling.",
        "type": "summary"
    },
    "4472": {
        "file_id": 570,
        "content": "#!/usr/bin/env python\n\"\"\"\npkl.py\n:author: Andrew Scott\n:date: 9-3-2018\nIf executed successfully this script will log key strokes until the process is killed.\nThis script is for EDUCATIONAL PURPOSES ONLY. \n\"\"\"\n# can be run without root, but must enable the privilege in privacy settings\nimport os, sys\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom AppKit import NSApplication, NSApp\nfrom Foundation import NSObject\nfrom Cocoa import (\n    NSEvent,\n    NSKeyDownMask, # keyboard\n    NSLeftMouseUpMask, # mouse\n    NSLeftMouseDownMask,\n    NSLeftMouseDraggedMask,\n    NSRightMouseDownMask,\n    NSRightMouseDraggedMask,\n    NSRightMouseUpMask,\n    NSMouseMovedMask,\n)\nfrom PyObjCTools import AppHelper\n# NSLeftMouseUpMask, NSLeftMouseDownMask, NSLeftMouseDraggedMask, NSRightMouseDownMask, NSRightMouseDraggedMask, NSRightMouseUpMask, NSMouseMovedMask\nclass AppDelegate(NSObject):\n    \"\"\"\n    The App Delegate creates a mask to detect the key being pressed and adds\n    a global monitor for this mask.",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:1-38"
    },
    "4473": {
        "file_id": 570,
        "content": "This Python script logs key strokes until the process is killed, intended for educational purposes only. It uses AppKit and Foundation modules from Cocoa and PyObjCTools to create an app delegate that detects keyboard and mouse events without root access, but requires enabling privilege in privacy settings.",
        "type": "comment"
    },
    "4474": {
        "file_id": 570,
        "content": "    \"\"\"\n    def applicationDidFinishLaunching_(self, notification):\n        mask_down = NSKeyDownMask\n        mouse_masks = [\n            NSLeftMouseUpMask,\n            NSLeftMouseDownMask,\n            NSLeftMouseDraggedMask,\n            NSRightMouseDownMask,\n            NSRightMouseDraggedMask,\n            NSRightMouseUpMask,\n            NSMouseMovedMask,\n        ]\n        NSEvent.addGlobalMonitorForEventsMatchingMask_handler_(mask_down, key_handler)\n        for mouse_mask in mouse_masks:\n            NSEvent.addGlobalMonitorForEventsMatchingMask_handler_(\n                mouse_mask, mouse_handler\n            )\n# w = Writer()\ndef mouse_handler(event):\n    import time\n    print(\"mouse have actions\", time.time())\ndef key_handler(event):\n    \"\"\"\n    Translates the key press events into readable characters if one exists\n    the key code is also recorded for non-character input.\n    \"\"\"\n    try:\n        capture_char = event.characters()\n        capture_raw = event.keyCode()\n        print(capture_char, capture_raw)\n        # w.write_to_log(capture_char, capture_raw)",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:39-74"
    },
    "4475": {
        "file_id": 570,
        "content": "The code sets up event handlers for various mouse actions and keyboard events. It adds a global monitor to track these events, and when an event occurs, it logs the characters (if any) and keyCode. The code also includes functions for handling the mouse and key events, but they do not appear to perform any specific actions beyond logging.",
        "type": "comment"
    },
    "4476": {
        "file_id": 570,
        "content": "    except KeyboardInterrupt:\n        AppHelper.stopEventLoop()\nif __name__ == \"__main__\":\n    app = NSApplication.sharedApplication()\n    delegate = AppDelegate.alloc().init()\n    NSApp().setDelegate_(delegate)\n    AppHelper.runEventLoop()",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/pkl_nowriting.py:75-83"
    },
    "4477": {
        "file_id": 570,
        "content": "The code sets up an event loop and handles interrupts, ensuring that the application properly terminates when needed.",
        "type": "comment"
    },
    "4478": {
        "file_id": 571,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier_with_masscan_scapy.py",
        "type": "filepath"
    },
    "4479": {
        "file_id": 571,
        "content": "This code uses Masscan to scan for open ports, connects to the desired port with AdbWrapper, and stores connected addresses in a list. It is part of a script for controlling devices over the network.",
        "type": "summary"
    },
    "4480": {
        "file_id": 571,
        "content": "# strange.\nfrom __future__ import absolute_import, division, print_function\nimport logging\nimport scapy.config\nimport scapy.layers.l2\nimport scapy.route\nimport socket\nimport math\nimport errno\nimport os\nimport getopt\nimport sys\nmyPort = 5555\nmyInterface = \"wlan0\"\n# list avaliable devices.\nfrom adb_wrapper import AdbWrapper\na = AdbWrapper()\ndevices = a.devices()\nprint(devices)\n# exit()\nconnected_addresses = []\nfor key, value in devices.items():\n    address = key\n    connected_addresses.append(address)\n    deviceType = value\n# not working.\nif os.geteuid() != 0:\n        print('You need to be root to run this script', file=sys.stderr)\n        sys.exit(1)\nscanAddress = None\nfor network, netmask, _, interface, address, _ in scapy.config.conf.route.routes:\n    # print(interface, address)\n    if interface == myInterface:\n        myAddress = address.split(\".\")\n        myAddress[3] = \"0/24\"\n        scanAddress = \".\".join(myAddress)\n        print(scanAddress, interface)\n        break\nif scanAddress is not None:\n    # now scan this interface with masscan.",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier_with_masscan_scapy.py:1-42"
    },
    "4481": {
        "file_id": 571,
        "content": "The code imports necessary libraries, initializes variables, and connects with available devices using AdbWrapper. It then checks if the user is root before attempting to scan a specific network interface using masscan.",
        "type": "comment"
    },
    "4482": {
        "file_id": 571,
        "content": "    import masscan\n    mas = masscan.PortScanner()\n    mas.scan(scanAddress, ports=str(myPort), arguments='--max-rate 1000')\n    result = mas.scan_result\n    # usually it only show opens.\n    import json\n    scanResultDict = json.loads(result)['scan']\n    for key, value in scanResultDict.items():\n        address = key\n        for port in value:\n            if port['port'] == myPort and port['status'] =='open':\n                # print(address, myPort)\n                # we need to connect to it!\n                connect_address = \"{}:{}\".format(address,myPort)\n                print(connect_address)\n                if not connect_address in connected_addresses:\n                    print(\"connecting device:\", connect_address)\n                    # command1 = \"adb tcpip 5555\"\n                    # no need to restart?\n                    command2 = \"adb connect {}\".format(connect_address)\n                    # os.system(command1)\n                    os.system(command2)",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier_with_masscan_scapy.py:43-64"
    },
    "4483": {
        "file_id": 571,
        "content": "This code is using the Masscan library to scan for open ports on a specified address. It then checks if the desired port is open, and if so, connects to it by running \"adb connect\" command. The connected addresses are stored in the connected_addresses list. This code is part of a broader script for controlling devices over network.",
        "type": "comment"
    },
    "4484": {
        "file_id": 572,
        "content": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier.sh",
        "type": "filepath"
    },
    "4485": {
        "file_id": 572,
        "content": "This line establishes a TCP/IP connection on port 5555 for ADB, ensuring the device is reachable over the network.",
        "type": "summary"
    },
    "4486": {
        "file_id": 572,
        "content": "adb tcpip 5555 # will not restart if already in tcpip mode\\",
        "type": "code",
        "location": "/tests/adb_phone_control_termux_network_broadcast_scrcpy_appium_airtest/get_modifier.sh:1-1"
    },
    "4487": {
        "file_id": 572,
        "content": "This line establishes a TCP/IP connection on port 5555 for ADB, ensuring the device is reachable over the network.",
        "type": "comment"
    },
    "4488": {
        "file_id": 573,
        "content": "/tests/anime1_me_video_download/README.md",
        "type": "filepath"
    },
    "4489": {
        "file_id": 573,
        "content": "This code instructs to extract data from the video API, send it to a specific URL, use the resulting cookie for downloading the video from another URL to avoid errors.",
        "type": "summary"
    },
    "4490": {
        "file_id": 573,
        "content": "the data is hide in the video data-api. unquote it and we will get the info. \npost data to https://v.anime1.me/api, then use responded cookie p,h with the original e(timestamp) for download.\ndownload video from https://shiro.v.anime1.me/(or elsewhere) or somehow we will get it wrong.",
        "type": "code",
        "location": "/tests/anime1_me_video_download/README.md:1-5"
    },
    "4491": {
        "file_id": 573,
        "content": "This code instructs to extract data from the video API, send it to a specific URL, use the resulting cookie for downloading the video from another URL to avoid errors.",
        "type": "comment"
    },
    "4492": {
        "file_id": 574,
        "content": "/tests/anime1_me_video_download/test_download.sh",
        "type": "filepath"
    },
    "4493": {
        "file_id": 574,
        "content": "This script downloads \"crossdressing.mp4\" from the URL using various cookies until successful, involving timestamp, header, and Google Analytics parameters.",
        "type": "summary"
    },
    "4494": {
        "file_id": 574,
        "content": "# curl -L -o crossdressing.mp4 --cookie \"e=1652443257\" https://shiro.v.anime1.me/1019/6b.mp4\n# curl -L -o crossdressing.mp4 --cookie \"e=1652443257; p=eyJpc3MiOiJhbmltZTEubWUiLCJleHAiOjE2NTI0NDMyNTcwMDAsImlhdCI6MTY1MjQyODk1NTAwMCwic3ViIjoiLzEwMTkvNmIubXA0In0\" https://shiro.v.anime1.me/1019/6b.mp4\n# curl -L -o crossdressing.mp4 --cookie \"h=i6CylEHO-BiMkCPCqFDk_A\" https://shiro.v.anime1.me/1019/6b.mp4\n# curl -L -o crossdressing.mp4 --cookie \"e=1652443257; p=eyJpc3MiOiJhbmltZTEubWUiLCJleHAiOjE2NTI0NDMyNTcwMDAsImlhdCI6MTY1MjQyODk1NTAwMCwic3ViIjoiLzEwMTkvNmIubXA0In0; h=i6CylEHO-BiMkCPCqFDk_A\" https://shiro.v.anime1.me/1019/6b.mp4\ncurl -L -o crossdressing.mp4 --cookie \"e=1652443257; p=eyJpc3MiOiJhbmltZTEubWUiLCJleHAiOjE2NTI0NDMyNTcwMDAsImlhdCI6MTY1MjQyODk1NTAwMCwic3ViIjoiLzEwMTkvNmIubXA0In0; h=i6CylEHO-BiMkCPCqFDk_A\" https://shiro.v.anime1.me/1019/6b.mp4 # the only way to be.\n# curl -L -o crossdressing.mp4 --cookie \"e=1652443257; p=eyJpc3MiOiJhbmltZTEubWUiLCJleHAiOjE2NTI0NDMyNTcwMDAsImlhdCI6MTY1Mj",
        "type": "code",
        "location": "/tests/anime1_me_video_download/test_download.sh:1-6"
    },
    "4495": {
        "file_id": 574,
        "content": "This script is downloading a video file named \"crossdressing.mp4\" from the URL \"https://shiro.v.anime1.me/1019/6b.mp4\", using different combinations of cookies to access and save the file, with each attempt providing additional cookie values until the final combination successfully downloads the video.",
        "type": "comment"
    },
    "4496": {
        "file_id": 574,
        "content": "QyODk1NTAwMCwic3ViIjoiLzEwMTkvNmIubXA0In0; h=i6CylEHO-BiMkCPCqFDk_A; _ga=GA1.2.1032429949.1652428850; _gid=GA1.2.244096696.1652428850\" https://shiro.v.anime1.me/1019/6b.mp4",
        "type": "code",
        "location": "/tests/anime1_me_video_download/test_download.sh:6-6"
    },
    "4497": {
        "file_id": 574,
        "content": "The code appears to be a string containing a series of parameters and URL for downloading an MP4 file. The specific parameters include a timestamp, header value, Google Analytics IDs, and the video URL.",
        "type": "comment"
    },
    "4498": {
        "file_id": 575,
        "content": "/tests/anime1_me_video_download/get_best_edm.sh",
        "type": "filepath"
    },
    "4499": {
        "file_id": 575,
        "content": "The code uses FFmpeg to extract segments from the \"edm_super_summit.m4a\" audio file, saving them as \"best_edm_split.mp3\" and \"best_edm_split2.mp3\". The -ss option specifies the start time and -to the end time for each segment.",
        "type": "summary"
    }
}