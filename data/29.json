{
    "2900": {
        "file_id": 326,
        "content": "url = \"https://nyaa.si/view/1627038\"\nimport requests\nfrom NyaaPy import utils, torrent\nr = requests.get(url)\nSITE = utils.TorrentSite.NYAASI\njson_data = utils.parse_single(request_text=r.text, site=SITE)\ndata_class = torrent.json_to_class(json_data)\nimport rich\n# json_data['seeders']\n# json_data['title']\n# json_data['files']\nrich.print(json_data)\nprint()\nprint(\"_\"*20)\nprint()\nrich.print(data_class)\nbreakpoint()",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_torrent_file_list.py:1-25"
    },
    "2901": {
        "file_id": 326,
        "content": "This code fetches data from the Nyaa.si website using requests library, parses it using NyaaPy's utils and torrent modules, and prints the parsed JSON data and the corresponding data class object.",
        "type": "comment"
    },
    "2902": {
        "file_id": 327,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_api_connector.py",
        "type": "filepath"
    },
    "2903": {
        "file_id": 327,
        "content": "The Python script uses requests and BeautifulSoup to search the Nyaa torrent site for anime with 7+ seeders, retrieves results, stores in \"output.html\", and checks if more pages exist using a template and NyaaPy library for torrent handling.",
        "type": "summary"
    },
    "2904": {
        "file_id": 327,
        "content": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport requests\nurl = \"https://nyaa.si\" # change this to mirror sites.\nMIN_SEEDERS=7 # must be greater than this.\nquery = \"oniichan wa oshimai! 01\"\nsort_term = \"seeders\"\nanime_categories = {\n    \"Anime\": \"1_0\",\n    \"Anime - Anime Music Video\": \"1_1\",\n    \"Anime - English-translated\": \"1_2\",\n    \"Anime - Non-English-translated\": \"1_3\",\n    \"Anime - Raw\": \"1_4\",\n}\ncategory_code = anime_categories[\"Anime\"]  # anime\npage = 1  # start page: 1\nend_of_page = False\n# better not to use rss version since it will not sort terms.\nparams = dict(f=0, c=category_code, q=query, s=sort_term, o=\"desc\", p=page)\n# better parse it yourself first huh?\n# r = requests.get(url, params=params)\n# assert r.code == 200\n# text = r.text\nwith open(\"output.html\", \"r\") as f:\n    text = f.read()\nfrom bs4 import BeautifulSoup\n# with open(\"output.html\",'w+') as f:\n#    f.write(text)\nsoup = BeautifulSoup(text, \"html.parser\")\n# breakpoint()\nimport parse\ntemplate = \"Displaying results {start:d}-{end:d} out of {total:d} results.\"",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_api_connector.py:1-48"
    },
    "2905": {
        "file_id": 327,
        "content": "The code is a Python script that uses the requests library to make an API request to the Nyaa torrent site. It searches for a specific anime with 7 or more seeders, retrieves the results, and stores them in a file named \"output.html\". The BeautifulSoup library is used to parse the HTML response, and the parse module seems to be utilized for further processing.",
        "type": "comment"
    },
    "2906": {
        "file_id": 327,
        "content": "banner = soup.find(\"div\", class_=\"pagination-page-info\").text\npagination_info = banner.split(\"\\n\")[0]\npagination_info_result = parse.parse(template, pagination_info)\nif pagination_info_result:\n    if pagination_info_result[\"total\"] == pagination_info_result[\"end\"]:\n        print(\"Reached end of page.\")\n        end_of_page = True\nfrom NyaaPy import utils\nSITE = utils.TorrentSite.NYAASI\njson_info = utils.parse_nyaa(request_text=text, limit=None, site=SITE)\nimport rich\nrich.print(json_info)\n# breakpoint()\nfor videoInfo in json_info:\n    seeders = int(videoInfo['seeders'])\n    seeders_enough = seeders>=MIN_SEEDERS\n    print('seeders?',seeders)\n    print(\"seeders enough?\", seeders_enough)\n    # videoInfo['id'] -> \"https://nyaa.si/view/{}\"\n# you can also download torrent file for only file info.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/nyaa_api_connector.py:50-77"
    },
    "2907": {
        "file_id": 327,
        "content": "The code retrieves the banner from a webpage, extracts pagination information, and checks if it has reached the end of the page. It then parses the response using a template and determines if there are enough seeders for each video info. The code prints the number of seeders and whether they are enough based on a minimum seeders threshold. The code uses the NyaaPy library for site-specific torrent handling.",
        "type": "comment"
    },
    "2908": {
        "file_id": 328,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py",
        "type": "filepath"
    },
    "2909": {
        "file_id": 328,
        "content": "The code utilizes ffmpeg to extract subtitles, sets anime series constants, filters series names, and reads filenames from a JSON. It checks for bangume names, identifies episode index location, compares with expected position, and prints the episode index or displays \"EPISODE?\" if not recognized.",
        "type": "summary"
    },
    "2910": {
        "file_id": 328,
        "content": "subtitle_types = [\"ass\", \"srt\"]\nvideo_types = [\n    \"mkv\",\n    \"mov\",\n    \"mp4\",\n    \"flv\",\n    \"avi\",\n    \"ogv\",\n    \"webm\",\n    \"ts\",\n    \"wmv\",\n    \"webm\",\n    \"m4v\",\n    \"3gp\",\n]\n# use ffmpeg for subtitle extraction?\nfiletypes = {\"subtitle\": subtitle_types, \"video\": video_types}\nBangumi_Name = \"Yahari Ore no Seishun Lovecome wa Machigatte Iru.\".strip()\nepisodeIndex = 3\nchinese_simplified_sub_types = [\"chs\", \"简体\", \"简日\"]\nchinese_traditional_sub_types = [\"繁日\", \"繁体\", \"繁體\", \"cht\"]\nimport json\n# replace non-alphanumeric charcters.\nepisode_formatter = lambda episode_index: str(episode_index).zfill(2)\nimport re\n# also replace all double spaces.\ndef double_space_replacer(chars: str):\n    if \"  \" in chars:\n        chars = chars.replace(\"  \", \" \")\n        return double_space_replacer(chars)\n    else:\n        return chars\nalphanumeric_filter = lambda chars: double_space_replacer(\n    re.sub(r\"[^a-z0-9]\", \" \", chars)\n)\nbangume_name_lower_alphanumeric = alphanumeric_filter(Bangumi_Name.lower())\nwith open(\"test_filenames.json\", \"r\") as f:",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py:1-46"
    },
    "2911": {
        "file_id": 328,
        "content": "This code defines file types for subtitles and videos, uses ffmpeg for subtitle extraction, defines constants related to a specific anime series, applies an alphanumeric filter to the anime name, and reads filenames from a JSON file.",
        "type": "comment"
    },
    "2912": {
        "file_id": 328,
        "content": "    fnames = json.loads(f.read())\nfor fname in fnames:\n    fname_lower = fname.lower()\n    fname_lower_alphanumeric = alphanumeric_filter(fname_lower)\n    file_extension = fname_lower.split(\".\")[-1]\n    current_file_type = \"unknown\"\n    for filetype, file_extensions in filetypes.items():\n        if file_extension in file_extensions:\n            current_file_type = filetype\n            break\n    print(f\"<{current_file_type}> {fname}\")\n    print(fname_lower_alphanumeric)\n    substring_location_start = fname_lower_alphanumeric.find(\n        bangume_name_lower_alphanumeric\n    )\n    if substring_location_start!=-1:\n        substring_location_end = substring_location_start + len(\n        bangume_name_lower_alphanumeric\n    )\n        assert fname_lower_alphanumeric[substring_location_start: substring_location_end] == bangume_name_lower_alphanumeric\n        episodeIndexLocation = fname_lower_alphanumeric.find(f\" {episode_formatter(episodeIndex)} \")\n        if episodeIndexLocation!=-1:\n            if episodeIndexLocation+1>=substring_location_end:",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py:47-71"
    },
    "2913": {
        "file_id": 328,
        "content": "Reading file names from a JSON, filtering, and determining their types. Checking if the bangume name substring is present in the filename. Identifying the episode index location and comparing it with the expected position.",
        "type": "comment"
    },
    "2914": {
        "file_id": 328,
        "content": "                print(\"EPISODE?\") # this is the index we want\n                print(episodeIndex)",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_resolution_parsing_chapter_recognition.py:72-73"
    },
    "2915": {
        "file_id": 328,
        "content": "Code snippet checks the episode index and prints it. If the desired index is not recognized, it displays \"EPISODE?\" for clarification.",
        "type": "comment"
    },
    "2916": {
        "file_id": 329,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/name_fuzzy.py",
        "type": "filepath"
    },
    "2917": {
        "file_id": 329,
        "content": "This code initializes two empty lists, 'filenames' and 'bangumi_names'. 'bangumi_names' contains two string values representing anime titles.",
        "type": "summary"
    },
    "2918": {
        "file_id": 329,
        "content": "filenames = []\nbangumi_names= [\"Yahari Ore no Seishun Lovecome wa Machigatte Iru.\",\"Yahari Ore no Seishun Love Come wa Machigatteiru.\"]",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/name_fuzzy.py:1-3"
    },
    "2919": {
        "file_id": 329,
        "content": "This code initializes two empty lists, 'filenames' and 'bangumi_names'. 'bangumi_names' contains two string values representing anime titles.",
        "type": "comment"
    },
    "2920": {
        "file_id": 330,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/make_node_symlink.sh",
        "type": "filepath"
    },
    "2921": {
        "file_id": 330,
        "content": "This script creates a symbolic link named \"node_modules\" pointing to the $NODE_PATH, presumably to resolve or fix an issue with file locations.",
        "type": "summary"
    },
    "2922": {
        "file_id": 330,
        "content": "ln -s $NODE_PATH node_modules # to fix shit.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/make_node_symlink.sh:1-1"
    },
    "2923": {
        "file_id": 330,
        "content": "This script creates a symbolic link named \"node_modules\" pointing to the $NODE_PATH, presumably to resolve or fix an issue with file locations.",
        "type": "comment"
    },
    "2924": {
        "file_id": 331,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/kill_aria2c.sh",
        "type": "filepath"
    },
    "2925": {
        "file_id": 331,
        "content": "This command is killing the aria2c process with a SIGINT signal, specifically targeting the specified anime episode titled 'Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' from the Kamigami & VCB-Studio group.",
        "type": "summary"
    },
    "2926": {
        "file_id": 331,
        "content": "ps aux | grep '[Kamigami&VCB-Studio] Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' | grep -v grep | awk '{print $1}' | xargs -Iabc kill -s INT abc",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/kill_aria2c.sh:1-1"
    },
    "2927": {
        "file_id": 331,
        "content": "This command is killing the aria2c process with a SIGINT signal, specifically targeting the specified anime episode titled 'Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]' from the Kamigami & VCB-Studio group.",
        "type": "comment"
    },
    "2928": {
        "file_id": 332,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/dynamic_import.mjs",
        "type": "filepath"
    },
    "2929": {
        "file_id": 332,
        "content": "Code imports and initializes two modules, FfmpegCommand and WebTorrent, using dynamic import. The code checks the data types of the imported functions, with FfmpegCommand being a function and WebTorrent appearing as a class in the console despite its data type being \"function\".",
        "type": "summary"
    },
    "2930": {
        "file_id": 332,
        "content": "const FfmpegCommand = (await import(`${process.env.NODE_PATH}/fluent-ffmpeg/index.js`)).default \nconst WebTorrent = (await import(`${process.env.NODE_PATH}/webtorrent/index.js`)).default \n// promise!\n// shit this ESM can directly use await statements.\nconsole.log(FfmpegCommand)\nconsole.log(typeof(FfmpegCommand)) // \"function\", with default name.\nconsole.log(WebTorrent)\nconsole.log(typeof(WebTorrent)) // \"function\"? why i see \"class\" in console.log?\n// this syntax is not recommended. autocompletion will not work.",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/dynamic_import.mjs:1-12"
    },
    "2931": {
        "file_id": 332,
        "content": "Code imports and initializes two modules, FfmpegCommand and WebTorrent, using dynamic import. The code checks the data types of the imported functions, with FfmpegCommand being a function and WebTorrent appearing as a class in the console despite its data type being \"function\".",
        "type": "comment"
    },
    "2932": {
        "file_id": 333,
        "content": "/tests/anime_highlight_cuts/bittorrent_downloader/download_given_file_to_given_name.sh",
        "type": "filepath"
    },
    "2933": {
        "file_id": 333,
        "content": "This script downloads a torrent file using aria2c and removes temporary files once finished. The script sets the base path, torrent name, and file ID for the download. It also includes two different command variations for stopping the download after completion with timeout options. The commands use kill and grep to end the aria2c process with a signal and remove temporary files.",
        "type": "summary"
    },
    "2934": {
        "file_id": 333,
        "content": "# how to end downloading when finished?\n# using some command?\nBASE_PATH=\"/Users/jamesbrown/Downloads/anime_download\"\n# DOWNLOAD_FILE_PATH=\"$BASE_PATH/sample.webp\"\nTORRENT_NAME=\"[Kamigami&VCB-Studio] Yahari Ore no Seishun Lovecome wa Machigatte Iru. [Ma10p_1080p]\"\n# torrent name might be different.\nTORRENT_PATH=\"$BASE_PATH/$TORRENT_NAME.torrent\"\n# echo \"ps aux | grep '$TORRENT_NAME' | grep -v grep | awk '{print \\$1}' | xargs -Iabc kill -s INT abc\" > kill_aria2c.sh\nFILE_ID=\"117\"\n# timeout set to what?\n# rm \"$DOWNLOAD_FILE_PATH\"\nrm -rf \"$TORRENT_NAME\"\nrm -rf \"$TORRENT_NAME.aria2\"\n# this will be ignored.\n# change directory to our temp directory.\n# this speed shall be precalculated.\n# \n# you may check integrity.\n# just count seeders.\n# aria2c -x 16 --select-file=\"$FILE_ID\" --seed-time=0 --file-allocation=none \"$TORRENT_PATH\"\n# aria2c -x 16 --select-file=\"$FILE_ID\" --seed-time=0 --file-allocation=none --lowest-speed-limit=300K --bt-stop-timeout=60 \"$TORRENT_PATH\"",
        "type": "code",
        "location": "/tests/anime_highlight_cuts/bittorrent_downloader/download_given_file_to_given_name.sh:1-27"
    },
    "2935": {
        "file_id": 333,
        "content": "This script downloads a torrent file using aria2c and removes temporary files once finished. The script sets the base path, torrent name, and file ID for the download. It also includes two different command variations for stopping the download after completion with timeout options. The commands use kill and grep to end the aria2c process with a signal and remove temporary files.",
        "type": "comment"
    },
    "2936": {
        "file_id": 334,
        "content": "/tests/bilibili_search_api_modification_section_params_get_related_videos/testApi.py",
        "type": "filepath"
    },
    "2937": {
        "file_id": 334,
        "content": "The code imports functions from the \"bilibili_api\" module and performs actions related to video searching and retrieval on Bilibili platform, using bilibili_search_api module to search for videos and write results to JSON files.",
        "type": "summary"
    },
    "2938": {
        "file_id": 334,
        "content": "from bilibili_api import sync, search\nBSP = search.bilibiliSearchParams()\n# result = sync(\n#     search.search(\n#         keyword=\"汪汪\",\n#         params={\"tids\": BSP.all.tids.动物圈.tid, \"duration\": BSP.all.duration._10分钟以下},\n#         page=1\n#     )\n# )\n# print(result)\n# how to get suggested keyword?\n# suggested_keyword = sync(search.get_suggest_keywords(keyword = \"汪汪\"))\n# print(suggested_keyword)\n# you might want to split this.\n# this is not deterministic.\n# ['汪汪队立大功 第二季 中文配音', '汪汪队立大功', '汪汪队立大功神威狗狗', '汪汪队', '特别任务 汪汪队立大功 冒险湾的一天', '雀魂汪汪录', '汪汪公主biu', '汪汪来透剧', '汪汪在亚美尼亚', '汪汪队立大功 第一季 中文配音']\n# ['汪汪队立大功', '汪汪队', '汪汪队立大功 第一季 中文配音', '汪汪队立大功 第二季 中文配音', '汪汪录', '汪汪队立大功大电影', '汪汪队立大功中文', '汪汪队立大功神威狗狗', '汪汪汪', '汪汪队中文']\nimport json\n# result_str = json.dumps(result, ensure_ascii=False, indent=4)\n# with open(\"search_result_all.json\",'w+') as f:\n#     f.write(result_str)\n# get video info\nfrom bilibili_api import video\nbvid = \"BV1iw411Z7xt\"\nv = video.Video(bvid=bvid)\n# info=sync(v.get_info())\n# # print(info)\n# with open('video_info.json', 'w+') as f:",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/testApi.py:1-38"
    },
    "2939": {
        "file_id": 334,
        "content": "This code imports functions from the \"bilibili_api\" module, initializes a search object, and attempts to perform various actions related to video searching and retrieval on Bilibili platform. It includes searching for videos using specified keywords and tags, getting suggested keywords, obtaining video information, and saving search results and video info as JSON files.",
        "type": "comment"
    },
    "2940": {
        "file_id": 334,
        "content": "#     f.write(json.dumps(info, indent=4, ensure_ascii=False))\n# -> pages to access all parted videos.\n# -> ugc_season to get maker collected seasons.\n# # video tags\n# able to get from search\n# related videos\n# related = sync(v.get_related())\n# with open('video_related.json', 'w+') as f:\n#     f.write(json.dumps(related, indent=4, ensure_ascii=False))\n# search video\nresult = sync(\n    search.search_by_type(\n        keyword=\"汪汪\",\n        params={\"tids\": BSP.all.tids.动物圈.tid, \"duration\": BSP.all.duration._10分钟以下},\n        page=1,\n        search_type=search.SearchObjectType.VIDEO,\n    )\n)\nwith open('search_by_type_result_video.json','w+') as f:\n    f.write(json.dumps(result, indent=4, ensure_ascii=False))\n# with open(\"search_result_all.json\", \"r\") as f:\n#     data = f.read()\n#     data = json.loads(data)",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/testApi.py:39-68"
    },
    "2941": {
        "file_id": 334,
        "content": "This code is using the bilibili_search_api module to search for videos related to a specific keyword and writes the results to json files. The script first calls the get_related() function on each video, then writes the related videos to a 'video_related.json' file. Next, it searches for a specific type of video using the search_by_type() function and writes the result to 'search_by_type_result_video.json'. Additionally, there is commented code that suggests reading data from 'search_result_all.json', but this is not executed in this script.",
        "type": "comment"
    },
    "2942": {
        "file_id": 335,
        "content": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py",
        "type": "filepath"
    },
    "2943": {
        "file_id": 335,
        "content": "The code showcases Bilibili search query URLs with parameters for keyword, source, tid, order type, and duration filter, related to the video search API of Bilibili allowing content searches, modifications, and testing. It defines section categories and provides sorting options for bilibili search results with example URLs and API retrieval of related videos.",
        "type": "summary"
    },
    "2944": {
        "file_id": 335,
        "content": "# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36\n# 综合排序\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=click\n# 最多点击\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=pubdate\n# 最新发布\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=dm\n# 最多弹幕\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=stow\n# 最多收藏\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=stow&duration=1\n# https://search.bilibili.com/all?keyword=%E",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:1-14"
    },
    "2945": {
        "file_id": 335,
        "content": "This code provides example URLs for Bilibili search queries, demonstrating different sorting options such as overall popularity, latest publication date, and number of comments or favorites. The URLs include various parameters like keyword, source, tid, and order type, along with an optional duration filter for favorite videos.",
        "type": "comment"
    },
    "2946": {
        "file_id": 335,
        "content": "9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=stow&duration=2\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=stow&duration=3\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&tids=36&order=stow&duration=4\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&order=stow&duration=4&tids=1\n# https://search.bilibili.com/all?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&order=stow&duration=4&tids=24\n# https://search.bilibili.com/article?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24&order=attention\n# https://search.bilibili.com/article?keyword=",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:14-25"
    },
    "2947": {
        "file_id": 335,
        "content": "This code appears to be a collection of example URLs containing various parameters for searching on Bilibili, likely related to their video search API. The parameters include specific keywords, duration, and article or all searches, as well as other potential options like order and tids. These are most likely used to test and modify the bilibili_search_api function in this codebase.",
        "type": "comment"
    },
    "2948": {
        "file_id": 335,
        "content": "%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24&order=scores\n# https://search.bilibili.com/live?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24\n# https://search.bilibili.com/live?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24&search_type=live_user\n# https://search.bilibili.com/live?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24&search_type=live_room\nclass bilibiliSearchParams:\n    class _path:\n        综合 = \"all\"\n        视频 = \"video\" # for now you only search for video, recommend it to qq. remember do not use message post by yourself. or maybe you can make a switch for that?\n        番剧 = \"bangumi\"\n        影视 = \"pgc\"\n        直播 = \"live\"\n        专栏 = \"article\"\n        话题 = \"topic\"\n        用户 = \"upuser\"\n    class all:\n        class order:",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:25-45"
    },
    "2949": {
        "file_id": 335,
        "content": "This code is part of the bilibiliSearchParams class, defining search parameters for different types of content on Bilibili. The available content types are \"all\", \"video\", \"bangumi\", \"pgc\", \"live\", \"article\", and \"topic\". The order parameter includes options like \"scores\" and can be used with the specified content type to refine the search results.",
        "type": "comment"
    },
    "2950": {
        "file_id": 335,
        "content": "            综合排序 = None\n            最多点击 = \"click\"\n            最新发布 = \"pubdate\"\n            最多弹幕 = \"dm\"\n            最多收藏 = \"stow\"\n        class duration:\n            全部时长 = None\n            _10分钟以下 = 1\n            _10_30分钟 = 2\n            _30_60分钟 = 3\n            _60分钟以上 = 4\n        class tids:\n            全部分区 = None\n            ########################\n            class 番剧:\n                tid = 13\n                连载动画 = 33\n                完结动画 = 32\n                资讯 = 51\n                官方延伸 = 152\n            class 国创:\n                tid = 167\n                国产动画 = 153\n                国产原创相关 = 168\n                布袋戏 = 169\n                动态漫·广播剧 = 195\n                资讯 = 170\n            class 动画:\n                tid = 1\n                MAD_AMV = 24\n                MMD_3D = 25\n                短片·手书·配音 = 47\n                手办·模玩 = 210\n                特摄 = 86\n                综合 = 27\n            class 游戏:\n                tid = 4\n                单机游戏 = 17\n                电子竞技 = 171\n                手机游戏 = 172\n                网络游戏 = 65",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:46-92"
    },
    "2951": {
        "file_id": 335,
        "content": "This code defines different video categories and their corresponding TID values for sorting and filtering purposes in a Bilibili search API modification function. The categories include anime, Chinese animation, games, and more.",
        "type": "comment"
    },
    "2952": {
        "file_id": 335,
        "content": "                桌游棋牌 = 173\n                GMV = 121\n                音游 = 136\n                Mugen = 19\n            class 鬼畜:\n                tid = 119\n                鬼畜调教 = 22\n                音MAD = 26\n                人力VOCALOID = 126\n                鬼畜剧场 = 216\n                教程演示 = 127\n            class 音乐:\n                tid = 3\n                原创音乐 = 28\n                翻唱 = 31\n                演奏 = 59\n                VOCALOID·UTAU = 30\n                音乐现场 = 29\n                MV = 193\n                乐评盘点 = 243\n                音乐教学 = 244\n                音乐综合 = 130\n            class 舞蹈:\n                tid = 129\n                宅舞 = 20\n                街舞 = 198\n                明星舞蹈 = 199\n                中国舞 = 200\n                舞蹈综合 = 154\n                舞蹈教程 = 156\n            class 影视:\n                tid = 181\n                影视杂谈 = 182\n                影视剪辑 = 183\n                小剧场 = 85\n                预告·资讯 = 184\n            class 娱乐:\n                tid = 5\n                综艺 = 71\n                娱乐杂谈 = 241\n                粉丝创作 = 242",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:93-138"
    },
    "2953": {
        "file_id": 335,
        "content": "This code defines several classes with different tags (173, 121, 136, 19, 119, 22, 26, 126, 216, 127, 3, 28, 31, 59, 30, 29, 193, 243, 244, 130, 129, 20, 198, 199, 200, 154, 156, 181, 182, 183, 85, 71, 241) for categorizing videos on Bilbili.",
        "type": "comment"
    },
    "2954": {
        "file_id": 335,
        "content": "                明星综合 = 137\n            class 知识:\n                tid = 36\n                科学科普 = 201\n                社科·法律·心理 = 124\n                人文历史 = 228\n                财经商业 = 207\n                校园学习 = 208\n                职业职场 = 209\n                设计·创意 = 229\n                野生技能协会 = 122\n            class 科技:\n                tid = 188\n                数码 = 95\n                软件应用 = 230\n                计算机技术 = 231\n                科工机械 = 232\n            class 资讯:\n                tid = 202\n                热点 = 203\n                环球 = 204\n                社会 = 205\n                综合 = 206\n            class 美食:\n                tid = 211\n                美食制作 = 76\n                美食侦探 = 212\n                美食测评 = 213\n                田园美食 = 214\n                美食记录 = 215\n            class 生活:\n                tid = 160\n                搞笑 = 138\n                出行 = 250\n                三农 = 251\n                家居房产 = 239\n                手工 = 161\n                绘画 = 162\n                日常 = 21\n            class 汽车:\n                tid = 223",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:139-185"
    },
    "2955": {
        "file_id": 335,
        "content": "This code defines various classes, each representing a different section category on Bilibili. Each class has a unique 'tid' and a brief description of the content it contains. These sections include knowledge, technology, news, food, life, and cars. The categories are used to retrieve related videos for a search query in the Bilibili API.",
        "type": "comment"
    },
    "2956": {
        "file_id": 335,
        "content": "                赛车 = 245\n                改装玩车 = 246\n                新能源车 = 246\n                房车 = 248\n                摩托车 = 240\n                购车攻略 = 227\n                汽车生活 = 176\n            class 时尚:\n                tid = 155\n                美妆护肤 = 157\n                仿妆cos = 252\n                穿搭 = 158\n                时尚潮流 = 159\n            class 运动:\n                tid = 234\n                篮球 = 235\n                足球 = 249\n                健身 = 164\n                竞技体育 = 236\n                运动文化 = 237\n                运动综合 = 238\n            class 动物圈:\n                tid = 217\n                喵星人 = 218\n                汪星人 = 219\n                大熊猫 = 220\n                野生动物 = 221\n                爬宠 = 222\n                动物综合 = 75\n            ########################\n    video = all\n    class article:\n        class order:\n            综合排序 = None\n            最多点击 = \"click\"\n            最新发布 = \"pubdate\"\n            最多喜欢 = \"attention\"\n            最多评论 = \"scores\"\n    class live:\n        class search_type:\n            全部 = None",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:186-233"
    },
    "2957": {
        "file_id": 335,
        "content": "The code contains different sections and their corresponding tags for a search API. It includes categories such as cars, fashion, sports, and animals with specific tag IDs and subcategories. The code also defines order options (like most popular or latest) and live search types (all or specified).",
        "type": "comment"
    },
    "2958": {
        "file_id": 335,
        "content": "            主播 = \"live_user\"\n            直播间 = \"live_room\"\n    class upuser:\n        class order:\n            默认排序 = None\n            粉丝数由高到低 = \"fans\"\n            Lv等级由高到低 = \"level\"\n        class order_sort:\n            正序 = None\n            倒序 = 1\n# https://search.bilibili.com/upuser?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24&order=fans\n# https://search.bilibili.com/upuser?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24&order=fans&order_sort=1\n# https://search.bilibili.com/upuser?keyword=%E9%A9%AC%E5%85%8B%E6%80%9D%E4%BD%A9%E6%81%A93&from_source=webtop_search&spm_id_from=333.1007&duration=4&tids=24&order=level\n# bilibiliSearchParams.order.最多弹幕\nprint(bilibiliSearchParams.video.tids)",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_search_section_pets.py:234-253"
    },
    "2959": {
        "file_id": 335,
        "content": "This code defines a class \"upuser\" with an inner class \"order\", which contains different sorting options for bilibili search results. The outer class \"order_sort\" provides ascending and descending order options. The code also includes example URLs for different search parameters, and the last line prints the value of \"bilibiliSearchParams.video.tids\".",
        "type": "comment"
    },
    "2960": {
        "file_id": 336,
        "content": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_get_user_info_followers_dynamic.py",
        "type": "filepath"
    },
    "2961": {
        "file_id": 336,
        "content": "The code imports the \"user\" module from \"bilibil_api\", retrieves user information like followers and followings, but lacks implementation for top_followers. It extracts data using various methods, converts non-JSON serializable results to strings, stores in a dictionary, and dumps it into JSON format.",
        "type": "summary"
    },
    "2962": {
        "file_id": 336,
        "content": "from bilibili_api import user, sync\nu = user.User(660303135)\n# u.get_channel_list\n# data = sync(u.get_relation_info())\n# [\"follower\"]\n# {'mid': 660303135, 'following': 34, 'whisper': 0, 'black': 0, 'follower': 1158}\n# get followers less than 200 but view greater than 3000.\n# also get that damn publish date!\n# print(data)\n# print(data.keys())\n# print(dir(u))\n# you can also get followings to get the 'target video'\npotentialMethods = [\n    # \"credential\",#TypeError: 'Credential' object is not callable\n# error executing u.credential()\n    \"get_all_followings\",\n    \"get_article_list\",\n    \"get_articles\",\n    \"get_audios\",\n    # \"get_channel_list\",\n    # \"get_channel_videos_season\",#TypeError: get_channel_videos_season() missing 1 required positional argument: 'sid'\n# error executing u.get_channel_videos_season()\n# Traceback (most recent call last):\n    # \"get_channel_videos_series\", #TypeError: get_channel_videos_series() missing 1 required positional argument: 'sid'\n# error executing u.get_channel_videos_series()\n    # \"get_channels\",",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_get_user_info_followers_dynamic.py:1-27"
    },
    "2963": {
        "file_id": 336,
        "content": "The code is importing the \"user\" module from \"bilibil_api\" and creating an instance of it. It then calls some methods to get user information, specifically focusing on followers and followings. The comments suggest further exploration of available functions and parameters for getting specific types of user data such as articles, audios, and videos. The code also encounters errors when trying to use certain methods without the required arguments.",
        "type": "comment"
    },
    "2964": {
        "file_id": 336,
        "content": "    \"get_cheese\",\n    \"get_dynamics\", # has offset parameter.\n    \"get_followers\", # key feature. we need this some how.\n    \"get_followings\",\n    \"get_live_info\",\n    \"get_overview_stat\",\n    \"get_relation_info\",\n    \"get_subscribed_bangumi\",\n    # \"get_uid\", # probabily not async. #    raise TypeError('An asyncio.Future, a coroutine or an awaitable is '\n# TypeError: An asyncio.Future, a coroutine or an awaitable is required\n# error executing u.get_uid()\n    # \"get_up_stat\", # bilibili_api.exceptions.CredentialNoBiliJctException.CredentialNoBiliJctException: Credential 类未提供 bili_jct。\n# error executing u.get_up_stat()\n    \"get_user_info\",\n    \"get_videos\",\n    # \"modify_relation\", # TypeError: modify_relation() missing 1 required positional argument: 'relation'\n# error executing u.modify_relation()\n##########################################\n# our most wanted feature, top_followers #\n##########################################\n    # \"top_followers\",# bilibili_api.exceptions.ResponseCodeException.ResponseCodeException: 接口返回错误代码：-101，信息：账号未登录。",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_get_user_info_followers_dynamic.py:28-48"
    },
    "2965": {
        "file_id": 336,
        "content": "The code contains various functions for interacting with the Bilibili API, including methods to get user information, videos, dynamics, and more. Some functions are incomplete or require additional parameters. The most desired feature, top_followers, is not yet implemented due to an error.",
        "type": "comment"
    },
    "2966": {
        "file_id": 336,
        "content": "# error executing u.top_followers()\n]\n# breakpoint()\n# get_overview_stat()\nimport json\nmdata = {}\nimport progressbar\nfor key in progressbar.progressbar(potentialMethods):\n    command = \"u.{}()\".format(key)\n    try:\n        result = sync(eval(command))\n        # Object of type ChannelSeries is not JSON serializable\n        if type(result) not in [dict, list, tuple, int, float, str]:\n            print(type(result))\n            print('COMMAND:',key)\n            breakpoint()\n            result = str(result)\n        mdata.update({key:result})\n        import time\n        time.sleep(3)\n    except:\n        import traceback\n        traceback.print_exc()\n        print('error executing {}'.format(command))\nmString = json.dumps(mdata, indent=4, ensure_ascii=False)\nwith open('user_data_api.json','w+') as f:\n    f.write(mString)\nprint(\"DUMP COMPLETE\")",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/test_get_user_info_followers_dynamic.py:49-78"
    },
    "2967": {
        "file_id": 336,
        "content": "The code is attempting to extract user data from the Bilibili platform API. It iterates through a list of potential methods, dynamically executes each method on an object 'u', and stores the results in a dictionary. If the result type is not JSON serializable (like ChannelSeries), it converts it to a string before storing. Finally, it dumps the data into a JSON file named \"user_data_api.json\" and prints \"DUMP COMPLETE\".",
        "type": "comment"
    },
    "2968": {
        "file_id": 337,
        "content": "/tests/bilibili_search_api_modification_section_params_get_related_videos/template.j2",
        "type": "filepath"
    },
    "2969": {
        "file_id": 337,
        "content": "This code defines a class with properties named after channel names, where the values are their respective channel TIDs. It also includes subchannels as additional properties, each with its own TID.",
        "type": "summary"
    },
    "2970": {
        "file_id": 337,
        "content": "class {{ channelName }}:\n    tid = {{ channelTid }}{% for subChannelName, subChannelTid in subChannels %}\n    {{ subChannelName }} = {{ subChannelTid }}{% endfor %}",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/template.j2:2-4"
    },
    "2971": {
        "file_id": 337,
        "content": "This code defines a class with properties named after channel names, where the values are their respective channel TIDs. It also includes subchannels as additional properties, each with its own TID.",
        "type": "comment"
    },
    "2972": {
        "file_id": 338,
        "content": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py",
        "type": "filepath"
    },
    "2973": {
        "file_id": 338,
        "content": "The code processes generators, repairs links, detects errors, and extracts links using regular expressions. It also parses video descriptions for BGM detection and author keyword extraction with Jieba segmentation, and updates video information by processing video-related data.",
        "type": "summary"
    },
    "2974": {
        "file_id": 338,
        "content": "import json\nfrom bs4 import BeautifulSoup\nfrom lazero.utils.logger import sprint\ndef generatorToList(generator):\n    return [x for x in generator]\ndef linkFixer(link, prefix=\"http:\"):\n    if link.startswith(\"//\"):\n        return prefix + link\n    return link\ndef traceError(errorMsg: str = \"error!\", _breakpoint: bool = False):\n    import traceback\n    traceback.print_exc()\n    sprint(errorMsg)\n    if _breakpoint:\n        return breakpoint()\ndef extractLinks(description, extract_bgm=True):\n    \"\"\"Extract and remove links in description\"\"\"\n    import re\n    # notice, we don't need to go wild here. we just want the title and the cover, and the tags.\n    expression = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n    # expr = re.compile(expression)\n    links = re.findall(expression, description)\n    # if links == None:\n    #     links = []\n    desc_without_link = re.sub(expression, \"\", description)\n    desc_without_link_per_line = [\n        x.replace(\"\\n\", \"\").strip() for x in desc_without_link.split(\"\\n\")",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:1-37"
    },
    "2975": {
        "file_id": 338,
        "content": "The code contains functions for handling generators, fixing links, error tracing, and extracting links from descriptions. It uses regular expressions to find links in the description and removes them while preserving other relevant information like titles and tags.",
        "type": "comment"
    },
    "2976": {
        "file_id": 338,
        "content": "    ]\n    desc_without_link_per_line = [x for x in desc_without_link_per_line if len(x) > 0]\n    bgms = []\n    final_desc_list = []\n    if not extract_bgm:\n        final_desc_list = desc_without_link_per_line\n    else:\n        for line in desc_without_link_per_line:\n            bgmCandidateTemplates = [\"{}：\", \"{}:\", \"{} \"]\n            fixers = [x.format(\"\") for x in bgmCandidateTemplates]\n            bgmCandidates = [x.format(\"bgm\") + \"(.+)\" for x in bgmCandidateTemplates]\n            has_bgm = False\n            for candidate in bgmCandidates:\n                bgm_parse_result = re.findall(candidate, line.lower())\n                if len(bgm_parse_result) > 0:\n                    has_bgm = True\n                    # bgm = line[len(bgmCandidates) :]\n                    bgm = bgm_parse_result[0]\n                    bgm = bgm.strip()\n                    for fixer in fixers:\n                        bgm = bgm.strip(fixer)\n                    if len(bgm) > 0:\n                        bgms.append(bgm)\n                    break",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:38-61"
    },
    "2977": {
        "file_id": 338,
        "content": "This code extracts background music (BGMs) from a list of descriptions. It checks each description line for specific patterns using regular expressions and adds them to the bgms list if found. If no BGMs are found, it stores all the description lines without links in final_desc_list.",
        "type": "comment"
    },
    "2978": {
        "file_id": 338,
        "content": "            if not has_bgm:\n                final_desc_list.append(line)\n    desc_without_link = \"\\n\".join(final_desc_list)\n    return links, bgms, desc_without_link\ndef videoDurationStringToSeconds(durationString):\n    if type(durationString) == int:\n        return durationString  # not string at all.\n    if type(durationString) != str:\n        print(\"unknown durationString type: %s\" % type(durationString))\n        return None\n    durationString = durationString.strip()\n    mList = durationString.split(\":\")[::-1]\n    if len(mList) > 3:\n        print(\"DURATION STRING TOO LONG\")\n        return None\n    seconds = 0\n    for index, elem in enumerate(mList):\n        elem = int(elem)\n        seconds += (60**index) * elem\n    return seconds\ndef clearHtmlTags(htmlObject):\n    a = BeautifulSoup(htmlObject, features=\"lxml\")\n    return a.text\ndef detectAuthorRelatedKeywords(title_tag, author_keywords):\n    abandon = False\n    for keyword in author_keywords:\n        if len(keyword) > 1:\n            if keyword in title_tag:\n                abandon = True  # detected this thing.",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:62-96"
    },
    "2979": {
        "file_id": 338,
        "content": "The code contains functions for parsing video descriptions, converting duration strings to seconds, and detecting related keywords. It also handles cases where a background music (BGM) is or isn't present. The final description without links is returned along with the links and BGMs.",
        "type": "comment"
    },
    "2980": {
        "file_id": 338,
        "content": "                break\n    return abandon\ndef getAuthorKeywords(author):\n    author = author.strip()\n    import jieba\n    author_keywords = jieba.lcut(author)\n    author_keywords = [x.strip() for x in author_keywords]\n    author_keywords = [x for x in author_keywords if len(x) > 0]\n    return author_keywords\ndef removeAuthorRelatedTags(description_or_title, author):\n    templates = [\"【{}】\", \"@{}\", \"{}\"]\n    tags = [template.format(author) for template in templates]\n    for tag in tags:\n        description_or_title = description_or_title.replace(tag, \"\")\n    return description_or_title\ndef splitTitleTags(title, author_keywords):\n    import re\n    pattern = r\"【.+】\"\n    title_tags = re.findall(pattern, title)\n    title = re.sub(pattern, \"\", title)\n    title_tags = [x.lstrip(\"【\").rstrip(\"】\").strip() for x in title_tags]\n    title_tags = [x for x in title_tags if len(x) > 0]\n    final_title_tags = []\n    for title_tag in title_tags:\n        detected = detectAuthorRelatedKeywords(title_tag, author_keywords)\n        if not detected:",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:97-131"
    },
    "2981": {
        "file_id": 338,
        "content": "This code performs the following tasks:\n1. Extracts author keywords using Jieba segmentation and removes leading/trailing whitespace, while discarding empty strings.\n2. Removes author-related tags from the description or title by replacing them with an empty string.\n3. Splits the title into tags, removing any leading/trailing brackets, and eliminating empty strings.\n4. Detects if each tag contains any of the author's keywords and adds it to a list called \"final_title_tags\" only if it does.",
        "type": "comment"
    },
    "2982": {
        "file_id": 338,
        "content": "            final_title_tags.append(title_tag)\n    return title, title_tags\ndef parseVideoSearchItem(video, disableList: list = [], debug=False):\n    bvid = video[\"bvid\"]\n    pubdate = video['pubdate']\n    if \"author\" not in disableList:\n        author = video[\"author\"]\n        author_id = video[\"mid\"] # this is important. may let us able to find out the fans count.\n    else:\n        author = \"\"\n        author_id = -1\n    author_keywords = getAuthorKeywords(author)\n    if \"tag\" not in disableList:\n        tag = video[\"tag\"]\n        tags = tag.split(\",\")\n        tags = [\n            tag for tag in tags if not detectAuthorRelatedKeywords(tag, author_keywords)\n        ]\n    else:\n        tags = []\n    if \"typeid\" not in disableList and \"typename\" not in disableList:\n        categoryId = int(video.get(\"typeid\", video.get(\"type_id\")))\n        categoryName = video.get(\"typename\", video.get(\"type_name\"))\n    else:\n        categoryId = 0\n        categoryName = \"\"\n    title = video[\"title\"]  # remove those markers, please?",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:132-160"
    },
    "2983": {
        "file_id": 338,
        "content": "The function takes a video object, optional disabled list for author and tag keywords, and debug flag as input. It extracts the bvid and pubdate from the video object. If author is not in disableList, it retrieves the author name and id. The author's keywords are obtained using getAuthorKeywords function. If tag is not in disableList, it splits the tags and removes any related to author keywords. The typeid and typename are also extracted if not in disableList, otherwise set to default values. Finally, title removal markers are applied.",
        "type": "comment"
    },
    "2984": {
        "file_id": 338,
        "content": "    title = clearHtmlTags(title)\n    title = removeAuthorRelatedTags(title, author)\n    title, title_tags = splitTitleTags(\n        title, author_keywords\n    )  # use author for filtering unwanted title tags.\n    duration = video[\"duration\"]  # this is not recommended. we need seconds.\n    play = video.get(\"play\", video.get(\"view\"))  # select some hot videos.\n    cover = video[\"pic\"]\n    cover = linkFixer(cover)\n    if \"description\" not in disableList:\n        description = video.get(\"description\", video.get(\"desc\"))\n        description = clearHtmlTags(description)\n        description = removeAuthorRelatedTags(description, author)\n    else:\n        description = \"\"\n    links_in_description, bgms, description = extractLinks(description)\n    duration_seconds = videoDurationStringToSeconds(duration)\n    resultTuple = (\n        author,\n        author_id,\n        bvid,\n        tags,\n        categoryId,\n        categoryName,\n        title,\n        duration_seconds,\n        play,\n        cover,\n        description,\n        links_in_description,",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:161-190"
    },
    "2985": {
        "file_id": 338,
        "content": "This code parses video data from a bilibili search API response and extracts relevant information such as author, title, duration, play count, cover image, and description. It applies filters to remove unwanted HTML tags and uses author keywords for filtering. It converts duration strings to seconds and extracts links from the description.",
        "type": "comment"
    },
    "2986": {
        "file_id": 338,
        "content": "        bgms,\n        title_tags,\n        pubdate\n    )\n    if debug:\n        for metadata in resultTuple:\n            print(metadata)\n    from lazero.utils.logger import sprint\n    if debug:\n        sprint()\n    return resultTuple\n# you might want the creater's name, to filter out unwanted parts.\ndef iterateResultList(resultList, debug=False):\n    for video in resultList:\n        # be warned cause all these things might fail.\n        try:\n            if video[\"type\"] == \"video\":\n                yield parseVideoSearchItem(video, debug=debug)\n        except:\n            traceError(\"error iterating video metadata\")\n            continue\ndef parseSearchAllResult(data, debug=False):\n    # if not generator:\n    #     return generatorToList(parseSearchAllResult(data, debug=debug,generator=True))\n    results = data[\"result\"]\n    for elem in results:\n        try:\n            if elem[\"result_type\"] == \"video\":\n                resultList = elem[\"data\"]\n                for videoMetadata in iterateResultList(resultList, debug=debug):",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:191-227"
    },
    "2987": {
        "file_id": 338,
        "content": "This code defines a function `parseSearchAllResult` that takes in data and a boolean debug parameter. It extracts the \"result\" list from the data, then iterates through each element checking if its type is 'video'. For each video, it yields a parsed video metadata using the `iterateResultList` function, while handling any exceptions that may occur. The `iterateResultList` function iterates over a result list of video items, yielding the parsed data for videos and handling exceptions related to parsing video metadata.",
        "type": "comment"
    },
    "2988": {
        "file_id": 338,
        "content": "                    yield videoMetadata\n        except:\n            traceError(\"error iterating data results\")\ndef parseSearchVideoResult(data, debug=False):\n    # if not generator:\n    #     return generatorToList(parseSearchVideoResult(data, debug=debug,generator=True))\n    try:\n        resultList = data[\"result\"]\n        try:\n            for videoMetadata in iterateResultList(resultList, debug=debug):\n                try:\n                    yield videoMetadata\n                except:\n                    traceError(\"error iterating video metadata\")\n        except:\n            traceError(\"error iterating result list\")\n    except:\n        traceError(\"error parsing search video result\")\ndef parseVideoInfo(videoInfo, debug=False):\n    data = videoInfo\n    # no tag out here.\n    secondaryVideoInfoList = []\n    data_copy = data.copy()\n    data_copy.update({\"author\": data[\"owner\"][\"name\"], \"mid\": data[\"owner\"][\"mid\"]})\n    data_copy.update(data[\"stat\"])\n    primaryVideoInfo = parseVideoSearchItem(\n        data_copy, disableList=[\"tag\", \"typeid\", \"typename\"], debug=debug",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:228-258"
    },
    "2989": {
        "file_id": 338,
        "content": "The code defines two functions, `parseSearchVideoResult` and `parseVideoInfo`, which are responsible for parsing video search results and video information respectively. The code utilizes exception handling to handle errors while iterating over data and result lists. It also includes a function `iterateResultList` to iterate over the result list.",
        "type": "comment"
    },
    "2990": {
        "file_id": 338,
        "content": "    )\n    # videoInfoList.append(primaryVideoInfo)\n    season = data.get(\"ugc_season\", {})  # we only care about this thing.\n    season_cover = season.get(\"cover\", None)  # it could be noting.\n    sections = season.get(\"sections\", [])\n    for section in sections:\n        for episode in section[\"episodes\"]:\n            # print(episode.keys())\n            # breakpoint()\n            arc = episode[\"arc\"]\n            stat = arc[\"stat\"]\n            videoInfo = episode.copy()\n            videoInfo.update(stat)\n            videoInfo.update(arc)\n            authorRelatedVideoInfo = parseVideoSearchItem(\n                videoInfo,\n                disableList=[\"tag\", \"typeid\", \"typename\", \"description\", \"author\"],\n                debug=debug,\n            )  # author is the same as the original video.\n            secondaryVideoInfoList.append(authorRelatedVideoInfo)\n            # BV1Cb4y1s7em\n            # []\n            # 0\n            # 这次真的燃起来了！！！\n            # 217\n            # 27911\n            # http://i2.hdslb.com/bfs/archive/c5a0d18ee077fb6a4ac0970ccb0a3788e137d14f.jpg",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:259-286"
    },
    "2991": {
        "file_id": 338,
        "content": "Code iterates through season episodes, extracts arc and stat information from each episode, creates a videoInfo dictionary with episode and arc data, updates the author-related video information by parsing the original video, and appends it to secondaryVideoInfoList.",
        "type": "comment"
    },
    "2992": {
        "file_id": 338,
        "content": "    return primaryVideoInfo, secondaryVideoInfoList\ndef parseVideoRelated(videoRelatedData, debug=False):\n    data = videoRelatedData\n    # if not generator:\n    #     return generatorToList(parseVideoRelated(data, debug=debug,generator=True))\n    try:\n        for videoInfo in data:\n            try:\n                videoInfo2 = videoInfo.copy()\n                videoInfo2.update({\"author\": videoInfo[\"owner\"][\"name\"]})\n                videoInfo2.update({\"mid\": videoInfo[\"owner\"][\"mid\"]})\n                # also update the stat.\n                videoInfo2.update(videoInfo[\"stat\"])\n                try:\n                    yield parseVideoSearchItem(\n                        videoInfo2,\n                        disableList=[\"tag\", \"typeid\", \"typename\"],\n                        debug=debug,\n                    )\n                    # print(videoMetadata)\n                except:\n                    traceError()\n            except:\n                traceError()\n    except:\n        traceError()\nif __name__ == \"__main__\":\n    # test_subject = \"search_video\"",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:287-318"
    },
    "2993": {
        "file_id": 338,
        "content": "This code defines a function `parseVideoRelated` that parses video-related data and yields parsed video information, and also includes an if block for generator handling. It updates the video info with author name and mid, and applies the `parseVideoSearchItem` to each item in the data list. If any error occurs during processing, it traces the error.",
        "type": "comment"
    },
    "2994": {
        "file_id": 338,
        "content": "    # test_subject = \"search_all\"\n    # test_subject = 'video_related'\n    test_subject = \"video_info\"\n    # test_subject = 'extract_links'\n    if test_subject == \"search_all\":\n        with open(\"search_result_all.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        for mresult in parseSearchAllResult(data):\n            print(\"RESULT:\")\n            sprint(mresult)\n    elif test_subject == \"search_video\":\n        with open(\"search_by_type_result_video.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        for mresult in parseSearchVideoResult(data):\n            print(\"VIDEO SEARCH RESULT:\")\n            sprint(mresult)\n    elif test_subject == \"video_info\":\n        with open(\"video_info.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        primaryVideoInfo, secondaryVideoInfoList = parseVideoInfo(data)\n        videoInfoList = [primaryVideoInfo] + secondaryVideoInfoList\n        for mVideoInfo in videoInfoList:",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:319-343"
    },
    "2995": {
        "file_id": 338,
        "content": "This code is testing different APIs by reading JSON files and parsing the data. It tests \"search_all\", \"search_video\", and \"video_info\" sections. For each section, it reads a corresponding JSON file, loads the data, and then prints the results after parsing. This appears to be part of API testing for a video search application.",
        "type": "comment"
    },
    "2996": {
        "file_id": 338,
        "content": "            print(mVideoInfo)\n            sprint()\n    elif test_subject == \"video_related\":\n        with open(\"video_related.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        for videoMetadata in parseVideoRelated(data):\n            print(videoMetadata)\n            sprint()\n    elif test_subject == \"extract_links\":\n        description = (\n            \"http://www.toutiao.com/a6347649852365897986/ 男子送走从小养大的狗，狗狗用泪汪汪的眼神看着他\\n\"\n            + \"https://www.youtube.com/watch?v=r724w57oXyU\"\n            + \" https://www.youtube.com/shorts/UYCy8HD1C7o\"\n        )\n        links, desc = extractLinks(description)\n        print(links)\n        print(desc)\n    else:\n        raise Exception(\"unknown test_subject:\", test_subject)",
        "type": "code",
        "location": "/tests/bilibili_search_api_modification_section_params_get_related_videos/searchDataParser.py:344-363"
    },
    "2997": {
        "file_id": 338,
        "content": "The code snippet appears to handle different test subjects, each with a specific task. For \"video_related\", it reads data from a JSON file and processes it using the parseVideoRelated function, then prints videoMetadata for each videoMetadata in the parsed data. The \"extract_links\" subject extracts links from a given description and prints them. Unknown test subjects will raise an Exception.",
        "type": "comment"
    },
    "2998": {
        "file_id": 339,
        "content": "/tests/bilibili_search_api_modification_section_params_get_related_videos/recursive_search_bilibili_test.py",
        "type": "filepath"
    },
    "2999": {
        "file_id": 339,
        "content": "The code changes directory, initializes OpenCV, and fetches video metadata for production. It imports necessary modules and displays an image using imshow, pausing until a keyboard event occurs for visualization purposes.",
        "type": "summary"
    }
}