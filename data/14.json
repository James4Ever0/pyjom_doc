{
    "1400": {
        "file_id": 127,
        "content": "from bilibili_api import video_uploader, Credential\nfrom pyjom.platforms.bilibili.credentials import bilibiliCredential\nimport os\nfrom pyjom.platforms.bilibili.utils import bilibiliSync\n# you may use the 'sync' method elsewhere.\n# damn. out of sync.\n# recall the order of applying decorators\n# WTF is the order?\n@bilibiliSync\nasync def asyncVideoUploader(\n    videoPath, title, description, meta, credential, cover_path\n):\n    page = video_uploader.VideoUploaderPage(\n        path=videoPath,\n        title=title,\n        description=description,\n    )  # are you sure?\n    uploader = video_uploader.VideoUploader(\n        [page], meta, credential, cover_path=cover_path\n    )\n    # will this work as expected?\n    # @uploader.on(\"__ALL__\")\n    # async def ev(data):\n    #     print(data)\n    result = await uploader.start()  # with bvid, aid as key.\n    # please tell me where the fuck you upload my video upto?\n    # print(\"upload video result:\", result)\n    return result # there's no upload_id. but you can do it in other way, with methods inside the class.",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:1-34"
    },
    "1401": {
        "file_id": 127,
        "content": "This code defines an asynchronous function for uploading videos to Bilibili using the video_uploader module from bilibili_api. It takes videoPath, title, description, meta, credential, and cover_path as parameters, and uses the VideoUploaderPage and VideoUploader classes from the video_uploader module to initiate the upload process. The function is decorated with @bilibiliSync for synchronization purposes.",
        "type": "comment"
    },
    "1402": {
        "file_id": 127,
        "content": "    # if possible please return something like upload_id?\n    # upload video result: {'aid': 901508571, 'bvid': 'BV1MN4y1P7mq'}\n    # breakpoint()  # comment it out later? or we will check why this upload fails. maybe it is because we have duplicated name/cover.\n    # return result[\"bvid\"]  # choose to be in this way?\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport os\nimport re\nimport sys\nimport math\nimport base64\nimport requests\nfrom requests.adapters import HTTPAdapter\nimport threading\nfrom threading import Event\nimport copy\nimport traceback\n# you better embed it inside your function? what a creep?\n# but that will make it impossible to test against other shits.\nclass MultithreadUploader(object):\n    ## what is the cookie string look like?\n    def __init__(self, cookie_string):\n        # TODO: 增加登录接口使用账号密码登陆\n        #  get all related shits?\n        cookie = cookie_string\n        self.MAX_RETRYS = 5\n        self.profile = \"ugcupos/yb\"\n        self.cdn = \"ws\"\n        self.csrf = re.search(\"bili_jct=(.*?);\", cookie + \";\").group(1)",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:35-67"
    },
    "1403": {
        "file_id": 127,
        "content": "Class \"MultithreadUploader\" is a custom class for uploading videos to Bilibili platform using multiple threads. It takes a cookie string as input and has features like retry mechanism and profile settings for caching, CDN, etc.",
        "type": "comment"
    },
    "1404": {
        "file_id": 127,
        "content": "        self.mid = re.search(\"DedeUserID=(.*?);\", cookie + \";\").group(1)\n        self.session = requests.session()\n        self.session.mount(\"https://\", HTTPAdapter(max_retries=self.MAX_RETRYS))\n        self.session.headers[\"cookie\"] = cookie\n        self.session.headers[\n            \"Accept\"\n        ] = \"application/json, text/javascript, */*; q=0.01\"\n        self.session.headers[\n            \"User-Agent\"\n        ] = \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36\"\n        self.session.headers[\"Referer\"] = \"https://space.bilibili.com/{mid}/#!/\".format(\n            mid=self.mid\n        )\n        self.upload_id = None\n    def _preupload(self, filename, filesize):\n        # 1.获取本次上传所需信息\n        preupload_url = \"https://member.bilibili.com/preupload\"\n        params = {\n            \"os\": \"upos\",\n            \"r\": \"upos\",\n            \"ssl\": \"0\",\n            \"name\": filename,\n            \"size\": filesize,\n            \"upcdn\": self.cdn,\n            \"profile\": self.profile,",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:68-94"
    },
    "1405": {
        "file_id": 127,
        "content": "The code sets up the necessary headers and session parameters for interacting with Bilibili's API, then defines a function _preupload that makes a request to \"https://member.bilibili.com/preupload\" to obtain pre-upload information. The parameters for this request include filename, file size, cdn, and profile.",
        "type": "comment"
    },
    "1406": {
        "file_id": 127,
        "content": "        }\n        response = self.session.get(preupload_url, params=params)\n        upload_info = response.json()\n        # 本次上传bilibili端文件名\n        upload_info[\"bili_filename\"] = (\n            upload_info[\"upos_uri\"].split(\"/\")[-1].split(\".\")[0]\n        )\n        # 本次上传url\n        endpoint = \"http:%s/\" % upload_info[\"endpoint\"]\n        upload_url = re.sub(r\"^upos://\", endpoint, upload_info[\"upos_uri\"])\n        print(\"UPLOAD URL:\", upload_url, file=sys.stderr)\n        # 本次上传session\n        upload_session = requests.session()\n        upload_session.mount(\"http://\", HTTPAdapter(max_retries=self.MAX_RETRYS))\n        upload_session.headers[\"X-Upos-Auth\"] = upload_info[\"auth\"]\n        # 2.获取本次上传的upload_id\n        response = upload_session.post(upload_url + \"?uploads&output=json\")\n        upload_info[\"upload_id\"] = response.json()[\n            \"upload_id\"\n        ]  # here you have upload_id\n        self.upload_id = upload_info[\"upload_id\"]\n        print(\"UPLOAD INFO:\", upload_info, file=sys.stderr)\n        return upload_url, upload_info, upload_session",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:95-120"
    },
    "1407": {
        "file_id": 127,
        "content": "This code snippet handles the process of uploading a file to Bilibili. It first fetches pre-upload information, extracts relevant details like filename and endpoint URL. Then it generates an upload URL using this information and creates a session for the upload. The function returns the upload URL, upload info, and the upload session.",
        "type": "comment"
    },
    "1408": {
        "file_id": 127,
        "content": "    def _multithread_upload(\n        self, filepath, filesize, upload_url, upload_info, upload_session\n    ):\n        # 3.分块上传文件\n        CHUNK_SIZE = 4 * 1024 * 1024\n        total_chunks = math.ceil(filesize * 1.0 / CHUNK_SIZE)\n        offset = 0\n        chunk = 0\n        parts_info = {\"parts\": []}\n        with open(filepath, \"rb\") as fp:\n            events = []\n            while True:\n                blob = fp.read(CHUNK_SIZE)\n                if not blob:\n                    break\n                params = {\n                    \"partNumber\": chunk + 1,\n                    \"uploadId\": upload_info[\"upload_id\"],\n                    \"chunk\": chunk,\n                    \"chunks\": total_chunks,\n                    \"size\": len(blob),\n                    \"start\": offset,\n                    \"end\": offset + len(blob),\n                    \"total\": filesize,\n                }\n                # here we go?\n                def multiparts():\n                    blob0 = copy.deepcopy(blob)\n                    chunk0 = chunk\n                    thisevent = Event()",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:122-151"
    },
    "1409": {
        "file_id": 127,
        "content": "The code reads a file in chunks of 4MB (CHUNK_SIZE) and calculates the total number of chunks required to complete the upload. It then starts a loop where it reads each chunk, creates a dictionary with parameters including partNumber, uploadId, chunk number, total chunks, size of the blob, start and end offsets of the blob, and file's total size. The function seems to be preparing to call another function \"multiparts\" which is defined later in the code block.",
        "type": "comment"
    },
    "1410": {
        "file_id": 127,
        "content": "                    events.append(thisevent)\n                    offset0 = offset\n                    while True:\n                        try:\n                            response = upload_session.put(\n                                upload_url, params=params, data=blob0\n                            )\n                            print(\n                                \"Uploading...\",\n                                math.floor(chunk0 / total_chunks * 100),\n                                \"%  UPLOAD CHUNK\",\n                                chunk0,\n                                \":\",\n                                response.text,\n                                file=sys.stderr,\n                            )\n                            print(\"done for {}\".format(offset0))\n                            thisevent.set()\n                            break\n                        except:\n                            print(\"error in chunk {}\".format(offset0))\n                            traceback.print_exc()\n                threading.Thread(target=multiparts, args=(), daemon=True).start()",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:152-175"
    },
    "1411": {
        "file_id": 127,
        "content": "This code is handling the upload of a chunk of data to Bilibili using a session with retry on error. It creates an event and appends it to a list, initializes the offset, and then enters a while loop to attempt uploading the chunk. If successful, it sets the event to complete, otherwise it prints an error message. A new thread is created to execute a function called multiparts.",
        "type": "comment"
    },
    "1412": {
        "file_id": 127,
        "content": "                parts_info[\"parts\"].append({\"partNumber\": chunk + 1, \"eTag\": \"etag\"})\n                chunk += 1\n                offset += len(blob)\n            for event in events:\n                event.wait()\n            print(\"finished waiting.\")\n        return parts_info\n    def _upload(self, filepath):\n        \"\"\"执行上传文件操作\"\"\"\n        if not os.path.isfile(filepath):\n            print(\"FILE NOT EXISTS:\", filepath, file=sys.stderr)\n            return\n        filename = os.path.basename(filepath)\n        filesize = os.path.getsize(filepath)\n        upload_url, upload_info, upload_session = self._preupload(filename, filesize)\n        # 4.标记本次上传完成\n        parts_info = self._multithread_upload(\n            filepath, filesize, upload_url, upload_info, upload_session\n        )\n        params = {\n            \"output\": \"json\",\n            \"name\": filename,\n            \"profile\": self.profile,\n            \"uploadId\": upload_info[\"upload_id\"],\n            \"biz_id\": upload_info[\"biz_id\"],\n        }\n        response = upload_session.post(upload_url, params=params, data=parts_info)",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:177-205"
    },
    "1413": {
        "file_id": 127,
        "content": "The code uploads a file to Bilibili using multipart upload. It first checks if the file exists, then retrieves the upload URL and necessary information through `_preupload` function. The actual multipart upload is performed in `_multithread_upload`, with progress events handled concurrently. Finally, it posts the parts information to the upload URL along with other parameters to complete the upload.",
        "type": "comment"
    },
    "1414": {
        "file_id": 127,
        "content": "        print(\n            \"UPLOAD RESULT:\",\n            response.text,\n            file=sys.stderr,  # but till then we can use the upload_id.\n        )  # here we do not have the result.\n        return upload_info  # still, not the bvid thing we want.\n    def _cover_up(self, image_path):\n        \"\"\"上传图片并获取图片链接\"\"\"\n        if not os.path.isfile(image_path):\n            return \"\"\n        import tempfile\n        import cv2\n        with tempfile.NamedTemporaryFile(suffix=\".jpg\") as f:\n            jpeg_image_path = f.name\n            image = cv2.imread(image_path)\n            cv2.imwrite(jpeg_image_path, image)\n            fp = open(jpeg_image_path, \"rb\")\n            encode_data = base64.b64encode(fp.read())\n            # warning. forced to use jpeg.\n            url = \"https://member.bilibili.com/x/vu/web/cover/up\"\n            data = {\n                \"cover\": b\"data:image/jpeg;base64,\" + encode_data,\n                \"csrf\": self.csrf,\n            }\n            response = self.session.post(url, data=data)\n            return response.json()[\"data\"][\"url\"]",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:206-234"
    },
    "1415": {
        "file_id": 127,
        "content": "This function uploads an image to Bilibili and returns the image URL. It first checks if the input file exists, then converts the image to JPEG format using OpenCV. The converted image is encoded as base64 and sent in a POST request to Bilibili's cover upload endpoint. Finally, it retrieves and returns the image URL from the response.",
        "type": "comment"
    },
    "1416": {
        "file_id": 127,
        "content": "    def upload_video_and_cover(self, filepath, cover_path):\n        # 上传文件, 获取上传信息\n        upload_info = self._upload(filepath)\n        if not upload_info:\n            ## fuck?\n            print(\"upload failed?\")\n            return {}, \"\"\n        # 获取图片链接\n        cover_url = self._cover_up(cover_path) if cover_path else \"\"\n        return upload_info, \"\"\n    def postupload(self, upload_info, cover_url, metadata):\n        title = \"\"\n        tid = 0\n        tag = \"\"\n        desc = \"\"\n        source = \"\"\n        # cover_path=\"\",\n        dynamic = \"\"\n        # mission_id = None\n        no_reprint = 1\n        \"\"\"视频投稿\n        Args:\n            filepath   : 视频文件路径\n            title      : 投稿标题\n            tid        : 投稿频道id,详见https://member.bilibili.com/x/web/archive/pre\n            tag        : 视频标签，多标签使用','号分隔\n            desc       : 视频描述信息\n            source     : 转载视频出处url\n            cover_path : 封面图片路径\n            dynamic    : 分享动态, 比如：\"#周五##放假# 劳资明天不上班\"\n            no_reprint : 1表示不允许转载,0表示允许\n        \"\"\"\n        # TODO:",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:236-270"
    },
    "1417": {
        "file_id": 127,
        "content": "This function `upload_video_and_cover` uploads a video file and optional cover image, returning the upload information. It first calls the `_upload` method to upload the video and checks if it was successful. If not, it prints an error message and returns empty information. Then it retrieves the cover URL using the `_cover_up` method, if a cover path is provided. The function returns the upload information and an empty string.",
        "type": "comment"
    },
    "1418": {
        "file_id": 127,
        "content": "        # 1.增加多P上传\n        # 2.对已投稿视频进行删改, 包括删除投稿，修改信息，加P删P等\n        # 设置视频基本信息\n        params = {\n            \"source\": source,\n            \"title\": title,\n            \"tid\": tid,\n            \"tag\": tag,\n            \"no_reprint\": no_reprint,\n            \"desc\": desc,\n            # \"mission_id\": mission_id,\n            \"desc_format_id\": 0,\n            \"dynamic\": dynamic,\n            \"cover\": cover_url,\n            \"videos\": [\n                {\n                    \"filename\": upload_info[\"bili_filename\"],\n                    \"title\": title,\n                    \"desc\": \"\",\n                }\n            ],\n        }\n        params.update(metadata)\n        # 版权判断, 转载无版权\n        params[\"copyright\"] = 2 if params.get(\"source\") else 1\n        if source:\n            del params[\"no_reprint\"]\n        # tag设置\n        mtag = params.get(\"tag\")\n        if isinstance(mtag, list):\n            params[\"tag\"] = \",\".join(mtag)\n        # if mission_id is None:\n        #     del params[\"mission_id\"]\n        url = \"https://member.bilibili.com/x/vu/web/add?csrf=\" + self.csrf",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:271-305"
    },
    "1419": {
        "file_id": 127,
        "content": "Sets video basic information, including source, title, TID, tag, no_reprint status, description, dynamic, cover URL, and video file details for upload. Updates parameters if necessary, checks copyright based on source flag, handles tag format, and sets URL with CSRF token.",
        "type": "comment"
    },
    "1420": {
        "file_id": 127,
        "content": "        response = self.session.post(url, json=params)\n        print(\"SET VIDEO INFO:\", response.text, file=sys.stderr)\n        return response.json() # {\"code\":0,\"message\":\"0\",\"ttl\":1,\"data\":{\"aid\":604946025,\"bvid\":\"BV1y84y1v7tM\"}}\n        # seriously, it is a ugc platform.\n        ## what is this fucking json?\n    def upload(\n        self,\n        filepath: str,\n        cover_path: str,\n        metadata: dict,\n    ):\n        upload_info, cover_url = self.upload_video_and_cover(filepath, cover_path)\n        if upload_info == {}:\n            # something went wrong.\n            return\n        response_json = self.postupload(upload_info, cover_url, metadata)\n        return response_json\ndef getCookieStringFromCookieDict(cookies_dict, mustcook=[\"DedeUserID\", \"bili_jct\"]):\n    cookies = cookies_dict\n    cookie_string = \"\"\n    for x in mustcook:\n        assert x in cookies.keys()\n    # ckeys = mustcook + [x for x in cookies.keys() if x not in mustcook]\n    # assert \"bili_jct\" in cookies.keys()\n    for key in mustcook:",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:306-333"
    },
    "1421": {
        "file_id": 127,
        "content": "Code snippet is performing the following tasks:\n1. Posting video info to server and returning response as JSON format.\n2. Uploading video and cover, then posting video information with cover URL to the server using a predefined function `postupload`.\n3. Converting cookies dictionary into a string with mandatory cookies \"DedeUserID\", \"bili_jct\".",
        "type": "comment"
    },
    "1422": {
        "file_id": 127,
        "content": "        assert key in cookies.keys()\n    # breakpoint()\n    for key, value in cookies.items():  # oh shit maybe i know it.\n        if key is not None and value is not None:\n            cookie_string += key + \"=\" + value + \"; \"\n    cookie_string = cookie_string[:-2]\n    return cookie_string\n##############################################################\ndef videoMultithreadUploader(\n    cookies_dict: dict = ...,\n    filepath: str = ...,\n    coverpath: str = ...,\n    metadata: dict = ...,\n):\n    # append new events?\n    # planning using two jsons. one for credential, one for video details.\n    # get picture.\n    cookie_string = getCookieStringFromCookieDict(cookies_dict)\n    # while True:\n    try:\n        uper = MultithreadUploader(cookie_string)\n        data = uper.upload(filepath, coverpath, metadata)\n        return True, data\n    except:\n        print(\"Exception found when uploading video.\")\n        traceback.print_exc()\n        return False, {}\n##############################################################\n# @bilibiliSync",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:334-367"
    },
    "1423": {
        "file_id": 127,
        "content": "The code defines a function `videoMultithreadUploader` that uploads a video using multithreading and returns True if successful or False otherwise. It first extracts cookies from the input dictionary and then uses the `MultithreadUploader` class to perform the actual upload. The uploaded data is returned as a tuple with the status and data. In case of an exception, it prints the traceback and returns (False, {}).",
        "type": "comment"
    },
    "1424": {
        "file_id": 127,
        "content": "# no need to be sync. really?\n@bilibiliCredential  # keyword 'dedeuserid' with default value.\ndef uploadVideo(\n    credential: Credential = ...,\n    # sessdata=\"\",\n    # bili_jct=\"\",\n    # buvid3=\"\", # credentials.\n    # dedeuserid: str = \"397424026\",\n    description: str = \"\",\n    dynamic: str = \"\",\n    tagString: str = \"\",\n    tagId: int = 21,  # what is 21? -> 日常\n    title: str = \"\",\n    close_danmaku: bool = False,\n    close_reply: bool = False,\n    videoPath: str = \"\",\n    cover_path: str = \"\",\n    multithread: bool = True,\n    # threads=3,\n):\n    # title='abdefg'\n    assert os.path.exists(videoPath)\n    assert os.path.exists(cover_path)\n    cookie_dict = {\n        key: credential.__dict__[key.lower()]\n        for key in [\"buvid3\", \"DedeUserID\", \"bili_jct\", \"SESSDATA\"]\n    }\n    # videoExtension = videoPath.split(\".\")[-1].lower()\n    # credential = Credential(sessdata=sessdata, bili_jct=bili_jct, buvid3=buvid3)\n    # you can pass it from somewhere else.\n    # 具体请查阅相关文档\n    meta = {\n        \"copyright\": 1,\n        \"source\": \"\",  # no source?",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:368-401"
    },
    "1425": {
        "file_id": 127,
        "content": "This function uploads a video to Bilibili and requires credentials, metadata such as title, description, and tags, and file paths for the video and cover image. The function uses assertions to ensure the file paths exist and creates a dictionary of required cookie values from the provided credential object. It also allows passing some parameters externally.",
        "type": "comment"
    },
    "1426": {
        "file_id": 127,
        "content": "        \"desc\": description,\n        \"desc_format_id\": 0,\n        \"dynamic\": dynamic,  # could be the same as desc.\n        \"interactive\": 0,\n        \"open_elec\": 1,\n        \"no_reprint\": 1,\n        \"subtitles\": {\"lan\": \"\", \"open\": 0},\n        \"tag\": tagString,\n        \"tid\": tagId,  # original is 21. what is it?\n        \"title\": title,\n        \"up_close_danmaku\": close_danmaku,\n        \"up_close_reply\": close_reply,\n    }\n    if multithread:\n        no_exception, mresult = videoMultithreadUploader(cookie_dict, videoPath, cover_path, meta)\n        if not no_exception:\n            raise Exception('videoMultithreadUploader error')\n        try:\n            code, message = mresult.get('code'), mresult.get('message')\n            assert code == 0  # 为什么分区暂时不可用？\n            assert message == '0'\n        except:\n            print(\"Uploading to bilibili failed\")\n            breakpoint()\n            print()\n            raise Exception('videoMultithreadUploader error: invalid response:', mresult)\n        result = mresult.get('data',{})",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:402-428"
    },
    "1427": {
        "file_id": 127,
        "content": "This code is creating a dictionary with metadata for uploading a video to Bilibili. It includes various parameters like description, interactive setting, and tags. The code also implements multithreading for the upload process, handling exceptions and checking for valid response codes from the API. If there's an error or invalid response, it raises an exception and prints a failure message.",
        "type": "comment"
    },
    "1428": {
        "file_id": 127,
        "content": "    else:\n        result = asyncVideoUploader(\n            videoPath, title, description, meta, credential, cover_path\n        )\n    print(\"multithread?\", multithread)\n    print(\"upload video result:\", result)\n    try:\n        assert 'aid' in result.keys()\n        assert 'bvid' in result.keys()\n    except:\n        raise Exception(\"error: no valid upload result obtained:\", result)\n        # {'aid': 817422346, 'bvid': 'BV1NG4y1t7zk'}\n        # in this format.\n    return result\n# host your web application online, then make money through it!",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/uploader.py:429-445"
    },
    "1429": {
        "file_id": 127,
        "content": "This code checks if the uploader is not async, then calls `asyncVideoUploader` with provided parameters. It then asserts that the result contains 'aid' and 'bvid' keys before returning the result. The print statements are for debugging purposes.",
        "type": "comment"
    },
    "1430": {
        "file_id": 128,
        "content": "/pyjom/platforms/bilibili/searchDataParser.py",
        "type": "filepath"
    },
    "1431": {
        "file_id": 128,
        "content": "This function parses Bilibili video data, enabling metadata extraction and error handling. It retrieves bvid, pubdate, author name, tags, title, duration, play count, cover image, and description, while disabling specified author-related tags.",
        "type": "summary"
    },
    "1432": {
        "file_id": 128,
        "content": "import json\n# from bs4 import BeautifulSoup\nfrom lazero.utils.logger import sprint\nfrom pyjom.platforms.bilibili.utils import (\n    # generatorToList,\n    linkFixer,\n    traceError,\n    extractLinks,\n    videoDurationStringToSeconds,\n    getAuthorKeywords,\n    clearHtmlTags,\n    splitTitleTags,\n    removeAuthorRelatedTags,\n)\ndef parseVideoSearchItem(video, disableList: list = [], debug=False):\n    from pyjom.platforms.bilibili.utils import detectAuthorRelatedKeywords\n    bvid = video[\"bvid\"]\n    pubdate = video[\"pubdate\"]\n    if \"author\" not in disableList:\n        author = video[\"author\"]\n        author_id = video[\n            \"mid\"\n        ]  # this is important. may let us able to find out the fans count.\n    else:\n        author = \"\"\n        author_id = -1\n    author_keywords = getAuthorKeywords(author)\n    if \"tag\" not in disableList:\n        tag = video[\"tag\"]\n        tags = tag.split(\",\")\n        tags = [\n            tag for tag in tags if not detectAuthorRelatedKeywords(tag, author_keywords)\n        ]\n    else:",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:1-37"
    },
    "1433": {
        "file_id": 128,
        "content": "Function to parse video search item data from Bilibili platform, takes a video object and an optional list of keywords to disable (author and tag). Extracts bvid, pubdate, author name, author ID, tags, and filters out author-related tags if specified.",
        "type": "comment"
    },
    "1434": {
        "file_id": 128,
        "content": "        tags = []\n    if \"typeid\" not in disableList and \"typename\" not in disableList:\n        categoryId = int(video.get(\"typeid\", video.get(\"type_id\")))\n        categoryName = video.get(\"typename\", video.get(\"type_name\"))\n    else:\n        categoryId = 0\n        categoryName = \"\"\n    title = video[\"title\"]  # remove those markers, please?\n    title = clearHtmlTags(title)\n    title = removeAuthorRelatedTags(title, author)\n    title, title_tags = splitTitleTags(\n        title, author_keywords\n    )  # use author for filtering unwanted title tags.\n    duration = video[\"duration\"]  # this is not recommended. we need seconds.\n    play = video.get(\"play\", video.get(\"view\"))  # select some hot videos.\n    cover = video[\"pic\"]\n    cover = linkFixer(cover)\n    if \"description\" not in disableList:\n        description = video.get(\"description\", video.get(\"desc\"))\n        description = clearHtmlTags(description)\n        description = removeAuthorRelatedTags(description, author)\n    else:\n        description = \"\"\n    links_in_description, bgms, description = extractLinks(description)",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:38-61"
    },
    "1435": {
        "file_id": 128,
        "content": "The code checks for certain video types and disables them if present in the disable list. It retrieves category ID, category name, title, duration, play count, cover image, and description from the video data. The title is cleaned by removing markers, clearing HTML tags, and filtering unwanted tags using author keywords. Duration and play count are retrieved with fallback options. Cover image is fixed for links. If description is not disabled, it's also cleaned of HTML tags and filtered for author-related tags, and links in the description, background music, and modified description are extracted.",
        "type": "comment"
    },
    "1436": {
        "file_id": 128,
        "content": "    duration_seconds = videoDurationStringToSeconds(duration)\n    resultTuple = (\n        author,\n        author_id,\n        bvid,\n        tags,\n        categoryId,\n        categoryName,\n        title,\n        duration_seconds,\n        play,\n        cover,\n        description,\n        links_in_description,\n        bgms,\n        title_tags,\n        pubdate,\n    )\n    if debug:\n        for metadata in resultTuple:\n            print(metadata)\n    from lazero.utils.logger import sprint\n    if debug:\n        sprint()\n    return resultTuple\n# you might want the creater's name, to filter out unwanted parts.\ndef iterateResultList(resultList, debug=False):\n    for video in resultList:\n        # be warned cause all these things might fail.\n        try:\n            if video[\"type\"] == \"video\":\n                yield parseVideoSearchItem(video, debug=debug)\n        except:\n            traceError(\"error iterating video metadata\")\n            continue\ndef parseSearchAllResult(data, debug=False):\n    # if not generator:\n    #     return generatorToList(parseSearchAllResult(data, debug=debug,generator=True))",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:62-106"
    },
    "1437": {
        "file_id": 128,
        "content": "The code defines functions for parsing and iterating through search results from a specific platform, bilibili. It converts video duration strings to seconds, extracts relevant metadata, and handles potential errors during iteration.",
        "type": "comment"
    },
    "1438": {
        "file_id": 128,
        "content": "    results = data[\"result\"]\n    for elem in results:\n        try:\n            if elem[\"result_type\"] == \"video\":\n                resultList = elem[\"data\"]\n                for videoMetadata in iterateResultList(resultList, debug=debug):\n                    yield videoMetadata\n        except:\n            traceError(\"error iterating data results\")\ndef parseSearchVideoResult(data, debug=False):\n    # if not generator:\n    #     return generatorToList(parseSearchVideoResult(data, debug=debug,generator=True))\n    try:\n        resultList = data[\"result\"]\n        try:\n            for videoMetadata in iterateResultList(resultList, debug=debug):\n                try:\n                    yield videoMetadata\n                except:\n                    traceError(\"error iterating video metadata\")\n        except:\n            traceError(\"error iterating result list\")\n    except:\n        traceError(\"error parsing search video result\")\ndef parseVideoInfo(videoInfo, debug=False):\n    data = videoInfo\n    # no tag out here.\n    secondaryVideoInfoList = []",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:107-138"
    },
    "1439": {
        "file_id": 128,
        "content": "The code defines functions for parsing search video results and video information from data. It iterates through the results, extracting relevant metadata, and handles potential errors during the process. The parsed results are then yielded or converted to a list if necessary.",
        "type": "comment"
    },
    "1440": {
        "file_id": 128,
        "content": "    data_copy = data.copy()\n    data_copy.update({\"author\": data[\"owner\"][\"name\"], \"mid\": data[\"owner\"][\"mid\"]})\n    data_copy.update(data[\"stat\"])\n    primaryVideoInfo = parseVideoSearchItem(\n        data_copy, disableList=[\"tag\", \"typeid\", \"typename\"], debug=debug\n    )\n    # videoInfoList.append(primaryVideoInfo)\n    season = data.get(\"ugc_season\", {})  # we only care about this thing.\n    season_cover = season.get(\"cover\", None)  # it could be noting.\n    sections = season.get(\"sections\", [])\n    for section in sections:\n        for episode in section[\"episodes\"]:\n            # print(episode.keys())\n            # breakpoint()\n            arc = episode[\"arc\"]\n            stat = arc[\"stat\"]\n            videoInfo = episode.copy()\n            videoInfo.update(stat)\n            videoInfo.update(arc)\n            authorRelatedVideoInfo = parseVideoSearchItem(\n                videoInfo,\n                disableList=[\"tag\", \"typeid\", \"typename\", \"description\", \"author\"],\n                debug=debug,\n            )  # author is the same as the original video.",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:139-162"
    },
    "1441": {
        "file_id": 128,
        "content": "This code parses bilibili search data and extracts relevant information. It creates a primary video info, updates it with necessary attributes, handles seasonal content, and iterates through episodes to create individual video infos for each episode. This is done by updating video stats and arc attributes, then calling parseVideoSearchItem function. The author remains the same as the original video.",
        "type": "comment"
    },
    "1442": {
        "file_id": 128,
        "content": "            secondaryVideoInfoList.append(authorRelatedVideoInfo)\n            # BV1Cb4y1s7em\n            # []\n            # 0\n            # 这次真的燃起来了！！！\n            # 217\n            # 27911\n            # http://i2.hdslb.com/bfs/archive/c5a0d18ee077fb6a4ac0970ccb0a3788e137d14f.jpg\n    return primaryVideoInfo, secondaryVideoInfoList\ndef parseVideoRelated(videoRelatedData, debug=False):\n    data = videoRelatedData\n    # if not generator:\n    #     return generatorToList(parseVideoRelated(data, debug=debug,generator=True))\n    try:\n        for videoInfo in data:\n            try:\n                videoInfo2 = videoInfo.copy()\n                videoInfo2.update({\"author\": videoInfo[\"owner\"][\"name\"]})\n                videoInfo2.update({\"mid\": videoInfo[\"owner\"][\"mid\"]})\n                # also update the stat.\n                videoInfo2.update(videoInfo[\"stat\"])\n                try:\n                    yield parseVideoSearchItem(\n                        videoInfo2,\n                        disableList=[\"tag\", \"typeid\", \"typename\"],",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:163-190"
    },
    "1443": {
        "file_id": 128,
        "content": "This function parses video-related data and returns the primary video information and a list of secondary video information. It updates the video information with the author's name, ID, and statistics before yielding the result.",
        "type": "comment"
    },
    "1444": {
        "file_id": 128,
        "content": "                        debug=debug,\n                    )\n                    # print(videoMetadata)\n                except:\n                    traceError()\n            except:\n                traceError()\n    except:\n        traceError()\nif __name__ == \"__main__\":\n    # fake tests.\n    # test_subject = \"search_video\"\n    # test_subject = \"search_all\"\n    # test_subject = 'video_related'\n    test_subject = \"video_info\"\n    # test_subject = 'extract_links'\n    if test_subject == \"search_all\":\n        with open(\"search_result_all.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        for mresult in parseSearchAllResult(data):\n            print(\"RESULT:\")\n            sprint(mresult)\n    elif test_subject == \"search_video\":\n        with open(\"search_by_type_result_video.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        for mresult in parseSearchVideoResult(data):\n            print(\"VIDEO SEARCH RESULT:\")\n            sprint(mresult)\n    elif test_subject == \"video_info\":",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:191-223"
    },
    "1445": {
        "file_id": 128,
        "content": "The code is running tests on a Python module for parsing search results and video information from Bilibili. It executes the main function with different test subjects, such as \"search_all\", \"search_video\", \"video_info\", and \"extract_links\". If an error occurs during execution, it calls a \"traceError\" function to log the exception.",
        "type": "comment"
    },
    "1446": {
        "file_id": 128,
        "content": "        with open(\"video_info.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        primaryVideoInfo, secondaryVideoInfoList = parseVideoInfo(data)\n        videoInfoList = [primaryVideoInfo] + secondaryVideoInfoList\n        for mVideoInfo in videoInfoList:\n            print(mVideoInfo)\n            sprint()\n    elif test_subject == \"video_related\":\n        with open(\"video_related.json\", \"r\") as f:\n            data = f.read()\n            data = json.loads(data)\n        for videoMetadata in parseVideoRelated(data):\n            print(videoMetadata)\n            sprint()\n    elif test_subject == \"extract_links\":\n        description = (\n            \"http://www.toutiao.com/a6347649852365897986/ 男子送走从小养大的狗，狗狗用泪汪汪的眼神看着他\\n\"\n            + \"https://www.youtube.com/watch?v=r724w57oXyU\"\n            + \" https://www.youtube.com/shorts/UYCy8HD1C7o\"\n        )\n        links, desc = extractLinks(description)\n        print(links)\n        print(desc)\n    else:\n        raise Exception(\"unknown test_subject:\", test_subject)",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/searchDataParser.py:224-249"
    },
    "1447": {
        "file_id": 128,
        "content": "This code block handles different cases for parsing data from JSON files and extracting links from descriptions. It loads data from \"video_info.json\" or \"video_related.json\", processes it using parseVideoInfo or parseVideoRelated functions, then prints the results. If test_subject is \"extract_links\", it extracts links from a given description using extractLinks function and prints them. For any other test_subject, an Exception is raised.",
        "type": "comment"
    },
    "1448": {
        "file_id": 129,
        "content": "/pyjom/platforms/bilibili/postMetadata.py",
        "type": "filepath"
    },
    "1449": {
        "file_id": 129,
        "content": "The code filters videos, generates Bilibili post metadata, supports language selection and error handling, extracts video metadata, fetches related videos, applies limits, and generates covers and descriptions for dog or cat topics.",
        "type": "summary"
    },
    "1450": {
        "file_id": 129,
        "content": "from pyjom.commons import *\nimport cv2\nfrom pyjom.modules.topicGenerator.onlineTopicGenerator import getMetaTopicString\nfrom bilibili_api import sync, search\nfrom lazero.utils.tools import flattenUnhashableList  # one of my classic methods\nfrom lazero.utils.logger import sprint\n# TODO: you know the drill. if it really contains nonacceptable characters (currently, must be some rule changes), you use Notofu font for rendering and OCR for recognition.\n# well you might want tesseract.\n# i suspect this change is due to language models used in bilibili's system\nfrom pyjom.languagetoolbox import filterNonChineseOrEnglishOrJapaneseCharacters\ndef filterTitleWithCoreTopicSet(title, core_topic_set, debug=False):\n    value = False\n    for core_topic in core_topic_set:\n        if core_topic in title:\n            value = True\n            break\n    if debug:\n        print(\"TITLE:\", title)\n        print(\"CORE TOPIC SET:\", core_topic_set)\n        print(\"VALUE:\", value)\n        breakpoint()\n    return value\ndef filterTitleListWithCoreTopicSet(titleList, core_topic_set, debug=False):",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:1-27"
    },
    "1451": {
        "file_id": 129,
        "content": "This code filters titles for a video platform, checking if they contain specific core topics. It utilizes existing modules and tools for this purpose. The function filterTitleListWithCoreTopicSet takes in a list of titles and a set of core topics, returning true if any title contains a core topic. The function filterTitleWithCoreTopicSet checks individual titles for a single core topic. Both functions have optional debug parameter to print information about the process.",
        "type": "comment"
    },
    "1452": {
        "file_id": 129,
        "content": "    newTitleList = []\n    for title in titleList:\n        result = filterTitleWithCoreTopicSet(title, core_topic_set)\n        if result:\n            newTitleList.append(title)\n    if debug:\n        print(\"TITLE LIST:\", titleList)\n        print(\"CORE TOPIC SET:\", core_topic_set)\n        sprint(\"NEW TITLE LIST:\", newTitleList)\n    return newTitleList\ndef randomChoiceTagList(\n    tag_list, selected_tag_groups=3, selected_tag_per_group=2, pop=True\n):\n    import random\n    if not pop:\n        selected_tags = random.sample(tag_list, selected_tag_groups)\n    else:\n        selected_tags = [\n            shuffleAndPopFromList(tag_list) for _ in range(selected_tag_groups)\n        ]\n    selected_tags = [\n        random.sample(tags, min(len(tags), selected_tag_per_group))\n        for tags in selected_tags\n    ]\n    # flatten this thing.\n    selected_tags = flattenUnhashableList(selected_tags)\n    return list(set(selected_tags))\nfrom typing import Literal\nfrom pyjom.imagetoolbox import resizeImageWithPadding\ndef getCoverTargetFromCoverListDefault(",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:28-64"
    },
    "1453": {
        "file_id": 129,
        "content": "This function takes a list of titles, applies a filter based on a core topic set, and creates a new title list. It also generates random tag groups and flattens them to create a final list of unique tags. The function is part of a larger codebase for processing data related to the Bilibili platform.",
        "type": "comment"
    },
    "1454": {
        "file_id": 129,
        "content": "    cover_list,\n    dog_or_cat_original,\n    input_width: int = 1200,\n    output_width: int = 1920,\n    filter_function=lambda image: image,\n    histogramMatch=True,\n    delta=0.2,\n    flip: Literal[True, False, \"random\"] = True,\n):  # default function does not process this tag.\n    import random\n    if flip == \"random\":\n        flip = random.choice([True, False])\n    # random.shuffle(cover_list)\n    # reference_histogram_cover = random.choice(cover_list)\n    reference_histogram_cover = shuffleAndPopFromList(cover_list)\n    cover_target = None\n    # for cover in cover_list:\n    while len(cover_list) > 0:\n        cover = shuffleAndPopFromList(cover_list)\n        import os\n        os.environ[\"http\"] = \"\"\n        os.environ[\"https\"] = \"\"\n        from pyjom.imagetoolbox import (\n            imageLoader,\n            # imageDogCatCoverCropAdvanced,\n            imageHistogramMatch,\n        )\n        image = imageLoader(cover)\n        # downscale this image first.\n        image = resizeImageWithPadding(\n            image, input_width, None, border_type=\"replicate\"",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:65-100"
    },
    "1455": {
        "file_id": 129,
        "content": "The code takes a list of image covers, randomly selects one as the reference histogram cover, and iterates over the remaining covers. It prepares for image processing by setting environment variables, loading images, downscaling if necessary, and possibly flipping the image based on a random choice.",
        "type": "comment"
    },
    "1456": {
        "file_id": 129,
        "content": "        )  # are you sure? it is just a cover image.\n        cropped_image = filter_function(\n            image\n        )  # we should do something to the filter function!\n        if cropped_image is not None:\n            if histogramMatch:\n                cropped_image = imageHistogramMatch(\n                    cropped_image, reference_histogram_cover, delta=delta\n                )\n            if flip:\n                cropped_image = cv2.flip(cropped_image, 1)\n            cover_target = cropped_image\n            break\n    if cover_target is not None:\n        cover_target = resizeImageWithPadding(\n            cover_target, output_width, None, border_type=\"replicate\"\n        )  # this is strange.\n    return cover_target\ndef getCoverTargetFromCoverListForDogCat(cover_list, dog_or_cat_original):\n    from pyjom.imagetoolbox import (\n        # imageLoader,\n        imageDogCatCoverCropAdvanced,\n        # imageHistogramMatch,\n    )\n    return getCoverTargetFromCoverListDefault(\n        cover_list,\n        dog_or_cat_original,",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:101-130"
    },
    "1457": {
        "file_id": 129,
        "content": "The code applies advanced image cropping and processing for a dog or cat cover image. It checks the cover list, performs histogram matching if necessary, and flips the image if required. Finally, it resizes the image with padding using replicate border type. The function \"imageLoader\" and \"imageHistogramMatch\" are imported but not used in this specific code.",
        "type": "comment"
    },
    "1458": {
        "file_id": 129,
        "content": "        filter_function=lambda image: imageDogCatCoverCropAdvanced(\n            image,\n            yolov5_confidence_threshold=0.27,  # you made it smaller.\n            dog_or_cat=dog_or_cat_original,  # already configured. no need to do shit.\n            area_threshold=0.30,  # 0.7 # could be smaller.\n            corner=False,\n        ),\n    )\nBSP = search.bilibiliSearchParams()\nimport random\nfrom typing import Callable\ndef getBilibiliPostMetadata(\n    sleepTime=2,\n    customParaphraser:Union[Callable,None]=None,\n    getMetatopic={},\n    bgmCacheSetName: Union[str, None] = \"bilibili_cached_bgm_set\",\n    getTids={},  # these two are not specified here.\n    genericTids:list[int]=[],\n    orders=[\n        BSP.all.order.最多点击,\n        BSP.all.order.最多收藏,\n        BSP.all.order.最新发布,\n        BSP.all.order.最多弹幕,\n        BSP.all.order.综合排序,\n    ],\n    pageIndexRange=(1, 5),\n    duration=BSP.all.duration._10分钟以下,\n    lang=\"zh\",\n    duration_limit={\"min\": 70, \"max\": 5 * 60},\n    play_limit={\"min\": 10000},\n    titleLengthLimit={\"min\": 7, \"max\": 17},",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:131-165"
    },
    "1459": {
        "file_id": 129,
        "content": "This function generates Bilibili post metadata by specifying parameters like search type, video duration, order of sorting, and title length limits. It also allows for custom paraphrasing, language selection, and optional background music caching.",
        "type": "comment"
    },
    "1460": {
        "file_id": 129,
        "content": "    getCoverTargetFromCoverList=getCoverTargetFromCoverListDefault,  # what is the default process?\n    bgmCacheAutoPurge=False,\n):\n    if bgmCacheSetName and bgmCacheAutoPurge:\n        removeRedisValueByKey(bgmCacheSetName)\n    selected_topic_list_dict = {key: [] for key in getMetatopic.keys()}\n    randomTarget = lambda: random.choice(list(selected_topic_list_dict.keys()))\n    dog_or_cat = randomTarget()\n    description_list = []\n    bgm_list = []\n    title_list = []\n    tag_list = []\n    cover_list = []\n    bvid_list = []\n    def clearMyLists():\n        nonlocal bvid_list, bgm_list, title_list, tag_list, cover_list, bvid_list, description_list\n        description_list = []\n        bgm_list = []\n        title_list = []\n        tag_list = []\n        cover_list = []\n        bvid_list = []\n    getKeywords = {\n        key: lambda: getMetaTopicString(value) for key, value in getMetatopic.items()\n    }\n    # getDogTid = lambda: random.choice([BSP.all.tids.动物圈.tid, BSP.all.tids.动物圈.汪星人])\n    # getCatTid = lambda: random.choice([BSP.all.tids.动物圈.tid, BSP.all.tids.动物圈.喵星人])",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:166-196"
    },
    "1461": {
        "file_id": 129,
        "content": "This code retrieves metadata from a bilibili platform, filters and selects topics, randomly chooses between dog or cat content, and initializes lists for BGM, title, tag, cover, and video ID. It also defines functions to clear lists and retrieve keywords. The code does not contain a default process for `getCoverTargetFromCoverList`.",
        "type": "comment"
    },
    "1462": {
        "file_id": 129,
        "content": "    # getTid = {\"dog\": getDogTid, \"cat\": getCatTid}\n    getTid = {key: lambda: random.choice(value) for key, value in getTids.items()}\n    getTargetTid = {key: lambda: random.choice([v for v in value if v not in genericTids]) for key, value in getTids.items()}\n    getRandomPage = lambda: random.randint(*pageIndexRange)  # not so broad.\n    # getRandomPage = lambda: random.randint(1, 50)  # broad range!\n    randomOrder = lambda: random.choice(orders)\n    while True:\n        try:\n            core_topic_set = {\n                *flattenUnhashableList(\n                    [value for key, value in getMetatopic[dog_or_cat].items()]\n                )\n            }\n            static_core_topic_list = flattenUnhashableList(\n                getMetatopic[dog_or_cat][\"static\"]\n            )\n            metatopicString = getKeywords[dog_or_cat]()\n            print(\"METATOPIC STRING:\", metatopicString)\n            # we use video only search.\n            search_tid = getTid[dog_or_cat]()\n            target_tid = getTargetTid[dog_or_cat]()",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:197-223"
    },
    "1463": {
        "file_id": 129,
        "content": "This code dynamically generates a set of core topics, static core topic list, and metatopic string for the bilibili platform. It uses lambda functions to generate random values for TIDs, page index, and order. The code ensures that the selected TID is not present in genericTids. Finally, it prints the metatopic string and assigns a search TID and target TID for further processing.",
        "type": "comment"
    },
    "1464": {
        "file_id": 129,
        "content": "            result = sync(\n                search.search_by_type(\n                    keyword=metatopicString,\n                    params={\n                        \"tids\": search_tid,\n                        \"duration\": duration,\n                        \"order\": randomOrder(),\n                    },\n                    page=getRandomPage(),\n                    search_type=search.SearchObjectType.VIDEO,\n                )\n            )\n            # print(result)\n            # breakpoint()\n            from pyjom.platforms.bilibili.searchDataParser import parseSearchVideoResult\n            from pyjom.mathlib import checkMinMaxDict\n            def updateMyLists(\n                videoMetadata,\n                duration_limit={\"min\": 70, \"max\": 5 * 60},\n                titleLengthLimit={\"min\": 7, \"max\": 17},\n                play_limit={\"min\": 10000},\n                debugTag=\"debug\",\n            ):\n                nonlocal bvid_list, bgm_list, title_list, tag_list, cover_list, bvid_list, description_list, static_core_topic_list  # use nonlocal instead in nested functions.",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:225-252"
    },
    "1465": {
        "file_id": 129,
        "content": "The code searches for video results on Bilibili based on specified criteria and uses the search result to update local lists of videos, titles, tags, covers, descriptions, and static core topics. It checks duration limits, title length limits, play counts, and debugs if needed.",
        "type": "comment"
    },
    "1466": {
        "file_id": 129,
        "content": "                (\n                    author,\n                    author_id,\n                    bvid,\n                    tags,\n                    categoryId,\n                    categoryName,\n                    title,\n                    duration_seconds,\n                    play,\n                    cover,\n                    description,\n                    links_in_description,\n                    bgms,\n                    title_tags,\n                    pubdate,\n                ) = videoMetadata\n                # print(\"VIDEO_METADATA\",videoMetadata)\n                # breakpoint()\n                if not checkMinMaxDict(len(title), titleLengthLimit):\n                    return\n                if not filterTitleWithCoreTopicSet(title, static_core_topic_list):\n                    return\n                if len(tags) > 0:\n                    tagContainStaticCoreTopicFlags = [\n                        int(filterTitleWithCoreTopicSet(tag, static_core_topic_list))\n                        for tag in tags\n                    ]",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:253-280"
    },
    "1467": {
        "file_id": 129,
        "content": "This code extracts video metadata such as author, duration, title, and tags. It checks the length of the title against a limit and filters it for any static core topic. If the tag contains a static core topic, it creates a boolean flag for each tag. The function then returns the extracted metadata and flag list.",
        "type": "comment"
    },
    "1468": {
        "file_id": 129,
        "content": "                    mTagFlag = sum(tagContainStaticCoreTopicFlags) > 0\n                    if not mTagFlag:\n                        return\n                else:\n                    return\n                if duration_seconds == None:\n                    print(debugTag, \"VIDEO_METADATA\", videoMetadata)\n                    breakpoint()\n                elif play == None:\n                    print(debugTag, \"VIDEO_METADATA\", videoMetadata)\n                    breakpoint()\n                if len(bgms) > 0:\n                    bgm_list += bgms\n                try:\n                    if checkMinMaxDict(duration_seconds, duration_limit):\n                        if checkMinMaxDict(play, play_limit):\n                            bvid_list += [bvid]\n                            cover_list += [cover]\n                            title_list += [title]  # this for topic modeling?\n                            if description not in [\"\", None]:\n                                description_list += [description]\n                            if len(tags) > 0:",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:281-302"
    },
    "1469": {
        "file_id": 129,
        "content": "This code checks if a video's metadata contains certain elements and whether they meet specific duration and play limits. If the video meets these criteria, it adds it to a list of bvids for further processing. It also handles potential errors by printing a debug message and breaking the execution. The title is added to a list for topic modeling purposes.",
        "type": "comment"
    },
    "1470": {
        "file_id": 129,
        "content": "                                tag_list += [\n                                    tags\n                                ]  # are you sure? this will make the tag_list into different shape!\n                except:\n                    traceError()\n                    breakpoint()\n            def updateMyListsWithIterable(\n                iterable,\n                duration_limit={\"min\": 70, \"max\": 5 * 60},\n                play_limit={\"min\": 10000},\n                titleLengthLimit={\"min\": 7, \"max\": 17},\n                debugTag=\"debug\",\n            ):\n                for videoMetadata in iterable:\n                    updateMyLists(\n                        videoMetadata,\n                        duration_limit=duration_limit,\n                        play_limit=play_limit,\n                        titleLengthLimit=titleLengthLimit,\n                        debugTag=debugTag,\n                    )\n            updateMyListsWithIterable(\n                parseSearchVideoResult(result),\n                duration_limit=duration_limit,",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:303-328"
    },
    "1471": {
        "file_id": 129,
        "content": "The code defines a function updateMyListsWithIterable that takes an iterable of videoMetadata and applies the updateMyLists function to each element while applying duration, play, and title length limits. The parseSearchVideoResult is called with result and passed as an argument to updateMyListsWithIterable along with other parameters.",
        "type": "comment"
    },
    "1472": {
        "file_id": 129,
        "content": "                play_limit=play_limit,\n                titleLengthLimit=titleLengthLimit,\n                debugTag=\"searchVideoResult\",\n            )\n            # do the related video search?\n            if len(bvid_list) > 0:\n                # get video info!\n                from bilibili_api import video\n                bvid = random.choice(bvid_list)\n                v = video.Video(bvid=bvid)\n                videoInfo = sync(v.get_info())\n                from pyjom.platforms.bilibili.searchDataParser import parseVideoInfo\n                primaryVideoInfo, secondaryVideoInfoList = parseVideoInfo(videoInfo)\n                # for videoMetadata in secondaryVideoInfoList:\n                updateMyListsWithIterable(\n                    secondaryVideoInfoList, debugTag=\"secondaryVideoInfoList\"\n                )\n                # then we get related videos.\n                result = sync(v.get_related())\n                from pyjom.platforms.bilibili.searchDataParser import parseVideoRelated\n                # import json",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:329-353"
    },
    "1473": {
        "file_id": 129,
        "content": "Searching for a random Bilibili video and retrieving its information, then parsing the results to update the secondary video list and fetch related videos.",
        "type": "comment"
    },
    "1474": {
        "file_id": 129,
        "content": "                # print(json.dumps(result, indent=4, ensure_ascii=False))\n                # print('parsing related video info')\n                # breakpoint()\n                updateMyListsWithIterable(\n                    parseVideoRelated(result), debugTag=\"videoRelated\"\n                )\n            # now what do you want? suggested keywords?\n            suggested_queries = sync(\n                search.get_suggest_keywords(keyword=metatopicString)\n            )\n            if type(suggested_queries) != list:\n                suggested_queries = []\n            # now we need to collect the keywords.\n            # notice: we can only update this for selected topic like cat or dog. these keywords might not be shared.\n            topic_modeling_source_sentences = suggested_queries.copy()\n            for tags in tag_list:\n                sentence = \" \".join(tags)\n                topic_modeling_source_sentences.append(sentence)\n            for title in title_list:\n                topic_modeling_source_sentences.append(title)",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:355-377"
    },
    "1475": {
        "file_id": 129,
        "content": "The code is parsing video-related information, updating lists with iterable data, and collecting suggested keywords for a specific topic by joining tags and titles into sentences.",
        "type": "comment"
    },
    "1476": {
        "file_id": 129,
        "content": "            from pyjom.modules.topicGenerator.onlineTopicGenerator import (\n                topicModeling,\n                topicWordSelection,\n            )\n            topics = topicModeling(topic_modeling_source_sentences, lang=lang)\n            selectedWord = topicWordSelection(\n                topics, core_topic_set, selected_topic_list_dict[dog_or_cat]\n            )\n            dog_or_cat_original = dog_or_cat\n            dog_or_cat = randomTarget()\n            if selectedWord is not None:\n                keywords = \" \".join(\n                    [getKeywords[dog_or_cat](), selectedWord]\n                )  # for next iteration.\n                print(\"REFRESHING KEYWORDS:\", keywords)\n            else:\n                keywords = getKeywords[dog_or_cat]()\n            # print(selected_topic_list_dict)\n            # breakpoint()\n            filtered_title_list = filterTitleListWithCoreTopicSet(\n                title_list, static_core_topic_list\n            )  # could be enhabced with CLIP\n            filtered_description_list = filterTitleListWithCoreTopicSet(",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:379-404"
    },
    "1477": {
        "file_id": 129,
        "content": "This code imports topic generation and word selection functions, generates topics using the topicModeling function, selects a word from the generated topics, randomizes dog_or_cat variable, joins keywords with selectedWord for next iteration if not None, otherwise uses original getKeywords function, filters title list with core topic set, and possibly enhances description list filtering with CLIP.",
        "type": "comment"
    },
    "1478": {
        "file_id": 129,
        "content": "                description_list, static_core_topic_list\n            )\n            # filtered_title_list = filterTitleListWithCoreTopicSet(title_list, core_topic_set) # could be enhabced with CLIP\n            # store the bgm elsewhere?\n            # where? you store it where?\n            if bgmCacheSetName:  # no matter what you got to do this.\n                for item in bgm_list:\n                    addToRedisCachedSet(item, bgmCacheSetName)\n            if len(filtered_description_list) > 3:\n                if len(filtered_title_list) > 3:\n                    if len(cover_list) > 3:\n                        if len(tag_list) > 3:\n                            if len(bgm_list) > 3:\n                                # time to yield something.\n                                # detect this thing!\n                                # filtered_cover_list = []\n                                # this method needs to change. the cover_list.\n                                cover_target = getCoverTargetFromCoverList(\n                                    cover_list,",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:405-424"
    },
    "1479": {
        "file_id": 129,
        "content": "This code filters and processes various lists (title, description, cover, tag, and bgm) for a post. It checks the lengths of these lists and adds items to a Redis cached set if necessary. The code also calls other methods like `filterTitleListWithCoreTopicSet` and `getCoverTargetFromCoverList`.",
        "type": "comment"
    },
    "1480": {
        "file_id": 129,
        "content": "                                    dog_or_cat_original,  # this is the label of the selected metatopic. might be useful.\n                                )\n                                # this is a general thing.\n                                # r = requests.get(cover)\n                                # content = r.content\n                                # # corrupted or not?\n                                # image = cv2.imdecode(content, cv2.IMREAD_COLOR)\n                                # mCover = random.choice(filtered_cover_list) # what is this cover list?\n                                # mDescription = random.choice(filtered_description_list)\n                                mDescription = shuffleAndPopFromList(\n                                    filtered_description_list\n                                )\n                                if cover_target is not None:\n                                    # you want to pop these things?\n                                    # clearly a list of strings",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:425-439"
    },
    "1481": {
        "file_id": 129,
        "content": "The code is selecting a random cover and description from filtered lists for a post's metadata. It uses the requests library to fetch image content, cv2 to decode it, and shuffleAndPopFromList function to select elements from the filtered description list. The cover target could be used to filter these elements further.",
        "type": "comment"
    },
    "1482": {
        "file_id": 129,
        "content": "                                    mTagSeries = randomChoiceTagList(\n                                        tag_list, pop=True\n                                    )  # a collection of tags.\n                                    mTagSeries = [filterNonChineseOrEnglishOrJapaneseCharacters(tag) for tag in mTagSeries]\n                                    # mTitle = random.shuffle(filtered_title_list)\n                                    mTitle = shuffleAndPopFromList(filtered_title_list)\n                                    # mBgm = random.choice(bgm_list)\n                                    # really serious?\n                                    mBgm = shuffleAndPopFromList(bgm_list)\n                                    # you enable this paraphrase option here.\n                                    if customParaphraser:\n                                        mTitle = customParaphraser(mTitle)\n                                        mDescription = customParaphraser(mDescription)\n                              ",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:440-454"
    },
    "1483": {
        "file_id": 129,
        "content": "This code randomly selects tags, titles, and background music for a post, potentially applying paraphrasing to the title and description if a custom function is provided.",
        "type": "comment"
    },
    "1484": {
        "file_id": 129,
        "content": "      yield (cover_target, mTagSeries, filterNonChineseOrEnglishOrJapaneseCharacters(mTitle), mBgm, filterNonChineseOrEnglishOrJapaneseCharacters(mDescription), dog_or_cat_original, \n                                    target_tid\n                                    # search_tid\n                                    )  # one additional return value\n                                    # the search tid is not good.\n                                    # we must remove the generic tid.\n                                    clearMyLists()\n        except:\n            import time\n            time.sleep(sleepTime)\n            from lazero.utils.logger import traceError\n            traceError(\"error when fetching metatopic\")\ndef getBilibiliPostMetadataForDogCat(\n    dog_or_cat: Literal[\"dog\", \"cat\"] = \"dog\",\n    bgmCacheSetName=\"bilibili_cached_bgm_set\",\n    bgmCacheAutoPurge=False,\n    customParaphraser:Union[Callable, None]=None\n):\n    dynamics = [[\"可爱\", \"萌\", \"萌宠\"], [\"行为\", \"燃\"], [\"搞笑\", \"逗比\", \"魔性\"]]\n    cat_metatopic = {",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:454-478"
    },
    "1485": {
        "file_id": 129,
        "content": "This code defines a function `getBilibiliPostMetadataForDogCat` that fetches post metadata for bilibili posts related to dogs or cats. It takes parameters such as the type of animal, custom paraphraser, and more. The function handles potential errors by logging them and retrying after a sleep time if necessary. It also defines `dynamics`, which seems to represent different types of content for the metadata.",
        "type": "comment"
    },
    "1486": {
        "file_id": 129,
        "content": "        \"static\": [\n            [\"喵喵\", \"猫\", \"猫咪\", \"喵\"],\n        ],\n        \"dynamic\": dynamics,\n    }\n    dog_metatopic = {\n        \"static\": [\n            [\n                \"狗狗\",\n                \"狗\",\n                \"汪汪\",\n                \"修勾\",\n                \"汪\",\n                \"狗子\",\n            ],\n        ],\n        \"dynamic\": dynamics,\n    }\n    getMetatopic = {\n        \"dog\": dog_metatopic,\n        \"cat\": cat_metatopic,\n    }\n    # bullshit.\n    # must use subcategories.\n    getTids = {\n        \"dog\": [BSP.all.tids.动物圈.tid, BSP.all.tids.动物圈.汪星人],\n        \"cat\": [BSP.all.tids.动物圈.tid, BSP.all.tids.动物圈.喵星人],\n    }\n    genericTids = [BSP.all.tids.动物圈.tid] # these tids cannot be used for video posting.\n    ## then the decision.\n    getMetatopic = {\n        key: value for key, value in getMetatopic.items() if key == dog_or_cat\n    }\n    getTids = {key: value for key, value in getTids.items() if key == dog_or_cat}\n    return getBilibiliPostMetadata(  # this is a premature version. the deeplearning version might interest you more. but how the fuck i can integrate DL into this shit?",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:479-515"
    },
    "1487": {
        "file_id": 129,
        "content": "This code defines two metatopics, one for cats and one for dogs, and creates dictionaries to map \"dog\" and \"cat\" keys to their respective metatopics and tids. The tids are specific to the Bilibili platform and belong to the animal category. The code also includes a genericTids list that cannot be used for video posting. Finally, it filters the metatopic and tid dictionaries based on the \"dog_or_cat\" key before returning the BilibiliPostMetadata object.",
        "type": "comment"
    },
    "1488": {
        "file_id": 129,
        "content": "        getMetatopic=getMetatopic,\n        getTids=getTids,\n        getCoverTargetFromCoverList=getCoverTargetFromCoverListForDogCat,\n        bgmCacheSetName=bgmCacheSetName,\n        bgmCacheAutoPurge=bgmCacheAutoPurge,\n        customParaphraser = customParaphraser,\n        genericTids=genericTids # cannot used for upload tid specification.\n    )",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/postMetadata.py:516-523"
    },
    "1489": {
        "file_id": 129,
        "content": "Defining functions for retrieving metadata, handling TIDs, selecting a cover target, setting BGM cache parameters, and using a custom paraphraser. These will be used in the main function of this platform module. The genericTids cannot be used for upload tid specification.",
        "type": "comment"
    },
    "1490": {
        "file_id": 130,
        "content": "/pyjom/platforms/bilibili/database.py",
        "type": "filepath"
    },
    "1491": {
        "file_id": 130,
        "content": "The code is for a video recommendation program that uses text processing, SQLite database, BM25 algorithm, and hybrid search algorithms to retrieve Bilibili user videos, handle pagination, and update databases. It defines functions for video searching and refreshing status, interacts with a database, initializes a scheduler, creates tables, sets up FastAPI application, contains video search endpoints, retrieves video info from generators, schedules tasks, handles forms, registers videos on Bilibili platform, uses Uvicorn server, and runs bilibiliRecommendationServer function.",
        "type": "summary"
    },
    "1492": {
        "file_id": 130,
        "content": "from lazero.utils.json import jsonify\n# ellipsis = type(...)\n# serve my video, serve my cat video, dog video, set priority, serve others video\n# by means of query? or just directly ask me for it.\n# you'd better mimic the video that you have never recommend, and these audience have never seen before.\nimport time\n# utils.\ndef default(value, default_, isInstance=lambda v: v in [..., None]):\n    if isInstance(value):\n        return default_\n    return value\nimport datetime\nfrom typing import Union, Literal\nfrom functools import lru_cache\nimport random\n# you might want to add this to bilibili platform api, if there's no use of pyjom.commons\nfrom pyjom.platforms.bilibili.credentials import getCredentialByDedeUserId\nfrom pyjom.platforms.bilibili.utils import (\n    linkFixer,\n    videoDurationStringToSeconds,\n    clearHtmlTags,\n)\nfrom lazero.search.preprocessing import getFourVersionsOfProcessedLine\nimport jieba\nimport opencc\nimport jieba.analyse as ana\nimport progressbar\nimport pydantic\n@lru_cache(maxsize=4)\ndef getOpenCCConverter(converter_type: str = \"t2s\"):",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/database.py:1-43"
    },
    "1493": {
        "file_id": 130,
        "content": "This code appears to be a part of a larger program that deals with video recommendations and retrieval on the bilibili platform. It imports various libraries and functions, such as jieba for text processing, opencc for Chinese-to-simplified Chinese conversion, and pydantic for data validation. The getOpenCCConverter function is a memoized function that converts text using OpenCC's \"t2s\" type.",
        "type": "comment"
    },
    "1494": {
        "file_id": 130,
        "content": "    converter = opencc.OpenCC(converter_type)\n    return converter\ndef isChineseCharacter(char):\n    assert len(char) == 1\n    return char >= \"\\u4e00\" and char <= \"\\u9fff\"\ndef containChineseCharacters(text):\n    for char in text:\n        if isChineseCharacter(char):\n            return True\n    return False\nfrom lazero.utils.mathlib import extract_span\ndef textPreprocessing(text):\n    converter = getOpenCCConverter()\n    text = converter.convert(text)\n    (\n        final_line,\n        final_cutted_line,\n        final_stemmed_line,\n        final_cutted_stemmed_line,\n    ) = getFourVersionsOfProcessedLine(text)\n    # breakpoint()\n    wordlist = jieba.lcut(final_cutted_line)\n    final_wordlist = []\n    for w in wordlist:\n        word = w.strip()\n        if len(word) > 0:\n            final_wordlist.append(word)\n    flags = [int(containChineseCharacters(word)) for word in final_wordlist]\n    chineseSpans = extract_span(flags, target=1)\n    nonChineseSpans = extract_span(flags, target=0)\n    finalSpans = [(span, True) for span in chineseSpans] + [",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/database.py:44-82"
    },
    "1495": {
        "file_id": 130,
        "content": "This code snippet performs text preprocessing on a given text. It uses the OpenCC library to convert the text to simplified Chinese if needed, and then applies Jieba's jieba.lcut method for word segmentation. The resulting words are checked for their presence in the Chinese character range (u4e00-u9fff). Flags are created based on whether each word contains a Chinese character or not. The extract_span function is then used to identify spans of consecutive words with similar flags, which are assumed to be either Chinese or non-Chinese text.",
        "type": "comment"
    },
    "1496": {
        "file_id": 130,
        "content": "        (span, False) for span in nonChineseSpans\n    ]\n    finalSpans.sort(key=lambda span: span[0])\n    finalWordList = []\n    for span, isChineseSpan in finalSpans:\n        subWordList = final_wordlist[span[0] : span[1]]\n        subChars = \"\".join(subWordList)\n        subCharList = [c for c in subChars]  # 直接给你逐字切割了 说不定就有用了\n        if isChineseSpan:\n            subWordList = jieba.lcut_for_search(subChars)\n        finalWordList.extend(subWordList)\n        finalWordList.extend(subCharList)\n    return \" \".join(finalWordList)\nfrom nltk.corpus import stopwords\n@lru_cache(maxsize=1)\ndef getStopwords(languages: tuple = (\"chinese\", \"english\")):\n    stopword_list = []\n    for lang in languages:\n        stopword_list.extend(stopwords.words(lang))\n    return stopword_list\ndef keywordExtracting(\n    text,\n    method: Literal[\"tfidf\", \"random\"] = \"tfidf\",\n    languages: tuple = (\"chinese\", \"english\"),\n    topK: int = 5,\n):\n    # remove all stopwords.\n    keyword_list = textPreprocessing(text).split(\" \")\n    stopword_list = getStopwords(languages=languages)",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/database.py:83-117"
    },
    "1497": {
        "file_id": 130,
        "content": "This code performs text preprocessing and keyword extraction. It removes stopwords, utilizes a custom function for Chinese word segmentation, and implements TF-IDF or random selection of top keywords from the preprocessed text. It also stores commonly used stopwords in memory using LRU cache.",
        "type": "comment"
    },
    "1498": {
        "file_id": 130,
        "content": "    results = []\n    for k in keyword_list:\n        if k.lower() not in stopword_list:\n            results.append(k)\n    if method == \"random\":\n        random.shuffle(results)\n        return results[:topK]\n    elif method == \"tfidf\":\n        myText = \" \".join(results)\n        tags = ana.extract_tags(myText, topK=topK)\n        return tags\n    else:\n        raise Exception(\"Unknown keyword extraction method: %s\" % method)\n################################BILIBILI QUERY DATA MODELS######################\n# @reloading\nclass queryForm(pydantic.BaseModel):\n    query: str  # required?\n    page_size: Union[int, None] = None\n    page_num: int = 1\n    query_for_search_cached: Union[str, None] = None\n    # you are going to inherit this.\n    @property\n    def query_for_search(\n        self,\n    ):  # make sure the preprocessing is only called once. really?\n        if self.query_for_search_cached is None:\n            query = self.query\n            self.query_for_search_cached = textPreprocessing(query)\n        return self.query_for_search_cached",
        "type": "code",
        "location": "/pyjom/platforms/bilibili/database.py:118-151"
    },
    "1499": {
        "file_id": 130,
        "content": "This code performs keyword extraction based on the provided method. It filters out stopwords, shuffles results if using the \"random\" method, and uses TF-IDF for the \"tfidf\" method. The `queryForm` class is a Pydantic model for BiliBili query data models with properties for query, page size, page number, and cached preprocessed search query.",
        "type": "comment"
    }
}