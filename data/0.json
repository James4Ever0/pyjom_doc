{
    "0": {
        "file_id": 0,
        "content": "/README.en.md",
        "type": "filepath"
    },
    "1": {
        "file_id": 0,
        "content": "The code is a README for the \"pyjom\" project, providing an overview, installation instructions, and details on its top-down approach to create a Python content producer. It also includes information on contributing and using Gitee features with dependencies and Star History API integration for visualization.",
        "type": "summary"
    },
    "2": {
        "file_id": 0,
        "content": "# pyjom\n<p align=\"center\">\n    <a href=\"https://github.com/James4Ever0/pyjom\"><img alt=\"pyjom\" src=\"https://visitor-badge.glitch.me/badge?page_id=James4Ever0.pyjom\"></a>\n    <a href=\"https://github.com/James4Ever0/pyjom\"><img alt=\"pyjom\" src=\"https://img.shields.io/github/stars/James4Ever0/pyjom.svg\"></a>\n    <a href=\"https://github.com/James4Ever0/pyjom/releases\"><img alt=\"pyjom\" src=\"https://img.shields.io/github/release/James4Ever0/pyjom.svg\"></a>\n</p>\n#### Description\njerk off machine in python, or in other words, \"we media machine\", \"fully automated content producer\", \"the repeater\", \"the feedback loop\", \"retribution\"\n#### Software Architecture\nbased on top-down approach, this time we do not initiate the whole project from details since doing so will lose the grip on the infrastructure.\nwe try to build toy projects, toy modules in different folders. the whole thing shall be installable on pypi, avaliable to post to official pypi.org. not necessarily running on actual data yet.\n#### Installation",
        "type": "code",
        "location": "/README.en.md:1-17"
    },
    "3": {
        "file_id": 0,
        "content": "This code is a README for the \"pyjom\" project. It provides an overview of what the project does, its software architecture, and installation instructions. The project focuses on creating a content producer using Python, with a top-down approach to build modular components.",
        "type": "comment"
    },
    "4": {
        "file_id": 0,
        "content": "1.  git clone this project.\n2.  pip3 install pyjom\n3.  config the pyjom properly with cookies, passwords and so on.\n#### Instructions\n1.  pyjom requires several dependencies, shall be avaliable on all platforms.\n2.  xxxx\n3.  xxxx\n#### Contribution\n1.  Fork the repository\n2.  Create Feat_xxx branch\n3.  Commit your code\n4.  Create Pull Request\n#### Gitee Feature\n1.  You can use Readme\\_XXX.md to support different languages, such as Readme\\_en.md, Readme\\_zh.md\n2.  Gitee blog [blog.gitee.com](https://blog.gitee.com)\n3.  Explore open source project [https://gitee.com/explore](https://gitee.com/explore)\n4.  The most valuable open source project [GVP](https://gitee.com/gvp)\n5.  The manual of Gitee [https://gitee.com/help](https://gitee.com/help)\n6.  The most popular members  [https://gitee.com/gitee-stars/](https://gitee.com/gitee-stars/)\n## Star History\n<img src=\"https://api.star-history.com/svg?repos=james4ever0/pyjom&Timeline\" style=\"filter: invert(100%);\"></img>",
        "type": "code",
        "location": "/README.en.md:19-49"
    },
    "5": {
        "file_id": 0,
        "content": "The code contains instructions for setting up the project, contributing to it, and information about Gitee features. It requires dependencies, and shows a star history visualization using the Star History API.",
        "type": "comment"
    },
    "6": {
        "file_id": 1,
        "content": "/README.md",
        "type": "filepath"
    },
    "7": {
        "file_id": 1,
        "content": "The code represents the README.md file for the \"pyjom\" project, an automated content generation tool for media. It provides installation and usage instructions, integration plans with AI models like ChatGPT, related notes, GitHub repo link, readthedocs documentation, and mentions chaotic architecture possibly to be organized in the future. The README also includes links for donating via WeChat or Alipay and displays the author's star history.",
        "type": "summary"
    },
    "8": {
        "file_id": 1,
        "content": "# pyjom\n<p align=\"center\">\n    <a href=\"https://github.com/James4Ever0/pyjom\"><img alt=\"pyjom\" src=\"https://visitor-badge.glitch.me/badge?page_id=James4Ever0.pyjom\"></a>\n    <a href=\"https://github.com/James4Ever0/pyjom\"><img alt=\"pyjom\" src=\"https://img.shields.io/github/stars/James4Ever0/pyjom.svg\"></a>\n    <a href=\"https://github.com/James4Ever0/pyjom/releases\"><img alt=\"pyjom\" src=\"https://img.shields.io/github/release/James4Ever0/pyjom.svg\"></a>\n</p>\n[English version](./README.en.md)\n<p align=\"center\">\n  <a href=\"https://pyjom.readthedocs.io/en/latest/\">\n    <img src=\"https://tse4-mm.cn.bing.net/th/id/OIP-C.g0coL4omeFEhXvTh5rxedAHaKZ?pid=ImgDet&rs=1\" alt=\"pyjom\">\n  </a>\n</p>\n## 介绍\n自动化的自媒体内容制造机 自动运维自媒体 无人值守创作直播 全平台可运行 做一个有思想的复读机 有金饭碗的ebegger\n计划将ChatGPT类模型接入本项目 构造提示词集合 流水线式工作 (可以创建以前利用传统程序难以做到的事情 比如编写剧本 追踪视频来源 提取还原URL 反馈学习等等)\n## 文档\nreadthedocs 编写中 [文档地址](https://pyjom.readthedocs.io/en/latest/)\n## 我的笔记\n[杂乱的笔记](https://github.com/James4Ever0/notes) 有可能对你理解本项目有帮助\n## 软件架构\n本工程非常的乱 如果你能跑通 祝贺你\n自己以前写过很多有关于自媒体自动化的程序 不知道放到什么地方去了 可以的话会进行整理",
        "type": "code",
        "location": "/README.md:1-35"
    },
    "9": {
        "file_id": 1,
        "content": "This code represents the README.md file of the \"pyjom\" project, which is an automated content generation tool for media. It includes links to the GitHub repository and readthedocs documentation, as well as a brief introduction, plan to integrate ChatGPT-like models, and information about related notes. The code also mentions that the project architecture is chaotic and suggests it might be organized in the future.",
        "type": "comment"
    },
    "10": {
        "file_id": 1,
        "content": "以前还有一些关于AGI的代码 量化交易相关的 感兴趣自行查看\n## 安装教程\n1. pull下来本仓库\n2. 安装linux系统\n3. 安装python3\n4. 一切随缘\n## 使用说明\n1. 随便翻看目录 阅读代码并运行\n2. 看看我的笔记\n3. 看看相关的项目\n## 参与贡献\n1. Fork 本仓库\n2. 本地运行\n3. 提交代码\n4. 新建 Pull Request\n## 特技\n本人擅长到处聊天然后寻找灵感 毕竟没有灵感就没有代码 没有笔记\n据说投喂可以加快开发者写文档的速度 还有几率收到私发的女装照哦\n如果你想捐款 就投喂我吧~\n<table border=\"0\">\n  <tr>\n    <th>微信投喂</th>\n    <th>支付宝投喂</th>\n  </tr>\n  <tr>\n    <td><img width=\"100\" height=\"100\" src=\"https://api.qrserver.com/v1/create-qr-code/?size=300x300&data=wxp://f2f0V92qUQI0aBO5PXtWezujxMm-C1KFub6qCi1Obt3cn1KjZqDPqoWKn8ICCcwdt8zU\"></td>\n    <td><img width=\"100\" height=\"100\" src=\"https://api.qrserver.com/v1/create-qr-code/?size=300x300&data=https://qr.alipay.com/tsx10243tdewwaxrvullge8\"></td>\n  </tr>\n</table>\n## Star History\n<img src=\"https://api.star-history.com/svg?repos=james4ever0/pyjom&Timeline\" style=\"filter: invert(100%);\"></img>",
        "type": "code",
        "location": "/README.md:37-81"
    },
    "11": {
        "file_id": 1,
        "content": "This code is a README file for a Python project. It provides instructions on how to install and use the software, as well as information about contributing to the project. Additionally, it includes links for donating via WeChat or Alipay and displays the author's star history.",
        "type": "comment"
    },
    "12": {
        "file_id": 2,
        "content": "/symlinks/README.md",
        "type": "filepath"
    },
    "13": {
        "file_id": 2,
        "content": "This folder holds essential symlinks to crucial resources, ensuring efficient organization and access.",
        "type": "summary"
    },
    "14": {
        "file_id": 2,
        "content": "# this folder contains some important symlinks to my resources.",
        "type": "code",
        "location": "/symlinks/README.md:1-1"
    },
    "15": {
        "file_id": 2,
        "content": "This folder holds essential symlinks to crucial resources, ensuring efficient organization and access.",
        "type": "comment"
    },
    "16": {
        "file_id": 3,
        "content": "/tasks/README.md",
        "type": "filepath"
    },
    "17": {
        "file_id": 3,
        "content": "Code snippet describes the importance of having adequate actions for a project to avoid serious problems. It also mentions utilizing the entire project in practical ways, including the old AutoUP repo, to extract knowledge and data persistently.",
        "type": "summary"
    },
    "18": {
        "file_id": 3,
        "content": "Modules are good. Tests are good. In fact, everything could be good. But the shortage of actions will lead to serious problems.\nThis will make use of the entire project in every way, in practical manners, including the old AutoUP repo.\nThis will bring about the grit out of the project, running persistently to get practical knowledge/data.",
        "type": "code",
        "location": "/tasks/README.md:1-5"
    },
    "19": {
        "file_id": 3,
        "content": "Code snippet describes the importance of having adequate actions for a project to avoid serious problems. It also mentions utilizing the entire project in practical ways, including the old AutoUP repo, to extract knowledge and data persistently.",
        "type": "comment"
    },
    "20": {
        "file_id": 4,
        "content": "/tasks/qq/login_opq_arm64_another_account.sh",
        "type": "filepath"
    },
    "21": {
        "file_id": 4,
        "content": "The code initiates the login process on an ARM64 platform using Firefox browser. It navigates to a specific URL (localhost:8784/v1/Login/GetQRcode) and may require removing credential files for relogin.",
        "type": "summary"
    },
    "22": {
        "file_id": 4,
        "content": "# arm64\nfirefox http://localhost:8784/v1/Login/GetQRcode\n# if want to relogin must remove credential files. maybe it supports multi logins.",
        "type": "code",
        "location": "/tasks/qq/login_opq_arm64_another_account.sh:1-4"
    },
    "23": {
        "file_id": 4,
        "content": "The code initiates the login process on an ARM64 platform using Firefox browser. It navigates to a specific URL (localhost:8784/v1/Login/GetQRcode) and may require removing credential files for relogin.",
        "type": "comment"
    },
    "24": {
        "file_id": 5,
        "content": "/tasks/qq/login_opq_arm64.sh",
        "type": "filepath"
    },
    "25": {
        "file_id": 5,
        "content": "This code appears to be for an ARM64 system, likely running a Linux distribution. It launches Firefox and navigates it to a QR code login endpoint (localhost:8780/v1/Login/GetQRcode). It suggests that removing credential files may be necessary for relogin, possibly supporting multi-logins.",
        "type": "summary"
    },
    "26": {
        "file_id": 5,
        "content": "# arm64\nfirefox http://localhost:8780/v1/Login/GetQRcode\n# if want to relogin must remove credential files. maybe it supports multi logins.",
        "type": "code",
        "location": "/tasks/qq/login_opq_arm64.sh:1-4"
    },
    "27": {
        "file_id": 5,
        "content": "This code appears to be for an ARM64 system, likely running a Linux distribution. It launches Firefox and navigates it to a QR code login endpoint (localhost:8780/v1/Login/GetQRcode). It suggests that removing credential files may be necessary for relogin, possibly supporting multi-logins.",
        "type": "comment"
    },
    "28": {
        "file_id": 6,
        "content": "/tasks/qq/qq_red_packet_collect/deprecated_botoy_redpacket_collect_account_2.py",
        "type": "filepath"
    },
    "29": {
        "file_id": 6,
        "content": "This code is for the arm64 version of opqbot, disabling a 复读机 plugin and using the same config. It listens for group messages and processes red packet information, starting a daemon thread if a red packet is received.",
        "type": "summary"
    },
    "30": {
        "file_id": 6,
        "content": "# for arm64 version of opqbot\n# disable that 复读机 plugin.\n# disable this shit. we use the same config.\nfrom base_opq import *\n@bot.on_group_msg\ndef group(ctx: GroupMsg):\n    # print('收到群消息，群号为', ctx.FromGroupId)\n    data_dict = ctx.data  # recommend to use this json object. or not?\n    group_id = data_dict[\"FromGroupId\"]\n    RedBaginfo = data_dict[\"RedBaginfo\"]\n    if RedBaginfo is not None:\n        print(\"RECEIVED RED PACKET\")\n        startDaemonThread(openRedBag, (RedBaginfo, group_id))\n    # breakpoint()\nif __name__ == \"__main__\":\n    bot.run()\n# do not send porn shits or you need to relogin.",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/deprecated_botoy_redpacket_collect_account_2.py:1-26"
    },
    "31": {
        "file_id": 6,
        "content": "This code is for the arm64 version of opqbot, disabling a 复读机 plugin and using the same config. It listens for group messages and processes red packet information, starting a daemon thread if a red packet is received.",
        "type": "comment"
    },
    "32": {
        "file_id": 7,
        "content": "/tasks/qq/qq_red_packet_collect/commons.py",
        "type": "filepath"
    },
    "33": {
        "file_id": 7,
        "content": "The code has functions for replacing consecutive characters, checking a \"trace_source\" key, and improving sentence processing. It also handles text manipulation, generates weighted random yields, and shuffles elements if desired.",
        "type": "summary"
    },
    "34": {
        "file_id": 7,
        "content": "import random\nimport re\nfrom string import punctuation\nfrom base_opq import stderrPrint\ndef keywordDecorator(func, **kwargs2):\n    def mytarget(*margs, **kwargs):\n        if \"trace_source\" in kwargs.keys():\n            if kwargs2[\"trace_source\"]:\n                return func(*margs, **kwargs, **kwargs2), \".\".join(\n                    [__name__, func.__name__]\n                )\n        return func(*margs, **kwargs, **kwargs2)\n    return mytarget\ndef replaceDuplicateChar(sentence: str, char=\" \", maxRepeat: int = 3):\n    assert maxRepeat >= 0\n    source = char * (maxRepeat + 1)\n    target = char * maxRepeat\n    # c=0\n    while True:\n        # c+=1\n        # stderrPrint(\"RETRYING\",c)\n        if source in sentence:\n            # stderrPrint(len(source), len(target))\n            sentence = sentence.replace(source, target)\n        else:\n            break  # freaking important!\n    return sentence\ndef replaceDuplicateChars(sentence: str, maxRepeat: int = 3):\n    chars = set(list(sentence))\n    for char in chars:\n        sentence = replaceDuplicateChar(sentence, char, maxRepeat=maxRepeat)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/commons.py:1-38"
    },
    "35": {
        "file_id": 7,
        "content": "This code defines a function `replaceDuplicateChar` that replaces consecutive characters with the specified character and maximum repeats, and a function `replaceDuplicateChars` that applies this operation to all characters in the sentence. The code also includes a decorator `keywordDecorator` which checks if a \"trace_source\" key exists in the kwargs dictionary and performs an action accordingly.",
        "type": "comment"
    },
    "36": {
        "file_id": 7,
        "content": "    return sentence\n# this is not replaceDuplicateWords. this is removeDuplicateWords\n# don't know how to implement replaceDuplicateWords yet... use markov network? use CPM?\ndef removeDuplicateWords(sentence: str, removeWordLengthThreshold: int = 2):\n    # TODO: remove duplicate words inside, using jieba.\n    import jieba\n    wordList = jieba.lcut(sentence)\n    newWordList = []\n    for word in wordList:\n        if len(word) >= removeWordLengthThreshold:\n            if word in newWordList:\n                continue\n        newWordList.append(word)\n    # TODO: collect the candidateWordList from chat history.\n    # TODO: force replace mode: at least replace (n) words inside sentence\n    # TODO: mark words as replaceble by word type.\n    return \"\".join(newWordList)\ndef cutIncompleteSentenceTail(\n    sentence: str, threshold: int = len(\"这个群是我老公，你要是让我管管你老公\")\n):  # wtf?\n    if len(sentence) > threshold:\n        pun = \"，。……——“”‘’！； \" + punctuation  # with english space and puncs.\n        punList = list(set(list(pun)))",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/commons.py:39-66"
    },
    "37": {
        "file_id": 7,
        "content": "This code contains two functions: `removeDuplicateWords` and `cutIncompleteSentenceTail`. The first function aims to remove duplicate words from a sentence using the jieba library. It also mentions potential future improvements like collecting candidate word lists from chat history, replacing words based on their type, and enforcing a minimum number of replacements in the sentence. The second function is for cutting incomplete sentences that exceed a certain length threshold. It utilizes punctuation to separate the sentence into potentially complete segments. There are also mentions of potential improvements like collecting candidate word lists from chat history and replacing words based on their type.",
        "type": "comment"
    },
    "38": {
        "file_id": 7,
        "content": "        pattern = re.compile(\n            \"|\".join([re.escape(punctualChar) for punctualChar in punList])\n        )\n        resultList = re.split(pattern, sentence)\n        resultList = [x for x in resultList if len(x) > 0]\n        for index in range(\n            1, len(resultList)\n        ):  # will return first sentence nevertheless.\n            if pattern.match(resultList[-index]):  # suspected punctual element.\n                sentence = \"\".join(resultList)[:-index]\n                return sentence\n        sentence = resultList[0]  # failsafe.\n    return sentence\ndef generatedSentenceFixer(sentence, threshold=len(\"这个群是我老公，你要是让我管管你老公\"), maxRepeat=3):\n    sentence = replaceDuplicateChars(sentence, maxRepeat=maxRepeat)\n    sentence = cutIncompleteSentenceTail(sentence, threshold=threshold)\n    return sentence\ndef weightedRandomYielder(\n    elemList: list, elemWeights: list, shuffle=True, no_repeat=True, single=False\n):\n    assert len(elemList) >= 2\n    assert len(elemWeights) == len(elemList)\n    baseList = []",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/commons.py:67-93"
    },
    "39": {
        "file_id": 7,
        "content": "The code contains functions for manipulating text, specifically for cutting incomplete sentences and fixing generated sentences. It also includes a function to generate a weighted random yield from two lists of equal length.",
        "type": "comment"
    },
    "40": {
        "file_id": 7,
        "content": "    for elem, weight in zip(elemList, elemWeights):\n        assert weight > 0\n        assert type(weight) == int\n        baseList += [elem] * weight\n    if shuffle:\n        random.shuffle(baseList)\n    usedElem = []\n    for elem in baseList:\n        if single:\n            return elem\n        if not no_repeat:\n            yield elem\n        elif elem in usedElem:\n            continue\n        else:\n            usedElem.append(elem)\n            yield elem",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/commons.py:94-110"
    },
    "41": {
        "file_id": 7,
        "content": "Iterates through elements and their weights, adds elements to base list accordingly. If shuffle is True, randomizes the order of baseList. Iterates through baseList, yielding elements one at a time while handling non-repeating elements and avoiding repeats.",
        "type": "comment"
    },
    "42": {
        "file_id": 8,
        "content": "/tasks/qq/qq_red_packet_collect/chatApis.py",
        "type": "filepath"
    },
    "43": {
        "file_id": 8,
        "content": "The code utilizes libraries, chat functions for various APIs, and a function named `getChatApiReply` that selects an API, handles exceptions, logs errors, and returns responses.",
        "type": "summary"
    },
    "44": {
        "file_id": 8,
        "content": "import random\nimport urllib.parse\nimport requests\nfrom base_opq import getGroupNameFromDict\n# disable all proxies.\nimport os\nimport time\nos.environ[\"http_proxy\"] = \"\"\nos.environ[\"https_proxy\"] = \"\"\n# do not use freaking proxy, otherwise QingYunKe will not respond.\ndef checkApi(func, message, name):\n    response_message = func(message)\n    if response_message != None:\n        print(\"{} RESPONSE:\".format(name), response_message)\ndef chatAtri(\n    msg: str, group_id, retryFlag=False, timeout=5, BASE=\"http://api.nekomimi.icu/v1/\"\n):\n    url = BASE + \"chat?msg=%s\" % urllib.parse.quote(msg)\n    response = requests.get(url, timeout=timeout)\n    if response.status_code == 200:\n        data = response.json()\n        if data[\"status\"] == \"success\":\n            return data[\"message\"]\n    # return None\n    # nothing is returned if have error.\n    print(\"ATRI ERROR:\", response.status_code, response.json())\ndef chatGPT2Local(\n    msg: str, group_id, retryFlag=False, timeout=5, BASE=\"http://127.0.0.1:8729/\"\n):\n    # url = BASE + '?text=%s' % urllib.parse.quote(msg)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chatApis.py:1-39"
    },
    "45": {
        "file_id": 8,
        "content": "Code imports required libraries, disables proxies, and includes two chat functions (chatAtri and chatGPT2Local) for interacting with different APIs. chatAtri sends a message to the Atri API, while chatGPT2Local communicates with a local GPT-2 model through HTTP requests. Both return the response message if successful; otherwise, they print an error message.",
        "type": "comment"
    },
    "46": {
        "file_id": 8,
        "content": "    url = BASE\n    params = {\"text\": msg, \"retry\": retryFlag, \"group_id\": group_id}\n    response = requests.get(url, params=params)  # simply ignore timeout.\n    # response = requests.get(url, timeout=timeout, params = params)\n    if response.status_code == 200:\n        data = response.text\n        if len(data) > 0:\n            return data\n    # return None\n    # nothing is returned if have error.\n    print(\"GPT2LOCAL NO RESPONSE ERROR\")  # unknown error.\n# import subprocess\n# import json\ndef chatQingKeYun(\n    msg: str,\n    group_id,\n    retryFlag=False,\n    timeout=5,\n    url=\"http://api.qingyunke.com/api.php?key=free&appid=0&msg=\",\n):\n    msg = urllib.parse.quote(msg)\n    myUrl = url + msg\n    # print(myUrl)\n    # output = subprocess.check_output([\"curl\", myUrl])\n    # data = json.loads(output.decode(\"utf-8\"))\n    # import requests\n    data = requests.get(myUrl, timeout=timeout)\n    data = data.json()\n    print(data)\n    result = data[\"result\"]\n    assert result == 0  # 202 -> busy\n    content = data[\"content\"]\n    return content",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chatApis.py:40-76"
    },
    "47": {
        "file_id": 8,
        "content": "This function uses the QingKeYun API to process and return responses for a given message. It takes in parameters including the message text, group ID, retry flag, and timeout duration. The code handles potential errors, prints \"GPT2LOCAL NO RESPONSE ERROR\" when there is no response or an unknown error occurs.",
        "type": "comment"
    },
    "48": {
        "file_id": 8,
        "content": "    # breakpoint()\ndef chatOwnThink(msg: str, group_id, retryFlag=False, timeout=5):\n    url = \"https://api.ownthink.com/bot?appid=xiaosi&userid=user&spoken=\"\n    msg = urllib.parse.quote(msg)\n    myUrl = url + msg\n    data = requests.get(myUrl, timeout=timeout)\n    data = data.json()\n    # output = subprocess.check_output([\"curl\", myUrl])\n    # data = json.loads(output.decode(\"utf-8\"))\n    if data[\"message\"] == \"success\":\n        if data[\"data\"][\"type\"] == 5000:\n            return data[\"data\"][\"info\"][\"text\"]\n    # print(data)\n    # breakpoint()\n    # result = data['result']\n    # assert result == 0  # 202 -> busy\n    # content = data['content']\n    # return content\ndef chatXiaoIce(msg, group_id, retryFlag=False, timeout=5):\n    import requests\n    topic = getGroupNameFromDict(group_id)\n    if topic is None:\n        topic = \"aaa\"  # default topic. nothing.\n    r = requests.get(\n        \"http://localhost:8735/chat\",\n        params={\"topic\": topic, \"message\": msg},\n        timeout=timeout,\n    )\n    if r.status_code == 200:",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chatApis.py:77-111"
    },
    "49": {
        "file_id": 8,
        "content": "chatOwnThink and chatXiaoIce are two functions used to communicate with the ownthink.com API and local XiaoIce API, respectively. They both take a message as input, along with a group ID and optional retry flag and timeout values. If the request is successful, the function returns the text response from the API. The code also contains comments for potential future implementation of error handling, assertion checks, and content retrieval.",
        "type": "comment"
    },
    "50": {
        "file_id": 8,
        "content": "        try:\n            content = r.json()\n            assert content[\"msg\"] == \"success\"\n            reply = content[\"reply\"]\n            return reply\n        except:\n            from lazero.utils.logger import traceError\n            traceError(\"xiaoice client error\")\n    else:\n        print(\"xiaoice client got abnormal response code:\", r.status_code)\n# changed. non_standard.\ndef getChatApiReply(\n    msg: str, group_id, chatApiIndex=0, retryFlag=False, timeout=15\n):  # 15 seconds of grace time.\n    # chatApis = [chatQingKeYun, chatAtri]\n    # blacklist chatOwnThink.\n    chatApis = [chatAtri, chatGPT2Local, chatXiaoIce]  # no random shit!\n    # chatApi = random.choice(chatApis)\n    chatApi = chatApis[chatApiIndex]\n    try:\n        reply = chatApi(msg, group_id, retryFlag=retryFlag, timeout=timeout)\n        # will be None anyway.\n        return reply\n    except:\n        pass",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chatApis.py:112-139"
    },
    "51": {
        "file_id": 8,
        "content": "This code defines a function `getChatApiReply` that selects a chat API from a list and tries to retrieve a response for the input message. If an exception occurs, it logs an error or returns None if the retry flag is set. The code also includes a try-except block to handle potential exceptions during the API request.",
        "type": "comment"
    },
    "52": {
        "file_id": 9,
        "content": "/tasks/qq/qq_red_packet_collect/chat_local.py",
        "type": "filepath"
    },
    "53": {
        "file_id": 9,
        "content": "The code uses the Jiagu library for sentiment analysis, stack management, and string comparison to handle duplicates in chat stacks, calculating differences between strings, and ranking messages based on Levenshtein distance and sentiment before either releasing or removing the selected message.",
        "type": "summary"
    },
    "54": {
        "file_id": 9,
        "content": "# local chatbot implemetation.\n# first, we need experimental data.\n# a unified stack for every group.\n# import this shit ahead of everything.\nimport Levenshtein\nimport jiagu\nimport random\nfrom base_opq import stderrPrint\ndef update_stack(stack, elem, stackSize=300, no_duplicate=True):\n    if no_duplicate:\n        # check for duplicates.\n        if stack == []:\n            duplicate = False\n        else:\n            duplicate = stack[-1] == elem\n        if duplicate:\n            return stack\n    stack += [elem]\n    length = len(stack)\n    return stack[max(0, length - stackSize) :]\ndef getSentiment(sentence):\n    flag, probability = jiagu.sentiment(sentence)\n    # the probability that flag is true.\n    return flag, probability\ndef getAbsSentiment(sentence):  # ignore positive or negative.\n    flag, probability = getSentiment(sentence)\n    return probability\ndef getLinearSentiment(sentence):\n    flag, probability = getSentiment(sentence)\n    if flag == \"negative\":\n        probability = -probability\n    return probability",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chat_local.py:1-41"
    },
    "55": {
        "file_id": 9,
        "content": "This code contains various functions for sentiment analysis and managing a stack. It imports necessary libraries, updates a stack without duplicates (if specified), determines the sentiment of a sentence using Jiagu, and calculates linear sentiment by reversing negative sentiment probability.",
        "type": "comment"
    },
    "56": {
        "file_id": 9,
        "content": "def compareDifference(sent_0, sent_1):\n    distance = Levenshtein.distance(sent_0, sent_1)\n    return distance\ndef getRatioDifference(sent_0, sent_1, reverse=False):\n    if reverse:\n        base_length = len(sent_1)\n    else:\n        base_length = len(sent_0)\n    distance = compareDifference(sent_0, sent_1)\n    return min(1, distance / base_length)\ndef getMinDifference(sent_0, sent_1):\n    reverse = False\n    if len(sent_0) < len(sent_1):\n        reverse = True\n    return getRatioDifference(sent_0, sent_1, reverse=reverse)\nchat_stack = {}\nhistoricalReplies = []  # should also be a stack.\nchat_stack_lock = False\ndef updateChatStack(group_id, message, stackSize=300, no_duplicate=True):\n    chat_stack[group_id] = update_stack(\n        chat_stack.get(group_id, []),\n        message,\n        stackSize=stackSize,\n        no_duplicate=no_duplicate,\n    )\ndef sampleChatStack(\n    originGroup: int, msg: str, min_corpus_size=100, sample_size=2000, originGroupCut=50\n):  # must exclude sent messages.\n    # assert min_corpus_size >= sample_size",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chat_local.py:44-84"
    },
    "57": {
        "file_id": 9,
        "content": "This code contains three functions: `compareDifference`, `getRatioDifference`, and `getMinDifference`. These functions calculate the difference between two strings by comparing their characters. The `updateChatStack` function updates a chat stack, ensuring no duplicate messages are included. The `sampleChatStack` function samples messages from the chat stack, excluding sent messages, for text generation.",
        "type": "comment"
    },
    "58": {
        "file_id": 9,
        "content": "    # do not do this\n    population = [\n        (group_id, max(0, len(chat_stack[group_id]) - 1))\n        for group_id in chat_stack.keys()\n        if group_id != originGroup\n    ]\n    # population_size = sum([x[1] for x in population]) # wrong.\n    population = [  # no need to check against the original group here.\n        # if (chat_stack[group_id][index] != msg or group_id != originGroup)\n        [\n            (group_id, index)\n            for index in range(group_msg_size)\n            if chat_stack[group_id][index + 1] not in historicalReplies\n        ]\n        for group_id, group_msg_size in population\n    ]  # allow other group with same message or same group with other message\n    originGroupLength = len(chat_stack[originGroup]) - 1\n    if originGroupLength > originGroupCut:\n        # THIS WAS BLOODY WRONG\n        # WAS MISPLACED.\n        population.append(\n            [\n                (originGroup, index)\n                for index in range(0, originGroupLength - originGroupCut)\n                if chat_stack[originGroup][index] != msg",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chat_local.py:85-110"
    },
    "59": {
        "file_id": 9,
        "content": "Creates a list of group IDs and corresponding message indexes excluding the original group and message. Excludes groups with same messages or other messages from the same group. Retrieves number of messages in the original group and if more than the cutoff, adds original group's messages except the current one to the population list.",
        "type": "comment"
    },
    "60": {
        "file_id": 9,
        "content": "            ]\n        )\n    population = [x for y in population for x in y]\n    population_size = len(population)\n    if population_size < min_corpus_size:\n        return []\n    sample_size = min(population_size, sample_size)\n    # it must equal.\n    sample = random.sample(population, sample_size)\n    return sample\ndef sentimentFilter(sentiment, threshold=0.85):\n    assert threshold > 0 and threshold < 1\n    # for too negative ones, we value it as 0.\n    if sentiment < -threshold or sentiment > threshold:\n        return 0\n    return abs(sentiment)\ndef getChatLocalResponse(\n    originGroup: int,\n    msg: str,\n    min_corpus_size=100,\n    sample_size=2000,\n    k_top=30,\n    originGroupCut=50,\n):\n    global chat_stack_lock\n    # assert min_corpus_size >= sample_size\n    if chat_stack_lock:\n        return  # do nothing. maybe another thread is holding the lock.\n    # must set a global lock.\n    chat_stack_lock = True\n    sample = sampleChatStack(\n        originGroup,\n        msg,\n        min_corpus_size=min_corpus_size,\n        sample_size=sample_size,",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chat_local.py:111-150"
    },
    "61": {
        "file_id": 9,
        "content": "This function, getChatLocalResponse, samples recent chat messages from a local stack for the given originGroup and message. It takes in parameters like min_corpus_size, sample_size, k_top, and originGroupCut. The function first checks if the global lock is set before proceeding to sample recent chat messages. If the lock is held by another thread, it returns without doing anything. Otherwise, it sets the global lock and calls the sampleChatStack function to get a list of recent chat messages that can be used for further analysis or processing.",
        "type": "comment"
    },
    "62": {
        "file_id": 9,
        "content": "        originGroupCut=originGroupCut,\n    )\n    if len(sample) == 0 or len(sample) != sample_size:  # no sample received.\n        chat_stack_lock = False  # release lock\n        return\n    # this sample must not be empty.\n    # rank by Levenshtein distance.\n    ranks = [\n        (getMinDifference(msg, chat_stack[group_id][gm_index]), index)\n        for index, (group_id, gm_index) in enumerate(sample)\n    ]\n    ranks.sort(key=lambda x: x[0])\n    selected_ranks = ranks[:k_top]\n    selected_ranks = [sample[index] for difference_score, index in selected_ranks]\n    # do we have to match the mood? like positive/negative -> positive/negative?\n    # increase the negativity?\n    # sentiment shall be next sentence.\n    selected_emotional_ranks = [\n        (getLinearSentiment(chat_stack[group_id][gm_index + 1]), index)\n        for index, (group_id, gm_index) in enumerate(selected_ranks)\n    ]\n    selected_emotional_ranks.sort(\n        key=lambda x: -sentimentFilter(x[0])\n    )  # select the extremes. do not select too extreme ones.",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chat_local.py:151-176"
    },
    "63": {
        "file_id": 9,
        "content": "This code is sampling messages from a chat stack, ranking them by Levenshtein distance, and then selecting the top k ranks based on that distance. It also considers the sentiment of the next message in the selection process. If there's no valid sample or if the sample size doesn't match the expected value, it releases the lock and returns without any action.",
        "type": "comment"
    },
    "64": {
        "file_id": 9,
        "content": "    mReplySentiment, mReplyIndex = selected_emotional_ranks[0]\n    mReply_group_id, mReply_gm_index = selected_ranks[mReplyIndex]\n    mReply = chat_stack[mReply_group_id][mReply_gm_index + 1]  # must plus one.\n    # before release lock we need to remove things from chat_stack and append things into historicalReplies(stack)\n    update_stack(historicalReplies, mReply)\n    # for _ in range(2):\n    #     del chat_stack[mReply_group_id][mReply_gm_index] # may cause problems. we might not delete this.\n    # discontinuality of message replies.\n    # you can somehow make the selected list immutable, into tuple.\n    chat_stack_lock = False\n    return mReply\n# must detect emotion level.\n# maybe do sampling on those stacks will help?\n# sample size must smaller tha population.",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/chat_local.py:177-194"
    },
    "65": {
        "file_id": 9,
        "content": "This code snippet selects a reply message from a chat_stack list, deletes the selected message from the stack, and updates a historicalReplies stack. The code intends to ensure message replies are immutable by removing them from the original list after selection, but this approach may cause issues.",
        "type": "comment"
    },
    "66": {
        "file_id": 10,
        "content": "/tasks/qq/qq_red_packet_collect/censorApis.py",
        "type": "filepath"
    },
    "67": {
        "file_id": 10,
        "content": "The code defines three functions for censoring replies based on sentiment analysis, including \"censorReply\", which sends a request to a censor API; \"censorReplyAbsSentiment\", which censors if the absolute sentiment score exceeds a certain threshold; and \"censorReplyLinearSentiment\", which censors if the linear sentiment score is below a certain level. However, there is an issue with the positive/negative flag for some sentences. The function also returns the original reply if the sentiment change after censoring is less than 0.5; otherwise, it returns the censored reply.",
        "type": "summary"
    },
    "68": {
        "file_id": 10,
        "content": "import requests\nfrom chat_local import getLinearSentiment, getAbsSentiment\ndef censorReply(reply, moderate=True):\n    url = \"http://127.0.0.1:8932/filter\"\n    response = requests.get(url, params={\"text\": reply, \"moderate\": moderate})\n    response = response.json()\n    reply = response[\"response\"]\n    return reply\ndef censorReplyAbsSentiment(\n    reply, moderate=True, sentiment_abs_level=0.6, censored_sentiment_threshold=0.8\n):\n    sentiment = getAbsSentiment(reply)\n    if sentiment > sentiment_abs_level:\n        reply = censorReply(reply)\n        censored_sentiment = getAbsSentiment(reply)\n        if censored_sentiment > censored_sentiment_threshold:\n            return None\n    return reply\n# however these sentiment based function will not work very well since the positive/negative flag is not working properly for sentence like \"操你妈\" -> (\"positive\", 0.8)\ndef censorReplyLinearSentiment(reply, moderate=True, sentiment_level=-0.9):\n    sentiment = getLinearSentiment(reply)\n    if sentiment < sentiment_level:\n        reply = censorReply(reply)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/censorApis.py:1-33"
    },
    "69": {
        "file_id": 10,
        "content": "This code defines three functions for censoring replies based on sentiment analysis. The \"censorReply\" function sends a request to a censor API, the \"censorReplyAbsSentiment\" function censors a reply if its absolute sentiment score is above a certain threshold, and the \"censorReplyLinearSentiment\" function censors a reply if its linear sentiment score is below a certain level. However, the positive/negative flag does not work properly for some sentences.",
        "type": "comment"
    },
    "70": {
        "file_id": 10,
        "content": "    return reply\ndef censorReplySentimentDelta(reply, moderate=True, sentiment_delta_level=0.5):\n    reply2 = censorReply(reply)\n    sentiment = getLinearSentiment(reply)\n    sentiment2 = getLinearSentiment(reply2)\n    sentiment_delta = sentiment2 - sentiment\n    if sentiment_delta < sentiment_delta_level:  # is that good?\n        return reply\n    else:\n        return reply2",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/censorApis.py:34-47"
    },
    "71": {
        "file_id": 10,
        "content": "This function censors a reply and returns the original reply if the sentiment change after censoring is less than 0.5; otherwise, it returns the censored reply.",
        "type": "comment"
    },
    "72": {
        "file_id": 11,
        "content": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py",
        "type": "filepath"
    },
    "73": {
        "file_id": 11,
        "content": "The code manages functions like ad sending, chat APIs, and sentiment analysis in opqbot. It ensures proper messaging practices by checking for banned words and repetition, schedules periodic message sending, sets up a weighted random reply yielder, monitors group chats, categorizes messages about cats and dogs, updates the database, manages ad counters and penalties, processes media messages, handles Chinese conversion, logs for GPT training, filters message types, writes chat cursor data, and manages red packets asynchronously.",
        "type": "summary"
    },
    "74": {
        "file_id": 11,
        "content": "# for arm64 version of opqbot\n# disable that 复读机 plugin.\nimport os\nos.environ['HTTP_PROXY'] = \"\"\nos.environ['HTTPS_PROXY'] = \"\"\n# shall you analyze the logs/redPacketLog_*.log to get topics from groups and individuals.\nfrom chat_local import *\nfrom adtools import sendCatOrDogAdToQQGroup, checkCatOrDog, makeCatOrDogConnections\nfrom chatApis import getChatApiReply\nfrom base_opq import *\nimport schedule\nfrom chat_local import getAbsSentiment\nfrom censorApis import censorReplyAbsSentiment\nfrom commons import (\n    weightedRandomYielder,\n    generatedSentenceFixer,\n    keywordDecorator,\n    removeDuplicateWords,\n    replaceDuplicateChar,\n)\nAD_INIT_COUNTER = 1\ngroupChatCursor = None\ngroupMsgSendStatus = {}\ngroupChatReplyHistory = []\ngroupNoReplyStack = {}  # 防止连续对一个群持续输出\n# qq群最多可以添加500个群 1500个好友 其中群可加的数量 = max(0,500 - 已加入群数量 - 好友数量)\n# 可以退出一些安静的群 不发红包的群 删除好友\n# action.getClusterInfo\n# \"\"\"获取当前集群信息\"\"\"\n# this is to get the current server running status. i suspect.\ndef groupMsgRepeater(msg: str, sentiment_threshold=0.7):\n    sentiment = getAbsSentiment(msg)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:1-45"
    },
    "75": {
        "file_id": 11,
        "content": "This code is for the arm64 version of opqbot, disabling the 复读机 plugin, and managing various functions like ad sending, chat APIs, base opq operations, sentiment analysis, censor replies, and more. It handles group messages, repeating them if necessary, while considering sentiment scores and maintaining a log for red packet collection.",
        "type": "comment"
    },
    "76": {
        "file_id": 11,
        "content": "    if sentiment > sentiment_threshold:\n        return msg\ndef checkGroupMsgSendStatus(group_id, decrease=True):\n    if group_id in groupMsgSendStatus.keys():\n        if decrease:\n            groupMsgSendStatus[group_id] -= 1  # the feedback shall be elsewhere.\n        if groupMsgSendStatus[group_id] <= 0:\n            del groupMsgSendStatus[group_id]\n            return True\n        else:\n            return False\n    return True\n# now async.\n@asyncThread\ndef sendBotGroupTextMsg(\n    replyGetterYielder,\n    groupBannedErrorBuffer=100,  # 被禁言之后的buffer\n    retry=3,\n    min_reply_length=3,  # some impirical value.\n    delay_time_range=(5, 15),\n    context_size_range=(1, 3),  # maybe we do not need no context. or not?\n    maxRepeatRange=(2, 5),\n    noReplyThreshold=3,\n    noReplyBuffer=75,\n):  # the context parameter may lead to OOM.\n    global groupChatCursor\n    # will clear cursor after sending\n    if groupChatCursor is not None:\n        # do work here.\n        group_id = groupChatCursor[\"group_id\"]\n        # groupChatCursor = None",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:46-80"
    },
    "77": {
        "file_id": 11,
        "content": "This function, when called with a replyGetterYielder object and other parameters such as groupBannedErrorBuffer, retry, delay_time_range, context_size_range, maxRepeatRange, noReplyThreshold, and noReplyBuffer, sends a message to a QQ group chat using an async thread. It also manages the groupMsgSendStatus dictionary to keep track of the number of messages sent to each group. The function checks if the group is currently banned or not, retries sending the message a certain number of times if necessary, and adjusts the send status accordingly.",
        "type": "comment"
    },
    "78": {
        "file_id": 11,
        "content": "        # return\n        result = checkGroupMsgSendStatus(group_id, decrease=False)  # failsafe.\n        if not result:\n            return\n        # modify this textMessage somehow? with context.\n        context = random.randint(*context_size_range)\n        textMessage = groupChatCursor[\"msg\"]\n        groupChatCursorWithContext = groupChatCursor.copy()\n        messageContext = chat_stack[group_id][-context:-1] + [\n            textMessage\n        ]  # include the last message.\n        messageContext = \" \".join(messageContext)  # just use space.\n        groupChatCursorWithContext[\"msg\"] = messageContext\n        for (\n            replyGetter,\n            argumentList,\n            flag,\n            needContext,\n            enableRetryFlag,\n        ) in replyGetterYielder:  # use all methods.\n            if exit_event.is_set():\n                break\n            retried = False\n            for _ in range(retry):  # retry for three times.\n                if exit_event.is_set():\n                    break\n                extraFlags = {}",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:81-109"
    },
    "79": {
        "file_id": 11,
        "content": "The code checks if the group message sending status is successful, then sets a context size range and uses it to construct a new text message. It joins all messages together with spaces and assigns the new message to the group chat cursor. Finally, it loops through multiple reply getters, trying them in order, with a maximum of three retries if the event is not set.",
        "type": "comment"
    },
    "80": {
        "file_id": 11,
        "content": "                if enableRetryFlag:\n                    extraFlags.update({\"retryFlag\": retried})\n                # stderrPrint(extraFlags,replyGetter)\n                if needContext:\n                    reply = replyGetter(\n                        *[groupChatCursorWithContext[key] for key in argumentList],\n                        **extraFlags\n                    )\n                else:\n                    reply = replyGetter(\n                        *[groupChatCursor[key] for key in argumentList], **extraFlags\n                    )\n                if reply is not None:\n                    retried = True  # only plus one on retryIndex when there is no error during generation.\n                    maxRepeat = random.randint(*maxRepeatRange)\n                    reply = generatedSentenceFixer(\n                        reply, maxRepeat=maxRepeat\n                    )  # fix this reply first.\n                    # add a new filter here.\n                    reply = removeDuplicateWords(reply)\n                    if reply in groupChatReplyHistory or len(reply) < min_reply_length:",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:110-132"
    },
    "81": {
        "file_id": 11,
        "content": "This code block retrieves a reply from a replyGetter function, depending on whether context is needed or not. If the reply is not None, it updates retryFlag and generates a new random maxRepeat value for generatedSentenceFixer to fix the reply. The reply is then passed through removeDuplicateWords filter before checking if it's already in groupChatReplyHistory or shorter than min_reply_length.",
        "type": "comment"
    },
    "82": {
        "file_id": 11,
        "content": "                        continue  # do not send repeated messages or unusually short messages.\n                    else:\n                        update_stack(groupChatReplyHistory, reply)\n                    # 句子里面不能有违禁词语 不然就不能输出\n                    reply = censorReplyAbsSentiment(reply)\n                    if reply is None:\n                        continue  # skip too vulgar sentences.\n                    if reply.count(\"*\") > 3:  # too much censor will make it unreadable.\n                        continue  # retry to get a better thing.\n                    # do reply.\n                    # stderrPrint(\"PROCESSING GROUP MESSAGE CURSOR:\", groupChatCursor)\n                    stderrPrint(flag, reply)\n                    # must control this shit. 如果被禁言了该如何处理 一般需要缓冲30次\n                    groupChatCursor = None  # remove it only one reply was to be made.\n                    delay = random.randint(*delay_time_range)\n                    time.sleep(delay)  # to make it more humane.\n                    sendMessageStatus = action.sendGroupText(",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:133-152"
    },
    "83": {
        "file_id": 11,
        "content": "Code checks if the message contains banned words, censors them if necessary, and ensures messages are not too short or repeated. If a suitable reply is found, it sends the message after a random delay to avoid flooding and make it appear more human-like.",
        "type": "comment"
    },
    "84": {
        "file_id": 11,
        "content": "                        group=group_id, content=reply\n                    )\n                    # stderrPrint(\"SENT MESSAGE STATUS:\",sendMessageStatus)\n                    if not (\n                        sendMessageStatus[\"ErrMsg\"] == \"\"\n                        and sendMessageStatus[\"Ret\"] == 0\n                    ):\n                        # some shit had happened. cannot send message without error.\n                        groupMsgSendStatus.update({group_id: groupBannedErrorBuffer})\n                    else:\n                        # no shit happened.\n                        groupNoReplyStack.update(\n                            {group_id: 1 + groupNoReplyStack.get(group_id, 0)}\n                        )\n                        # stderrPrint(\"UPDATE NOREPLYSTACK\", groupNoReplyStack)\n                        noReply = groupNoReplyStack.get(group_id, 0)\n                        if (\n                            noReply >= noReplyThreshold\n                        ):  # only this noReply greater than 0 we can write it to cursor. LOGIC ELSEWHERE",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:153-172"
    },
    "85": {
        "file_id": 11,
        "content": "Code snippet handles sending messages to a group using the 'sendMessageStatus' response. If an error occurs (non-empty 'ErrMsg' or non-zero 'Ret'), the group is marked as banned. If no errors, the count of unsent messages is incremented for that group. If the count exceeds a threshold, it can be written to the cursor.",
        "type": "comment"
    },
    "86": {
        "file_id": 11,
        "content": "                            groupNoReplyStack.update({group_id: -noReplyBuffer})\n                    # stderrPrint(\"sendMessageStatus:\", sendMessageStatus)\n                    return True\ndef sendRandomGroupMessage():\n    sendAtriGroupChatMessage = (\n        keywordDecorator(getChatApiReply, chatApiIndex=0),\n        [\"msg\", \"group_id\"],\n        \"SENDING ATRI API REPLY:\",\n        True,\n        True,\n    )  # last is enableRetryFlag\n    sendGPT2GroupChatMessage = (\n        keywordDecorator(getChatApiReply, chatApiIndex=1),\n        [\"msg\", \"group_id\"],\n        \"SENDING GPT2 API REPLY:\",\n        True,\n        True,\n    )  # last is enableRetryFlag\n    sendXiaoIceGroupChatMessage = (\n        keywordDecorator(getChatApiReply, chatApiIndex=2),\n        [\"msg\", \"group_id\"],\n        \"SENDING XIAOICE API REPLY:\",\n        True,\n        True,\n    )\n    sendChatLocalResponse = (\n        getChatLocalResponse,\n        [\"group_id\", \"msg\"],\n        \"SENDING CHATLOCAL REPLY:\",\n        False,\n        False,\n    )\n    sendRepeaterResponse = (",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:173-209"
    },
    "87": {
        "file_id": 11,
        "content": "This code defines four different functions for sending messages to a group chat: `sendAtriGroupChatMessage`, `sendGPT2GroupChatMessage`, `sendXiaoIceGroupChatMessage`, and `sendChatLocalResponse`. Each function takes a \"group_id\" and a \"msg\", and has a specific label indicating the source of the message. The last parameter in each tuple indicates whether to retry sending if an error occurs.",
        "type": "comment"
    },
    "88": {
        "file_id": 11,
        "content": "        groupMsgRepeater,\n        [\"msg\"],\n        \"SENDING REPEATER REPLY:\",\n        False,\n        False,\n    )\n    replyGetterList = [\n        sendAtriGroupChatMessage,\n        sendGPT2GroupChatMessage,\n        sendChatLocalResponse,\n        sendRepeaterResponse,\n        sendXiaoIceGroupChatMessage,\n    ]\n    weightList = [2, 5, 1, 1, 5]\n    # weightList = [1, 3, 2, 2, 5] # said that is girish, because of xiaoice.\n    replyGetterYielder = weightedRandomYielder(replyGetterList, weightList)\n    sendBotGroupTextMsg(replyGetterYielder)\n# schedule.every(1).minute.do(sendApiGroupChatMessage)\n# schedule.every(30).seconds.do(sendChatLocalResponse) # will this shit work?\nschedule.every(1).minute.do(sendRandomGroupMessage)  # will this shit work?\ndef printGroupTextChatJson(group_id, sender_id, content):\n    message = {\"group_id\": group_id, \"sender_id\": sender_id, \"content\": content}\n    message = json.dumps(message, ensure_ascii=False)\n    stderrPrint(\n        \"[GROUP_TEXT_MESSAGE]\", message\n    )  # strange. who the fuck added this shit?",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:210-240"
    },
    "89": {
        "file_id": 11,
        "content": "This code is setting up a weighted random reply yielder for a group chat bot, with multiple reply options and weights. It also schedules a function to send a random group message periodically and prints group text chat messages in JSON format. The schedule functionality seems to have some uncertainty about its effectiveness.",
        "type": "comment"
    },
    "90": {
        "file_id": 11,
        "content": "# convert to simplified chinese.\nimport opencc\nchinese_t2s = opencc.OpenCC()\nadBuffer = {}\n# hook up this thing, send cat video only if we receive that topic.\nfrom adtools import checkIsCatOrDogImage\n@asyncThread\ndef catOrDogAsyncThread(group_id:str, sender_id:str,Content:str,is_image:bool=False, is_user:bool=False):\n    if is_image:\n        try:\n            cat_or_dog = checkIsCatOrDogImage(Content)\n        except:\n            import traceback\n            traceback.print_exc()\n            print(\"Exception when detecting image if it is cat or dog\")\n            return\n    else:\n        cat_or_dog = checkCatOrDog(Content)\n    # we need to update neo4j database, using group_id, sender_id, cat_or_dog.\n    if cat_or_dog:\n        makeCatOrDogConnections(\n            str(group_id), str(sender_id), cat_or_dog\n        )\n        # act accordingly. decide to send ad or not.\n        if adBuffer.get(str(group_id), 0) <= 0:\n            penalty = 10\n            # send the ad.\n            success = sendCatOrDogAdToQQGroup(str(group_id), cat_or_dog, action)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:243-274"
    },
    "91": {
        "file_id": 11,
        "content": "This code defines a function that checks whether the content sent in a QQ group is an image of a cat or dog. If it is, the function updates a Neo4j database and decides whether to send an ad based on a counter for each group. The code uses OpenCC library for text simplification and imports traceback module for error handling.",
        "type": "comment"
    },
    "92": {
        "file_id": 11,
        "content": "            if success:\n                penalty += 40 # every 50 messages we have one ad.\n            adBuffer[str(group_id)] = penalty\n        # decrease that counter by standard group messages.\nfrom botoy.collection import MsgTypes\n@bot.on_group_msg\ndef group(ctx: GroupMsg, groupInitReplyDelayRange=(4, 15)):\n    # too broad for groupInitReplyDelayRange to be (2, 20)\n    # global groupChatCursor\n    #    stderrPrint('收到群消息，群号为', ctx.FromGroupId)\n    # recommed you to check the curret group only.\n    #    stderrPrint(\"checkGroupNoReply:\",groupNoReplyStack.get(ctx.FromGroupId,None))\n    data_dict = ctx.data  # recommend to use this json object. or not?\n    groupName = data_dict.get(\"FromGroupName\", None)\n    group_id = data_dict[\"FromGroupId\"]\n    # decrease that ad counter.\n    adCounter = adBuffer.get(str(group_id), AD_INIT_COUNTER)\n    if adCounter > 0:\n        adCounter -= 1\n    adBuffer[str(group_id)] = adCounter\n    if groupName is not None:\n        updateGroupNameDict(groupName, group_id)\n    sender_id = data_dict[\"FromUserId\"]",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:275-301"
    },
    "93": {
        "file_id": 11,
        "content": "This code fragment monitors a group chat and manages ad counters based on the number of messages sent. For each message, it checks if a penalty should be added and updates an ad counter for the specific group ID. The ad counter is decreased with every standard group message received. It also updates the group name dictionary and handles user input data from messages sent to the group chat.",
        "type": "comment"
    },
    "94": {
        "file_id": 11,
        "content": "    RedBaginfoDict = data_dict[\"RedBaginfo\"]\n    RedBaginfo = ctx.RedBaginfo\n    MsgType = ctx.MsgType\n    # how to download these shits?\n    try:\n        from botoy.parser.group import Pic\n        if MsgType == MsgTypes.PicMsg:\n            pic_obj = Pic(**json.loads(ctx.Content))\n            pics = pic_obj.GroupPic\n            for pic in pics:\n                pic_url = pic.Url\n                catOrDogAsyncThread(str(group_id), str(sender_id),pic_url,is_image=True)\n        elif MsgType == MsgTypes.VideoMsg:\n            ...\n        elif MsgType == MsgTypes.VoiceMsg:\n            ...\n        elif MsgType == MsgTypes.JsonMsg:\n            ... # hope you can receive that? nope? you can only receive that by go-cqhttp.\n    except:\n        import traceback\n        traceback.print_exc()\n        print(\"ERROR WHEN PROCESSING MEDIA MESSAGES.\")\n        print(\"MSGTYPE:\",MsgType)\n    # first initialize random delay for every group in groupNoReplyStack\n    if group_id not in groupNoReplyStack.keys():\n        groupNoReplyStack.update({group_id: -random.randint(*groupInitReplyDelayRange)})",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:302-329"
    },
    "95": {
        "file_id": 11,
        "content": "This code is handling media messages (images, videos, voice) in a chat group. It tries to download images and may process videos or voice messages. If the message type is not recognized, it logs an error. The code also initializes random delay for a group's no-reply stack if the group ID isn't present.",
        "type": "comment"
    },
    "96": {
        "file_id": 11,
        "content": "    def writeGroupChatCursor(Content, enable_t2s=True):\n        if enable_t2s:\n            Content = chinese_t2s.convert(Content)\n        # content need to converted into simplified chinese.\n        global groupChatCursor, chat_stack_lock\n        # maybe we should create the mapping table here.\n        content_length = len(Content)\n        content_min_length = 4\n        # maybe we should split sentence into shorter ones, or via summarization/title generation apis.\n        content_max_length = 15\n        recv_content_min_length, recv_content_max_length = 4, 20\n        if not (Content.startswith(\"[\") or Content.endswith(\"]\")):\n            if (\n                content_length <= recv_content_max_length\n                and content_length >= recv_content_min_length\n            ):\n                printGroupTextChatJson(\n                    group_id, sender_id, Content\n                )  # why the fuck you are not printing?\n            if (\n                content_length <= content_max_length\n                and content_length >= content_min_length",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:331-352"
    },
    "97": {
        "file_id": 11,
        "content": "Function writes group chat cursor data to a file, with support for Chinese simplified to traditional conversion. The content length is checked against minimum and maximum thresholds before printing or potentially splitting into shorter segments.",
        "type": "comment"
    },
    "98": {
        "file_id": 11,
        "content": "            ):  # 新版qq之类的信息\n                # we log group chat text for gpt training here. shall we?\n                result = checkGroupMsgSendStatus(group_id)\n                if (\n                    result\n                ):  # will not write banned group to cursor since we will not reply it.\n                    noReply = groupNoReplyStack.get(group_id, 0)\n                    # stderrPrint(\"NOREPLYSTACK:\",groupNoReplyStack)\n                    if noReply >= 0:\n                        groupChatCursor = {\"group_id\": group_id, \"msg\": Content}\n                    else:\n                        groupNoReplyStack.update({group_id: noReply + 1})\n                # chat_stack update logic within the content length filter\n                if chat_stack_lock:\n                    # do not do anything about the chat_stack while locked.\n                    return\n                else:\n                    # check if we are hit by something interesting?\n                    catOrDogAsyncThread(group_id, sender_id, Content)",
        "type": "code",
        "location": "/tasks/qq/qq_red_packet_collect/botoy_redpacket_collect.py:353-373"
    },
    "99": {
        "file_id": 11,
        "content": "This code block handles QQ group chat messages and logs them for GPT training. It also manages a \"noReply\" counter for groups where the bot should not reply, and updates a chat_stack based on certain conditions. The chat_stack lock is checked to ensure no simultaneous updates are made. If interesting content is detected, it triggers a catOrDogAsyncThread function.",
        "type": "comment"
    }
}